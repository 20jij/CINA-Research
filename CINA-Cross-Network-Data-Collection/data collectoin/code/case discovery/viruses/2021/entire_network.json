{
    "https://github.com/mattupstate/flask-security": {
        "CVE Description": [
            "This affects all versions of package Flask-Security. When using the get_post_logout_redirect and get_post_login_redirect functions, it is possible to bypass URL validation and redirect a user to an arbitrary URL by providing multiple back slashes such as \\\\\\evil.com/path. This vulnerability is only exploitable if an alternative WSGI server other than Werkzeug is used, or the default behaviour of Werkzeug is modified using 'autocorrect_location_header=False. **Note:** Flask-Security is not maintained anymore."
        ],
        "Edges": [
            {
                "ParentSID": "17586473",
                "ParentRepo": "https://github.com/flask-admin/flask-admin",
                "StackOverflow_Post": {
                    "Id": "17586473",
                    "PostTypeId": "5",
                    "CreationDate": "2013-07-11T06:28:01.510",
                    "Score": "0",
                    "Body": "<p><code>Flask-Admin</code> is an advanced, extensible and simple to use 'administrative interface building' extension for the <code>Flask</code> framework.</p>\n\n<p>It comes with batteries included: model scaffolding for <code>SQLAlchemy</code>, <code>MongoEngine</code>, <code>pymongo</code> and <code>Peewee</code> ORMs, a simple file management interface and a lot of usage examples.</p>\n\n<p>You are not limited by the default functionality - instead of providing simple scaffolding for the ORM models, <code>Flask-Admin</code> provides tools that can be used to construct administrative interfaces of any complexity, using a consistent look and feel.</p>\n\n<p><strong>Documentation</strong>: <a href=\"https://flask-admin.readthedocs.io/en/latest/\" rel=\"nofollow noreferrer\">https://flask-admin.readthedocs.io/en/latest/</a></p>\n\n<p><strong>GitHub</strong>: <a href=\"https://github.com/flask-admin/flask-admin\" rel=\"nofollow noreferrer\">https://github.com/flask-admin/flask-admin</a></p>\n\n<p><strong>Issue tracker</strong>: <a href=\"https://github.com/flask-admin/flask-admin/issues\" rel=\"nofollow noreferrer\">https://github.com/flask-admin/flask-admin/issues</a></p>\n",
                    "OwnerUserId": "880326",
                    "LastEditorUserId": "1033581",
                    "LastEditDate": "2019-07-13T09:05:26.423",
                    "LastActivityDate": "2019-07-13T09:05:26.423",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "18442847",
                "ParentRepo": "https://github.com/mattupstate/overholt",
                "StackOverflow_Post": {
                    "Id": "18442847",
                    "PostTypeId": "2",
                    "ParentId": "9395587",
                    "CreationDate": "2013-08-26T11:17:18.850",
                    "Score": "19",
                    "Body": "<p><strong>Make sure to read</strong> Matt Wright's <a href=\"http://mattupstate.com/blog/how-i-structure-my-flask-applications/\" rel=\"noreferrer\"><strong><em>wonderful</em> post</strong></a> on the subject.</p>\n\n<p>The post features:</p>\n\n<ol>\n<li><p>A description of a structure for large flask projects</p></li>\n<li><p><a href=\"https://github.com/mattupstate/overholt\" rel=\"noreferrer\">An example application on Github</a></p></li>\n<li><p><strong>A description of best design practices in general</strong> when it comes to large web apps, like the MVC pattern, App factories, Services and Data Migration to name a few (most interesting feature IMHO).</p></li>\n</ol>\n",
                    "OwnerUserId": "2274357",
                    "LastEditorUserId": "383744",
                    "LastEditDate": "2016-05-09T04:17:03.170",
                    "LastActivityDate": "2016-05-09T04:17:03.170",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "20585497",
                "ParentRepo": "https://github.com/hansonkd/FlaskBootstrapSecurity",
                "StackOverflow_Post": {
                    "Id": "20585497",
                    "PostTypeId": "1",
                    "CreationDate": "2013-12-14T16:23:20.213",
                    "Score": "1",
                    "ViewCount": "294",
                    "Body": "<p>I'm using <a href=\"https://github.com/hansonkd/FlaskBootstrapSecurity\" rel=\"nofollow\">FlaskBootStrapSecurity project</a> which uses Flask Security. I have a situation where the flask.ext.security current_user has the same uuid for 2 users. </p>\n\n<p>For example,</p>\n\n<ol>\n<li>I log in with one user</li>\n<li>print  <code>current_user.uuid</code></li>\n<li>log out</li>\n<li>log in with a different user</li>\n<li>print <code>current_user.uuid</code></li>\n</ol>\n\n<p>and it is the same value for both  users.</p>\n\n<p>This occurs when I deploy to <code>nginx</code> but not when I run with <code>python manage.py runserver</code>.</p>\n",
                    "OwnerUserId": "865345",
                    "LastEditorUserId": "2425215",
                    "LastEditDate": "2013-12-14T16:24:27.020",
                    "LastActivityDate": "2013-12-14T16:24:27.020",
                    "Title": "flask-security - duplicate current_user.uuid values",
                    "Tags": "<python><flask-security>",
                    "AnswerCount": "0",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "20603311",
                "ParentRepo": "https://github.com/mattupstate/flask-social/issues/27",
                "StackOverflow_Post": {
                    "Id": "20603311",
                    "PostTypeId": "2",
                    "ParentId": "17998627",
                    "CreationDate": "2013-12-16T04:08:29.690",
                    "Score": "5",
                    "Body": "<p>This is doable without too much extra work using the <code>@login_failed.connect_via</code> decorator. With <code>app</code> as your instance of a Flask app, it would look like</p>\n\n<pre><code>@login_failed.connect_via(app):\ndef on_login_failed(sender, provider, oauth_response):\n    connection_values = get_connection_values_from_oauth_response(provider, oauth_response)\n    ds = current_app.security.datastore\n    user = ds.create_user( ... ) #fill in relevant stuff here\n    ds.commit()\n    connection_values['user_id'] = user.id\n    connect_handler(connection_values, provider)\n    login_user(user)\n    db.commit()\n    return render_template('success.html')\n</code></pre>\n\n<p>As for filling in the relevant stuff for creating the user, I just create a random string for the password, and haven't had issues leaving the email null. I also just included the exact same answer on the <a href=\"https://github.com/mattupstate/flask-social/issues/27\" rel=\"noreferrer\">Flask-Social github page</a>.</p>\n",
                    "OwnerUserId": "845071",
                    "LastActivityDate": "2013-12-16T04:08:29.690",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "21664997",
                "ParentRepo": "https://github.com/jrm2k6/gallezi",
                "StackOverflow_Post": {
                    "Id": "21664997",
                    "PostTypeId": "2",
                    "ParentId": "19387866",
                    "CreationDate": "2014-02-09T21:02:11.490",
                    "Score": "0",
                    "Body": "<p>For those interested, this solution didn't seem to work for me.\nWhat I did to fix it was to override the model view, and explicitely remove the column I didn't want (in this case, the one concerned by the <code>relationship</code> annotation).</p>\n\n<p>You can find my models.py and my overriden model views here: <a href=\"https://github.com/jrm2k6/gallezi\" rel=\"nofollow\">github repo</a> or in this <a href=\"https://gist.github.com/jrm2k6/8905880\" rel=\"nofollow\">gist</a></p>\n",
                    "OwnerUserId": "856942",
                    "LastActivityDate": "2014-02-09T21:02:11.490",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "30154774",
                "ParentRepo": "https://github.com/Netflix/security_monkey/issues/100",
                "StackOverflow_Post": {
                    "Id": "30154774",
                    "PostTypeId": "2",
                    "ParentId": "27308501",
                    "CreationDate": "2015-05-10T17:59:52.237",
                    "Score": "0",
                    "Body": "<p>It's still a problem with my environnement (macos + brew + code_transformers 0.2.3+2). Fixed with</p>\n\n<p><code>ln -s /usr/local/opt/dart/libexec /usr/local/opt/dart/libexec/bin/dart-sdk</code></p>\n\n<p>Edit: OR by using code_transformers 0.2.5 (see <a href=\"https://github.com/Netflix/security_monkey/issues/100\" rel=\"nofollow\">https://github.com/Netflix/security_monkey/issues/100</a>)</p>\n\n<p>I actually had to force it in pubspec.yaml :</p>\n\n<pre><code>dependency_overrides:\n  code_transformers: 0.2.5\n</code></pre>\n",
                    "OwnerUserId": "1420794",
                    "LastEditorUserId": "1420794",
                    "LastEditDate": "2015-05-10T18:09:30.463",
                    "LastActivityDate": "2015-05-10T18:09:30.463",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "31287446",
                "ParentRepo": "https://github.com/flask-admin/Flask-Admin/tree/master/examples/forms",
                "StackOverflow_Post": {
                    "Id": "31287446",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "31665630",
                    "CreationDate": "2015-07-08T08:34:14.713",
                    "Score": "2",
                    "ViewCount": "918",
                    "Body": "<p>I have created a web application using Flask, Flask-Admin and Flask-SQLAlchemy where the administrator can upload images. The image uploading functionality was imitated largely from <a href=\"https://github.com/flask-admin/Flask-Admin/tree/master/examples/forms\" rel=\"nofollow\">this Flask-Admin example</a>. For the production website, I use MySQL and uploading works perfectly fine. However, in the test suite I use a memory-mapped SQLite database and any attempt to upload an image through the same form fails with an <code>InterfaceError</code>. See <a href=\"https://gist.github.com/jgonggrijp/e09c3c2c558c16d2c2d5\" rel=\"nofollow\">this Gist</a> for the full details and a reduced test case.</p>\n\n<p>It seems like it might have something to do with type mapping, where the MySQL backend of SQLAlchemy appears to understand that the filename of the uploaded image must be inserted in the SQL statement while the SQLite backend does not. However, the Flask-Admin example that I linked to above works absolutely fine and it is based on SQLite, too.</p>\n\n<p>Who can tell me what is wrong, and what needs to be done to make the test pass?</p>\n\n<p><strong>Edit to add:</strong> it turned out the issue was already known by the Flask-Admin developers. See <a href=\"https://github.com/flask-admin/flask-admin/issues/890\" rel=\"nofollow\">ticket on GitHub</a>.</p>\n",
                    "OwnerUserId": "1166087",
                    "LastEditorUserId": "1166087",
                    "LastEditDate": "2015-07-29T07:36:46.750",
                    "LastActivityDate": "2015-07-29T07:36:46.750",
                    "Title": "Flask-Admin+SQLAlchemy image upload works in MySQL production env but not in SQLite testcase: InterfaceError",
                    "Tags": "<mysql><sqlite><file-upload><sqlalchemy><flask-admin>",
                    "AnswerCount": "1",
                    "CommentCount": "2",
                    "FavoriteCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "31808657",
                "ParentRepo": "https://github.com/cloudify-cosmo/cloudify-manager/blob/3.1-build/rest-service/manager_rest/blueprints_manager.py",
                "StackOverflow_Post": {
                    "Id": "31808657",
                    "PostTypeId": "2",
                    "ParentId": "31799811",
                    "CreationDate": "2015-08-04T11:54:52.593",
                    "Score": "0",
                    "Body": "<p>Looking at the error code that you can find here: <a href=\"https://github.com/cloudify-cosmo/cloudify-manager/blob/3.1-build/rest-service/manager_rest/blueprints_manager.py\" rel=\"nofollow\">https://github.com/cloudify-cosmo/cloudify-manager/blob/3.1-build/rest-service/manager_rest/blueprints_manager.py</a>\nThere could be several scenarios that you would get this error.\nIf for example you have deleted the deployment before running this workflow,or if you have stopped some of the services of the manager.</p>\n\n<p>I would try to recreate this deployment and execute the install workflow to see if it does reproduce.</p>\n",
                    "OwnerUserId": "2854238",
                    "LastActivityDate": "2015-08-04T11:54:52.593",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "34670444",
                "ParentRepo": "https://github.com/wooyek/flask-social-blueprint",
                "StackOverflow_Post": {
                    "Id": "34670444",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "34794806",
                    "CreationDate": "2016-01-08T05:59:24.537",
                    "Score": "2",
                    "ViewCount": "913",
                    "Body": "<p>I'm new to Flask blueprints, and I was wondering what the best practice is for implementing reusable blueprints such as <a href=\"https://github.com/wooyek/flask-social-blueprint\" rel=\"nofollow\">flask-social-blueprint</a> or <a href=\"https://github.com/brooksbrown/flask-users-blueprint\" rel=\"nofollow\">flask-users-blueprint</a>? Should I:</p>\n\n<ul>\n<li>copy-paste the code into my project and overwrite whatever I want to change, or</li>\n<li>import from the blueprint and then write overriding functions in a separate module?</li>\n</ul>\n\n<p>In other words, are blueprints meant to be boilerplate files that save you from typing, or are they like Flask \"extensions\"  and other Python modules to be imported without changing the original code?</p>\n",
                    "OwnerUserId": "1196444",
                    "LastActivityDate": "2016-01-14T16:32:42.427",
                    "Title": "Reusing Flask blueprints: extend or rewrite?",
                    "Tags": "<python><flask>",
                    "AnswerCount": "1",
                    "CommentCount": "4",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "36213748",
                "ParentRepo": "https://github.com/dgleba/flaskplayground/blob/master/201roles/auth/app.py",
                "StackOverflow_Post": {
                    "Id": "36213748",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "36222504",
                    "CreationDate": "2016-03-25T03:55:27.827",
                    "Score": "7",
                    "ViewCount": "11976",
                    "Body": "<p>I took the Flask-Admin auth example from <a href=\"https://github.com/flask-admin/flask-admin/tree/master/examples/auth\" rel=\"nofollow noreferrer\">here</a> and changed it slightly.</p>\n\n<p>I added the following block to the view below, but it doesn't show the export button. I was expecting it to add the export option to the admin views. It does print <code>---superuser</code> to the console.</p>\n\n<pre><code>        if current_user.has_role('superuser'):\n            can_export = True\n            print ' ---- superuser '\n</code></pre>\n\n<p>I have used the export feature many times before. It will work if I put the statement <code>can_export = True</code> just below <code>class MyModelView(sqla.ModelView):</code> I am using this as an example of controlling access to creating/editing/etc based on the user role. For example, I will want to have a readonly role where can_create=False, can_edit=False, etc.</p>\n\n<p>Can someone help? Can someone tell me what I am doing wrong?</p>\n\n<p>==</p>\n\n<p>This is the entire view.</p>\n\n<pre><code># Create customized model view class\nclass MyModelView(sqla.ModelView):\n\n    def is_accessible(self):\n        if not current_user.is_active or not current_user.is_authenticated:\n            return False\n\n        if current_user.has_role('superuser'):\n            return True\n\n        return False\n\n    def _handle_view(self, name, **kwargs):\n        \"\"\"\n        Override builtin _handle_view in order to redirect users when a view is not accessible.\n        \"\"\"\n        if current_user.has_role('superuser'):\n            can_export = True\n            print ' ---- superuser '\n\n        if not self.is_accessible():\n            if current_user.is_authenticated:\n                # permission denied\n                abort(403)\n            else:\n                # login\n                return redirect(url_for('security.login', next=request.url))\n</code></pre>\n\n<p>==</p>\n\n<p>For reference: I put the all the code <a href=\"https://github.com/dgleba/flaskplayground/blob/master/201roles/auth/app.py\" rel=\"nofollow noreferrer\">here</a>.</p>\n",
                    "OwnerUserId": "2744870",
                    "LastEditorUserId": "3329664",
                    "LastEditDate": "2017-11-23T11:30:50.100",
                    "LastActivityDate": "2019-09-18T06:30:16.920",
                    "Title": "Flask-Admin Role Based Access - Modify access based on role",
                    "Tags": "<python><flask><flask-admin>",
                    "AnswerCount": "2",
                    "CommentCount": "3",
                    "FavoriteCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "38643881",
                "ParentRepo": "https://github.com/Mozpacers/MozStar/",
                "StackOverflow_Post": {
                    "Id": "38643881",
                    "PostTypeId": "2",
                    "ParentId": "38641785",
                    "CreationDate": "2016-07-28T18:13:22.520",
                    "Score": "10",
                    "Body": "<p>From the documentation of CORS: <a href=\"http://flask-cors.corydolphin.com/en/latest/api.html?highlight=origin#flask_cors.cross_origin\" rel=\"nofollow noreferrer\">http://flask-cors.corydolphin.com/en/latest/api.html?highlight=origin#flask_cors.cross_origin</a></p>\n<pre class=\"lang-py prettyprint-override\"><code>flask_cors.cross_origin(*args, **kwargs)\n</code></pre>\n<blockquote>\n<p>The origin, or list of origins to allow requests from. The origin(s)\nmay be regular expressions, case-sensitive strings, or else an\nasterisk</p>\n</blockquote>\n<p>So, here you need to give <code>list</code> of <code>string</code>. Like:</p>\n<pre class=\"lang-py prettyprint-override\"><code>cross_origin([&quot;http://www.domain1.com&quot;, &quot;http://www.domain2.com&quot;]) \n</code></pre>\n<p>Notice here that you were giving all domain in a single string. But you needed to provide a list. Also notice that you provide Fully Qualified Domain Name (FQDN) as per <a href=\"https://www.rfc-editor.org/rfc/rfc6454#section-7.1\" rel=\"nofollow noreferrer\">RFC 6454</a> and <a href=\"https://www.w3.org/TR/cors/#access-control-allow-origin-response-header\" rel=\"nofollow noreferrer\">W3C Recommendation</a>.</p>\n<p>You can also do something like this:</p>\n<pre class=\"lang-py prettyprint-override\"><code>cors = CORS(app, resources={r&quot;/api/*&quot;: {&quot;origins&quot;: &quot;*&quot;}})\n</code></pre>\n<p>Here we're allowing every path in our app which starts with <code>/api</code>. Depending on your requirement, you can define appropriate path here. Here you can also specify origins to a list of domains you want to enable CORS for.</p>\n<p>Here is the link to the code I've written: <a href=\"https://github.com/Mozpacers/MozStar/\" rel=\"nofollow noreferrer\">https://github.com/Mozpacers/MozStar/</a></p>\n<p>CORS doesn't do anything special; you just need to reply to the request with a special header which says that <code>Access-Control-Allow-Origin</code> contains the domain request is coming from.</p>\n<p>For pre-flight requests, you can see how you can reply with custom headers with Flask before_request and after_request decorators: <a href=\"https://github.com/CuriousLearner/TrackMyLinks/blob/master/src/server/views.py#L130\" rel=\"nofollow noreferrer\">https://github.com/CuriousLearner/TrackMyLinks/blob/master/src/server/views.py#L130</a></p>\n",
                    "OwnerUserId": "3535547",
                    "LastEditorUserId": "-1",
                    "LastEditDate": "2021-10-07T08:14:10.917",
                    "LastActivityDate": "2019-07-19T14:18:48.430",
                    "CommentCount": "3",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "38643881",
                "ParentRepo": "https://github.com/CuriousLearner/TrackMyLinks/blob/master/src/server/views.py#L130",
                "StackOverflow_Post": {
                    "Id": "38643881",
                    "PostTypeId": "2",
                    "ParentId": "38641785",
                    "CreationDate": "2016-07-28T18:13:22.520",
                    "Score": "10",
                    "Body": "<p>From the documentation of CORS: <a href=\"http://flask-cors.corydolphin.com/en/latest/api.html?highlight=origin#flask_cors.cross_origin\" rel=\"nofollow noreferrer\">http://flask-cors.corydolphin.com/en/latest/api.html?highlight=origin#flask_cors.cross_origin</a></p>\n<pre class=\"lang-py prettyprint-override\"><code>flask_cors.cross_origin(*args, **kwargs)\n</code></pre>\n<blockquote>\n<p>The origin, or list of origins to allow requests from. The origin(s)\nmay be regular expressions, case-sensitive strings, or else an\nasterisk</p>\n</blockquote>\n<p>So, here you need to give <code>list</code> of <code>string</code>. Like:</p>\n<pre class=\"lang-py prettyprint-override\"><code>cross_origin([&quot;http://www.domain1.com&quot;, &quot;http://www.domain2.com&quot;]) \n</code></pre>\n<p>Notice here that you were giving all domain in a single string. But you needed to provide a list. Also notice that you provide Fully Qualified Domain Name (FQDN) as per <a href=\"https://www.rfc-editor.org/rfc/rfc6454#section-7.1\" rel=\"nofollow noreferrer\">RFC 6454</a> and <a href=\"https://www.w3.org/TR/cors/#access-control-allow-origin-response-header\" rel=\"nofollow noreferrer\">W3C Recommendation</a>.</p>\n<p>You can also do something like this:</p>\n<pre class=\"lang-py prettyprint-override\"><code>cors = CORS(app, resources={r&quot;/api/*&quot;: {&quot;origins&quot;: &quot;*&quot;}})\n</code></pre>\n<p>Here we're allowing every path in our app which starts with <code>/api</code>. Depending on your requirement, you can define appropriate path here. Here you can also specify origins to a list of domains you want to enable CORS for.</p>\n<p>Here is the link to the code I've written: <a href=\"https://github.com/Mozpacers/MozStar/\" rel=\"nofollow noreferrer\">https://github.com/Mozpacers/MozStar/</a></p>\n<p>CORS doesn't do anything special; you just need to reply to the request with a special header which says that <code>Access-Control-Allow-Origin</code> contains the domain request is coming from.</p>\n<p>For pre-flight requests, you can see how you can reply with custom headers with Flask before_request and after_request decorators: <a href=\"https://github.com/CuriousLearner/TrackMyLinks/blob/master/src/server/views.py#L130\" rel=\"nofollow noreferrer\">https://github.com/CuriousLearner/TrackMyLinks/blob/master/src/server/views.py#L130</a></p>\n",
                    "OwnerUserId": "3535547",
                    "LastEditorUserId": "-1",
                    "LastEditDate": "2021-10-07T08:14:10.917",
                    "LastActivityDate": "2019-07-19T14:18:48.430",
                    "CommentCount": "3",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "40553645",
                "ParentRepo": "https://github.com/graup/flask-restless-security",
                "StackOverflow_Post": {
                    "Id": "40553645",
                    "PostTypeId": "2",
                    "ParentId": "40553238",
                    "CreationDate": "2016-11-11T17:58:44.597",
                    "Score": "0",
                    "Body": "<p>I think especially for a scalable use I would use Flask-Restless together with Flask-JWT token authentication with token. </p>\n\n<p>Here is a pretty nice example > <a href=\"https://github.com/graup/flask-restless-security\" rel=\"nofollow noreferrer\">https://github.com/graup/flask-restless-security</a></p>\n\n<p>I am not sure I understand how you planning to authenticate without any user, or you just trying to lock app to use specific domain only? </p>\n",
                    "OwnerUserId": "2335820",
                    "LastActivityDate": "2016-11-11T17:58:44.597",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "43350806",
                "ParentRepo": "https://github.com/threatstream/mhn/wiki/Customizing-Maxmind-IP-Geo-DB-for-Internal-Networks",
                "StackOverflow_Post": {
                    "Id": "43350806",
                    "PostTypeId": "1",
                    "CreationDate": "2017-04-11T15:53:48.560",
                    "Score": "3",
                    "ViewCount": "3175",
                    "Body": "<p>How to create a custom Maxmind database with PRIVATE IPs address. </p>\n\n<p>I need something like this <a href=\"https://github.com/threatstream/mhn/wiki/Customizing-Maxmind-IP-Geo-DB-for-Internal-Networks\" rel=\"nofollow noreferrer\">Customizing Maxmind DB</a>.</p>\n\n<p>I tried to following this <a href=\"https://blog.maxmind.com/2015/09/29/building-your-own-mmdb-database-for-fun-and-profit/\" rel=\"nofollow noreferrer\">Building Your Own MMDB Database for Fun and Profit</a> . So I changed the PERL script to the following: </p>\n\n<pre><code>#!/usr/bin/env perl\n\nuse strict;\nuse warnings;\nuse feature qw( say );\n\nuse MaxMind::DB::Writer::Tree;\nuse Net::Works::Network;\n\nmy $filename = 'users.mmdb';\n\n# Your top level data structure will always be a map (hash).  The MMDB format\n# is strongly typed.  Describe your data types here.\n# See https://metacpan.org/pod/MaxMind::DB::Writer::Tree#DATA-TYPES\n\n\nmy %types = (\n    latitude =&gt; 'uint32',\n    longitude     =&gt; 'uint32',\n    city         =&gt; 'utf8_string',\n    country     =&gt; 'utf_string',\n);\n\nmy $tree = MaxMind::DB::Writer::Tree-&gt;new(\n\n    # \"database_type\" is some arbitrary string describing the database.  At\n    # MaxMind we use strings like 'GeoIP2-City', 'GeoIP2-Country', etc.\n    database_type =&gt; 'My-IP-Data',\n\n    # \"description\" is a hashref where the keys are language names and the\n    # values are descriptions of the database in that language.\n    description =&gt;\n        { en =&gt; 'My database of IP data', fr =&gt; q{Mon Data d'IP}, },\n\n    # \"ip_version\" can be either 4 or 6\n    ip_version =&gt; 4,\n\n    # add a callback to validate data going in to the database\n    map_key_type_callback =&gt; sub { $types{ $_[0] } },\n\n    # \"record_size\" is the record size in bits.  Either 24, 28 or 32.\n    record_size =&gt; 24,\n);\n\nmy %address_for_employee = (\n    '10.1.0.0/16' =&gt; {\n          latitude =&gt; -12.9608,\n        longitude      =&gt; 40.5078,\n        city         =&gt; 'Maputo',\n    country         =&gt; 'Mozambique',\n    },\n    '10.2.0.0/16' =&gt; {\n        latitude =&gt; -25.0519,\n        longitude      =&gt; 33.6442,\n        city         =&gt; 'Gaza',\n    country         =&gt; 'Mozambique',\n    },\n);\n\nfor my $address ( keys %address_for_employee ) {\n\n    # Create one network and insert it into our database\n    my $network = Net::Works::Network-&gt;new_from_string( string =&gt; $address );\n\n    $tree-&gt;insert_network( $network, $address_for_employee{$address} );\n}\n\n# Write the database to disk.\nopen my $fh, '&gt;:raw', $filename;\n$tree-&gt;write_tree( $fh );\nclose $fh;\n\nsay \"$filename has now been created\";\n</code></pre>\n\n<p>But no luck. \nNow Im getting the following error : \n<strong>Iteration is not currently allowed in trees with no nodes. Record type: empty at /usr/local/lib/perl/5.14.2/MaxMind/DB/Writer/Tree.pm line 292.</strong></p>\n\n<p>Can anybody help me creating a GEOIP2 DB with private ip address?</p>\n",
                    "OwnerUserId": "3631344",
                    "LastActivityDate": "2020-07-15T08:25:17.453",
                    "Title": "Custom MaxmindDB (geoip2) with Private IPs",
                    "Tags": "<perl><geoip><maxmind><geoip2>",
                    "AnswerCount": "2",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "45419927",
                "ParentRepo": "https://github.com/pjcunningham/flask-protected-resource",
                "StackOverflow_Post": {
                    "Id": "45419927",
                    "PostTypeId": "2",
                    "ParentId": "45390832",
                    "CreationDate": "2017-07-31T15:32:46.207",
                    "Score": "2",
                    "Body": "<p>Images/CSS/JS files are resources that can be protected in a similar manner to regular Flask views.</p>\n\n<p>Don't store and serve resources from under the <code>static</code> folder, instead store resources in a private location (Flask instance_paths could be used) and create routes that serves resources using <code>send_file</code>. </p>\n\n<p>The routes need to check if the <code>current_user</code> is authenticated and authorised (use roles for this). The routes also need to disable browser caching of the resource.</p>\n\n<p>A simple example (<code>@nocache</code> is a decorator that sets an appropriate response header):</p>\n\n<pre><code>@app.route('/resource/image/&lt;string:filename&gt;')\n@nocache\ndef resource_image(filename):\n\n    if not current_user.is_authenticated:\n        return '', 204\n\n    _image_path = get_instance_path('images', filename)\n\n    if not op.isfile(_image_path):\n        print \"Image not found : {}\".format(_image_path)\n        return '', 204\n\n    print \"Serving image : {}\".format(_image_path)\n\n    return send_file(_image_path)\n</code></pre>\n\n<p>The route would be used in a HTML template as follows:</p>\n\n<pre><code>&lt;p&gt;This is an unprotected page with a protected resource (image). If you are logged in you will see an image below.&lt;/p&gt;\n&lt;img src=\"{{ url_for('resource_image', filename='black.jpg') }}\"&gt;\n\n&lt;div style=\"padding:20px; height: 560px; width: 760px;background:url('{{ url_for('resource_image', filename='background.png') }}')\"&gt;\n    &lt;p&gt;If you are logged in you will see this paragraph is in a &lt;code&gt;div&lt;/code&gt; that has a protected &lt;code&gt;background:url&lt;/code&gt;&lt;/p&gt;\n&lt;/div&gt;\n</code></pre>\n\n<p>Full working example using Flask, Flask-Security and Flask-Alchemy on Github - <a href=\"https://github.com/pjcunningham/flask-protected-resource\" rel=\"nofollow noreferrer\">https://github.com/pjcunningham/flask-protected-resource</a></p>\n",
                    "OwnerUserId": "2800058",
                    "LastActivityDate": "2017-07-31T15:32:46.207",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "45726502",
                "ParentRepo": "https://github.com/stamaimer/ZhiFang/blob/master/app/models/__init__.py#L37",
                "StackOverflow_Post": {
                    "Id": "45726502",
                    "PostTypeId": "2",
                    "ParentId": "45726202",
                    "CreationDate": "2017-08-17T04:17:28.577",
                    "Score": "0",
                    "Body": "<p>You should use <code>relationship</code> from <code>SQLAlchemy</code> and modify your <code>to_json</code> to parse <code>relationship</code>.</p>\n\n<pre><code>class Post(db.Model):\n\n    # other fields\n\n    user = db.relationship(\"User\", foreign_keys=user_id)\n\n    @property\n    def json(self):\n\n        attrs = self.__mapper__.attrs.keys()\n\n        relationships = self.__mapper__.relationships.keys()\n\n        fields = [item for item in [attr for attr in attrs if attr not in relationships]]\n\n        container = {field: getattr(self, field) for field in fields}\n\n        for relationship in relationships:\n\n            related = getattr(self, relationship)\n\n            if related:\n\n                is_list = self.__mapper__.relationships[relationship].uselist\n\n                if is_list:\n\n                    container[relationship] = [record.to_dict(depth, include) for record in related]\n\n                else:\n\n                    container[relationship] = related.to_dict(depth, include)\n\n        return container\n</code></pre>\n\n<p>I moved <code>to_json</code> to <code>json</code>. You'd better have a base model class which has a <code>to_json</code> method which all subclass inherited from the base model class can have this method. There're some other question might be raise in the process convert instance of data model class. The <code>to_json</code> method which i provide is a simplify version of <a href=\"https://github.com/stamaimer/ZhiFang/blob/master/app/models/__init__.py#L37\" rel=\"nofollow noreferrer\"><code>to_dict</code></a>.</p>\n",
                    "OwnerUserId": "2714012",
                    "LastActivityDate": "2017-08-17T04:17:28.577",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "46811342",
                "ParentRepo": "https://github.com/damyanbogoev/flask-bookshelf/blob/master/bookshelf/config.py#L35-L39",
                "StackOverflow_Post": {
                    "Id": "46811342",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "46812202",
                    "CreationDate": "2017-10-18T13:27:48.040",
                    "Score": "0",
                    "ViewCount": "978",
                    "Body": "<p>I have a project where I defined a test configration in <code>config.py</code>, but I'm puzzled by the following:</p>\n\n<ol>\n<li><p>Many times there is a testing configuration for <code>config.py</code>\nbeing discussed in tutorials, like <a href=\"https://github.com/damyanbogoev/flask-bookshelf/blob/master/bookshelf/config.py#L35-L39\" rel=\"nofollow noreferrer\">this one</a></p></li>\n<li><p>Actual testing with database is usually done on application and database\ndefined in testclass (with or without Flask-Testing). This test setup does \nnot make use of testing configuration from <code>config.py</code></p>\n\n<p>See for example Flask-SQLAlchemy <a href=\"https://github.com/mitsuhiko/flask-sqlalchemy/blob/master/tests/conftest.py\" rel=\"nofollow noreferrer\">own test fixtures</a>\nor some of links listed <a href=\"https://github.com/mini-kep/db/issues/10#issuecomment-336132711\" rel=\"nofollow noreferrer\">here</a></p></li>\n</ol>\n\n<p>There is some advice about a test database being created specifically for the tests, eg from <a href=\"https://pythonhosted.org/Flask-Testing/#testing-with-sqlalchemy\" rel=\"nofollow noreferrer\">testing-with-sqlalchemy</a>:</p>\n\n<blockquote>\n  <p>First, ensure you set the database URI to something other than your production database ! Second, it\u2019s usually a good idea to create and drop your tables with each test run, to ensure clean tests</p>\n</blockquote>\n\n<p>There are no tutorials that say <strong>\"you do not need a testing configuration, do your test setup in your base test class\"</strong>. Is this something assumed? </p>\n\n<p>Tst configuration \nin <code>config.py</code> and explicit test setup in class - are they mutually exclusive?\nOr sometimes you combine the two?</p>\n\n<p>P.S. <a href=\"http://exploreflask.com/en/latest/configuration.html\" rel=\"nofollow noreferrer\">Here</a> is a list of project configurations without testing config. </p>\n",
                    "OwnerUserId": "1758363",
                    "LastEditorUserId": "1758363",
                    "LastEditDate": "2018-06-13T11:21:01.207",
                    "LastActivityDate": "2018-06-13T11:21:01.207",
                    "Title": "flask testing configuration in config.py vs. base test class",
                    "Tags": "<python><unit-testing><flask><flask-sqlalchemy><flask-testing>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "48719186",
                "ParentRepo": "https://github.com/stamaimer/flask-starter",
                "StackOverflow_Post": {
                    "Id": "48719186",
                    "PostTypeId": "2",
                    "ParentId": "48718768",
                    "CreationDate": "2018-02-10T09:23:05.320",
                    "Score": "1",
                    "Body": "<p>I think the best way is reorganize the structure of your project. Try to move the view functions to a separate package or module. You can follow the <a href=\"https://exploreflask.com/en/latest/organizing.html\" rel=\"nofollow noreferrer\">exploreflask</a> to organize your project. Or you can check my <a href=\"https://github.com/stamaimer/flask-starter\" rel=\"nofollow noreferrer\">common project structure</a> of Flask project.</p>\n",
                    "OwnerUserId": "2714012",
                    "LastActivityDate": "2018-02-10T09:23:05.320",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "48956932",
                "ParentRepo": "https://github.com/fbenavides69/control-escolar",
                "StackOverflow_Post": {
                    "Id": "48956932",
                    "PostTypeId": "1",
                    "CreationDate": "2018-02-23T22:09:42.750",
                    "Score": "0",
                    "ViewCount": "836",
                    "Body": "<p>I am using Flask-security and I have not been able to integrate Flask-bootstrap in order to customize the user interface of the login, register, and other pages.</p>\n\n<p>The project is hosted here:\n<a href=\"https://github.com/fbenavides69/control-escolar\" rel=\"nofollow noreferrer\">https://github.com/fbenavides69/control-escolar</a></p>\n\n<p>I have installed via pip the packages and can render the login, register and other pages, yet for some reason, I can not get them to render user bootstrap. I have followed the recommendations on c/p the security pages under the templates directory in the application, to override the look and feel, yet have not had any success.</p>\n\n<p>Can someone please point me to what I am missing?</p>\n\n<p>Here is the code for the login_user.html:</p>\n\n<pre><code>{% extends \"layout.html\" %}\n\n{% block body %}\n    {{super()}}\n\n    {% include \"navbar.html\" %}\n\n    {% block content %}\n        {{super()}}\n\n        {% from \"security/_macros.html\" import render_field_with_errors, render_field %}\n        {% from \"security/_form_macros.html\" import render_field %}\n        &lt;div class=\"container\"&gt;\n        {% include \"security/_messages.html\" %}\n        &lt;h1&gt;{{ _('Login') }}&lt;/h1&gt;\n        &lt;form action=\"{{ url_for_security('login') }}\" method=\"POST\" name=\"login_user_form\"&gt;\n          {{ login_user_form.hidden_tag() }}\n          {{ render_field_with_errors(login_user_form.email) }}\n          {{ render_field_with_errors(login_user_form.password) }}\n          {{ render_field_with_errors(login_user_form.remember) }}\n          {{ render_field(login_user_form.next) }}\n          {{ render_field(login_user_form.submit) }}\n        &lt;/form&gt;\n        {% include \"security/_menu.html\" %}\n        &lt;/div&gt;\n\n    {% endblock content %}\n\n{% endblock body %}\n</code></pre>\n\n<p>Here is the layout.html:</p>\n\n<pre><code>{% extends \"bootstrap/base.html\" %}\n\n{% block html_attribs %} \n    lang=\"sp\" \n{% endblock %}\n{% block metas %}\n    &lt;meta charset=\"utf-8\"&gt;\n{% endblock %}\n</code></pre>\n\n<p>Here is the file structure under which the templates are stored:</p>\n\n<pre><code>application\n+-site\n  +-templates\n    +-security\n      +- login_user.html\n      +- register_user.html\n</code></pre>\n\n<p>Here the code for the init file:</p>\n\n<pre><code>''' Flask Application Factory\n\n    Blueprint Flask application using the factory pattern,\n    with configuration setup and blueprint module registration\n'''\nfrom flask import Flask\nfrom flask_bootstrap import Bootstrap\nfrom flask_security import Security\nfrom flask_security import SQLAlchemyUserDatastore\nfrom flask_debugtoolbar import DebugToolbarExtension\nfrom flask_admin import Admin\nfrom flask_admin.contrib.sqla import ModelView\nfrom .models import db\nfrom .models import User\nfrom .models import Role\nfrom .admin import admin\n\n\ndef create_app():\n    ''' create_app\n\n        input:\n            None\n\n        output:\n            app -- flask web application instance\n\n        Read configuration values in the following order:\n            1) default, values which can be overwritten later\n            2) intance, for your eyes only not stored in repo values\n            3) environment, selectable values from:\n                - development\n                - stagging\n                - production\n\n        Setup web interface with Bootstrap framework\n    '''\n\n    # Initialize app\n    app = Flask(__name__, instance_relative_config=True)\n\n    # Load default config values\n    app.config.from_object('config.default')\n    # Load instance config values not stored in repo\n    app.config.from_pyfile('config.py')\n    # Load environment config values\n    app.config.from_envvar('APP_CONFIG_FILE')\n\n    # Create database connection\n    db.init_app(app)\n\n    # Instantiate Admin section\n    admin.init_app(app)\n\n    # Initialize bootstrap\n    Bootstrap(app)\n\n    # Setup Flask-Security\n    security = Security(app, SQLAlchemyUserDatastore(db, User, Role))\n\n    # Debug = True to enable the toolbar\n    toolbar = DebugToolbarExtension(app)\n\n    # Load blueprint modules\n    from application.site.routes import mod as site\n    from application.api.routes import mod as api\n\n    # Register blueprint modules for use\n    app.register_blueprint(site)\n    app.register_blueprint(api, url_prefix='/api')\n\n    return app\n</code></pre>\n",
                    "OwnerUserId": "982446",
                    "LastEditorUserId": "982446",
                    "LastEditDate": "2018-02-24T03:20:39.350",
                    "LastActivityDate": "2018-02-24T04:43:02.683",
                    "Title": "Flask-bootstrap customizing Flask-security",
                    "Tags": "<python><flask><flask-security><flask-bootstrap>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "49307758",
                "ParentRepo": "https://github.com/fbenavides69/body-mass-index",
                "StackOverflow_Post": {
                    "Id": "49307758",
                    "PostTypeId": "2",
                    "ParentId": "49283494",
                    "CreationDate": "2018-03-15T19:27:49.540",
                    "Score": "0",
                    "Body": "<p>Turns out the definition of the User class for the <strong>secondary</strong> was badly done, as well as the implementation of the <strong>roles_users</strong> table</p>\n\n<p>Also, the sequence for the <strong>first request</strong> was not proper, it has now been fixed!</p>\n\n<p>It now all works well, this sample application integrates Flask with React, enjoy!\n<a href=\"https://github.com/fbenavides69/body-mass-index\" rel=\"nofollow noreferrer\">github repo for bmi challange</a></p>\n",
                    "OwnerUserId": "982446",
                    "LastActivityDate": "2018-03-15T19:27:49.540",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "51371101",
                "ParentRepo": "https://github.com/briancappello/flask-react-spa",
                "StackOverflow_Post": {
                    "Id": "51371101",
                    "PostTypeId": "2",
                    "ParentId": "11804922",
                    "CreationDate": "2018-07-16T22:56:54.380",
                    "Score": "0",
                    "Body": "<p>This <a href=\"https://github.com/briancappello/flask-react-spa\" rel=\"nofollow noreferrer\">repository</a> is a good example of how <a href=\"https://github.com/maxcountryman/flask-login\" rel=\"nofollow noreferrer\">flask-login</a> and <a href=\"https://github.com/mattupstate/flask-security\" rel=\"nofollow noreferrer\">flask-security</a> can be connected with flask-admin.</p>\n\n<p>In <a href=\"https://www.reddit.com/r/flask/comments/7tr82o/example_integrating_flask_admin_into_flask_webapp/\" rel=\"nofollow noreferrer\">this reddit post</a> the author of the boilerplate describes shortly the implementation logic.</p>\n",
                    "OwnerUserId": "2248627",
                    "LastEditorUserId": "2248627",
                    "LastEditDate": "2018-07-16T23:05:48.557",
                    "LastActivityDate": "2018-07-16T23:05:48.557",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "53017724",
                "ParentRepo": "https://github.com/jonalxh/Flask-Admin-Dashboard",
                "StackOverflow_Post": {
                    "Id": "53017724",
                    "PostTypeId": "1",
                    "CreationDate": "2018-10-27T00:17:27.857",
                    "Score": "1",
                    "ViewCount": "1316",
                    "Body": "<p>I'm using Flask Admin (<a href=\"https://github.com/jonalxh/Flask-Admin-Dashboard\" rel=\"nofollow noreferrer\">https://github.com/jonalxh/Flask-Admin-Dashboard</a>) and I have a doubt.</p>\n\n<p>Let's say that I have a Model with:</p>\n\n<p>Product</p>\n\n<p>Serial Number</p>\n\n<p>Price</p>\n\n<p>I was looking for a way to display a new row that would display the total price of products in stock.</p>\n\n<p>Can someone point me to the right direction?</p>\n\n<p>Thank you.</p>\n\n<p>I have already looked into this but when I display a custom view,I can't do CRUD actions like I do on the \"standard\" models view: <a href=\"https://stackoverflow.com/questions/47124728/how-do-you-add-a-summary-row-for-flask-admin\">How do you add a summary row for Flask-Admin?</a></p>\n\n<p>P.S: I'm learning python so please excuse me if this is a basic issue that I'm wasting your time with</p>\n",
                    "OwnerUserId": "6796093",
                    "LastActivityDate": "2018-11-01T17:47:52.130",
                    "Title": "Flask Admin Models - Summary row",
                    "Tags": "<python><flask-sqlalchemy><flask-admin>",
                    "AnswerCount": "1",
                    "CommentCount": "2",
                    "FavoriteCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "53106661",
                "ParentRepo": "https://github.com/pjcunningham/Flask-Admin-Dashboard-Summary",
                "StackOverflow_Post": {
                    "Id": "53106661",
                    "PostTypeId": "2",
                    "ParentId": "53017724",
                    "CreationDate": "2018-11-01T17:47:52.130",
                    "Score": "4",
                    "Body": "<p>The method outlined in the answer to the referenced <a href=\"https://stackoverflow.com/a/47167011/2800058\">question</a> can also be made to work with Flask-Admin-Dashboard.</p>\n\n<p>I have created a sample project <a href=\"https://github.com/pjcunningham/Flask-Admin-Dashboard-Summary\" rel=\"nofollow noreferrer\">Flask-Admin-Dashboard-Summary</a> on Github.</p>\n\n<p><a href=\"https://i.stack.imgur.com/nQ2TX.jpg\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/nQ2TX.jpg\" alt=\"Summary Rows for Project View\"></a></p>\n\n<p><strong>Below are the essential concepts.</strong></p>\n\n<p>To show a summary table a view needs to:</p>\n\n<ul>\n<li>inject summary values into the view</li>\n<li>define what Jinja template to use and suitably modify it to use the injected summary values</li>\n</ul>\n\n<p><strong>Setting up the Jinja template</strong></p>\n\n<p><code>templates/admin/model/summary_list.html</code> is a direct copy of <a href=\"https://github.com/flask-admin/flask-admin/blob/master/flask_admin/templates/bootstrap3/admin/model/list.html\" rel=\"nofollow noreferrer\">list.html</a>, from the Flask-Admin Bootstrap 3 template folder.</p>\n\n<p>Note the file name, <code>summary_list.html</code>, as this is used in the view definition's <code>render</code> method.</p>\n\n<p>The following block of html has been inserted at line 163:</p>\n\n<pre><code>{# This adds the summary data #}\n{% for row in summary_data %}\n&lt;tr&gt;\n    {% if actions %}\n    &lt;td&gt;\n        {# leave this empty #}\n    &lt;/td&gt;\n    {% endif %}\n    {# This is the summary line title and goes in the action column, note that the action may not be visible!!! #}\n    {% if admin_view.column_display_actions %}\n        &lt;td&gt;&lt;strong&gt;{{ row['title'] or ''}}&lt;/strong&gt;&lt;/td&gt;\n    {% endif %}\n    {# This is the summary line data and goes in the individual columns #}\n    {% for c, name in list_columns %}\n        &lt;td class=\"col-{{c}}\"&gt;\n            &lt;strong&gt;{{ row[c] or ''}}&lt;/strong&gt;\n        &lt;/td&gt;\n    {% endfor %}\n&lt;/tr&gt;\n{% endfor %}\n</code></pre>\n\n<p><strong>Setting up the view</strong></p>\n\n<p>Line 61, define the template to use:</p>\n\n<pre><code># don't call the custom page list.html as you'll get a recursive call\nlist_template = 'admin/model/summary_list.html'\n</code></pre>\n\n<p>Line 75, override the view's <code>render(self, template, **kwargs)</code> method:</p>\n\n<pre><code>def render(self, template, **kwargs):\n    # we are only interested in the summary_list page\n    if template == 'admin/model/summary_list.html':\n        # append a summary_data dictionary into kwargs\n        # The title attribute value appears in the actions column\n        # all other attributes correspond to their respective Flask-Admin 'column_list' definition\n        _current_page = kwargs['page']\n        kwargs['summary_data'] = [\n            {'title': 'Page Total', 'name': None, 'cost': self.page_cost(_current_page)},\n            {'title': 'Grand Total', 'name': None, 'cost': self.total_cost()},\n        ]\n    return super(ProjectView, self).render(template, **kwargs)\n</code></pre>\n\n<p>Note the helper methods to provide the actual summary data at lines 66 and 71, these need to be adjusted as necessary:</p>\n\n<pre><code>def page_cost(self, current_page):\n    # this should take into account any filters/search inplace\n    _query = self.session.query(Project).limit(self.page_size).offset(current_page * self.page_size)\n    return sum([p.cost for p in _query])\n\ndef total_cost(self):\n    # this should take into account any filters/search inplace\n    return self.session.query(func.sum(Project.cost)).scalar()\n</code></pre>\n",
                    "OwnerUserId": "2800058",
                    "LastActivityDate": "2018-11-01T17:47:52.130",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "55281434",
                "ParentRepo": "https://github.com/AndreiD/Flask-Easy-Template",
                "StackOverflow_Post": {
                    "Id": "55281434",
                    "PostTypeId": "1",
                    "CreationDate": "2019-03-21T13:22:47.040",
                    "Score": "0",
                    "ViewCount": "22",
                    "Body": "<p>Good Morning!\nI am a beginner in the python / flask world ... I found <a href=\"https://github.com/AndreiD/Flask-Easy-Template\" rel=\"nofollow noreferrer\">this template</a> and found it complete and simple, good for beginners and with some interesting features.</p>\n\n<p>I just can not run this template. It has some packages that do not install by pip (pycrypto==2.6.1, python-cloudfiles==1.7.11, python-loaders==0.2.3).\nWas this a reason? Can anybody help me?</p>\n\n<p>I need some help to run this template.\n<a href=\"https://i.stack.imgur.com/dhhr6.png\" rel=\"nofollow noreferrer\">enter image description here</a></p>\n\n<p>Thanks!</p>\n",
                    "OwnerUserId": "9938264",
                    "LastEditorUserId": "7515530",
                    "LastEditDate": "2019-03-21T14:04:04.483",
                    "LastActivityDate": "2019-03-22T00:24:57.093",
                    "Title": "Error in template flask run AndreiD/Flask-Easy-Template",
                    "Tags": "<python><templates><flask>",
                    "AnswerCount": "1",
                    "CommentCount": "3",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "56017718",
                "ParentRepo": "https://github.com/zenodo/zenodo/issues/1508",
                "StackOverflow_Post": {
                    "Id": "56017718",
                    "PostTypeId": "2",
                    "ParentId": "56017717",
                    "CreationDate": "2019-05-07T07:38:37.670",
                    "Score": "0",
                    "Body": "<p>It seems that this <a href=\"https://github.com/zenodo/zenodo/issues/1508\" rel=\"nofollow noreferrer\">is a limitation of the current query interface</a>.  The query language does not support queries for nested fields, such as the related identifiers.  The provided documentation was misleading and has been corrected through <a href=\"https://github.com/zenodo/zenodo-docs-user/pull/70\" rel=\"nofollow noreferrer\">this pull request</a>. In addition, a Zenodo developer commented that the corresponding identifiers can be accessed through the <code>related.identifier</code> keyword, for example <a href=\"https://zenodo.org/search?page=1&amp;size=20&amp;q=related.identifier:%2210.1109%2FTSE.2019.2892149%22\" rel=\"nofollow noreferrer\">related.identifier:\"10.1109/TSE.2019.2892149\"</a>.</p>\n",
                    "OwnerUserId": "20520",
                    "LastEditorUserId": "20520",
                    "LastEditDate": "2019-05-07T13:38:04.527",
                    "LastActivityDate": "2019-05-07T13:38:04.527",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "58015939",
                "ParentRepo": "https://github.com/pubmania/flask_admin_skeleton",
                "StackOverflow_Post": {
                    "Id": "58015939",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "58017338",
                    "CreationDate": "2019-09-19T17:09:39.580",
                    "Score": "3",
                    "ViewCount": "1959",
                    "Body": "<p>I am experimenting with flask and just creating some basic functionality to add data to a form displayed in a modal. While I have managed to get the form to display in the modal and save it from the modal, I am struggling to understand what needs to be done to ensure that field validation errors are shown on the modal itself. Currently if there are errors user is redirected to a whole page with edit form.</p>\n\n<p>They say picture is better than words - So here is a gif showing what is happening:</p>\n\n<p><a href=\"https://i.stack.imgur.com/i9Cj5.gif\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/i9Cj5.gif\" alt=\"Modal Form Error Goes to the page\"></a></p>\n\n<p>The entire app code is on <a href=\"https://github.com/pubmania/flask_admin_skeleton\" rel=\"nofollow noreferrer\">github</a> and the current state on heroku can be accessed <a href=\"https://flask-admin-skeleton.herokuapp.com/home\" rel=\"nofollow noreferrer\">here</a>... username: <em>admin@admin.com</em> and password: <em>adminpassword</em>. It's all sandbox anyway.</p>\n\n<p>Relevant code is as below:</p>\n\n<p>routes.py</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>\n@expenses.route(\"/expense\")\n@login_required\ndef expense():\n    page = request.args.get('page', 1, type=int)\n    expenses = Expense.query.order_by(Expense.expense_date.desc()).paginate(page=page, per_page=5)\n    form = ExpenseForm()\n    return render_template('expense/expense.html', expenses=expenses, form=form)\n\n\n@expenses.route(\"/expense/new\", methods=['GET', 'POST'])\n@login_required\ndef new_expense():\n    form = ExpenseForm()\n    if form.validate_on_submit():\n        expense = Expense(description=form.description.data, expense_date=form.expense_date.data,\n                        amount=form.amount.data,vat_amount=form.vat_amount.data,Transferrable=form.Transferrable.data, author=current_user)\n        db.session.add(expense)\n        db.session.commit()\n        flash('Your expense has been created!', 'success')\n        return redirect(url_for('expenses.expense'))\n    return render_template('expense/create_expense.html', title='New Expense',\n                           form=form, legend='New Expense')\n</code></pre>\n\n<p>Now the expenses.html is a big one but on it the modal is called using the following:</p>\n\n<pre class=\"lang-html prettyprint-override\"><code>&lt;button type=\"button\" class=\"btn btn-primary btn-sm m-1\" data-toggle=\"modal\" data-target=\"#AddNewModal\"&gt;Add New Expense&lt;/button&gt;\n{% include \"expense/partials/addModal.html\" %}\n</code></pre>\n\n<p>and the addModal.html is as shown below:</p>\n\n<pre class=\"lang-html prettyprint-override\"><code>&lt;!-- Add New Modal --&gt;\n{% from \"util/macros.html\" import form_field with context %}\n&lt;div class=\"modal fade\" id=\"AddNewModal\" tabindex=\"-1\" role=\"dialog\" aria-labelledby=\"AddNewModalLabel\" aria-hidden=\"true\"&gt;\n  &lt;div class=\"modal-dialog\" role=\"document\"&gt;\n    &lt;div class=\"modal-content\"&gt;\n      &lt;div class=\"modal-header\"&gt;\n        &lt;h5 class=\"modal-title\" id=\"AddNewModalLabel\"&gt;Add New Expense&lt;/h5&gt;\n        &lt;button type=\"button\" class=\"close\" data-dismiss=\"modal\" aria-label=\"Close\"&gt;\n        &lt;span aria-hidden=\"true\"&gt;&amp;times;&lt;/span&gt;\n        &lt;/button&gt;\n      &lt;/div&gt;\n      &lt;div class=\"modal-body\"&gt;\n        &lt;div class=\"amount-section\"&gt;\n          &lt;form method=\"POST\" action=\"/expense/new\"&gt;\n          {{ form.hidden_tag() }}\n          &lt;fieldset class=\"form-group\"&gt;\n            &lt;legend class=\"border-bottom mb-4\"&gt;{{ legend }}&lt;/legend&gt;\n            &lt;div class=\"form-group\"&gt;\n              {{ form.description.label(class=\"form-control-label\") }}\n              {% if form.description.errors %}\n                {{ form.description(class=\"form-control form-control-lg is-invalid\") }}\n                &lt;div class=\"invalid-feedback\"&gt;\n                  {% for error in form.description.errors %}\n                  &lt;span&gt;{{ error }}&lt;/span&gt;\n                  {% endfor %}\n                &lt;/div&gt;\n              {% else %}\n                {{ form.description(class=\"form-control form-control-lg\") }}\n              {% endif %}\n            &lt;/div&gt;\n            &lt;div class=\"form-group\"&gt;\n              {{ form.amount.label(class=\"form-control-label\") }}\n              {% if form.amount.errors %}\n                {{ form.amount(class=\"form-control form-control-lg is-invalid\") }}\n                &lt;div class=\"invalid-feedback\"&gt;\n                {% for error in form.amount.errors %}\n                  &lt;span&gt;{{ error }}&lt;/span&gt;\n                {% endfor %}\n                &lt;/div&gt;\n              {% else %}\n                {{ form.amount(class=\"form-control form-control-lg\") }}\n              {% endif %}\n            &lt;/div&gt;\n            &lt;div class=\"form-group\"&gt;\n              {{ form.expense_date.label(class=\"form-control-label\") }}\n              {% if form.expense_date.errors %}\n                {{ form.expense_date(class=\"form-control form-control-lg is-invalid\") }}\n                &lt;div class=\"invalid-feedback\"&gt;\n                  {% for error in form.expense_date.errors %}\n                    &lt;span&gt;{{ error }}&lt;/span&gt;\n                  {% endfor %}\n                &lt;/div&gt;\n              {% else %}\n                {{ form.expense_date(class=\"form-control form-control-lg\", type=\"date\") }}\n              {% endif %}\n            &lt;/div&gt;\n            &lt;div class=\"form-group\"&gt;\n              {{ form.vat_amount.label(class=\"form-control-label\") }}\n              {% if form.vat_amount.errors %}\n                {{ form.vat_amount(class=\"form-control form-control-lg is-invalid\") }}\n                &lt;div class=\"invalid-feedback\"&gt;\n                  {% for error in form.vat_amount.errors %}\n                    &lt;span&gt;{{ error }}&lt;/span&gt;\n                  {% endfor %}\n                &lt;/div&gt;\n              {% else %}\n                {{ form.vat_amount(class=\"form-control form-control-lg\") }}\n              {% endif %}\n            &lt;/div&gt;\n            &lt;!-- {{ form_field(form.vat_amount,with_label=True) }} --&gt;\n            &lt;div class=\"form-group\"&gt;\n            {% if form.Transferrable.errors %}\n              {{ form.Transferrable(class=\"form-control form-control-lg is-invalid\") }}\n              &lt;div class=\"invalid-feedback\"&gt;\n                {% for error in form.Transferrable.errors %}\n                  &lt;span&gt;{{ error }}&lt;/span&gt;\n                {% endfor %}\n              &lt;/div&gt;\n            {% else %}\n              {{ form.Transferrable(type=\"checkbox\") }}\n            {% endif %}\n              {{ form.Transferrable.label(class=\"form-control-label\") }}\n            &lt;/div&gt;\n            &lt;!-- {{ form_field(form.Transferrable) }} --&gt;\n            &lt;p&gt;&lt;button type=\"submit\" class=\"btn btn-primary\"&gt;Add&lt;/button&gt;&lt;/p&gt;\n            &lt;/fieldset&gt;\n          &lt;/form&gt;\n        &lt;/div&gt;\n        &lt;div class=\"modal-footer\"&gt;\n          &lt;button type=\"button\" class=\"btn btn-secondary\" data-dismiss=\"modal\"&gt;Close&lt;/button&gt;\n        &lt;/div&gt;\n      &lt;/div&gt;\n    &lt;/div&gt;\n  &lt;/div&gt;\n&lt;/div&gt;\n\n</code></pre>\n",
                    "OwnerUserId": "5965677",
                    "LastEditorUserId": "5965677",
                    "LastEditDate": "2019-09-19T17:25:43.800",
                    "LastActivityDate": "2019-09-19T19:15:44.757",
                    "Title": "Flask - Form on Modal - How to display the field error on modal?",
                    "Tags": "<flask><flask-sqlalchemy><flask-wtforms><flask-bootstrap>",
                    "AnswerCount": "1",
                    "CommentCount": "2",
                    "FavoriteCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "59503285",
                "ParentRepo": "https://github.com/mattupstate/flask-social-example",
                "StackOverflow_Post": {
                    "Id": "59503285",
                    "PostTypeId": "1",
                    "CreationDate": "2019-12-27T16:11:14.237",
                    "Score": "-1",
                    "ViewCount": "104",
                    "Body": "<p>I am trying to use Flask-Social.\nWhile installing <a href=\"https://github.com/mattupstate/flask-social-example\" rel=\"nofollow noreferrer\">Flask Social Example</a> on a virtualenv, I got error for cssmin 0.1.4.</p>\n\n<pre><code>...\n    raise HTTPError(req.full_url, code, msg, hdrs, fp)\nurllib.error.HTTPError: HTTP Error 403: SSL is required\n----------------------------------------\nERROR: Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\n</code></pre>\n\n<p>How to fix this? Should I download cssmin source and install manually?</p>\n",
                    "OwnerDisplayName": "user12603675",
                    "LastActivityDate": "2019-12-28T06:58:15.733",
                    "Title": "Pip installation error while installing cssmin 0.1.4",
                    "Tags": "<python><flask>",
                    "AnswerCount": "1",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "69580503",
                "ParentRepo": "https://github.com/Programmer-RD-AI/Stackoverflow-Questions/tree/main/Is%20there%20a%20way%20to%20do%20string%20removing%20in%20html%20tags%3F",
                "StackOverflow_Post": {
                    "Id": "69580503",
                    "PostTypeId": "2",
                    "ParentId": "69580380",
                    "CreationDate": "2021-10-15T06:00:27.447",
                    "Score": "0",
                    "Body": "<p>If you want to show without the '', you will need to show this as an element of the list.</p>\n<pre><code>  a = ['1','2']\n  So you will need to do like\n  &lt;h1&gt;\n  {{a[0]}}\n  &lt;/h1&gt;\n</code></pre>\n<p>Or you can do something like below. It is not the best way but this does work to remove the ''. From the list, the code is:</p>\n<p><a href=\"https://github.com/Programmer-RD-AI/Stackoverflow-Questions/tree/main/Is%20there%20a%20way%20to%20do%20string%20removing%20in%20html%20tags%3F\" rel=\"nofollow noreferrer\">https://github.com/Programmer-RD-AI/Stackoverflow-Questions/tree/main/Is%20there%20a%20way%20to%20do%20string%20removing%20in%20html%20tags%3F</a></p>\n<p>Check the above link. You can get the code from there.</p>\n",
                    "OwnerUserId": "13542203",
                    "LastEditorUserId": "1839439",
                    "LastEditDate": "2021-10-15T09:49:27.770",
                    "LastActivityDate": "2021-10-15T09:49:27.770",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            }
        ],
        "Type": 2
    },
    "https://github.com/cliftonc/calipso": {
        "CVE Description": [
            "This affects all versions of package calipso. It is possible for a malicious module to overwrite files on an arbitrary file system through the module install functionality."
        ],
        "Edges": [
            {
                "SID": "24346996",
                "StackOverflow_Post": {
                    "Id": "24346996",
                    "PostTypeId": "1",
                    "CreationDate": "2014-06-22T00:10:48.207",
                    "Score": "1",
                    "ViewCount": "85",
                    "Body": "<p>is good practice to include my modules in node_modules for make require search easy,if not why not?</p>\n\n<p><strong>Explanation:</strong></p>\n\n<p>In  node.js cms calipso( <a href=\"https://github.com/cliftonc/calipso\" rel=\"nofollow\">https://github.com/cliftonc/calipso</a>) \ntheir modules not inside node_modules: then the include the modules without auto option:</p>\n\n<pre><code>calipso = require(path.join(rootpath, 'lib/calipso'));\n</code></pre>\n\n<p>vs if it was inside node_modules:</p>\n\n<pre><code>calipso = require('calipso');\n</code></pre>\n",
                    "OwnerUserId": "342984",
                    "LastEditorUserId": "342984",
                    "LastEditDate": "2014-06-22T10:19:39.607",
                    "LastActivityDate": "2014-06-22T10:19:39.607",
                    "Title": "is good practice to include my modules in node_modules for make require search easy,if not why not?",
                    "Tags": "<node.js><express>",
                    "AnswerCount": "1",
                    "CommentCount": "1",
                    "FavoriteCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            }
        ],
        "Type": 0
    },
    "https://github.com/Studio-42/elFinder": {
        "CVE Description": [
            "The package studio-42/elfinder before 2.1.58 are vulnerable to Remote Code Execution (RCE) via execution of PHP code in a .phar file. NOTE: This only applies if the server parses .phar files as PHP."
        ],
        "Edges": [
            {
                "SID": "3091394",
                "StackOverflow_Post": {
                    "Id": "3091394",
                    "PostTypeId": "2",
                    "ParentId": "3090720",
                    "CreationDate": "2010-06-22T08:19:53.883",
                    "Score": "5",
                    "Body": "<p>Found a better one... </p>\n\n<p><a href=\"http://elrte.ru/en/elfinder/demo\" rel=\"nofollow noreferrer\">http://elrte.ru/en/elfinder/demo</a></p>\n\n<p><strong>Update</strong></p>\n\n<p>demo - <a href=\"https://studio-42.github.io/elFinder/\" rel=\"nofollow noreferrer\">https://studio-42.github.io/elFinder/</a></p>\n\n<p>source - <a href=\"https://github.com/Studio-42/elFinder\" rel=\"nofollow noreferrer\">https://github.com/Studio-42/elFinder</a></p>\n",
                    "OwnerUserId": "261591",
                    "LastEditorUserId": "261591",
                    "LastEditDate": "2017-09-05T17:51:59.057",
                    "LastActivityDate": "2017-09-05T17:51:59.057",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "14377150",
                "ParentRepo": "https://github.com/barryvdh/laravel-elfinder",
                "StackOverflow_Post": {
                    "Id": "14377150",
                    "PostTypeId": "5",
                    "CreationDate": "2013-01-17T10:37:56.613",
                    "Score": "0",
                    "Body": "<p>elFinder is an open-source file manager for web, written in JavaScript using jQuery UI. Creation is inspired by simplicity and convenience of Finder program used in Mac OS X operating system.</p>\n\n<h2>Feature Overview:</h2>\n\n<ul>\n<li>Supports all operations with files and folders on a remote server (copy, move, upload, create folder/file, rename, etc.)</li>\n<li>Supports multiple root directories</li>\n<li>Can be used with Local file storage, MySQL database or FTP volumes</li>\n<li>Easy integration with web editors (elRTE, CKEditor, TinyMCE)</li>\n<li>3rd party connectors</li>\n<li>Flexible configuration of access rights, upload file types, user interface and other</li>\n<li>Extensibility (you can create as many commands as you wish)</li>\n</ul>\n\n<h2>Project History</h2>\n\n<p>elFinder was created by <a href=\"http://www.std42.ru/\" rel=\"nofollow noreferrer\">Studio-42</a> in 2009. The last update by the company was released on April 10th, 2012 (<a href=\"https://github.com/Studio-42/elFinder/releases\" rel=\"nofollow noreferrer\">version 2.0-rc1</a>). After that, the plugin has been maintained by the user <a href=\"https://stackoverflow.com/users/4692745\">nao-pon</a> and by the community.</p>\n\n<p><strong>Important note</strong>: If you want use this plugin, make sure you use one of the latest releases (<a href=\"https://github.com/Studio-42/elFinder#downloads\" rel=\"nofollow noreferrer\">2.x or 2.1</a>) available on GitHub, as they have innumerous bug fixes that are not present on the official plugin page.</p>\n\n<h2>Documentation</h2>\n\n<ul>\n<li><a href=\"http://elfinder.org/\" rel=\"nofollow noreferrer\">Website</a></li>\n<li><a href=\"https://github.com/Studio-42/elFinder\" rel=\"nofollow noreferrer\">GitHub</a></li>\n<li><a href=\"https://github.com/Studio-42/elFinder/issues\" rel=\"nofollow noreferrer\">Issues</a></li>\n<li><a href=\"https://github.com/Studio-42/elFinder/wiki\" rel=\"nofollow noreferrer\">Wiki</a></li>\n</ul>\n\n<h2>3rd Party Connectors</h2>\n\n<ul>\n<li><a href=\"https://github.com/Studio-42/elfinder-python\" rel=\"nofollow noreferrer\">Python</a></li>\n<li><a href=\"https://github.com/mikery/django-elfinder\" rel=\"nofollow noreferrer\">Django</a></li>\n<li><a href=\"https://github.com/phallstrom/el_finder\" rel=\"nofollow noreferrer\">Ruby/Rails</a></li>\n<li><a href=\"https://github.com/Studio-42/elfinder-servlet\" rel=\"nofollow noreferrer\">Java Servlet</a></li>\n<li><a href=\"https://github.com/barryvdh/laravel-elfinder\" rel=\"nofollow noreferrer\">Laravel</a></li>\n<li><a href=\"https://github.com/Studio-42/elFinder/wiki/3rd-party-connectors,-plugins,-modules\" rel=\"nofollow noreferrer\">... other 3rd party connectors, plugins and modules</a></li>\n</ul>\n",
                    "OwnerUserId": "1862812",
                    "LastEditorUserId": "1033581",
                    "LastEditDate": "2019-06-10T14:46:07.293",
                    "LastActivityDate": "2019-06-10T14:46:07.293",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "17528870",
                "ParentRepo": "https://github.com/helios-ag/FMElfinderBundle",
                "StackOverflow_Post": {
                    "Id": "17528870",
                    "PostTypeId": "2",
                    "ParentId": "17520855",
                    "CreationDate": "2013-07-08T14:13:13.333",
                    "Score": "3",
                    "Body": "<p>You need an filebrowser, thirdparty, or written by yourself.\nAs a example you can use Elfinder, configured by yourself or via bundle, like <a href=\"https://github.com/helios-ag/FMElfinderBundle\" rel=\"nofollow\">FMElfinderBundle</a> \nThe readme explains how to configure bundle to work with <a href=\"https://github.com/trsteel88/TrsteelCkeditorBundle\" rel=\"nofollow\">trsteel CKeditor bundle</a>, but configuration for Ivory should be almost the same</p>\n",
                    "OwnerUserId": "648021",
                    "LastActivityDate": "2013-07-08T14:13:13.333",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "27167707",
                "ParentRepo": "https://github.com/imagecms/ImageCMS",
                "StackOverflow_Post": {
                    "Id": "27167707",
                    "PostTypeId": "2",
                    "ParentId": "2048179",
                    "CreationDate": "2014-11-27T09:57:43.783",
                    "Score": "0",
                    "Body": "<p>Open Source CMS:</p>\n\n<ul>\n<li><a href=\"https://github.com/goFrendiAsgard/No-CMS\" rel=\"nofollow\">No CMS</a></li>\n<li><a href=\"https://github.com/diyphpdeveloper/cms-canvas\" rel=\"nofollow\">CMS Canvas</a></li>\n<li><a href=\"https://github.com/imagecms/ImageCMS\" rel=\"nofollow\">Image CMS</a></li>\n</ul>\n",
                    "OwnerUserId": "2802965",
                    "LastActivityDate": "2014-11-27T09:57:43.783",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "29339561",
                "ParentRepo": "https://github.com/MihailDev/yii2-elfinder",
                "StackOverflow_Post": {
                    "Id": "29339561",
                    "PostTypeId": "2",
                    "ParentId": "29339322",
                    "CreationDate": "2015-03-30T06:20:52.343",
                    "Score": "2",
                    "Body": "<p>You need to define your Upload Action:</p>\n\n<pre><code>&lt;?= $form-&gt;field($model, 'content')-&gt;widget(CKEditor::className(), [\n        'options' =&gt; ['rows' =&gt; 6],\n        'preset' =&gt; 'basic'\n        'clientOptions' =&gt; [\n            'filebrowserUploadUrl' =&gt; 'site/url'\n        ]\n    ]) ?&gt;\n</code></pre>\n\n<p>And there should be your handler for file uploads on this route (<a href=\"http://hosannahighertech.co.tz/blog/mweledi/11-Yii2-CKEditor-and-Images-Upload\" rel=\"nofollow\">http://hosannahighertech.co.tz/blog/mweledi/11-Yii2-CKEditor-and-Images-Upload</a>).</p>\n\n<p>You also can use file manager plugin which have integration with ckeditor:</p>\n\n<p><a href=\"https://github.com/MihailDev/yii2-elfinder\" rel=\"nofollow\">https://github.com/MihailDev/yii2-elfinder</a></p>\n\n<p><a href=\"https://github.com/MihailDev/yii2-ckeditor\" rel=\"nofollow\">https://github.com/MihailDev/yii2-ckeditor</a></p>\n",
                    "OwnerUserId": "1852788",
                    "LastActivityDate": "2015-03-30T06:20:52.343",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "30821828",
                "ParentRepo": "https://github.com/trntv/yii2-starter-kit/blob/master/docs/installation.md#configure-your-web-server",
                "StackOverflow_Post": {
                    "Id": "30821828",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "30848001",
                    "CreationDate": "2015-06-13T17:58:03.777",
                    "Score": "2",
                    "ViewCount": "1107",
                    "Body": "<p>I'm trying to deploy this Yii2 installation (<a href=\"https://github.com/trntv/yii2-starter-kit/blob/master/docs/installation.md#configure-your-web-server\" rel=\"nofollow\">https://github.com/trntv/yii2-starter-kit/blob/master/docs/installation.md#configure-your-web-server</a>) but I'm having problems.\nI think problems are related with this configuration step: \"Configure your web server\".</p>\n\n<p>I've the webpage running here: <a href=\"http://vector5.raspctl.com/yii2-starter-kit/frontend/web/\" rel=\"nofollow\">http://vector5.raspctl.com/yii2-starter-kit/frontend/web/</a></p>\n\n<p>But no one of the options works. For example, \"Connect\" option (<a href=\"http://vector5.raspctl.com/yii2-starter-kit/frontend/web/user/sign-in/login\" rel=\"nofollow\">http://vector5.raspctl.com/yii2-starter-kit/frontend/web/user/sign-in/login</a>)</p>\n\n<p>I can't found the error, any help?</p>\n\n<p>Thanks.</p>\n",
                    "OwnerUserId": "3139207",
                    "LastActivityDate": "2015-06-15T14:38:53.530",
                    "Title": "Error deploying yii2-starter-kit Yii2 installation",
                    "Tags": "<web-services><yii2>",
                    "AnswerCount": "1",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "38598578",
                "ParentRepo": "https://github.com/macdabby/Lightning/commit/202ae9156ebf034c8cb4b625161015763fa0658f",
                "StackOverflow_Post": {
                    "Id": "38598578",
                    "PostTypeId": "2",
                    "ParentId": "38556135",
                    "CreationDate": "2016-07-26T19:41:03.093",
                    "Score": "0",
                    "Body": "<p>I was able to set the height to 60% with a top margin of 20% and 100vh when in mobile mode. I also had to change the dialog position to fixed and disable the scroll setting, which I think was a new addition after 5.2.2 which would explain why I only recently starting having this issue after updating. This is what I was able to do:</p>\n\n<p><a href=\"https://github.com/macdabby/Lightning/commit/202ae9156ebf034c8cb4b625161015763fa0658f\" rel=\"nofollow\">https://github.com/macdabby/Lightning/commit/202ae9156ebf034c8cb4b625161015763fa0658f</a></p>\n",
                    "OwnerUserId": "1117937",
                    "LastActivityDate": "2016-07-26T19:41:03.093",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "44718991",
                "ParentRepo": "https://github.com/bestmomo/laravel5-3-example/blob/master/bootstrap/app.php",
                "StackOverflow_Post": {
                    "Id": "44718991",
                    "PostTypeId": "1",
                    "CreationDate": "2017-06-23T10:19:59.377",
                    "Score": "3",
                    "ViewCount": "403",
                    "Body": "<p>I have created a factory class that creates a Laravel application instance and it works well. I am just not so sure about some of the decision I have made around what my factory method should return in case the application cannot be created.</p>\n\n<pre><code>class LaravelApplicationFactory{\n  public static function createApplication($options = array()){\n     if(isset($options['app.dir']){\n        return new Application($options['app.dir']);\n     }else{\n       return null;\n     }\n   }\n }\n</code></pre>\n\n<p>I am asking this question because I know that at some point I read that rather than returning null values one should instead throw exceptions. </p>\n\n<p>If this is the case how best can I leverage the factory pattern without embroidering my implementation with flawed design decisions?</p>\n\n<p>Client code would consume my factory as follows for the time being:</p>\n\n<pre><code>//file: index.php\n\n/** imports */\nuse cAspire\\Core\\Factory\\LaravelApplicationFactory;\n\nLaravelApplicationFactory::createApplication([\n  'app.dir' =&gt; __DIR__\n]);\n</code></pre>\n\n<p>This is inspired by the bootstrap file which can be found in any Laravel 5.* implementation under the <a href=\"https://github.com/bestmomo/laravel5-3-example/blob/master/bootstrap/app.php\" rel=\"nofollow noreferrer\">bootstrap.php</a> file.</p>\n",
                    "OwnerUserId": "2919028",
                    "LastEditorUserId": "2919028",
                    "LastEditDate": "2017-06-23T11:55:32.510",
                    "LastActivityDate": "2017-06-23T11:55:32.510",
                    "Title": "Factory Object and return null on object creation failure",
                    "Tags": "<php><null><factory-pattern>",
                    "AnswerCount": "0",
                    "CommentCount": "6",
                    "FavoriteCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "47858276",
                "ParentRepo": "https://github.com/Laravel-Backpack/Demo/blob/master/resources/views/vendor/backpack/base/inc/sidebar.blade.php#L38:L46",
                "StackOverflow_Post": {
                    "Id": "47858276",
                    "PostTypeId": "2",
                    "ParentId": "47853103",
                    "CreationDate": "2017-12-17T18:39:04.417",
                    "Score": "6",
                    "Body": "<p>In <code>resources/views/vendor/backpack/base/inc/sidebar.blade.php</code> you can add your own menu-items. Using <code>.treeview</code> and <code>.treeview-menu</code> you can make those items expandable:</p>\n\n<p>See also <a href=\"https://github.com/Laravel-Backpack/Demo/blob/master/resources/views/vendor/backpack/base/inc/sidebar.blade.php#L38:L46\" rel=\"noreferrer\">the source code</a> of that image.</p>\n\n<pre class=\"lang-html prettyprint-override\"><code>&lt;li class=\"treeview\"&gt;\n  &lt;a href=\"#\"&gt;&lt;i class=\"fa fa-key\"&gt;&lt;/i&gt; &lt;span&gt;Roles &amp; Permissions&lt;/span&gt; &lt;i class=\"fa fa-angle-left pull-right\"&gt;&lt;/i&gt;&lt;/a&gt;\n  &lt;ul class=\"treeview-menu\"&gt;\n    &lt;li&gt;\n      &lt;a href=\"{{ url(config('backpack.base.route_prefix', 'admin') . '/role') }}\"&gt;&lt;span&gt;Roles&lt;/span&gt;&lt;/a&gt;\n    &lt;/li&gt;\n    &lt;li&gt;\n      &lt;a href=\"{{ url(config('backpack.base.route_prefix', 'admin') . '/permission') }}\"&gt;&lt;span&gt;Permissions&lt;/span&gt;&lt;/a&gt;\n    &lt;/li&gt;\n  &lt;/ul&gt;\n&lt;/li&gt;\n</code></pre>\n\n\n",
                    "OwnerUserId": "2232346",
                    "LastActivityDate": "2017-12-17T18:39:04.417",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "48196458",
                "ParentRepo": "https://github.com/updivision/estarter-ecommerce-for-laravel",
                "StackOverflow_Post": {
                    "Id": "48196458",
                    "PostTypeId": "1",
                    "CreationDate": "2018-01-10T21:35:46.127",
                    "Score": "0",
                    "ViewCount": "2174",
                    "Body": "<p>I am following the <a href=\"https://github.com/updivision/estarter-ecommerce-for-laravel\" rel=\"nofollow noreferrer\">eStarter - ecommerce on Laravel</a> README.md and ran into an issue trying to seed the database:</p>\n\n<pre><code>php artisan migrate --seed\n</code></pre>\n\n<p>The seeders don't create all the table columns necessary to navigate the admin. \nDoes anyone have a dummy SQL dump I can manually import? This way I can hit the ground running!</p>\n\n<p>Many thanks</p>\n",
                    "OwnerUserId": "1238280",
                    "LastActivityDate": "2018-01-24T05:30:25.183",
                    "Title": "Laravel Backpack eCommerce - Demo data",
                    "Tags": "<laravel>",
                    "AnswerCount": "1",
                    "CommentCount": "2",
                    "FavoriteCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "50652973",
                "ParentRepo": "https://github.com/hashmode/cakephp-tinymce-elfinder",
                "StackOverflow_Post": {
                    "Id": "50652973",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "50654421",
                    "CreationDate": "2018-06-02T02:26:21.863",
                    "Score": "0",
                    "ViewCount": "1899",
                    "Body": "<p>I am having this error which does not seem to make sense. I am using this plugin: <a href=\"https://github.com/hashmode/cakephp-tinymce-elfinder\" rel=\"nofollow noreferrer\">https://github.com/hashmode/cakephp-tinymce-elfinder</a>. I am in need of creating and admin route. However, even though CakePHP sees the plugin, it does not see the Controller within it. I don't see what I am doing wrong.</p>\n\n<p>This is my route for <code>/admin/elfinder</code>:</p>\n\n<pre><code>Router::prefix('admin', function ($routes) {\n  $routes-&gt;connect('/elfinder', ['plugin' =&gt; 'CakephpTinymceElfinder', 'controller' =&gt; 'Elfinders', 'action' =&gt; 'elfinder']);\n});\n</code></pre>\n\n<p>This is the controller/action I am trying to access</p>\n\n<p><a href=\"https://github.com/hashmode/cakephp-tinymce-elfinder/blob/master/src/Controller/ElfindersController.php\" rel=\"nofollow noreferrer\">https://github.com/hashmode/cakephp-tinymce-elfinder/blob/master/src/Controller/ElfindersController.php</a></p>\n\n<p>But I get the following error:</p>\n\n<pre><code>2018-06-01 15:20:33 Error: [Cake\\Routing\\Exception\\MissingControllerException] Controller class Elfinders could not be found.\nRequest URL: /admin/elfinder\n</code></pre>\n\n<p>It is definitely finding the Plugin. Why can't CakePHP find the controller?</p>\n",
                    "OwnerUserId": "597237",
                    "LastActivityDate": "2018-06-03T13:25:01.437",
                    "Title": "Cakephp 3.6 - Missing Controller Error",
                    "Tags": "<cakephp><cakephp-3.0>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "55605843",
                "ParentRepo": "https://github.com/yii2-starter-kit/yii2-starter-kit",
                "StackOverflow_Post": {
                    "Id": "55605843",
                    "PostTypeId": "2",
                    "ParentId": "55605516",
                    "CreationDate": "2019-04-10T06:15:34.190",
                    "Score": "0",
                    "Body": "<p>Yes you can. But if you need this kind of structure it is good to use Yii2-advanced template. Or if you want you can use also starter kit by trntv here is <a href=\"https://github.com/yii2-starter-kit/yii2-starter-kit\" rel=\"nofollow noreferrer\">link</a>. It has lots of features that will easy your development. </p>\n\n<p>What if you want it as module, you need basic template but you will not have separate web folders. Just use Gii to create module. Instructions how to work and create modules are given <a href=\"https://www.yiiframework.com/doc/guide/2.0/en/structure-modules\" rel=\"nofollow noreferrer\">here</a>.  </p>\n",
                    "OwnerUserId": "8141182",
                    "LastActivityDate": "2019-04-10T06:15:34.190",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "61424660",
                "ParentRepo": "https://github.com/simialbi/yii2-elfinder",
                "StackOverflow_Post": {
                    "Id": "61424660",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "61429849",
                    "CreationDate": "2020-04-25T11:05:59.170",
                    "Score": "0",
                    "ViewCount": "473",
                    "Body": "<p>I am using this module in yii2 framework but unable to set the correct URL \n<a href=\"https://github.com/simialbi/yii2-elfinder\" rel=\"nofollow noreferrer\">https://github.com/simialbi/yii2-elfinder</a></p>\n\n<pre><code> 'connectionSets' =&gt; [\n                'default' =&gt; [ // like elfinder roots\n                    [\n                        'class' =&gt; 'simialbi\\yii2\\elfinder\\ElFinderConfigurationLocalFileSystem',\n                        'path'  =&gt; '@webroot/uploads',\n                        'URL'   =&gt; '@web/file/files' // HERE PROBLEM\n                    ]\n                ]\n            ],\n</code></pre>\n\n<p>This is how I have defined URL <code>'URL'   =&gt; '@web/file/files'</code> where <code>file</code> is my controller and <code>files</code> is my action . \nCould you please let me know how exactly this URL show be passed in yii2 basic template .</p>\n\n<p><code>127.0.0.1:8080/project/elfinder/proxy/index?baseUrl=QHdlYi9maWxlL2ZpbGVz&amp;path=/NewFolder/file_example_PNG_500kB.png&amp;_t=1587811929</code></p>\n",
                    "OwnerUserId": "8702531",
                    "LastActivityDate": "2020-04-25T17:36:27.720",
                    "Title": "How to set URL for elfinder in yii2?",
                    "Tags": "<php><yii2><yii-extensions><yii2-basic-app><elfinder>",
                    "AnswerCount": "2",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "61424660",
                "ParentRepo": "https://github.com/simialbi/yii2-elfinder",
                "StackOverflow_Post": {
                    "Id": "61424660",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "61429849",
                    "CreationDate": "2020-04-25T11:05:59.170",
                    "Score": "0",
                    "ViewCount": "473",
                    "Body": "<p>I am using this module in yii2 framework but unable to set the correct URL \n<a href=\"https://github.com/simialbi/yii2-elfinder\" rel=\"nofollow noreferrer\">https://github.com/simialbi/yii2-elfinder</a></p>\n\n<pre><code> 'connectionSets' =&gt; [\n                'default' =&gt; [ // like elfinder roots\n                    [\n                        'class' =&gt; 'simialbi\\yii2\\elfinder\\ElFinderConfigurationLocalFileSystem',\n                        'path'  =&gt; '@webroot/uploads',\n                        'URL'   =&gt; '@web/file/files' // HERE PROBLEM\n                    ]\n                ]\n            ],\n</code></pre>\n\n<p>This is how I have defined URL <code>'URL'   =&gt; '@web/file/files'</code> where <code>file</code> is my controller and <code>files</code> is my action . \nCould you please let me know how exactly this URL show be passed in yii2 basic template .</p>\n\n<p><code>127.0.0.1:8080/project/elfinder/proxy/index?baseUrl=QHdlYi9maWxlL2ZpbGVz&amp;path=/NewFolder/file_example_PNG_500kB.png&amp;_t=1587811929</code></p>\n",
                    "OwnerUserId": "8702531",
                    "LastActivityDate": "2020-04-25T17:36:27.720",
                    "Title": "How to set URL for elfinder in yii2?",
                    "Tags": "<php><yii2><yii-extensions><yii2-basic-app><elfinder>",
                    "AnswerCount": "2",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "62147398",
                "ParentRepo": "https://github.com/Laravel-Backpack/demo/blob/master/config/backpack/base.php#L223",
                "StackOverflow_Post": {
                    "Id": "62147398",
                    "PostTypeId": "2",
                    "ParentId": "61160607",
                    "CreationDate": "2020-06-02T07:58:26.110",
                    "Score": "0",
                    "Body": "<p>That config should hold the <strong>name of the password broker</strong> that Backpack uses inside the Authentication. </p>\n\n<p>It should NOT be gibberish, but the actual name of the password broker to be used. By default that's <code>backpack</code> as you can <a href=\"https://github.com/Laravel-Backpack/demo/blob/master/config/backpack/base.php#L223\" rel=\"nofollow noreferrer\">see in our demo</a>. If commented out, it will use the same password broker that the stock Laravel Auth uses - as explained in the comment. <strong>I recommend you write <code>backpack</code> there - that should fix it for you.</strong> </p>\n\n<p>This value should only be changed when you want to customize the authentication, and have mixed auth for users and admins, things like that. It uses Laravel's authentication, which is unnecessarily complicated if you ask me, but that's where the password broker concept is from.</p>\n",
                    "OwnerUserId": "603036",
                    "LastActivityDate": "2020-06-02T07:58:26.110",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "66064434",
                "ParentRepo": "https://github.com/ozdemirburak/laravel-8-simple-cms",
                "StackOverflow_Post": {
                    "Id": "66064434",
                    "PostTypeId": "1",
                    "CreationDate": "2021-02-05T13:46:39.163",
                    "Score": "0",
                    "ViewCount": "653",
                    "Body": "<p>Trait method customizeSlugEngine has not been applied, because there are collisions with other trait methods on App\\Base\\SluggableModel</p>\n<p>at app/Base/SluggableModel.php:17</p>\n<p>I tried everything, this is project from github, this project:\n<a href=\"https://github.com/ozdemirburak/laravel-8-simple-cms\" rel=\"nofollow noreferrer\">ozdemirburak\n/\nlaravel-8-simple-cms | GitHub</a>\nWhat is this error, here is code SluggableModel.php:</p>\n<pre><code>&lt;?php\n\nnamespace App\\Base;\n\nuse App\\Base\\Traits\\SluggableEngine;\nuse Cviebrock\\EloquentSluggable\\Sluggable;\nuse Cviebrock\\EloquentSluggable\\SluggableScopeHelpers;\nuse Illuminate\\Database\\Eloquent\\Model;\n\n/**\n * App\\Base\\SluggableModel\n *\n * @method static \\Illuminate\\Database\\Eloquent\\Builder|\\App\\Base\\SluggableModel findSimilarSlugs($attribute, $config, $slug)\n * @method static \\Illuminate\\Database\\Eloquent\\Builder|\\App\\Base\\SluggableModel whereSlug($slug)\n * @mixin \\Eloquent\n */\nclass SluggableModel extends Model\n{\n    use Sluggable, SluggableEngine, SluggableScopeHelpers;\n\n    /**\n     * @var array\n     */\n    protected $guarded = ['created_at', 'id'];\n\n    /**\n     * @return array\n     */\n    public function sluggable()\n    {\n        return [\n            'slug' =&gt; [\n                'source'   =&gt; 'title',\n                'onUpdate' =&gt; true\n            ]\n        ];\n    }\n}\n</code></pre>\n<p>SlugabbleEngine.php:</p>\n<pre><code>&lt;?php\n\nnamespace App\\Base\\Traits;\n\nuse Cocur\\Slugify\\Slugify;\n\ntrait SluggableEngine\n{\n    /**\n     * Currently, eloquent-sluggable does not provide activeRuleset function, so to do it on your own for any language\n     * with following the key value rule pairs can be found within the link below.\n     *\n     * @link https://github.com/cocur/slugify/blob/3b29d43b0c0d6af590f998ddf096e6d8aaeb6634/src/RuleProvider/DefaultRuleProvider.php#L784\n     *\n     * @param \\Cocur\\Slugify\\Slugify $engine\n     * @param string $attribute\n     * @return \\Cocur\\Slugify\\Slugify\n     */\n    public function customizeSlugEngine(Slugify $engine, $attribute)\n    {\n        return $this-&gt;getTurkishEngine($engine);\n    }\n\n    /**\n     * @param \\Cocur\\Slugify\\Slugify $engine\n     *\n     * @return \\Cocur\\Slugify\\Slugify\n     */\n    protected function getTurkishEngine(Slugify $engine)\n    {\n        $engine-&gt;addRule('\u00c7', 'C');\n        $engine-&gt;addRule('\u011e', 'G');\n        $engine-&gt;addRule('\u0130', 'I');\n        $engine-&gt;addRule('\u015e', 'S');\n        $engine-&gt;addRule('\u00d6', 'O');\n        $engine-&gt;addRule('\u00dc', 'U');\n        $engine-&gt;addRule('\u011f', 'g');\n        $engine-&gt;addRule('\u0131', 'i');\n        $engine-&gt;addRule('\u015f', 's');\n        $engine-&gt;addRule('\u00f6', 'o');\n        $engine-&gt;addRule('\u00fc', 'u');\n        return $engine;\n    }\n}\n</code></pre>\n",
                    "OwnerUserId": "15084492",
                    "LastEditorUserId": "12340179",
                    "LastEditDate": "2021-03-01T23:33:31.273",
                    "LastActivityDate": "2021-03-01T23:33:31.273",
                    "Title": "Trait method customizeSlugEngine has not been applied, because there are collisions with other trait methods on App\\Base\\SluggableModel",
                    "Tags": "<php><laravel><content-management-system>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            }
        ],
        "Type": 2
    },
    "https://github.com/lingthio/Flask-User": {
        "CVE Description": [
            "This affects all versions of package Flask-User. When using the make_safe_url function, it is possible to bypass URL validation and redirect a user to an arbitrary URL by providing multiple back slashes such as /////evil.com/path or \\\\\\evil.com/path. This vulnerability is only exploitable if an alternative WSGI server other than Werkzeug is used, or the default behaviour of Werkzeug is modified using 'autocorrect_location_header=False."
        ],
        "Edges": [
            {
                "ParentSID": "34866439",
                "ParentRepo": "https://github.com/chintal/tendril",
                "StackOverflow_Post": {
                    "Id": "34866439",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "37462969",
                    "CreationDate": "2016-01-19T00:13:51.817",
                    "Score": "10",
                    "ViewCount": "1969",
                    "Body": "<p>I would like to know what the best practices are for using SQLALchemy declarative models within business logic code. Perhaps stackexchange.codereview may have a been a better place to ask this, but I'm not sure. </p>\n\n<p>Here's some background. </p>\n\n<p>Let's say I have a bunch of classes doing various things. Most of them have little or nothing to do with each other.Each such class has between a hundred to thousand lines of code doing things that have precious little to do with the database. In fact, most of the classes aren't even database aware so far. I've gotten away with storing the actual information in flat files (csv, yaml, so on), and only maintaining a serial number table and a document path - serial number mapping in the database. Each object retrieves the files it needs by getting the correct paths from the database (by serial number) and reconstructs itself from there. This has been exceedingly convenient so far, since my 'models' have been (and admittedly, continue to be) more than fluid. </p>\n\n<p>As I expand the involvement of the database in the codebase I currently have, I seem to have settled on the following model, separating the database bits and the business logic into two completely separate parts, and joining them using specific function calls instead of inheritance or even composition. Here is a basic example of the kind of code I have now (pseudocode-quality): </p>\n\n<p>module/db/models.py:</p>\n\n<pre><code>class Example(Base):\n    id = Column(...)\n    some_var = Column(...)\n</code></pre>\n\n<p>module/db/controller.py:</p>\n\n<pre><code>from .models import Example\n\ndef get_example_by_id(id, session):\n    return session.query(Example).filter_by(id=id).one()\n\ndef upsert_example(id=None, some_var=None, session):\n    if id is not None:\n        try:\n            example_obj = get_example_by_id(id, session)\n            example_obj.some_var = some_var\n            return\n        except:\n            pass\n    example_obj = Example(some_var=some_var)\n    session.add(example_obj)\n    session.flush()\n</code></pre>\n\n<p>module/example.py:</p>\n\n<pre><code>from db import controller\n\nclass Example(object):\n    def __init__(self, id):\n        self._id = id\n        self._some_var = None\n        try:\n            self._load_from_db()\n            self._defined = True\n        except:\n            self._defined = False\n\n    def _load_from_db(self, session):\n        db_obj = controller.get_example_by_id(self._id, session)\n        self._some_var = db_obj.some_var\n\n    def create(some_var, session):\n        if self._defined is True:\n            raise Exception\n        self._some_var = some_var\n        self._sync_to_db(session)\n\n    def _sync_to_db(self, session):\n        controller.upsert_example(self._some_var, session)\n\n    @property\n    def some_var(self):\n        return self._some_var\n\n    ... \n</code></pre>\n\n<p>I'm not convinced this is the way to go. </p>\n\n<p>I have a few models following this pattern, and many more that I should implement in time. The database is currently only used for persistence and archiving. Once something is in the database, it's more or less read only from there on in. However, querying on it is becoming important. </p>\n\n<p>The reason I'm inclined to migrate from the flatfiles to the database is largely to improve scalability. </p>\n\n<p>Thus far, if I wanted to find all instances (rows) of Example with some_var = 3, I'd have to construct all of the instances from the flat files and iterate through them. This seems like a waste of both processor time and memory. In many cases, some_var is actually a calculated property, and reached by a fairly expensive process using source data contained in the flat file. </p>\n\n<p>With the structure above, what I would do is query on Example, obtain a list of 'id's which satisfy my criterion, and then reconstruct just those module instances.</p>\n\n<p>The ORM approach, however, as I understand it, would use thick models, where the objects returned by the query are themselves the objects I would need. I'm wondering whether it makes sense to try to move to that kind of a structure.</p>\n\n<p>To that end, I have the following 'questions' / thoughts:</p>\n\n<ul>\n<li><p>My instinct is that the code snippets above are anti-patterns more than they are useful patterns. I can't put my finger on why, exactly, but I'm not very happy with it. Is there a real, tangible disadvantage to the structure as listed above? Would moving to a more ORM-ish design provide advantages in functionality / performance / maintainability over this approach?</p></li>\n<li><p>I'm paranoid about tying myself down to a database schema. I'm also paranoid about regular DB migrations. The approach listed above gives me a certain peace of mind in knowing that if I do need to do some migration, it'll be limited to the _load_from_db and _sync_to_db functions, and let me mess around willy nilly with all the rest of the code. </p>\n\n<ul>\n<li>I'm I wrong about the cost of migrations in the thick-Model approach being high?</li>\n<li>Is my sense of security in restricting my code's db involvement more of a false sense of security rather than a useful separation? </li>\n</ul></li>\n<li><p>If I wanted to integrate Example from module/db/models.py with Example from module/example.py in the example above, what would be the cleanest way to go about it. Alternatively, what is an accepted pattern for handling business-logic heavy models with SQLAlchemy?</p></li>\n<li><p>In the code above, note that the business logic class keeps all of it's information in 'private' instance variables, while the Model class keeps all of it's information in class variables. How would integrating these two approaches actually work? Theoretically, they should still 'just work' even if put together in a single class definition. In practice, does it?</p></li>\n</ul>\n\n<p>(The actual codebase is on <a href=\"https://github.com/chintal/tendril\" rel=\"noreferrer\">github</a>, though it's not likely to be very readable)</p>\n",
                    "OwnerUserId": "1934174",
                    "LastActivityDate": "2016-05-26T13:56:27.417",
                    "Title": "SQLAlchemy Declarative: How to merge models and existing business logic classes",
                    "Tags": "<python><design-patterns><orm><sqlalchemy>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "FavoriteCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "40168871",
                "ParentRepo": "https://github.com/lingthio/Flask-User-starter-app",
                "StackOverflow_Post": {
                    "Id": "40168871",
                    "PostTypeId": "1",
                    "CreationDate": "2016-10-21T05:13:02.340",
                    "Score": "1",
                    "ViewCount": "50",
                    "Body": "<p>I am trying to create a form which contains some standard inputs as well as a file input using flask and flask-WTForms. The base of my app is based off of this boilerplate: <a href=\"https://github.com/lingthio/Flask-User-starter-app\" rel=\"nofollow\">https://github.com/lingthio/Flask-User-starter-app</a>. </p>\n\n<p>I have a form declared as such:</p>\n\n<pre><code>class DataAnalysisForm(Form):\nspecies = SelectField('species', choices=[\n    ('ecoli', 'Escherichia Coli'),\n    ('yeast', 'Saccharomyces Cerevisiae')\n], validators=[validators.Required()])\nfileDataType = RadioField('fileType', choices=[\n    ('csv', 'Exponential fold changes (.csv)'),\n    ('fasta', 'Raw RNA-seq data (.fasta/.fastq) (does not work yet!)')\n], validators=[validators.Required()], default='csv')\n\ndef is_data_file(message=\"only csv or fasta files\", extensions=None):\n    if (not extensions):\n        extensions = ['csv', 'fasta', 'fastq']\n    def _is_data_file(form, field):\n        if (not field.data or field.data.split('.')[-1] not in extensions):\n            raise validators.ValidationError(message)\n    return _is_data_file\n\nseqFile = FileField('seq file', validators=[validators.Required('seq file required'), is_data_file()])\n</code></pre>\n\n<p>and an html template declared as such:</p>\n\n<pre><code>{% from \"common/form_macros.html\" import render_field, render_radio_field, render_submit_field %}\n&lt;form action=\"/data_analysis\" method=\"POST\" class=\"form analysis-form\" role=\"form\" enctype=\"multipart/form-data\"&gt;\n\n    {{ form.hidden_tag() }}\n\n    &lt;div class=\"form-group\"&gt;\n        &lt;label for=\"speciesSelect\" class=\"step-label\"&gt;Step 1: Select the species of your samples&lt;/label&gt;\n        {{ render_field(form.species, label_visible=False) }}\n    &lt;/div&gt;\n    &lt;div class=\"form-group fileType\"&gt;\n        &lt;label for=\"expressionData\" class=\"step-label\"&gt;Step 2: Upload the gene expression data&lt;/label&gt;\n        {{ render_radio_field(form.fileDataType) }}\n    &lt;/div&gt;\n    &lt;div class=\"form-group\"&gt;\n        {{ render_field(form.seqFile) }}\n        &lt;small id=\"fileHelp\" class=\"form-text text-muted form-item-shift\"&gt;Exponential fold changes are preferred in csv format. More information about input data format is here.&lt;/small&gt;\n    &lt;/div&gt;\n\n    &lt;button type=\"submit\" class=\"btn btn-primary job-submit-btn\"&gt;Submit&lt;/button&gt;\n&lt;/form&gt;\n\n{% endblock %}\n</code></pre>\n\n<p>I made sure to have the enctype be \"multipart/form-data\" but when I go to actually execute the upload, it straight up skips the file, or if I have any validation in there, it rejects all validation. It's as if the file is never even there. </p>\n\n<p>The software I use is:</p>\n\n<ul>\n<li>Flask-WTF == 0.12</li>\n<li>Flask     == 0.10.1</li>\n</ul>\n\n<p>is there any reason as to why it's bugging out like this? </p>\n",
                    "OwnerUserId": "1406443",
                    "LastActivityDate": "2016-10-21T05:13:02.340",
                    "Title": "Flask-WTForms skipping file processing",
                    "Tags": "<python><file-upload><flask><flask-wtforms>",
                    "AnswerCount": "0",
                    "CommentCount": "0",
                    "ClosedDate": "2016-10-21T13:36:42.923",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "67378142",
                "ParentRepo": "https://github.com/lfernandez55/3200_Final_Project_Challenge",
                "StackOverflow_Post": {
                    "Id": "67378142",
                    "PostTypeId": "2",
                    "ParentId": "67376323",
                    "CreationDate": "2021-05-04T02:46:37.740",
                    "Score": "2",
                    "Body": "<p>In <a href=\"https://stackoverflow.com/questions/61939800/role-based-authorization-in-flask-login\">Role based authorization in flask-login</a> the accepted answer appears to be using <a href=\"https://pypi.org/project/Flask-Principal/\" rel=\"nofollow noreferrer\">Flask-Principal</a> However, you can also do this with <a href=\"https://flask-user.readthedocs.io/en/latest/\" rel=\"nofollow noreferrer\">Flask-User</a> which seems to be more actively maintained.  There's a <a href=\"https://flask-user.readthedocs.io/en/latest/basic_app.html#\" rel=\"nofollow noreferrer\">superb basic-app for Flask-User</a> which spins up with a single app.py file. The app provides two roles (admin and manager) as well as three routes that demo the authentication and basic role based authorization that is provided by Flask-User.  They are pretty self-explanatory:</p>\n<pre><code># The Home page is accessible to anyone\n@app.route('/')\ndef home_page():\n\n# The Members page is only accessible to authenticated users\n@app.route('/members')\n@login_required    # Use of @login_required decorator\ndef member_page():\n\n# The Admin page requires an 'Admin' role.\n@app.route('/admin')\n@roles_required('Admin')    # Use of @roles_required decorator\ndef admin_page():\n</code></pre>\n<p>Flask-User can also be used to do more complex forms of authorization.  You can make more roles and then authorize routes to only allow users access if they have that role and/or another role. For example, you could make an admin, a teacher, and a student role.  And then  vary accessibility based on those roles and/or combination of roles.  Here's a couple of examples:</p>\n<pre><code>@admin_blueprint.route('/admin/teacher_or_admin')\n@roles_required(['admin', 'teacher'])  # requires admin OR teacher role\ndef admin_teacher_or_admin():\n    return &quot;You have the right roles to access this page - it requires admin OR teacher roles&quot;\n\n@admin_blueprint.route('/admin/teacher_and_admin')\n@roles_required('admin','teacher')  # requires admin AND teacher roles\ndef admin_teacher_and_admin():\n    return &quot;You have the right roles to access this view&quot;\n\n@admin_blueprint.route('/admin/student')\n@roles_required('student')  \ndef admin_student():\n    return &quot;You have the right roles to access this page - requires student role&quot;\n</code></pre>\n<p>Although it's not a single file like the basic-user app above, this repo demonstrates these more advanced flask-user authorization capabilities: <a href=\"https://github.com/lfernandez55/3200_Final_Project_Challenge\" rel=\"nofollow noreferrer\">https://github.com/lfernandez55/3200_Final_Project_Challenge</a></p>\n",
                    "OwnerUserId": "2421365",
                    "LastActivityDate": "2021-05-04T02:46:37.740",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "69246153",
                "ParentRepo": "https://github.com/kwiersma/flask-celery-sqlalchemy",
                "StackOverflow_Post": {
                    "Id": "69246153",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "69246912",
                    "CreationDate": "2021-09-19T18:43:18.207",
                    "Score": "0",
                    "ViewCount": "321",
                    "Body": "<p>I have a Flask application using Celery, and the async processing works fine when the app is running locally. However, when I try to test (pytest) a route that uses Celery tasks, I get this error:</p>\n<pre><code>app/bp_dir/routes.py:12: in &lt;module&gt;\n    from app import db, celery_tasks\napp/celery_tasks.py:13: in &lt;module&gt;\n    @celery.task()\nE   AttributeError: 'NoneType' object has no attribute 'task'\n</code></pre>\n<p>It seems that Celery is not being spun up correctly when I'm testing. I think the underlying question is how to set up pytest fixtures so that routes importing Celery tasks can be tested.</p>\n<p>app/celery_tasks.py looks like this:</p>\n<pre><code>from app import celeryapp\n\ncelery = celeryapp.celery\n\n@celery.task()\ndef example_task():\n    time.sleep(3)\n    return 1\n</code></pre>\n<p>app/<strong>init</strong>.py</p>\n<pre><code>...\nfrom app import celeryapp\n\n\ndef create_app(config_class=Config):\n    app = Flask(__name__)\n    app.config.from_object(Config)\n\n    ...\n\n    # Celery\n    celery = celeryapp.create_celery_app(app)\n    celeryapp.celery = celery\n\n    ...\n\n\n    return app\n</code></pre>\n<p>app/celeryapp/<strong>init</strong>.py</p>\n<pre><code>from celery import Celery\n\nCELERY_TASK_LIST = [\n    'app.celery_tasks',\n]\n\ndb_session = None\ncelery = None\n\ndef create_celery_app(_app=None):\n    &quot;&quot;&quot;\n    Create a new Celery object and tie together the Celery config to the app's config.\n    Wrap all tasks in the context of the Flask application.\n    :param _app: Flask app\n    :return: Celery app\n    &quot;&quot;&quot;\n\n    from app import db\n\n    celery = Celery(_app.import_name,\n                    backend=_app.config['CELERY_BACKEND_URL'],\n                    broker=_app.config['CELERY_BROKER_URL'],\n                    include=CELERY_TASK_LIST)\n\n    celery.conf.update(_app.config)\n    always_eager = _app.config['TESTING'] or False\n    celery.conf.update({'TASK_ALWAYS_EAGER': always_eager,\n                        'CELERY_RESULT_BACKEND': 'redis'})\n\n    TaskBase = celery.Task\n\n    class ContextTask(TaskBase):\n        abstract = True\n\n        def __call__(self, *args, **kwargs):\n            if not celery.conf.CELERY_ALWAYS_EAGER:\n                with _app.app_context():\n                    return TaskBase.__call__(self, *args, **kwargs)\n            else:\n                # special pytest setup\n                db.session = db_session\n                return TaskBase.__call__(self, *args, **kwargs)\n\n        def after_return(self, status, retval, task_id, args, kwargs, einfo):\n            &quot;&quot;&quot;\n            After each Celery task, teardown our db session.\n            FMI: https://gist.github.com/twolfson/a1b329e9353f9b575131\n            Flask-SQLAlchemy uses create_scoped_session at startup which avoids any setup on a\n            per-request basis. This means Celery can piggyback off of this initialization.\n            &quot;&quot;&quot;\n            if _app.config['SQLALCHEMY_COMMIT_ON_TEARDOWN']:\n                if not isinstance(retval, Exception):\n                    db.session.commit()\n\n            # If we aren't in an eager request (i.e. Flask will perform teardown), then teardown\n            if not celery.conf.CELERY_ALWAYS_EAGER:\n                db.session.remove()\n\n    celery.Task = ContextTask\n\n\n    return celery\n</code></pre>\n<p>app/celeryapp/celery_worker.py</p>\n<pre><code>from app import celeryapp, create_app\n\napp = create_app()\ncelery = celeryapp.create_celery_app(app)\nceleryapp.celery = celery\n</code></pre>\n<p>The code for the Celery set up is mostly borrowed from this [repo]<a href=\"https://github.com/kwiersma/flask-celery-sqlalchemy\" rel=\"nofollow noreferrer\">https://github.com/kwiersma/flask-celery-sqlalchemy</a>. The repo has tests [here]<a href=\"https://github.com/kwiersma/flask-celery-sqlalchemy/tree/master/tests\" rel=\"nofollow noreferrer\">https://github.com/kwiersma/flask-celery-sqlalchemy/tree/master/tests</a>, but I can't really see what I'm missing.</p>\n<p>/testing_fixtures.py</p>\n<pre><code>import re\nimport flask\nimport pytest\nfrom app import create_app, db\n\nEMAIL = 'testemail@gmail.com'\nPASSWORD = 'Password123!'\n\ndef get_codes(data_structure):\n    return [(str(x)) for x in range(len(data_structure))]\n\ndef extract_csrf_token(response: flask.Response) -&gt; str:\n    # is there better way to get CSRF token? I couldn't find one\n    return re.search('name=&quot;csrf_token&quot; type=&quot;hidden&quot; value=&quot;([^&quot;]*)&quot;', str(response.data)).group(1)\n\n@pytest.fixture\ndef flask_app():\n    app = create_app()\n    app.config['SQLALCHEMY_DATABASE_URI'] = &quot;sqlite://&quot;\n    app.config['TESTING'] = True\n    app.config['SECRET_KEY'] = 'this is crucial for storing section'\n    app.testing = True\n\n    return app\n\n@pytest.fixture\ndef app_context(flask_app):\n    with flask_app.app_context():\n        yield\n\n@pytest.fixture\ndef setup_db(app_context):\n    db.create_all()\n\n@pytest.fixture\ndef test_client(setup_db, flask_app):\n    with flask_app.test_client() as c:\n        yield c\n\n@pytest.fixture\ndef registered_user(test_client, flask_app):\n    resp = test_client.get(&quot;/auth/register&quot;)  # to get csrf_token\n    csrf_token = extract_csrf_token(resp)\n\n    # follow_redirect=False is important - otherwise you won't be able to tell the difference between successful\n    # and faulty registration\n    resp = test_client.post('/auth/register',\n                            data={'email': EMAIL, 'password': PASSWORD, 'password2': PASSWORD,\n                                  'csrf_token': csrf_token, 'is_test':True},\n                            follow_redirects=False)\n    assert resp.status_code == 302, &quot;/auth/register should redirect on successful registering&quot;\n\n@pytest.fixture\ndef logged_client(registered_user, test_client):\n    resp = test_client.get(&quot;/auth/login&quot;)  # to get csrf_token\n    csrf_token = extract_csrf_token(resp)\n\n    resp = test_client.post('/auth/login', data={'email': EMAIL, 'password': PASSWORD, 'csrf_token': csrf_token})\n\n    assert resp.status_code == 302, &quot;/auth/login should redirect to another page on successful login&quot;\n\n    yield test_client\n\n    resp = test_client.get('/auth/logout')\n    assert resp.status_code == 302\n</code></pre>\n<p>Example test:</p>\n<pre><code>from testing_fixtures import *\n\ndef test_example_route(logged_client):\n    response = logged_client.get('/example_route')\n    assert response.status_code == 200\n</code></pre>\n<p>Example route:</p>\n<pre><code>from app import db, celery_tasks\n...\n\n@example_bp.route('/example_route')\ndef example_route():\n\n    return 1\n\n</code></pre>\n",
                    "OwnerUserId": "5431333",
                    "LastActivityDate": "2021-09-20T17:13:01.180",
                    "Title": "Pytest, Flask, Celery - Celery NoneType Error",
                    "Tags": "<python><flask><celery><pytest>",
                    "AnswerCount": "1",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            }
        ],
        "Type": 2
    },
    "https://github.com/Tjatse/ansi-html/issues/19": {
        "CVE Description": [
            "This affects all versions of package ansi-html. If an attacker provides a malicious string, it will get stuck processing the input for an extremely long time."
        ],
        "Edges": [
            {
                "SID": "69548370",
                "StackOverflow_Post": {
                    "Id": "69548370",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "69591894",
                    "CreationDate": "2021-10-13T00:30:31.153",
                    "Score": "13",
                    "ViewCount": "11543",
                    "Body": "<h1>Overview</h1>\n<p>I am having trouble resolving a ReDoS vulnerability identified by <code>npm audit</code>. My application has a nested sub-dependency <code>ansi-html</code> that is vulnerable to attack, but unfortunately, it seems that the <a href=\"https://github.com/Tjatse/ansi-html/issues/19\" rel=\"nofollow noreferrer\">maintainers have gone AWOL</a>. As you can see in the comments section of that Github issue, to get around this problem, the community has made a fork of the repo called <code>ansi-html-community</code> located <a href=\"https://github.com/mahdyar/ansi-html-community\" rel=\"nofollow noreferrer\">here</a>, which addresses this vulnerability.</p>\n<p>Thus, I would like to replace all nested references of <code>ansi-html</code> with <code>ansi-html-community</code>.</p>\n<h1>Problem</h1>\n<p>My normal strategy of using <code>npm-force-resolutions</code> does not seem to be able to override nested sub-dependencies with a different package altogether but rather only the same packages that are a different version number. I have researched this for several hours, but unfortunately, the only way I have found to fix this <a href=\"https://github.com/Tjatse/ansi-html/issues/19#issuecomment-937690221\" rel=\"nofollow noreferrer\">would appear to be with yarn</a>, which I am now seriously considering using instead of npm. However, this is not ideal as our entire CI/CD pipeline is configured to use npm.</p>\n<p>Does anyone know of any other way to accomplish nested sub-dependency package substitution/resolution without having to switch over to using yarn?</p>\n<h1>Related Questions</h1>\n<p>These are questions of interest that I was able to find, but unfortunately, they tend to only discuss methods to override package version number, not the package itself.</p>\n<h5>Discusses how to override version number:</h5>\n<p><a href=\"https://stackoverflow.com/questions/15806152/how-do-i-override-nested-npm-dependency-versions\">How do I override nested NPM dependency versions?</a></p>\n<h5>Has a comment discussion about <code>npm shrinkwrap</code> (not ideal):</h5>\n<p><a href=\"https://stackoverflow.com/questions/32239240/npm-how-to-override-a-dependent-packages-dependencies\">npm - how to override a dependent package&#39;s dependencies?</a></p>\n",
                    "OwnerUserId": "12649786",
                    "LastEditorUserId": "12649786",
                    "LastEditDate": "2022-04-13T09:31:45.427",
                    "LastActivityDate": "2022-04-13T09:31:45.427",
                    "Title": "How to override a nested npm sub-dependency with a different package altogether (not just different package version number)?",
                    "Tags": "<node.js><npm>",
                    "AnswerCount": "2",
                    "CommentCount": "0",
                    "FavoriteCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            }
        ],
        "Type": 1
    },
    "https://github.com/gordon-matt/elFinder.NetCore": {
        "CVE Description": [
            "This affects all versions of package elFinder.NetCore. The Path.Combine(...) method is used to create an absolute file path. Due to missing sanitation of the user input and a missing check of the generated path its possible to escape the Files directory via path traversal"
        ],
        "Edges": [
            {
                "SID": "62709997",
                "StackOverflow_Post": {
                    "Id": "62709997",
                    "PostTypeId": "1",
                    "CreationDate": "2020-07-03T06:54:41.400",
                    "Score": "0",
                    "ViewCount": "308",
                    "Body": "<p>I am trying to integrate the javascript elfinder library into my asp.net 3.1 + angular 9 project, I can launch the example project (<a href=\"https://github.com/gordon-matt/elFinder.NetCore\" rel=\"nofollow noreferrer\">https://github.com/gordon-matt/elFinder.NetCore</a>) , it works perfectly but when I integrate everything in my project I get the error &quot;elfinder debug: [warning] [elfinder] The volume root statuses requires<code> volumeid</code> property. &quot; it is displayed 10 times then an error 500 appears, I do not understand where it comes from?</p>\n",
                    "OwnerUserId": "6933109",
                    "LastEditorUserId": "1839439",
                    "LastEditDate": "2020-07-03T12:12:09.610",
                    "LastActivityDate": "2021-05-18T09:35:10.337",
                    "Title": "Integrate elFinder.NetCore in project : [error] The volume root statuses requires `volumeid` property",
                    "Tags": "<angular><asp.net-core-3.1><elfinder>",
                    "AnswerCount": "2",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            }
        ],
        "Type": 2
    },
    "https://github.com/RIOT-OS/RIOT": {
        "CVE Description": [
            "RIOT OS version 2020.01.1 is vulnerable to integer wrap-around in its implementation of calloc function, which can lead to arbitrary memory allocation, resulting in unexpected behavior such as a crash or a remote code injection/execution."
        ],
        "Edges": [
            {
                "SID": "31791190",
                "StackOverflow_Post": {
                    "Id": "31791190",
                    "PostTypeId": "1",
                    "CreationDate": "2015-08-03T15:29:01.643",
                    "Score": "3",
                    "ViewCount": "729",
                    "Body": "<p>I am trying to build a the simple built in hello-world example of the RIOT-OS on an emulated msba2 board, emulated by QEMU (Linux host).\n<a href=\"https://github.com/RIOT-OS/RIOT\" rel=\"nofollow noreferrer\">https://github.com/RIOT-OS/RIOT</a>\n<a href=\"https://github.com/RIOT-OS/RIOT/wiki/Board%3A-MSBA2\" rel=\"nofollow noreferrer\">https://github.com/RIOT-OS/RIOT/wiki/Board%3A-MSBA2</a></p>\n\n<p>I've created a linux kernel image and root file system for the qemu using buildroot, here is the .config file:\n<a href=\"http://pastebin.com/t0aJK0n2\" rel=\"nofollow noreferrer\">http://pastebin.com/t0aJK0n2</a></p>\n\n<p>Here is the QEMU code I use:</p>\n\n<pre><code>sudo qemu-system-arm -M versatilepb -m 256M -kernel /mnt/zImage -initrd\n /mnt/rootfs.ext2.gz -hda /mnt/arm926t_snapshot.img  -no-reboot -append \n\"root=/dev/ram mem=256M ramdisk_size=700000 rdinit=/sbin/init panic=1 \nrootfstype=ext2 rw\" -serial stdio -net nic,macaddr=00:16:3e:00:00:01 -net \ntap,ifname=tap0,script=no,downscript=no -tftp 192.168.40.174\n</code></pre>\n\n<p>I downloaded the RIOT-OS from git and I also downloaded the toolchain suggested for ARM architecture here:\n<a href=\"https://github.com/RIOT-OS/RIOT/wiki/Family:-ARM\" rel=\"nofollow noreferrer\">https://github.com/RIOT-OS/RIOT/wiki/Family:-ARM</a></p>\n\n<p>Here I downloaded the CodeBench toolchain for Linux: arm-2014.05-28-arm-none-eabi-i686-pc-linux-gnu.tar.bz2\nI know that I am emulating an arm926t architecture on the qemu which is ARM9 architecture and I know that ARM7 != ARM9, but I am hoping that I understood this article well, which I think says that ARM7 should be compatible with ARM9</p>\n\n<p><a href=\"http://infocenter.arm.com/help/index.jsp?topic=/com.arm.doc.dvi0027b/ar01s02s01.html\" rel=\"nofollow noreferrer\">http://infocenter.arm.com/help/index.jsp?topic=/com.arm.doc.dvi0027b/ar01s02s01.html</a></p>\n\n<p>I am doing this becouse buildroot can not build ARM7 architecture, only ARM9 and Cortex-M3, and I need ARM architecture for this project for reasons.\nNow, RIOT only support ARM7, but it also supports Cortex-M3 which buildroot can do, but when I tried to build it I got the error message \"target CPU does not support ARM mode\" which I couldn't get past, so I remained with the ARM9 architecture.(help with this is appriciated)\nBut I am getting off topic here.</p>\n\n<p>running uname -a on the emulated board I get this:\n<a href=\"https://i.stack.imgur.com/3b4D4.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/3b4D4.png\" alt=\"enter image description here\"></a></p>\n\n<p>So using tftp I downloaded the RIOT and the arm-none-eabi-gcc from the host to the emulated msba2 board, added the arm-none-eabi-gcc to path using the following command:<code>export PATH=${PATH}:/home/arm-2014.05/bin/</code>\nand I went into the RIOT/examples/hello world and ran the following build command:</p>\n\n<pre><code>make BOARD=msba2\n</code></pre>\n\n<p>To which I get the following:\n<a href=\"https://i.stack.imgur.com/53s0f.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/53s0f.png\" alt=\"enter image description here\"></a></p>\n\n<p>Also if I try to just simply run arm-none-eabi-gcc I get the same thing.</p>\n\n<p>As you might guess I am very new to embedded systems,emulations , RIOT-OS, stackoverflow, or Linux as a matter of fact so I am sorry if this is a noob question or if I didnt give enough information about the matter.</p>\n",
                    "OwnerUserId": "3078328",
                    "LastEditorUserId": "4094489",
                    "LastEditDate": "2020-08-31T10:47:12.943",
                    "LastActivityDate": "2020-08-31T10:47:12.943",
                    "Title": "Building RIOT-OS hello-world example fails on QEMU emulated ARM board",
                    "Tags": "<gcc><makefile><arm><qemu><riot-os>",
                    "AnswerCount": "0",
                    "CommentCount": "6",
                    "FavoriteCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            }
        ],
        "Type": 2
    },
    "https://github.com/etcd-io/etcd": {
        "CVE Description": [
            "Authentication vulnerability found in Etcd-io v.3.4.10 allows remote attackers to escalate privileges via the debug function."
        ],
        "Edges": [
            {
                "ParentSID": "5860423",
                "ParentRepo": "https://github.com/spf13/viper",
                "StackOverflow_Post": {
                    "Id": "5860423",
                    "PostTypeId": "5",
                    "CreationDate": "2011-05-02T17:39:04.997",
                    "Score": "0",
                    "Body": "<p>Please consider using <a href=\"/questions/tagged/viper-architecture\" class=\"post-tag\" title=\"show questions tagged &#39;viper-architecture&#39;\" rel=\"tag\">viper-architecture</a>, <a href=\"/questions/tagged/viper-go\" class=\"post-tag\" title=\"show questions tagged &#39;viper-go&#39;\" rel=\"tag\">viper-go</a>, <a href=\"/questions/tagged/viper-mode\" class=\"post-tag\" title=\"show questions tagged &#39;viper-mode&#39;\" rel=\"tag\">viper-mode</a>, or <a href=\"/questions/tagged/viper-lang\" class=\"post-tag\" title=\"show questions tagged &#39;viper-lang&#39;\" rel=\"tag\">viper-lang</a> instead of this catch-all tag.</p>\n<ol>\n<li><strong>VIPER</strong> is an application architecture, which stands for <strong>View, Interactor, Presenter, Entity, and Router</strong>. VIPER is intended to divide app\u2019s logical structure into distinct layers of responsibility. It attempts to observe SOLID design patterns in the best way so as to keep code easily maintainable clean, reusable and testable.</li>\n<li><strong>Viper</strong> (mode) is also a Vi emulation package for Emacs.</li>\n<li><strong>Viper</strong> is also a configuration library for Golang at <a href=\"https://github.com/spf13/viper\" rel=\"nofollow noreferrer\">https://github.com/spf13/viper</a></li>\n<li><strong>Viper</strong> is an open-source verification infrastructure, designed to simplify the development of formal, separation-logic-based verifiers for different programming languages.</li>\n</ol>\n",
                    "OwnerUserId": "4634527",
                    "LastEditorUserId": "10871073",
                    "LastEditDate": "2021-05-17T18:38:28.577",
                    "LastActivityDate": "2021-05-17T18:38:28.577",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "11069838",
                "ParentRepo": "https://github.com/chrislusf/seaweedfs",
                "StackOverflow_Post": {
                    "Id": "11069838",
                    "PostTypeId": "2",
                    "ParentId": "1961191",
                    "CreationDate": "2012-06-17T08:05:06.423",
                    "Score": "10",
                    "Body": "<p>Use <a href=\"https://github.com/chrislusf/seaweedfs\" rel=\"nofollow\">Seaweed-FS</a> (used to be called Weed-FS), an implementation of Facebook's haystack paper.</p>\n\n<p>Seaweed-FS is very flexible and pared down to the basics. It was created to store billions of images and serve them fast.</p>\n",
                    "OwnerUserId": "997701",
                    "LastEditorUserId": "997701",
                    "LastEditDate": "2016-06-04T07:43:43.640",
                    "LastActivityDate": "2016-06-04T07:43:43.640",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "16031801",
                "ParentRepo": "https://github.com/coreos/etcd",
                "StackOverflow_Post": {
                    "Id": "16031801",
                    "PostTypeId": "2",
                    "ParentId": "2629680",
                    "CreationDate": "2013-04-16T08:07:05.153",
                    "Score": "210",
                    "Body": "<p>For me this is actually pretty simple:</p>\n<h1>The <em>subprocess</em> option:</h1>\n<p><code>subprocess</code> is <strong>for running other executables</strong> --- it's basically a wrapper around <code>os.fork()</code> and <code>os.execve()</code> with some support for optional plumbing (setting up PIPEs to and from the subprocesses.\nObviously you could use other inter-process communications (IPC) mechanisms, such as sockets, or Posix or SysV shared memory. But you're going to be limited to whatever interfaces and IPC channels are supported by the programs you're calling.</p>\n<p>Commonly, one uses any <code>subprocess</code> synchronously --- simply calling some external utility and reading back its output or awaiting its completion (perhaps reading its results from a temporary file, or after it's posted them to some database).</p>\n<p>However one can spawn hundreds of subprocesses and poll them.  My own personal favorite utility <a href=\"https://bitbucket.org/jimd/classh\" rel=\"noreferrer\">classh</a> does exactly that.\n<strong>The biggest disadvantage</strong> of the <code>subprocess</code> module is that I/O support is generally blocking.  There is a draft <a href=\"https://www.python.org/dev/peps/pep-3145/\" rel=\"noreferrer\" title=\"PEP 3145 -- Asynchronous I/O For subprocess.Popen\">PEP-3145</a> to fix that in some future version of Python 3.x and an alternative <a href=\"http://www.lysator.liu.se/%7Ebellman/download/asyncproc.py\" rel=\"noreferrer\" title=\"asyncproc.py\">asyncproc</a> (Warning that leads right to the download, not to any sort of documentation nor README).  I've also found that it's relatively easy to just import <code>fcntl</code> and manipulate your <code>Popen</code> PIPE file descriptors directly --- though I don't know if this is portable to non-UNIX platforms.</p>\n<p>(Update: 7 August 2019: Python 3 support for ayncio subprocesses: <a href=\"https://docs.python.org/3/library/asyncio-subprocess.html\" rel=\"noreferrer\">asyncio Subprocessses</a>)</p>\n<p><code>subprocess</code> <strong>has almost no event handling support</strong> ... <strong>though</strong> you can use the <code>signal</code> module and plain old-school UNIX/Linux signals --- killing your processes softly, as it were.</p>\n<h1>The <em>multiprocessing</em> option:</h1>\n<p><code>multiprocessing</code> is <strong>for running functions within your existing (Python) code</strong> with support for more flexible communications among this family of processes.\nIn particular it's best to build your <code>multiprocessing</code> IPC around the module's <code>Queue</code> objects where possible, but you can also use <code>Event</code> objects and various other features (some of which are, presumably, built around <code>mmap</code> support on the platforms where that support is sufficient).</p>\n<p>Python's <code>multiprocessing</code> module is intended to provide interfaces and features which are very <strong>similar to</strong> <code>threading</code> while allowing CPython to scale your processing among multiple CPUs/cores despite the GIL (Global Interpreter Lock).  It leverages all the fine-grained SMP locking and coherency effort that was done by developers of your OS kernel.</p>\n<h1>The <em>threading</em> option:</h1>\n<p><code>threading</code> is <strong>for a fairly narrow range of applications which are I/O bound</strong> (don't need to scale across multiple CPU cores) and which benefit from the extremely low latency and switching overhead of thread switching (with shared core memory) vs. process/context switching.  On Linux this is almost the empty set (Linux process switch times are extremely close to its thread-switches).</p>\n<p><code>threading</code> suffers from <strong>two major disadvantages in Python</strong>.</p>\n<p>One, of course, is implementation specific --- mostly affecting CPython.  That's the GIL.  For the most part, most CPython programs will not benefit from the availability of more than two CPUs (cores) and often performance will <em>suffer</em> from the GIL locking contention.</p>\n<p>The larger issue which is not implementation specific, is that threads share the same memory, signal handlers, file descriptors and certain other OS resources.  Thus the programmer must be extremely careful about object locking, exception handling and other aspects of their code which are both subtle and which can kill, stall, or deadlock the entire process (suite of threads).</p>\n<p>By comparison the <code>multiprocessing</code> model gives each process its own memory, file descriptors, etc.  A crash or unhandled exception in any one of them will only kill that resource and robustly handling the disappearance of a child or sibling process can be considerably easier than debugging, isolating and fixing or working around similar issues in threads.</p>\n<ul>\n<li>(Note: use of <code>threading</code> with major Python systems, such as <a href=\"http://www.numpy.org/\" rel=\"noreferrer\">NumPy</a>, may suffer considerably less from GIL contention than most of your own Python code would.  That's because they've been specifically engineered to do so; the native/binary portions of NumPy, for example, will release the GIL when that's safe).</li>\n</ul>\n<h1>The <em>twisted</em> option:</h1>\n<p>It's also worth noting that <a href=\"http://twistedmatrix.com/\" rel=\"noreferrer\" title=\"Twisted Matrix Labs\">Twisted</a> offers yet another alternative which is both <strong>elegant and very challenging to understand</strong>.  Basically, at the risk of over simplifying to the point where fans of Twisted may storm my home with pitchforks and torches, Twisted provides event-driven co-operative multi-tasking within any (single) process.</p>\n<p>To understand how this is possible one should read about the features of <code>select()</code> (which can be built around the <em>select()</em> or <em>poll()</em> or similar OS system calls).\nBasically it's all driven by the ability to make a request of the OS to sleep pending any activity on a list of file descriptors or some timeout.</p>\n<p>Awakening from each of these calls to <code>select()</code> is an event --- either one involving input available (readable) on some number of sockets or file descriptors, or buffering space becoming available on some other (writable) descriptors or sockets, some exceptional conditions (TCP out-of-band PUSH'd packets, for example), or a TIMEOUT.</p>\n<p>Thus the Twisted programming model is built around handling these events then looping on the resulting &quot;main&quot; handler, allowing it to dispatch the events to your handlers.</p>\n<p>I personally think of the name, <em><strong>Twisted</strong></em> as evocative of the programming model ... since your approach to the problem must be, in some sense, &quot;twisted&quot; inside out.  Rather than conceiving of your program as a series of operations on input data and outputs or results, you're writing your program as a service or daemon and defining how it reacts to various events.  (In fact the core &quot;main loop&quot; of a Twisted program is (usually?  always?) a <code>reactor()</code>).</p>\n<p>The <strong>major challenges to using Twisted</strong> involve twisting your mind around the event driven model and also eschewing the use of any class libraries or toolkits which are not written to co-operate within the Twisted framework.  This is why Twisted supplies its own modules for SSH protocol handling, for curses, and its own subprocess/Popen functions, and many other modules and protocol handlers which, at first blush, would seem to duplicate things in the Python standard libraries.</p>\n<p>I think it's useful to understand Twisted on a conceptual level even if you never intend to use it.  It may give insights into performance, contention, and event handling in your threading, multiprocessing and even subprocess handling as well as any distributed processing you undertake.</p>\n<p>(<strong>Note:</strong> Newer versions of Python 3.x are including <a href=\"https://docs.python.org/3/library/asyncio-task.html\" rel=\"noreferrer\">asyncio</a> (asynchronous I/O) features such as <em>async def</em>, the <em>@async.coroutine</em> decorator, and the <em>await</em> keyword, and <em>yield from future</em> support.  All of these are roughly similar to <strong>Twisted</strong> from a process (co-operative multitasking) perspective).\n(For the current status of Twisted support for Python 3, check out: <a href=\"https://twistedmatrix.com/documents/current/core/howto/python3.html\" rel=\"noreferrer\">https://twistedmatrix.com/documents/current/core/howto/python3.html</a>)</p>\n<h1>The <em>distributed</em> option:</h1>\n<p>Yet another realm of processing you haven't asked about, but which is worth considering, is that of <em><strong>distributed</strong></em> processing.  There are many Python tools and frameworks for distributed processing and parallel computation.  Personally I think the easiest to use is one which is least often considered to be in that space.</p>\n<p>It is almost trivial to build distributed processing around <a href=\"http://redis.io/\" rel=\"noreferrer\" title=\"Redis\">Redis</a>.  The entire key store can be used to store work units and results, Redis LISTs can be used as <code>Queue()</code> like object, and the PUB/SUB support can be used for <code>Event</code>-like handling. You can hash your keys and use values, replicated across a loose cluster of Redis instances, to store the topology and hash-token mappings to provide consistent hashing and fail-over for scaling beyond the capacity of any single instance for co-ordinating your workers and marshaling data (pickled, JSON, BSON, or YAML) among them.</p>\n<p>Of course as you start to build a larger scale and more sophisticated solution around Redis you are re-implementing many of the features that have already been solved using, <a href=\"http://www.celeryproject.org/\" rel=\"noreferrer\">Celery</a>, <a href=\"https://spark.apache.org/\" rel=\"noreferrer\">Apache Spark</a> and <a href=\"http://hadoop.apache.org/\" rel=\"noreferrer\">Hadoop</a>, <a href=\"https://zookeeper.apache.org/\" rel=\"noreferrer\">Zookeeper</a>, <a href=\"https://github.com/coreos/etcd\" rel=\"noreferrer\">etcd</a>, <a href=\"http://cassandra.apache.org/\" rel=\"noreferrer\">Cassandra</a> and so on.  Those all have modules for Python access to their services.</p>\n<p>[Update: A couple of resources for consideration if you're considering Python for computationally intensive across distributed systems: <a href=\"https://ipyparallel.readthedocs.io/en/latest/\" rel=\"noreferrer\">IPython Parallel</a> and <a href=\"https://spark.apache.org/docs/0.9.0/python-programming-guide.html\" rel=\"noreferrer\">PySpark</a>.  While these are general purpose distributed computing systems, they are particularly accessible and popular subsystems data science and analytics].</p>\n<h1>Conclusion</h1>\n<p>There you have the gamut of processing alternatives for Python, from single threaded, with simple synchronous calls to sub-processes, pools of polled subprocesses, threaded and multiprocessing, event-driven co-operative multi-tasking, and out to distributed processing.</p>\n",
                    "OwnerUserId": "149076",
                    "LastEditorUserId": "149076",
                    "LastEditDate": "2022-01-28T19:40:05.060",
                    "LastActivityDate": "2022-01-28T19:40:05.060",
                    "CommentCount": "6",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "24371790",
                "ParentRepo": "https://github.com/kelseyhightower/confd",
                "StackOverflow_Post": {
                    "Id": "24371790",
                    "PostTypeId": "2",
                    "ParentId": "24361195",
                    "CreationDate": "2014-06-23T17:25:09.987",
                    "Score": "2",
                    "Body": "<p>Yes, this is absolutely possible. It involves two steps:</p>\n\n<ol>\n<li><p>Service discovery for the docker containers that make up your development environments. This means writing their IP:port combo into etcd when the containers are started.\nThis blog post goes into detail on the service registration part of it: <a href=\"http://coreos.com/blog/zero-downtime-frontend-deploys-vulcand/\" rel=\"nofollow\">http://coreos.com/blog/zero-downtime-frontend-deploys-vulcand/</a></p></li>\n<li><p>Using confd to dynamically write out your nginx config. Confd will read from etcd and use a loop to set up your server blocks. Nginx will then be reloaded to apply the new settings.\nYou can see this all put together in this blog post: <a href=\"http://marceldegraaf.net/2014/04/24/experimenting-with-coreos-confd-etcd-fleet-and-cloudformation.html\" rel=\"nofollow\">http://marceldegraaf.net/2014/04/24/experimenting-with-coreos-confd-etcd-fleet-and-cloudformation.html</a></p></li>\n</ol>\n\n<p>Confd Github:\n<a href=\"https://github.com/kelseyhightower/confd\" rel=\"nofollow\">https://github.com/kelseyhightower/confd</a></p>\n",
                    "OwnerUserId": "3109085",
                    "LastActivityDate": "2014-06-23T17:25:09.987",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "25454760",
                "ParentRepo": "https://github.com/openshift/origin",
                "StackOverflow_Post": {
                    "Id": "25454760",
                    "PostTypeId": "2",
                    "ParentId": "25400838",
                    "CreationDate": "2014-08-22T20:00:26.340",
                    "Score": "2",
                    "Body": "<blockquote>\n  <p>Is docker supported in openshift origin or online as of now or it will be there in future release of V3? If yes, how does it work?</p>\n</blockquote>\n\n<p>We just released the V3 repo here so it is in Origin <a href=\"https://github.com/openshift/origin\" rel=\"nofollow\">https://github.com/openshift/origin</a>.</p>\n\n<blockquote>\n  <p>I have seen there are different docker images available for openshift in docker hub here. How do these work?</p>\n</blockquote>\n\n<p><em>You answered this in the comments, just clarifying here for visibility.</em><br>\nLinux containers, or \u201cGears\u201d, have always been a core component of OpenShift. Docker is new standard for containerization through the libcontainer project. To quote this great article <a href=\"https://www.openshift.com/blogs/openshift-v3-platform-combines-docker-kubernetes-atomic-and-more\" rel=\"nofollow\">https://www.openshift.com/blogs/openshift-v3-platform-combines-docker-kubernetes-atomic-and-more</a>:</p>\n\n<p>The OpenShift v3 Cartridge format will adopt the Docker packaging model and enable users to leverage any application component packaged as a Docker image. This will enable developers to tap into the Docker Hub community to both access and share container images to use in OpenShift. Customers will also be able to leverage Red Hat certified container images from both Red Hat and our ISV partners. Our recently launched OpenShift Marketplace will expand to include solutions from both SaaS partners and certified ISV\u2019s.<br>\n......<br>\nIn OpenShift v3, we will be integrating Kubernetes in the OpenShift Broker to drive container orchestration.</p>\n\n<blockquote>\n  <p>Docker is mainly for provisioning application portability, say I already have an application running in my docker installed locally, so how can this be migrated to openshift environment, or, how in openshift docker can images be created?</p>\n</blockquote>\n\n<p>I'm quoting from the article again, but \"The OpenShift v3 Cartridge format will adopt the Docker packaging model and enable users to leverage any application component packaged as a Docker image. This will enable developers to tap into the Docker Hub community to both access and share container images to use in OpenShift\"</p>\n",
                    "OwnerUserId": "1914161",
                    "LastActivityDate": "2014-08-22T20:00:26.340",
                    "CommentCount": "3",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "25650410",
                "ParentRepo": "https://github.com/rqlite/rqlite",
                "StackOverflow_Post": {
                    "Id": "25650410",
                    "PostTypeId": "2",
                    "ParentId": "16032825",
                    "CreationDate": "2014-09-03T17:33:46.473",
                    "Score": "21",
                    "Body": "<p>I used the Raft consensus protocol to replicate my SQLite database. You can find the system here:</p>\n\n<p><a href=\"https://github.com/rqlite/rqlite\" rel=\"noreferrer\">https://github.com/rqlite/rqlite</a></p>\n",
                    "OwnerUserId": "2019554",
                    "LastEditorUserId": "399759",
                    "LastEditDate": "2019-05-10T17:11:15.260",
                    "LastActivityDate": "2019-05-10T17:11:15.260",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "26882837",
                "ParentRepo": "https://github.com/coreos/flannel",
                "StackOverflow_Post": {
                    "Id": "26882837",
                    "PostTypeId": "1",
                    "CreationDate": "2014-11-12T08:56:04.503",
                    "Score": "-1",
                    "ViewCount": "474",
                    "Body": "<p>I am very new to flannel overlay network with kubernetes, we want to know how packets are transmitted across container in different host using flannel overlay network, below mentioned reference link which contains diagram in order to transmit packet between container in different host, can any one explain how its happen? Reference link ::  <a href=\"https://github.com/coreos/flannel\" rel=\"nofollow\">https://github.com/coreos/flannel</a></p>\n",
                    "OwnerUserId": "4040083",
                    "LastActivityDate": "2014-11-13T21:32:02.457",
                    "Title": "Need help to understand Overlay Network formed by Flannel",
                    "Tags": "<kubernetes>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "30823095",
                "ParentRepo": "https://github.com/rancherio/rancher",
                "StackOverflow_Post": {
                    "Id": "30823095",
                    "PostTypeId": "5",
                    "CreationDate": "2015-06-13T20:12:51.900",
                    "Score": "0",
                    "Body": "<p>Rancher is an open source project that provides a complete platform for operating Docker in production. It provides infrastructure services such as multi-host networking, global and local load balancing, and volume snapshots. It integrates native Docker management capabilities such as Docker Machine and Docker Swarm. It offers a rich user experience that enables devops admins to operate Docker in production at large scale.</p>\n\n<p><a href=\"https://github.com/rancherio/rancher\" rel=\"nofollow\">https://github.com/rancherio/rancher</a></p>\n",
                    "OwnerUserId": "4857050",
                    "LastEditorUserId": "4857050",
                    "LastEditDate": "2015-06-14T00:23:10.677",
                    "LastActivityDate": "2015-06-14T00:23:10.677",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "31076772",
                "ParentRepo": "https://github.com/go-kit/kit/tree/master/log",
                "StackOverflow_Post": {
                    "Id": "31076772",
                    "PostTypeId": "2",
                    "ParentId": "16895651",
                    "CreationDate": "2015-06-26T15:17:01.493",
                    "Score": "65",
                    "Body": "<p>Some more suggestions, now that the existing answers are quite old:</p>\n\n<ul>\n<li><a href=\"https://github.com/op/go-logging\" rel=\"noreferrer\">https://github.com/op/go-logging</a> - smaller than the other here</li>\n<li><a href=\"https://github.com/sirupsen/logrus\" rel=\"noreferrer\">https://github.com/sirupsen/logrus</a> - used in many popular projects such as Docker</li>\n<li><a href=\"https://github.com/inconshreveable/log15\" rel=\"noreferrer\">https://github.com/inconshreveable/log15</a></li>\n<li><a href=\"https://github.com/golang/glog\" rel=\"noreferrer\">https://github.com/golang/glog</a> - from Google, implementation of their C++ glog library in Go</li>\n<li><a href=\"https://github.com/go-kit/kit/tree/master/log\" rel=\"noreferrer\">https://github.com/go-kit/kit/tree/master/log</a> focused on \"structured logging\" which is better for tools to consume</li>\n<li><a href=\"https://github.com/uber-go/zap\" rel=\"noreferrer\">https://github.com/uber-go/zap</a> - \"blazing fast\"</li>\n</ul>\n",
                    "OwnerUserId": "448734",
                    "LastEditorUserId": "474189",
                    "LastEditDate": "2019-06-25T08:13:54.373",
                    "LastActivityDate": "2019-06-25T08:13:54.373",
                    "CommentCount": "3",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "32282075",
                "ParentRepo": "https://github.com/mailgun/vulcand",
                "StackOverflow_Post": {
                    "Id": "32282075",
                    "PostTypeId": "2",
                    "ParentId": "32281691",
                    "CreationDate": "2015-08-29T02:17:21.313",
                    "Score": "0",
                    "Body": "<p>You could run a proxy on your host that can be notified by the container after it receives the port from the master service, and which will then set up the necessary port forwarding.</p>\n\n<p>Something like <a href=\"https://github.com/mailgun/vulcand\" rel=\"nofollow\">vulcand</a>, which is an <code>etcd</code> backed proxy, might fit the bill.</p>\n",
                    "OwnerUserId": "147356",
                    "LastActivityDate": "2015-08-29T02:17:21.313",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "33577228",
                "ParentRepo": "https://github.com/minio/mc",
                "StackOverflow_Post": {
                    "Id": "33577228",
                    "PostTypeId": "2",
                    "ParentId": "28196954",
                    "CreationDate": "2015-11-06T23:35:13.953",
                    "Score": "1",
                    "Body": "<p>As an alternative to <code>s3cmd</code>, <code>aws-cli</code> - you might consider using <a href=\"https://github.com/minio/mc\" rel=\"nofollow\">https://github.com/minio/mc</a> </p>\n\n<p><code>mc</code> implements <code>mc mirror</code> command to recursively sync files and directories to multiple destinations in parallel. </p>\n\n<p>Features a cool progress bar and session management for resumable copy/mirror operations. </p>\n\n<pre><code>$ mc mirror\nNAME:\n   mc mirror - Mirror folders recursively from a single source to many destinations.\n\nUSAGE:\n   mc mirror SOURCE TARGET [TARGET...]\n\nEXAMPLES:\n   1. Mirror a bucket recursively from Minio cloud storage to a bucket on Amazon S3 cloud storage.\n      $ mc mirror https://play.minio.io:9000/photos/2014 https://s3.amazonaws.com/backup-photos\n\n   2. Mirror a local folder recursively to Minio cloud storage and Amazon S3 cloud storage.\n      $ mc mirror backup/ https://play.minio.io:9000/archive https://s3.amazonaws.com/archive\n\n   3. Mirror a bucket from aliased Amazon S3 cloud storage to multiple folders on Windows.\n      $ mc mirror s3/documents/2014/ C:\\backup\\2014 C:\\shared\\volume\\backup\\2014\n\n   4. Mirror a local folder of non english character recursively to Amazon s3 cloud storage and Minio cloud storage.\n      $ mc mirror \u672c\u8a9e/ s3/mylocaldocuments play/backup\n\n   5. Mirror a local folder with space characters to Amazon s3 cloud storage\n      $ mc mirror 'workdir/documents/Aug 2015' s3/miniocloud\n</code></pre>\n\n<p>Hope this helps. </p>\n",
                    "OwnerUserId": "4465767",
                    "LastEditorUserId": "4465767",
                    "LastEditDate": "2015-11-09T06:44:35.040",
                    "LastActivityDate": "2015-11-09T06:44:35.040",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "35812932",
                "ParentRepo": "https://github.com/minio/minio",
                "StackOverflow_Post": {
                    "Id": "35812932",
                    "PostTypeId": "2",
                    "ParentId": "23991694",
                    "CreationDate": "2016-03-05T10:25:11.387",
                    "Score": "16",
                    "Body": "<p>You can try installing <a href=\"https://github.com/minio/minio\" rel=\"noreferrer\">minio</a> server on your laptop/system, its open source &amp; single static binary. Server is S3 compatible. Then you can try <a href=\"https://github.com/minio/minio-java\" rel=\"noreferrer\">minio-java client library</a> for all operations, following is basic <a href=\"https://github.com/minio/minio-java/tree/master/examples\" rel=\"noreferrer\">operations example</a>.</p>\n\n<p>Installing minio server [GNU/Linux]</p>\n\n<pre><code>$ wget https://dl.minio.io/server/minio/release/linux-amd64/minio\n$ chmod 755 minio\n$ ./minio --help  \n</code></pre>\n\n<p>Hope it helps\nDisclaimer: I work for <a href=\"https://www.minio.io\" rel=\"noreferrer\">Minio</a></p>\n",
                    "OwnerUserId": "2390296",
                    "LastEditorUserId": "4465767",
                    "LastEditDate": "2016-03-05T11:19:16.877",
                    "LastActivityDate": "2016-03-05T11:19:16.877",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "36322854",
                "ParentRepo": "https://github.com/rancher/rancher/issues/4175",
                "StackOverflow_Post": {
                    "Id": "36322854",
                    "PostTypeId": "2",
                    "ParentId": "32703465",
                    "CreationDate": "2016-03-31T02:00:41.237",
                    "Score": "1",
                    "Body": "<p>It looks like you are doing the same thing I did: running Rancher and a Rancher agent on the same machine.\nTake a look at this <a href=\"https://github.com/rancher/rancher/issues/4175\" rel=\"nofollow noreferrer\">github issue</a>. The TLDR; Look under Admin > Settings  for the Host Registration URL. Make sure it isn't set to localhost.</p>\n\n<p><a href=\"https://i.stack.imgur.com/8UoTa.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/8UoTa.png\" alt=\"Rancher Host Registration URL\"></a></p>\n",
                    "OwnerUserId": "130006",
                    "LastActivityDate": "2016-03-31T02:00:41.237",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "36490644",
                "ParentRepo": "https://github.com/hyperledger/fabric",
                "StackOverflow_Post": {
                    "Id": "36490644",
                    "PostTypeId": "2",
                    "ParentId": "36422491",
                    "CreationDate": "2016-04-08T02:43:07.797",
                    "Score": "2",
                    "Body": "<p>The Linux Foundation's <a href=\"https://github.com/hyperledger/fabric\" rel=\"nofollow\">Hyperledger Project</a> implements a blockchain that does not require a currency/incentive. There are others that have emerged recently including JP Morgan's <a href=\"https://github.com/buckie/juno\" rel=\"nofollow\">Juno</a> and Intel's <a href=\"http://intelledger.github.io\" rel=\"nofollow\">IntelLedger</a>.</p>\n",
                    "OwnerUserId": "4774061",
                    "LastActivityDate": "2016-04-08T02:43:07.797",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "36590296",
                "ParentRepo": "https://github.com/etcd-io/etcd/blob/master/client/keys.go#L158",
                "StackOverflow_Post": {
                    "Id": "36590296",
                    "PostTypeId": "2",
                    "ParentId": "36589813",
                    "CreationDate": "2016-04-13T06:28:06.777",
                    "Score": "4",
                    "Body": "<p>Is there any way that you can take advantage of zero values?  All data types get initialized to a zero value, so that is a form of default logic.</p>\n\n<p>An options object is a pretty common idiom. The <a href=\"https://github.com/etcd-io/etcd/blob/master/client/keys.go#L158\" rel=\"nofollow noreferrer\">etcd client library</a> has some examples (SetOptions,GetOptions,DeleteOptions) similar to the following.</p>\n\n<pre class=\"lang-go prettyprint-override\"><code>type MyOptions struct {\n    Field1 int      // zero value (default) of int is 0\n    Field2 string   // zero value (default) of string is \"\"\n}\n\nfunc DoAction(arg1, arg2 string, options *MyOptions){\n    var defaultValue1 int = 30        // some reasonable default\n    var defaultValue2 string = \"west\" // some reasonable default\n\n    if options != nil {\n        defaultValue1 = options.Field1 // override with our values\n        defaultValue2 = options.Field2 \n    }\n    doStuffWithValues\n</code></pre>\n\n<p>An relevant question (and very much in the mindset of Go) would be, do you need this kind of complexity?  The flexibility is nice, but most things in the standard library try to only deal with 1 default piece of info/logic at a time to avoid this.</p>\n",
                    "OwnerUserId": "151825",
                    "LastEditorUserId": "151825",
                    "LastEditDate": "2019-03-20T18:08:40.607",
                    "LastActivityDate": "2019-03-20T18:08:40.607",
                    "CommentCount": "7",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "36920089",
                "ParentRepo": "https://github.com/lytics/metafora/blob/8ec2f856db6abe826989b255a02908fc3f0c5eef/m_etcd/transport.go#L73",
                "StackOverflow_Post": {
                    "Id": "36920089",
                    "PostTypeId": "2",
                    "ParentId": "36902925",
                    "CreationDate": "2016-04-28T16:11:43.340",
                    "Score": "0",
                    "Body": "<p><strong>With the new Client:</strong></p>\n\n<p>You use the GetOptions.Quorum : <a href=\"https://github.com/coreos/etcd/blob/master/client/keys.go#L211\" rel=\"nofollow\">https://github.com/coreos/etcd/blob/master/client/keys.go#L211</a></p>\n\n<p>Which you pass to the KeysAPI.Getcall: <a href=\"https://github.com/coreos/etcd/blob/master/client/keys.go#L103\" rel=\"nofollow\">https://github.com/coreos/etcd/blob/master/client/keys.go#L103</a></p>\n\n<p><strong>With the old client:</strong></p>\n\n<p>You use the SetConsistency func on the client.\n<code>\n    c := etcd.NewClient(hosts)\n    if err := c.SetConsistency(etcd.STRONG_CONSISTENCY); err != nil {\n        return nil, err\n    }\n</code>\nexample: <a href=\"https://github.com/lytics/metafora/blob/8ec2f856db6abe826989b255a02908fc3f0c5eef/m_etcd/transport.go#L73\" rel=\"nofollow\">https://github.com/lytics/metafora/blob/8ec2f856db6abe826989b255a02908fc3f0c5eef/m_etcd/transport.go#L73</a></p>\n",
                    "OwnerUserId": "118201",
                    "LastActivityDate": "2016-04-28T16:11:43.340",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "36924484",
                "ParentRepo": "https://github.com/kubernetes/kubernetes.github.io/issues/458",
                "StackOverflow_Post": {
                    "Id": "36924484",
                    "PostTypeId": "2",
                    "ParentId": "36920171",
                    "CreationDate": "2016-04-28T20:04:23.567",
                    "Score": "75",
                    "Body": "<p>You could do it via the REST API using the <a href=\"https://github.com/kubernetes/kubernetes/blob/release-1.2/docs/devel/api-conventions.md#patch-operations\" rel=\"noreferrer\">PATCH verb</a>. However, an easier way is to use <a href=\"http://kubernetes.io/docs/user-guide/kubectl/kubectl_patch/\" rel=\"noreferrer\">kubectl patch</a>. The following command updates your app's tag:</p>\n\n<pre><code>kubectl patch deployment myapp-deployment -p \\\n  '{\"spec\":{\"template\":{\"spec\":{\"containers\":[{\"name\":\"myapp\",\"image\":\"172.20.34.206:5000/myapp:img:3.0\"}]}}}}'\n</code></pre>\n\n<p>According to <a href=\"http://kubernetes.io/docs/user-guide/kubectl/kubectl_patch/\" rel=\"noreferrer\">the documentation</a>, YAML format should be accepted as well. See <a href=\"https://github.com/kubernetes/kubernetes.github.io/issues/458\" rel=\"noreferrer\">Kubernetes issue #458</a> though (and in particular <a href=\"https://github.com/kubernetes/kubernetes.github.io/issues/458#issuecomment-216371921\" rel=\"noreferrer\">this comment</a>) which may hint at a problem.</p>\n",
                    "OwnerUserId": "420061",
                    "LastEditorUserId": "420061",
                    "LastEditDate": "2016-05-17T00:02:49.360",
                    "LastActivityDate": "2016-05-17T00:02:49.360",
                    "CommentCount": "4",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "37568724",
                "ParentRepo": "https://github.com/nginxinc/kubernetes-ingress",
                "StackOverflow_Post": {
                    "Id": "37568724",
                    "PostTypeId": "2",
                    "ParentId": "37557103",
                    "CreationDate": "2016-06-01T12:31:10.703",
                    "Score": "0",
                    "Body": "<p>You could use the ingress routing for this: </p>\n\n<ul>\n<li><a href=\"http://kubernetes.io/docs/user-guide/ingress/\" rel=\"nofollow\">http://kubernetes.io/docs/user-guide/ingress/</a></li>\n<li><a href=\"http://blog.kubernetes.io/2016/03/Kubernetes-1.2-and-simplifying-advanced-networking-with-Ingress.html\" rel=\"nofollow\">http://blog.kubernetes.io/2016/03/Kubernetes-1.2-and-simplifying-advanced-networking-with-Ingress.html</a>\n\n<ul>\n<li><a href=\"https://github.com/nginxinc/kubernetes-ingress\" rel=\"nofollow\">https://github.com/nginxinc/kubernetes-ingress</a></li>\n</ul></li>\n</ul>\n\n<p>Also to not use ingress you could setup services type <code>LoadBalancer</code> and then create CNAMEs to the ELB matching the domains you want to route.  </p>\n",
                    "OwnerUserId": "720502",
                    "LastActivityDate": "2016-06-01T12:31:10.703",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "38142529",
                "ParentRepo": "https://github.com/sorintlab/stolon",
                "StackOverflow_Post": {
                    "Id": "38142529",
                    "PostTypeId": "2",
                    "ParentId": "38140136",
                    "CreationDate": "2016-07-01T10:01:30.493",
                    "Score": "1",
                    "Body": "<ul>\n<li><p>one solution is to deploy HA postgresql, for example <a href=\"https://github.com/sorintlab/stolon\" rel=\"nofollow\">https://github.com/sorintlab/stolon</a></p></li>\n<li><p>another is to have some network storage attached to all nodes(NFS, glusterFS) and use volumeMounts in the pods</p></li>\n</ul>\n",
                    "OwnerUserId": "897410",
                    "LastActivityDate": "2016-07-01T10:01:30.493",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "38719782",
                "ParentRepo": "https://github.com/docker/swarmkit/issues/1077",
                "StackOverflow_Post": {
                    "Id": "38719782",
                    "PostTypeId": "2",
                    "ParentId": "38717965",
                    "CreationDate": "2016-08-02T11:56:26.557",
                    "Score": "5",
                    "Body": "<p>\"Inner\" load balancing? Not exactly.<br>\n<a href=\"https://github.com/docker/docker/commit/ea4fef2d875de39044ca7570c35365b75086e8a5\" rel=\"noreferrer\">Commit ea4fef2</a> documents it (<a href=\"https://github.com/docker/docker/blob/ea4fef2d875de39044ca7570c35365b75086e8a5/docs/swarm/key-concepts.md#load-balancing\" rel=\"noreferrer\"><code>docs/swarm/key-concepts.md</code></a>) as </p>\n\n<blockquote>\n  <p>Swarm uses <strong>ingress load balancing</strong> to expose the services you want to make available externally to the Swarm.<br>\n  Swarm can automatically assign the service a <code>PublishedPort</code> or you can configure a <code>PublishedPort</code> for the service in the 30000-32767 range.<br>\n  External components, such as cloud load balancers, can access the service on the <code>PublishedPort</code> of any node in the cluster, even if the node is not currently running the service.</p>\n  \n  <p>Swarm has an internal DNS component that automatically assigns each service in the Swarm DNS entry.<br>\n  Swarm uses <strong>internal load balancing</strong> to distribute requests among services within the cluster based upon the services' DNS name.</p>\n</blockquote>\n\n<p>Right now (docker 1.12 August 2016), that inner load balancing does not work consistently: <a href=\"https://github.com/docker/docker/issues/25325\" rel=\"noreferrer\">issue 25325</a></p>\n\n<blockquote>\n<pre><code>\u279c  ~ time curl http://10.218.3.5:30000\nI'm 272dd0310a95\ncurl http://10.218.3.5:30000  0.01s user 0.01s system 6% cpu 0.217 total\n\u279c  ~ time curl http://10.218.3.5:30000\ncurl: (7) Failed to connect to 10.218.3.5 port 30000: Operation timed out\n</code></pre>\n</blockquote>\n\n<p>And <a href=\"https://github.com/docker/swarmkit/issues/1077\" rel=\"noreferrer\">swarmkit issue 1077</a> illustrates there is no plan yet to </p>\n\n<blockquote>\n  <p>provide capabilities for session stickiness (cookie-based etc.) in this router mesh.<br>\n  As awesome as it would be, not all apps are stateless, and we need to route users to the proper container in certain cases</p>\n</blockquote>\n\n<p>Because:</p>\n\n<blockquote>\n  <p>since we do load balancing at L3/L4 it cannot be bases on things like session cookie.<br>\n  The best that can be done is to have Source IP based stickiness. </p>\n</blockquote>\n\n<p>And source IP is not always good enough:</p>\n\n<blockquote>\n  <p>That wouldn't work for our case.<br>\n  We would have an upstream load balancer (F5) which would make traffic appear to come from a single IP, the \"SNAT pool\" IP on the F5 since it is a full proxy.<br>\n  Effectively, Source IP based stickiness would cause all requests to go to one container since all the source IPs would come from the same address.</p>\n</blockquote>\n\n<p>So the internal load balancer remains quite \"basic\":</p>\n\n<blockquote>\n  <p>The main issue with adding \"session stickyness\" is that there are a hundred ways to do it.<br>\n  It is also an L7 feature, whereas <strong>our load balancing operates at L3/4</strong>.</p>\n  \n  <p>There are two high-level paths here:</p>\n  \n  <ul>\n  <li>Monitor events coming from the docker API to modify F5 state to route directly task slots.</li>\n  <li>Integrate with libnetwork and have the loadbalancer operate as an L7 LB would if it were running directly in the swarm.</li>\n  </ul>\n</blockquote>\n\n<p>The conclusion for now is:</p>\n\n<blockquote>\n  <p>If you want to handle all aspects of load balancing and not use IPVS, you can disable it by running services in DNSRR mode. You can run any load balancer inside of swarm to do load balancing, bypassing the service VIP and populate backends with the DNSRR entries.</p>\n</blockquote>\n\n<p>That is why the latest release 1.12 has, with <a href=\"https://github.com/docker/swarmkit/pull/827\" rel=\"noreferrer\">PR 827</a>, added support for DNSRR mode and disabling ingress.</p>\n",
                    "OwnerUserId": "6309",
                    "LastActivityDate": "2016-08-02T11:56:26.557",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "39400797",
                "ParentRepo": "https://github.com/Qihoo360/pika",
                "StackOverflow_Post": {
                    "Id": "39400797",
                    "PostTypeId": "2",
                    "ParentId": "39394284",
                    "CreationDate": "2016-09-08T21:56:59.273",
                    "Score": "3",
                    "Body": "<p>Maybe Pika? <a href=\"https://github.com/Qihoo360/pika\" rel=\"nofollow\">https://github.com/Qihoo360/pika</a></p>\n\n<blockquote>\n  <p>\"Pika is a persistent huge storage service , compatible with the vast\n  majority of redis interfaces (details), including string, hash, list,\n  zset, set and management interfaces. With the huge amount of data\n  stored, redis may suffer for a capacity bottleneck, and pika was born\n  for solving it. Except huge storage capacity, pika also support\n  master-slave mode by slaveof command, including full and partial\n  synchronization\"</p>\n</blockquote>\n",
                    "OwnerUserId": "307976",
                    "LastEditorUserId": "307976",
                    "LastEditDate": "2016-09-09T01:01:24.860",
                    "LastActivityDate": "2016-09-09T01:01:24.860",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "39456322",
                "ParentRepo": "https://github.com/kubernetes/autoscaler/tree/master/cluster-autoscaler",
                "StackOverflow_Post": {
                    "Id": "39456322",
                    "PostTypeId": "2",
                    "ParentId": "39454375",
                    "CreationDate": "2016-09-12T18:13:54.480",
                    "Score": "2",
                    "Body": "<p>Kubernetes cluster autoscaling does not use the Managed Instance Group autoscaler. It runs a <code>cluster-autoscaler</code> controller on the Kubernetes master that uses Kubernetes-specific signals to scale your nodes. <a href=\"https://github.com/kubernetes/autoscaler/tree/master/cluster-autoscaler\" rel=\"nofollow noreferrer\">The code</a> is in the <code>autoscaler</code> repo if you want more info.</p>\n\n<p>I've also sent out <a href=\"https://github.com/kubernetes/kubernetes.github.io/pull/1211\" rel=\"nofollow noreferrer\">a PR</a> to fix the invalid flag usage in the autoscaling docs. Thanks for catching that!</p>\n",
                    "OwnerUserId": "805800",
                    "LastEditorUserId": "1168315",
                    "LastEditDate": "2017-06-19T18:20:56.797",
                    "LastActivityDate": "2017-06-19T18:20:56.797",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "40703162",
                "ParentRepo": "https://github.com/AsynkronIT/gam",
                "StackOverflow_Post": {
                    "Id": "40703162",
                    "PostTypeId": "2",
                    "ParentId": "21494157",
                    "CreationDate": "2016-11-20T10:51:58.043",
                    "Score": "7",
                    "Body": "<p>Two years late but if anyone else is looking.\n<a href=\"https://github.com/AsynkronIT/gam\" rel=\"noreferrer\">https://github.com/AsynkronIT/gam</a></p>\n\n<p>GAM (Go Actor Model) supports both Akka like actors, and Ms Orleans like Virtual Grains.\nThe Ms Orleans like Virtual Grains are supported via Protobuf code generation to give you typed messages and typed grain types.\nSee \n<a href=\"https://github.com/AsynkronIT/gam/blob/dev/examples/cluster/member/main.go\" rel=\"noreferrer\">https://github.com/AsynkronIT/gam/blob/dev/examples/cluster/member/main.go</a>\n<a href=\"https://github.com/AsynkronIT/gam/blob/dev/examples/cluster/shared/protos.proto\" rel=\"noreferrer\">https://github.com/AsynkronIT/gam/blob/dev/examples/cluster/shared/protos.proto</a></p>\n\n<p>It's also extremely fast, 1 mil+ remote messages per sec.</p>\n",
                    "OwnerUserId": "317384",
                    "LastActivityDate": "2016-11-20T10:51:58.043",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "43256210",
                "ParentRepo": "https://github.com/kubernetes-incubator/external-dns",
                "StackOverflow_Post": {
                    "Id": "43256210",
                    "PostTypeId": "2",
                    "ParentId": "39781955",
                    "CreationDate": "2017-04-06T13:10:31.257",
                    "Score": "1",
                    "Body": "<p>One option is to front your services with an ingress resource (load balancer) and attach it to a static IP that you have previously reserved.</p>\n\n<p>I was unable to find this documented in either the Kubernetes or GKE documentation, but I did find it here:</p>\n\n<p><a href=\"https://github.com/kelseyhightower/ingress-with-static-ip\" rel=\"nofollow noreferrer\">https://github.com/kelseyhightower/ingress-with-static-ip</a></p>\n\n<p>Keep in mind that the value you set for the <code>kubernetes.io/ingress.global-static-ip-name</code> annotation is the name of the reserved IP resource, and not the IP itself.</p>\n\n<p>Previous to that being available, you needed to create a Global IP, attach it to a GCE load balancer which had a global forwarding rule targeting at the nodes of your cluster yourself.</p>\n\n<p>I do not believe there is a way to make this work automatically, today, if you do not wish to front your services with a k8s Ingress or GCP load balancer. That said, the Ingress is pretty straightforward, so I would recommend you go that route, if you can.</p>\n\n<p>There is also a Kubernetes Incubator project called \"external-dns\" that looks to be an add-on that supports this more generally, and entirely from within the cluster itself:</p>\n\n<p><a href=\"https://github.com/kubernetes-incubator/external-dns\" rel=\"nofollow noreferrer\">https://github.com/kubernetes-incubator/external-dns</a></p>\n\n<p>I have not yet tried that approach, but mention it hear as something you may want to follow.</p>\n",
                    "OwnerUserId": "1399860",
                    "LastActivityDate": "2017-04-06T13:10:31.257",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "43549716",
                "ParentRepo": "https://github.com/dgraph-io/dgraph/blob/master/protos/graphp/graphresponse.proto#L9",
                "StackOverflow_Post": {
                    "Id": "43549716",
                    "PostTypeId": "1",
                    "CreationDate": "2017-04-21T18:31:32.947",
                    "Score": "8",
                    "ViewCount": "1259",
                    "Body": "<p>I am trying to implement a grpc client in lua.After some exploration I think I need to </p>\n\n<p>1)use a lua http2 library for the transport layer communication<br>\n2)prot0buf library for request and response decoding<br>\n3)mapping the <a href=\"https://github.com/dgraph-io/dgraph/blob/master/protos/graphp/graphresponse.proto#L9\" rel=\"noreferrer\">service</a> name in proto file to a http endpoint<br>\n4)sending the request and body as per the protocol.</p>\n\n<p>I looked at the <a href=\"https://github.com/grpc/grpc/blob/master/doc/PROTOCOL-HTTP2.md\" rel=\"noreferrer\">https://github.com/grpc/grpc/blob/master/doc/PROTOCOL-HTTP2.md</a>.</p>\n\n<p>So do you have any pointers that can help me in implementing a bare minimum working client which can invoke a grpc service such as a dgraph database (<a href=\"https://docs.dgraph.io/v0.7.5/clients/\" rel=\"noreferrer\">https://docs.dgraph.io/v0.7.5/clients/</a>) .</p>\n\n<p>thanks</p>\n",
                    "OwnerUserId": "745018",
                    "LastEditorUserId": "745018",
                    "LastEditDate": "2017-04-22T12:42:39.460",
                    "LastActivityDate": "2017-04-22T12:42:39.460",
                    "Title": "how to implement a grpc client in lua at a bare minimum",
                    "Tags": "<lua><client><http2><grpc>",
                    "AnswerCount": "0",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "44030167",
                "ParentRepo": "https://github.com/coredns/coredns",
                "StackOverflow_Post": {
                    "Id": "44030167",
                    "PostTypeId": "1",
                    "CreationDate": "2017-05-17T16:21:04.903",
                    "Score": "2",
                    "ViewCount": "2120",
                    "Body": "<p>We are running kubernetes 1.5.7 on CoreOS in AWS.  Our kube-dns image versions are </p>\n\n<p>gcr.io/google_containers/kubedns-amd64:1.9\ngcr.io/google_containers/kube-dnsmasq-amd64:1.4.1</p>\n\n<p>The args that we pass to dnsmasq are</p>\n\n<pre><code>  --cache-size=1000\n  --no-resolv\n  --server=/in-addr.arpa/ip6.arpa/cluster.local/ec2.internal/127.0.0.1#10053\n  --server=169.254.169.253\n  --server=8.8.8.8\n  --log-facility=-\n  --log-async\n  --address=/com.cluster.local/com.svc.cluster.local/com.kube-system.svc.cluster.local/&lt;ourdomain&gt;.com.cluster.local/&lt;ourdomain&gt;.com.svc.cluster.local/&lt;ourdomain&gt;.com.kube-system.svc.cluster.local/com.ec2.internal/ec2.internal.kube-system.svc.cluster.local/ec2.internal.svc.cluster.local/ec2.internal.cluster.local/\n</code></pre>\n\n<p>We run 1 kube-dns pod per node in 20 node clusters.  For the last few months we have been experiencing DNS failures that range from a 5 - 10 minute event that renders our services mostly unusable because name resolution is failing for most name lookups.  During these events we were running 3 - 6 kube-dns pods.  Since then we have drastically over provisioned our kube-dns pods to 1 per node and have not seen any of the long 5 - 10 minute DNS failure events.  However now we are still seeing smaller DNS failure events that range from 1 - 30 seconds.  During the investigation of these issues we noticed in our logs the following errors from the dnsmasq-metrics container</p>\n\n<blockquote>\n  <p>ERROR: logging before flag.Parse: W0517 03:19:50.139060       1 server.go:53] Error getting metrics from dnsmasq: read udp 127.0.0.1:36181->127.0.0.1:53: i/o timeout</p>\n</blockquote>\n\n<p>When ever we have one of our smaller DNS events lasting 1 - 30 seconds we find the these logs from the kube-dns pods. For awhile we were suspecting that we were experiencing an iptables/conntrack problem wrt to pods hitting the kube-dns service.  But based off these dnsmasq related errors we believe dnsmasq is refusing connections for some period of time causing the DNS failures we have been experiencing.  For people who are not familiar with the dnsmasq-metrics container it is performing DNS lookups against the dnsmasq container in the same pod to get dnsmasq stats.  If the dnsmasq stats cannot be retrieved via a DNS lookup it seems logical to think that services performing a DNS lookup could experience the same problem.</p>\n\n<p>It's worth noting that during these issues we do NOT see the following logs from dnsmasq which makes me believe we are not hitting this threshold.</p>\n\n<blockquote>\n  <p>dnsmasq: Maximum number of concurrent DNS queries reached (max: 150)</p>\n</blockquote>\n\n<p>I feel pretty confident that our current DNS errors are related to dnsmasq refusing connections intermittently.  I'm curious if other users are seeing the same problems where the kube-dns pod logs the error from dnsmasq-metrics and during that same time frame DNS errors are logged from applications in the cluster.</p>\n\n<p>Additionally if anyone has any ideas on what to do next to find out exactly what is happening wrt dnsmasq refusing connections.  I'm pondering if it would be useful to run dnsmasq in debug mode but also worried that will introduce other problems related to running in debug mode.  Other options we are considering is slowly rolling out CoreDNS (<a href=\"https://github.com/coredns/coredns\" rel=\"nofollow noreferrer\">https://github.com/coredns/coredns</a>).</p>\n",
                    "OwnerUserId": "6067470",
                    "LastActivityDate": "2017-06-21T17:50:53.147",
                    "Title": "Kube-dns - Intermittent name resolution errors",
                    "Tags": "<kubernetes>",
                    "AnswerCount": "1",
                    "CommentCount": "2",
                    "FavoriteCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "45289848",
                "ParentRepo": "https://github.com/jpmorganchase/quorum/pull/146",
                "StackOverflow_Post": {
                    "Id": "45289848",
                    "PostTypeId": "2",
                    "ParentId": "44246165",
                    "CreationDate": "2017-07-24T20:52:00.927",
                    "Score": "0",
                    "Body": "<p>Unfortunately this capability is not currently supported in Quorum if you require transaction privacy. If you don't want transaction privacy you can the standard web3j library.</p>\n\n<p>For background as to where this is currently, please refer to the discussion on the following pull request <a href=\"https://github.com/jpmorganchase/quorum/pull/146\" rel=\"nofollow noreferrer\">https://github.com/jpmorganchase/quorum/pull/146</a>.</p>\n",
                    "OwnerUserId": "3211687",
                    "LastActivityDate": "2017-07-24T20:52:00.927",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "45407515",
                "ParentRepo": "https://github.com/projectcalico/calico/blob/master/master/getting-started/kubernetes/installation/hosted/rbac.yaml",
                "StackOverflow_Post": {
                    "Id": "45407515",
                    "PostTypeId": "2",
                    "ParentId": "45364975",
                    "CreationDate": "2017-07-31T04:36:25.103",
                    "Score": "3",
                    "Body": "<p>I found the cause.\nThis issue is not related to kube-dns.\nI just missed out applying <a href=\"https://github.com/projectcalico/calico/blob/master/master/getting-started/kubernetes/installation/hosted/rbac.yaml\" rel=\"nofollow noreferrer\">ClusterRole/ClusterRoleBinding</a>, before deplying calico</p>\n",
                    "OwnerUserId": "2172787",
                    "LastActivityDate": "2017-07-31T04:36:25.103",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "45510794",
                "ParentRepo": "https://github.com/alexedwards/scs",
                "StackOverflow_Post": {
                    "Id": "45510794",
                    "PostTypeId": "2",
                    "ParentId": "43862627",
                    "CreationDate": "2017-08-04T15:40:33.587",
                    "Score": "2",
                    "Body": "<p>I had some good experience using <a href=\"https://github.com/alexedwards/scs\" rel=\"nofollow noreferrer\">https://github.com/alexedwards/scs</a> for session-handling.</p>\n\n<p>It also includes a setting for idle-timeout:</p>\n\n<pre><code>session.IdleTimeout(30*time.Minute)\n</code></pre>\n\n<p>I don't know if switching the session-library is an option for you, but scs integrates pretty seamlessly, so it might be worth looking at it at least. :)</p>\n",
                    "OwnerUserId": "3144840",
                    "LastActivityDate": "2017-08-04T15:40:33.587",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "46029196",
                "ParentRepo": "https://github.com/influxdata/chronograf/issues/1960",
                "StackOverflow_Post": {
                    "Id": "46029196",
                    "PostTypeId": "2",
                    "ParentId": "45929025",
                    "CreationDate": "2017-09-04T01:21:39.240",
                    "Score": "3",
                    "Body": "<p><strong>Short answer:</strong> It is not possible to display data in UTC in <code>Chronograf</code> 1.3 yet.</p>\n\n<p><code>Chronograf</code> by default offset <code>influxdb</code>'s UTC data to whatever your local browser's time is.</p>\n\n<p>I have raised a github issue to the Chronograf team and hopefully it will support displaying data in UTC soon.</p>\n\n<p>See: <a href=\"https://github.com/influxdata/chronograf/issues/1960\" rel=\"nofollow noreferrer\">https://github.com/influxdata/chronograf/issues/1960</a></p>\n\n<p><strong>Reference:</strong></p>\n\n<p><a href=\"https://community.influxdata.com/t/chronograf-set-to-use-local-or-set-timezone/947\" rel=\"nofollow noreferrer\">https://community.influxdata.com/t/chronograf-set-to-use-local-or-set-timezone/947</a></p>\n\n<p><a href=\"https://github.com/influxdata/chronograf/issues/1960\" rel=\"nofollow noreferrer\">https://github.com/influxdata/chronograf/issues/1960</a></p>\n",
                    "OwnerUserId": "4014291",
                    "LastActivityDate": "2017-09-04T01:21:39.240",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "46392112",
                "ParentRepo": "https://github.com/kubernetes/apiserver",
                "StackOverflow_Post": {
                    "Id": "46392112",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "46392534",
                    "CreationDate": "2017-09-24T16:11:12.333",
                    "Score": "-2",
                    "ViewCount": "96",
                    "Body": "<p>It's very often I see .go files committed to pkg folder, like here <a href=\"https://github.com/kubernetes/apiserver\" rel=\"nofollow noreferrer\">https://github.com/kubernetes/apiserver</a> what particular reason doing that vs using vendor folder for 3rdparty dependencies or commit your own code into src dir?</p>\n",
                    "OwnerUserId": "306025",
                    "LastActivityDate": "2017-09-25T10:20:32.140",
                    "Title": "Understanding need to place .go files under pkg folder?",
                    "Tags": "<go>",
                    "AnswerCount": "2",
                    "CommentCount": "2",
                    "ClosedDate": "2017-09-25T09:44:46.183",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "47632118",
                "ParentRepo": "https://github.com/kubernetes-incubator/descheduler",
                "StackOverflow_Post": {
                    "Id": "47632118",
                    "PostTypeId": "2",
                    "ParentId": "47631878",
                    "CreationDate": "2017-12-04T11:16:41.433",
                    "Score": "2",
                    "Body": "<p>The scheduler will try to figure out the most reasonable way of scheduling at given point in time, which can change later on and results in situations like you described. Two simple ways to manage this in one way or another are :</p>\n\n<ul>\n<li>use DaemonSet instead of Deployment : will make sure you have one and only one pod per node (matching nodeSelector / tolerations etc.)</li>\n<li><p>use PodAntiAffinity : you can make sure that two pods of the same deployment in the same version are never deployed on the same node. This is what I personally prefer for many apps (unless I want more then one to be scheduled per node). Note that it will be in a bit of trouble if you decide to scale your deployment to more replicas then you have nodes.\nExample for versioned PodAntiAffinity I use :</p>\n\n<pre><code>metadata:\n  labels:\n    app: {{ template \"fullname\" . }}\n    version: {{ .Values.image.tag }}\nspec:\n  affinity:\n    podAntiAffinity:\n      requiredDuringSchedulingIgnoredDuringExecution:\n      - labelSelector:\n          matchExpressions:\n          - key: app\n            operator: In\n            values: [\"{{ template \"fullname\" . }}\"]\n          - key: version\n            operator: In\n            values: [\"{{ .Values.image.tag }}\"]\n        topologyKey: kubernetes.io/hostname\n</code></pre></li>\n<li><p>consider fiddling with <a href=\"https://github.com/kubernetes-incubator/descheduler\" rel=\"nofollow noreferrer\">Descheduler</a> which is like an evil twin of Kubes Scheduler component which will cause deleting of pods for them tu reschedule differently</p></li>\n</ul>\n",
                    "OwnerUserId": "3871750",
                    "LastEditorUserId": "3871750",
                    "LastEditDate": "2017-12-05T09:43:18.347",
                    "LastActivityDate": "2017-12-05T09:43:18.347",
                    "CommentCount": "7",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "47892113",
                "ParentRepo": "https://github.com/GoogleCloudPlatform/k8s-stackdriver/tree/master/custom-metrics-stackdriver-adapter",
                "StackOverflow_Post": {
                    "Id": "47892113",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "47918230",
                    "CreationDate": "2017-12-19T17:18:25.147",
                    "Score": "1",
                    "ViewCount": "227",
                    "Body": "<p>For a multi zoned, multi cluster setup. Is it possible to dynamically expose or retrieve the zone in which the master node is running, from a pod? Since this is needed to correctly push our metrics to stackdriver, in order to run a <a href=\"https://github.com/GoogleCloudPlatform/k8s-stackdriver/tree/master/custom-metrics-stackdriver-adapter\" rel=\"nofollow noreferrer\">horizontal pod autoscaler</a> based on them.</p>\n\n<p>I can hardcode it in the individual deployments but I would like to avoid that.</p>\n\n<p>I've tried looking in the compute internal metadata endpoint, and in the <a href=\"https://stackoverflow.com/questions/47891326/way-to-get-list-of-field-references-in-kubernetes/47891675#47891675\">reference variables</a> kubernetes has, but none seem to expose the zone of the master.</p>\n",
                    "OwnerUserId": "1165797",
                    "LastActivityDate": "2017-12-21T05:03:18.730",
                    "Title": "Fetch the zone of the master node from a pod in container engine",
                    "Tags": "<kubernetes><google-cloud-platform><google-kubernetes-engine><stackdriver><google-cloud-stackdriver>",
                    "AnswerCount": "1",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "48262009",
                "ParentRepo": "https://github.com/kubernetes-incubator/metrics-server",
                "StackOverflow_Post": {
                    "Id": "48262009",
                    "PostTypeId": "2",
                    "ParentId": "48261189",
                    "CreationDate": "2018-01-15T11:24:57.997",
                    "Score": "2",
                    "Body": "<p>There is no better or worse here, you need both :)</p>\n\n<p>Heapster is a solution that makes it possible for Prometheus to collect metrics for the kube cluster. It is also intended to be replaced by <a href=\"https://github.com/kubernetes-incubator/metrics-server\" rel=\"nofollow noreferrer\">Metrics Server</a> eventually. Heapster will also allow things like <code>kubectl top pods</code> to work, but will not give you a long term metrics storage / analysis / alerting. For that, you need something like Prometheus+Grafana.</p>\n",
                    "OwnerUserId": "3871750",
                    "LastActivityDate": "2018-01-15T11:24:57.997",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "48302071",
                "ParentRepo": "https://github.com/jetstack/cert-manager",
                "StackOverflow_Post": {
                    "Id": "48302071",
                    "PostTypeId": "2",
                    "ParentId": "47337817",
                    "CreationDate": "2018-01-17T13:15:03.907",
                    "Score": "1",
                    "Body": "<p>If you use Kubernetes on top of Google Compute Engine, a good solution is <a href=\"https://github.com/jetstack/cert-manager\" rel=\"nofollow noreferrer\">cert-manager</a>, which is a successor of <a href=\"https://github.com/jetstack/kube-lego\" rel=\"nofollow noreferrer\">kube-lego</a>. Both can automatically requests certificates for Kubernetes Ingress resources from Let's Encrypt:</p>\n\n<blockquote>\n  <p><strong>Features</strong></p>\n  \n  <ul>\n  <li>Recognizes the need of a new certificate for this cases:\n  \n  <ul>\n  <li>No certificate existing</li>\n  <li>Existing certificate is not containing all domain names</li>\n  <li>Existing certificate is expired or near to its expiry date (cf. option LEGO_MINIMUM_VALIDITY)</li>\n  <li>Existing certificate is unparseable, invalid or not matching the secret key</li>\n  </ul></li>\n  <li>Creates a user account (incl. private key) for Let's Encrypt and stores it in Kubernetes secrets (secret name is configurable via LEGO_SECRET_NAME)</li>\n  <li>Obtains the missing certificates from Let's Encrypt and authorizes the request with the HTTP-01 challenge</li>\n  <li>Makes sure that the specific Kubernetes objects (Services, Ingress) contain the rights configuration for the HTTP-01 challenge to succeed</li>\n  <li>Official Kubernetes Helm chart for simplistic deployment.</li>\n  </ul>\n</blockquote>\n\n<p>A step-by-step tutorial for GCE <a href=\"http://docs.cert-manager.io/en/latest/tutorials/acme/dns-validation.html\" rel=\"nofollow noreferrer\">is available</a>.</p>\n",
                    "OwnerUserId": "442427",
                    "LastEditorUserId": "442427",
                    "LastEditDate": "2018-06-12T14:39:31.460",
                    "LastActivityDate": "2018-06-12T14:39:31.460",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "48550737",
                "ParentRepo": "https://github.com/hyperledger/fabric-chaincode-evm",
                "StackOverflow_Post": {
                    "Id": "48550737",
                    "PostTypeId": "2",
                    "ParentId": "48549299",
                    "CreationDate": "2018-01-31T20:16:45.217",
                    "Score": "3",
                    "Body": "<p>There are three projects within Hyperledger that will support EVM based smart contracts. Hyperledger <a href=\"https://github.com/hyperledger/burrow\" rel=\"nofollow noreferrer\">Burrow</a>, which is the descendant of ErisDB implements an EVM conforming to the Ethereum specification, that uses Tendermint for consensus and is increasingly being componentized such that its EVM can be used as a library in other projects.</p>\n\n<p>Hyperledger <a href=\"https://github.com/hyperledger/sawtooth-seth\" rel=\"nofollow noreferrer\">Seth</a> is the first integration of Hyperledger Burrow's EVM into the Sawtooth platform.</p>\n\n<p>Hyperledger <a href=\"https://github.com/hyperledger/fabric-chaincode-evm\" rel=\"nofollow noreferrer\">Fabric</a> is also undergoing a project to integrate the Burrow EVM, though presently awaiting a refactor of the Burrow library to be merged.</p>\n\n<p>The process of developing Dapps should be the same.</p>\n",
                    "OwnerUserId": "4774061",
                    "LastActivityDate": "2018-01-31T20:16:45.217",
                    "CommentCount": "6",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "48577211",
                "ParentRepo": "https://github.com/kubernetes-helm/chartmuseum",
                "StackOverflow_Post": {
                    "Id": "48577211",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "48731728",
                    "CreationDate": "2018-02-02T06:52:25.430",
                    "Score": "10",
                    "ViewCount": "6038",
                    "Body": "<p>As <a href=\"https://github.com/kubernetes-helm/chartmuseum\" rel=\"noreferrer\">https://github.com/kubernetes-helm/chartmuseum</a>, I set up chartmuseum by running <code>helm install incubator/chartmuseum</code> in Kubernetes cluster.</p>\n\n<p>When I want to upload chart by running </p>\n\n<p><code>curl --data-binary \"@mychart-0.1.0.tgz\" http://$URL:$PORT/api/charts</code></p>\n\n<p>it returns <code>404 page not found</code> even if i run it in the container which chartmuseum running on.</p>\n",
                    "OwnerUserId": "4365254",
                    "LastEditorUserId": "278183",
                    "LastEditDate": "2018-08-13T18:35:23.757",
                    "LastActivityDate": "2019-03-05T11:33:30.497",
                    "Title": "Fail to upload chart to chartmuseum",
                    "Tags": "<kubernetes><kubernetes-helm>",
                    "AnswerCount": "1",
                    "CommentCount": "1",
                    "FavoriteCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "48687200",
                "ParentRepo": "https://github.com/cilium/cilium",
                "StackOverflow_Post": {
                    "Id": "48687200",
                    "PostTypeId": "5",
                    "CreationDate": "2018-02-08T13:55:57.237",
                    "Score": "0",
                    "Body": "<p>Cilium is an open source software for transparently securing the network connectivity between application services deployed using Linux container management platforms like Docker and Kubernetes.</p>\n\n<p>Resources:</p>\n\n<ul>\n<li>Main page: <a href=\"https://cilium.io\" rel=\"nofollow noreferrer\">https://cilium.io</a></li>\n<li>GitHub repository: <a href=\"https://github.com/cilium/cilium\" rel=\"nofollow noreferrer\">https://github.com/cilium/cilium</a></li>\n<li>Reference documentation: <a href=\"https://docs.cilium.io\" rel=\"nofollow noreferrer\">https://docs.cilium.io</a></li>\n<li>Community Slack: <a href=\"https://cilium.herokuapp.com\" rel=\"nofollow noreferrer\">https://cilium.herokuapp.com</a></li>\n</ul>\n",
                    "OwnerUserId": "563158",
                    "LastEditorUserId": "3716552",
                    "LastEditDate": "2020-05-09T18:01:29.660",
                    "LastActivityDate": "2020-05-09T18:01:29.660",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "49042317",
                "ParentRepo": "https://github.com/pingcap/pd/blob/824cb5e416c9250ef310b3a25b5b6abc080249d3/cmd/pd-recover/main.go",
                "StackOverflow_Post": {
                    "Id": "49042317",
                    "PostTypeId": "2",
                    "ParentId": "49035036",
                    "CreationDate": "2018-03-01T03:47:35.510",
                    "Score": "2",
                    "Body": "<blockquote>\n  <p>Is there a way to destroy the local cluster ID on the TiKV instance so it can hook up with the PD properly?</p>\n</blockquote>\n\n<p>To hook up the TiKV instance with PD properly, you can change the PD\u2019s cluster ID. See the following steps and example.</p>\n\n<blockquote>\n  <p>Will PD be able to coordinate my existing TiKV nodes (with existing data) if I can get them to talk again?</p>\n</blockquote>\n\n<p>Yes, it will.</p>\n\n<p>You can use  \"<a href=\"https://github.com/pingcap/pd/blob/824cb5e416c9250ef310b3a25b5b6abc080249d3/cmd/pd-recover/main.go\" rel=\"nofollow noreferrer\">pd-recover</a>\" to fix this issue. </p>\n\n<ul>\n<li><p>Step 1. Run the new pd-server with the cluster ID: <code>6527407705559138241</code>.</p></li>\n<li><p>Step 2. Change the cluster ID to <code>6520261967047847245</code>.</p>\n\n<pre><code>./pd-recover --endpoints \"http://the-new-pd-server:port\" --cluster-id 6520261967047847245 --alloc-id 100000000\n</code></pre></li>\n<li><p>Step 3. Restart the PD server.</p></li>\n</ul>\n\n<p>Note that PD has a MONOTONIC unique ID allocator which is the <code>alloc-id</code>. All region IDs and peer IDs are generated by the allocator. So please make sure the ID you choose for step 2 is big enough that no existing IDs can exceed, otherwise it will <strong>corrupt</strong> TiKV. </p>\n\n<hr>\n\n<p>Example</p>\n\n<pre><code>neil:bin/ (master) $ ./pd-server &amp;\n[1] 32718\n2018/03/01 10:51:01.343 util.go:59: [info] Welcome to Placement Driver (PD).                                                                                                                                                                                                               \n2018/03/01 10:51:01.343 util.go:60: [info] Release Version: 0.9.0\n2018/03/01 10:51:01.343 util.go:61: [info] Git Commit Hash: 651d0dd52a46b7990d0cd74d33f2f10194d46565\n2018/03/01 10:51:01.343 util.go:62: [info] Git Branch: namespace\n2018/03/01 10:51:01.343 util.go:63: [info] UTC Build Time:  2017-09-13 05:30:13\n2018/03/01 10:51:01.343 metricutil.go:83: [info] disable Prometheus push client\n2018/03/01 10:51:01.344 server.go:87: [info] PD config - Config({FlagSet:0xc420177500 Version:false ClientUrls:http://127.0.0.1:2379 PeerUrls:http://127.0.0.1:2380 AdvertiseClientUrls:http://127.0.0.1:2379 AdvertisePeerUrls:http://127.0.0.1:2380 Name:pd DataDir:default.pd InitialCluster:pd=http://127.0.0.1:2380 InitialClusterState:new Join: LeaderLease:3 Log:{Level: Format:text DisableTimestamp:false File:{Filename: LogRotate:true MaxSize:0 MaxDays:0 MaxBackups:0}} LogFileDeprecated: LogLevelDeprecated: TsoSaveInterval:3s Metric:{PushJob:pd PushAddress: PushInterval:0s} Schedule:{MaxSnapshotCount:3 MaxStoreDownTime:1h0m0s LeaderScheduleLimit:64 RegionScheduleLimit:12 ReplicaScheduleLimit:16} Replication:{MaxReplicas:3 LocationLabels:[]} QuotaBackendBytes:0 AutoCompactionRetention:1 TickInterval:500ms ElectionInterval:3s configFile: WarningMsgs:[] nextRetryDelay:1000000000 disableStrictReconfigCheck:false})\n2018/03/01 10:51:01.346 server.go:114: [info] start embed etcd\n2018/03/01 10:51:01.347 log.go:84: [info] embed: [listening for peers on  http://127.0.0.1:2380]\n2018/03/01 10:51:01.347 log.go:84: [info] embed: [pprof is enabled under /debug/pprof]\n2018/03/01 10:51:01.347 log.go:84: [info] embed: [listening for client requests on  127.0.0.1:2379]\n2018/03/01 10:51:01 systime_mon.go:11: [info] start system time monitor \n2018/03/01 10:51:01.408 log.go:84: [info] etcdserver: [name = pd]\n2018/03/01 10:51:01.409 log.go:84: [info] etcdserver: [data dir = default.pd]\n2018/03/01 10:51:01.409 log.go:84: [info] etcdserver: [member dir = default.pd/member]\n2018/03/01 10:51:01.409 log.go:84: [info] etcdserver: [heartbeat = 500ms]\n2018/03/01 10:51:01.409 log.go:84: [info] etcdserver: [election = 3000ms]\n2018/03/01 10:51:01.409 log.go:84: [info] etcdserver: [snapshot count = 100000]\n2018/03/01 10:51:01.409 log.go:84: [info] etcdserver: [advertise client URLs = http://127.0.0.1:2379]\n2018/03/01 10:51:01.409 log.go:84: [info] etcdserver: [initial advertise peer URLs = http://127.0.0.1:2380]\n2018/03/01 10:51:01.409 log.go:84: [info] etcdserver: [initial cluster = pd=http://127.0.0.1:2380]\n2018/03/01 10:51:01.475 log.go:84: [info] etcdserver: [starting member b71f75320dc06a6c in cluster 1c45a069f3a1d796]\n2018/03/01 10:51:01.475 log.go:84: [info] raft: [b71f75320dc06a6c became follower at term 0]\n2018/03/01 10:51:01.475 log.go:84: [info] raft: [newRaft b71f75320dc06a6c [peers: [], term: 0, commit: 0, applied: 0, lastindex: 0, lastterm: 0]]\n2018/03/01 10:51:01.475 log.go:84: [info] raft: [b71f75320dc06a6c became follower at term 1]\n2018/03/01 10:51:01.587 log.go:80: [warning] auth: [simple token is not cryptographically signed]\n2018/03/01 10:51:01.631 log.go:84: [info] etcdserver: [starting server... [version: 3.2.4, cluster version: to_be_decided]]\n2018/03/01 10:51:01.632 log.go:84: [info] etcdserver/membership: [added member b71f75320dc06a6c [http://127.0.0.1:2380] to cluster 1c45a069f3a1d796]\n2018/03/01 10:51:01.633 server.go:129: [info] create etcd v3 client with endpoints [http://127.0.0.1:2379]\n2018/03/01 10:51:03.476 log.go:84: [info] raft: [b71f75320dc06a6c is starting a new election at term 1]\n2018/03/01 10:51:03.476 log.go:84: [info] raft: [b71f75320dc06a6c became candidate at term 2]\n2018/03/01 10:51:03.476 log.go:84: [info] raft: [b71f75320dc06a6c received MsgVoteResp from b71f75320dc06a6c at term 2]\n2018/03/01 10:51:03.476 log.go:84: [info] raft: [b71f75320dc06a6c became leader at term 2]\n2018/03/01 10:51:03.476 log.go:84: [info] raft: [raft.node: b71f75320dc06a6c elected leader b71f75320dc06a6c at term 2]\n2018/03/01 10:51:03.477 log.go:84: [info] etcdserver: [setting up the initial cluster version to 3.2]\n2018/03/01 10:51:03.477 log.go:84: [info] etcdserver: [published {Name:pd ClientURLs:[http://127.0.0.1:2379]} to cluster 1c45a069f3a1d796]\n2018/03/01 10:51:03.477 log.go:84: [info] embed: [ready to serve client requests]\n2018/03/01 10:51:03.478 log.go:82: [info] embed: [serving insecure client requests on 127.0.0.1:2379, this is strongly discouraged!]\n2018/03/01 10:51:03.480 etcdutil.go:125: [warning] check etcd http://127.0.0.1:2379 status, resp: &amp;{cluster_id:2037210783374497686 member_id:13195394291058371180 revision:1 raft_term:2  3.2.4 24576 13195394291058371180 3 2}, err: &lt;nil&gt;, cost: 1.84566554s\n2018/03/01 10:51:03.489 log.go:82: [info] etcdserver/membership: [set the initial cluster version to 3.2]\n2018/03/01 10:51:03.489 log.go:84: [info] etcdserver/api: [enabled capabilities for version 3.2]\n2018/03/01 10:51:03.500 server.go:174: [info] init cluster id 6527803384525484955\n2018/03/01 10:51:03.579 tso.go:104: [info] sync and save timestamp: last 0001-01-01 00:00:00 +0000 UTC save 2018-03-01 10:51:06.578778001 +0800 CST\n2018/03/01 10:51:03.579 leader.go:249: [info] PD cluster leader pd is ready to serve\n\nneil:bin/ (master) $ ./pd-recover --endpoints \"http://localhost:2379\" --alloc-id 100000000 --cluster-id 66666666666\nrecover success! please restart the PD cluster\nneil:bin/ (master) $ kill 32718\n2018/03/01 10:51:35.258 server.go:228: [info] closing server\n2018/03/01 10:51:35.258 leader.go:107: [error] campaign leader err github.com/pingcap/pd/server/leader.go:269: server closed\n2018/03/01 10:51:35.258 leader.go:65: [info] server is closed, return leader loop\n2018/03/01 10:51:35.259 log.go:84: [info] etcdserver: [skipped leadership transfer for single member cluster]\n2018/03/01 10:51:35.259 log.go:84: [info] etcdserver/api/v3rpc: [grpc: addrConn.resetTransport failed to create client transport: connection error: desc = \"transport: Error while dialing dial tcp 127.0.0.1:2379: getsockopt: connection refused\"; Reconnecting to {127.0.0.1:2379 &lt;nil&gt;}]\n2018/03/01 10:51:35.259 log.go:84: [info] etcdserver/api/v3rpc: [Failed to dial 127.0.0.1:2379: grpc: the connection is closing; please retry.]\n2018/03/01 10:51:35.291 server.go:246: [info] close server\n2018/03/01 10:51:35.291 main.go:89: [info] Got signal [15] to exit.\n[1]  + 32718 done       ./pd-server\nneil:bin/ (master) $ ./pd-server\n2018/03/01 10:51:40.007 util.go:59: [info] Welcome to Placement Driver (PD).\n2018/03/01 10:51:40.007 util.go:60: [info] Release Version: 0.9.0\n2018/03/01 10:51:40.007 util.go:61: [info] Git Commit Hash: 651d0dd52a46b7990d0cd74d33f2f10194d46565\n2018/03/01 10:51:40.007 util.go:62: [info] Git Branch: namespace\n2018/03/01 10:51:40.007 util.go:63: [info] UTC Build Time:  2017-09-13 05:30:13\n2018/03/01 10:51:40.007 metricutil.go:83: [info] disable Prometheus push client\n2018/03/01 10:51:40.007 server.go:87: [info] PD config - Config({FlagSet:0xc4200771a0 Version:false ClientUrls:http://127.0.0.1:2379 PeerUrls:http://127.0.0.1:2380 AdvertiseClientUrls:http://127.0.0.1:2379 AdvertisePeerUrls:http://127.0.0.1:2380 Name:pd DataDir:default.pd InitialCluster:pd=http://127.0.0.1:2380 InitialClusterState:new Join: LeaderLease:3 Log:{Level: Format:text DisableTimestamp:false File:{Filename: LogRotate:true MaxSize:0 MaxDays:0 MaxBackups:0}} LogFileDeprecated: LogLevelDeprecated: TsoSaveInterval:3s Metric:{PushJob:pd PushAddress: PushInterval:0s} Schedule:{MaxSnapshotCount:3 MaxStoreDownTime:1h0m0s LeaderScheduleLimit:64 RegionScheduleLimit:12 ReplicaScheduleLimit:16} Replication:{MaxReplicas:3 LocationLabels:[]} QuotaBackendBytes:0 AutoCompactionRetention:1 TickInterval:500ms ElectionInterval:3s configFile: WarningMsgs:[] nextRetryDelay:1000000000 disableStrictReconfigCheck:false})\n2018/03/01 10:51:40.010 server.go:114: [info] start embed etcd\n2018/03/01 10:51:40 systime_mon.go:11: [info] start system time monitor \n2018/03/01 10:51:40.011 log.go:84: [info] embed: [listening for peers on  http://127.0.0.1:2380]\n2018/03/01 10:51:40.011 log.go:84: [info] embed: [pprof is enabled under /debug/pprof]\n2018/03/01 10:51:40.011 log.go:84: [info] embed: [listening for client requests on  127.0.0.1:2379]\n2018/03/01 10:51:40.019 log.go:84: [info] etcdserver: [name = pd]\n2018/03/01 10:51:40.020 log.go:84: [info] etcdserver: [data dir = default.pd]\n2018/03/01 10:51:40.020 log.go:84: [info] etcdserver: [member dir = default.pd/member]\n2018/03/01 10:51:40.020 log.go:84: [info] etcdserver: [heartbeat = 500ms]\n2018/03/01 10:51:40.020 log.go:84: [info] etcdserver: [election = 3000ms]\n2018/03/01 10:51:40.020 log.go:84: [info] etcdserver: [snapshot count = 100000]\n2018/03/01 10:51:40.020 log.go:84: [info] etcdserver: [advertise client URLs = http://127.0.0.1:2379]\n2018/03/01 10:51:40.020 log.go:84: [info] etcdserver: [restarting member b71f75320dc06a6c in cluster 1c45a069f3a1d796 at commit index 20]\n2018/03/01 10:51:40.020 log.go:84: [info] raft: [b71f75320dc06a6c became follower at term 2]\n2018/03/01 10:51:40.020 log.go:84: [info] raft: [newRaft b71f75320dc06a6c [peers: [], term: 2, commit: 20, applied: 0, lastindex: 20, lastterm: 2]]\n2018/03/01 10:51:40.072 log.go:80: [warning] auth: [simple token is not cryptographically signed]\n2018/03/01 10:51:40.113 log.go:84: [info] etcdserver: [starting server... [version: 3.2.4, cluster version: to_be_decided]]\n2018/03/01 10:51:40.115 log.go:84: [info] etcdserver/membership: [added member b71f75320dc06a6c [http://127.0.0.1:2380] to cluster 1c45a069f3a1d796]\n2018/03/01 10:51:40.116 etcdutil.go:62: [error] failed to get raft cluster member(s) from the given urls.\n2018/03/01 10:51:40.116 server.go:129: [info] create etcd v3 client with endpoints [http://127.0.0.1:2379]\n2018/03/01 10:51:40.116 log.go:82: [info] etcdserver/membership: [set the initial cluster version to 3.2]\n2018/03/01 10:51:40.116 log.go:84: [info] etcdserver/api: [enabled capabilities for version 3.2]\n2018/03/01 10:51:41.021 log.go:84: [info] raft: [b71f75320dc06a6c is starting a new election at term 2]\n2018/03/01 10:51:41.021 log.go:84: [info] raft: [b71f75320dc06a6c became candidate at term 3]\n2018/03/01 10:51:41.021 log.go:84: [info] raft: [b71f75320dc06a6c received MsgVoteResp from b71f75320dc06a6c at term 3]\n2018/03/01 10:51:41.021 log.go:84: [info] raft: [b71f75320dc06a6c became leader at term 3]\n2018/03/01 10:51:41.021 log.go:84: [info] raft: [raft.node: b71f75320dc06a6c elected leader b71f75320dc06a6c at term 3]\n2018/03/01 10:51:41.039 log.go:84: [info] etcdserver: [published {Name:pd ClientURLs:[http://127.0.0.1:2379]} to cluster 1c45a069f3a1d796]\n2018/03/01 10:51:41.039 log.go:84: [info] embed: [ready to serve client requests]\n2018/03/01 10:51:41.040 log.go:82: [info] embed: [serving insecure client requests on 127.0.0.1:2379, this is strongly discouraged!]\n2018/03/01 10:51:41.066 server.go:174: [info] init cluster id 66666666666\n2018/03/01 10:51:41.250 cache.go:379: [info] load 0 stores cost 465.361\u00b5s\n2018/03/01 10:51:41.251 cache.go:385: [info] load 0 regions cost 426.452\u00b5s\n2018/03/01 10:51:41.251 coordinator.go:123: [info] coordinator: Start collect cluster information\n2018/03/01 10:51:41.251 coordinator.go:126: [info] coordinator: Cluster information is prepared\n2018/03/01 10:51:41.251 coordinator.go:136: [info] coordinator: Run scheduler\n2018/03/01 10:51:41.252 tso.go:104: [info] sync and save timestamp: last 0001-01-01 00:00:00 +0000 UTC save 2018-03-01 10:51:44.251760951 +0800 CST\n2018/03/01 10:51:41.252 leader.go:249: [info] PD cluster leader pd is ready to serve\n^C2018/03/01 10:51:56.077 server.go:228: [info] closing server\n2018/03/01 10:51:56.077 coordinator.go:277: [info] balance-hot-region-scheduler stopped: context canceled\n2018/03/01 10:51:56.077 coordinator.go:277: [info] balance-region-scheduler stopped: context canceled\n2018/03/01 10:51:56.077 coordinator.go:277: [info] balance-leader-scheduler stopped: context canceled\n2018/03/01 10:51:56.077 leader.go:107: [error] campaign leader err github.com/pingcap/pd/server/leader.go:269: server closed\n2018/03/01 10:51:56.078 leader.go:65: [info] server is closed, return leader loop\n2018/03/01 10:51:56.078 log.go:84: [info] etcdserver: [skipped leadership transfer for single member cluster]\n2018/03/01 10:51:56.078 log.go:84: [info] etcdserver/api/v3rpc: [grpc: addrConn.resetTransport failed to create client transport: connection error: desc = \"transport: Error while dialing dial tcp 127.0.0.1:2379: getsockopt: connection refused\"; Reconnecting to {127.0.0.1:2379 &lt;nil&gt;}]\n2018/03/01 10:51:56.078 log.go:84: [info] etcdserver/api/v3rpc: [Failed to dial 127.0.0.1:2379: grpc: the connection is closing; please retry.]\n2018/03/01 10:51:56.118 server.go:246: [info] close server\n2018/03/01 10:51:56.118 main.go:89: [info] Got signal [2] to exit.\n</code></pre>\n",
                    "OwnerUserId": "3920448",
                    "LastActivityDate": "2018-03-01T03:47:35.510",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "49203050",
                "ParentRepo": "https://github.com/rancher/rke",
                "StackOverflow_Post": {
                    "Id": "49203050",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "49267386",
                    "CreationDate": "2018-03-09T22:20:39.020",
                    "Score": "5",
                    "ViewCount": "13374",
                    "Body": "<p>I'm using <a href=\"https://github.com/rancher/rke\" rel=\"noreferrer\">rke</a> to generate a Kubernetes cluster in a private cloud. It produces a <code>kube_config_cluster.yml</code> file. Is there a way to add this config to my <code>$HOME/.kube/config</code> file?</p>\n\n<p>Without having the .kube/config set, when using <code>kubectl</code>, I have to pass the argument:</p>\n\n<pre><code>kubectl --kubeconfig kube_config_cluster.yml &lt;command&gt;\n</code></pre>\n\n<p>Or set the KUBECONFIG environment variable.</p>\n\n<pre><code>export KUBECONFIG=kube_config_cluster.yml\n</code></pre>\n",
                    "OwnerUserId": "463038",
                    "LastActivityDate": "2019-12-04T02:40:52.393",
                    "Title": "How to save generated kube config to .kube/config",
                    "Tags": "<kubernetes><kubectl>",
                    "AnswerCount": "3",
                    "CommentCount": "1",
                    "FavoriteCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "49874360",
                "ParentRepo": "https://github.com/AsynkronIT/protoactor-go",
                "StackOverflow_Post": {
                    "Id": "49874360",
                    "PostTypeId": "2",
                    "ParentId": "21494157",
                    "CreationDate": "2018-04-17T09:22:43.713",
                    "Score": "6",
                    "Body": "<p>Akka is based on the Actor Model. For that, there is a nice Go framework I invite you to test : <a href=\"https://github.com/AsynkronIT/protoactor-go\" rel=\"noreferrer\">https://github.com/AsynkronIT/protoactor-go</a></p>\n\n<p>It is said to have great performance since it claims to be passing between nodes:</p>\n\n<blockquote>\n  <p>two million messages per second </p>\n</blockquote>\n\n<p>While Go is already implementing using CSP, Protoactor adds :</p>\n\n<ul>\n<li>Decoupled Concurrency</li>\n<li>Distributed by default</li>\n<li>Fault tolerance</li>\n</ul>\n",
                    "OwnerUserId": "4801289",
                    "LastActivityDate": "2018-04-17T09:22:43.713",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "49880981",
                "ParentRepo": "https://github.com/appscode/stash",
                "StackOverflow_Post": {
                    "Id": "49880981",
                    "PostTypeId": "2",
                    "ParentId": "49859036",
                    "CreationDate": "2018-04-17T14:37:55.060",
                    "Score": "8",
                    "Body": "<p>There are three reclaim policies which define what happens with the persistent volume after deletion of the bound volume claim</p>\n\n<ul>\n<li>Retain </li>\n<li>Delete</li>\n<li>Recycle</li>\n</ul>\n\n<p><strong>Delete</strong> means the persistent volume as well as the associated storage asset in the external infrastructure is deleted.</p>\n\n<p><strong>Recycle</strong> will clean up the volume rm -rf /thevolume/* and after that it will be available for new persistent volume claims.</p>\n\n<p><strong>Retain</strong> leaves persistent volume in state released which does not allow for new persistent volume claims to reclaim it. The whole reclaim process is manual. You need to delete the persistent volume yourself. You can backup the data from the storage asset and delete the data afterwards. Then you can either delete the storage asset or create a new persistent volume for this asset. </p>\n\n<p>If you want to write the data to another persistent volume using Kubernetes you could use a Job to copy the data.</p>\n\n<p>In that case make sure you use persistent volume access modes ROX - ReadOnlyMany or RWX - ReadWriteMany and start a Job running a container which claims the persistent volume to be backed-up using a selector and claim another destination backup volume. Then copy the data via the container.</p>\n\n<p>Alternatively, you can do the backup outside Kubernetes. Your method does then depend on the type of storage asset you are using. E.g., if you are using NFS you could mount source and destination and copy the data via command line.</p>\n\n<p>Both options I've framed are more or less manual backup strategy. If you aim for a more sophisticated backup strategy for production workloads you might have a look at <a href=\"https://github.com/appscode/stash\" rel=\"noreferrer\">Stash - Backup for your disks for production workloads in Kubernetes</a> </p>\n",
                    "OwnerUserId": "3172693",
                    "LastActivityDate": "2018-04-17T14:37:55.060",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "50024994",
                "ParentRepo": "https://github.com/starkandwayne/shield/blob/v0.10.9/bin/shield-pipe#L88-L117",
                "StackOverflow_Post": {
                    "Id": "50024994",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "50025152",
                    "CreationDate": "2018-04-25T14:35:12.967",
                    "Score": "0",
                    "ViewCount": "56",
                    "Body": "<p>Here the <a href=\"https://github.com/starkandwayne/shield/blob/v0.10.9/bin/shield-pipe#L88-L117\" rel=\"nofollow noreferrer\">original source code</a> (relevant 30 lines <code>bash</code> code highlighted)</p>\n\n<p>Here simplified (<code>s3</code> is a binary which streams to object storage). The dots (...) are options not posted here.</p>\n\n<pre><code>PULSE=$(mktemp -t shield-pipe.XXXXX)\ntrap \"rm -f ${PULSE}\" QUIT TERM INT\n\nset -o pipefail\nmysqldump ... | tee &gt;(tail -c1 &gt;$PULSE) | bzip2 | s3 stream ...\n</code></pre>\n\n<p>How does that work exactly? Can you explain me how this redirections and pipes working? Howto debug the error <code>mysqldump: Got errno 32 on write</code>. When manually invoked (only) <code>mysqldump</code>  never fails with an error.</p>\n",
                    "OwnerUserId": "1140727",
                    "LastActivityDate": "2018-04-25T14:53:14.983",
                    "Title": "Explain me how does this Shell pipe magic (... | tee >(tail -c1 >$PULSE) | bzip2 | ...) works?",
                    "Tags": "<mysql><bash><shell><pipe><io-redirection>",
                    "AnswerCount": "1",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "50564398",
                "ParentRepo": "https://github.com/brancz/kube-rbac-proxy",
                "StackOverflow_Post": {
                    "Id": "50564398",
                    "PostTypeId": "2",
                    "ParentId": "50559736",
                    "CreationDate": "2018-05-28T10:34:32.883",
                    "Score": "0",
                    "Body": "<p>Try to check out <a href=\"https://github.com/brancz/kube-rbac-proxy\" rel=\"nofollow noreferrer\">kube-rbac-proxy</a>. It has a couple of options that could be very useful in your case:</p>\n\n<pre><code>$ kube-rbac-proxy -h \nUsage of _output/linux/amd64/kube-rbac-proxy: \n...\n      --auth-header-groups-field-name string        The name of the field inside an http(2) request header to tell the upstream server about the user's groups (default \"x-remote-groups\")\n      --auth-header-groups-field-separator string   The separator string used for concatenating multiple group names in a group header field's value (default \"|\")  \n...\n</code></pre>\n\n<p>An example of its usage and YAML manifest can be found <a href=\"https://github.com/brancz/kube-rbac-proxy/tree/master/examples/non-resource-url\" rel=\"nofollow noreferrer\">here</a>. </p>\n",
                    "OwnerUserId": "9521610",
                    "LastActivityDate": "2018-05-28T10:34:32.883",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "51033630",
                "ParentRepo": "https://github.com/DirectXMan12/k8s-prometheus-adapter",
                "StackOverflow_Post": {
                    "Id": "51033630",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "51044942",
                    "CreationDate": "2018-06-26T01:11:36.113",
                    "Score": "1",
                    "ViewCount": "1939",
                    "Body": "<p>I'm attempting to get autoscaling set up using custom metrics.</p>\n\n<p>Currently, I have:</p>\n\n<ul>\n<li><a href=\"https://github.com/coreos/prometheus-operator\" rel=\"nofollow noreferrer\">Prometheus Operator</a> running in the <code>monitoring</code> namespace.</li>\n<li><a href=\"https://github.com/DirectXMan12/k8s-prometheus-adapter\" rel=\"nofollow noreferrer\">K8S Prometheus Adapter</a> running in the <code>custom-metrics</code> namespace, exposed through a service named <code>api</code>.</li>\n<li>A deployment running in the <code>my-namespace</code> namespace.</li>\n</ul>\n\n<p>I added a <code>HorizontalPodAutoscaler</code> in the <code>custom-metrics</code> namespace, targeting my deployment.</p>\n\n<p>The YAML looks like:</p>\n\n<pre><code>apiVersion: autoscaling/v1\nkind: HorizontalPodAutoscaler\nmetadata:\n  name: my-deployment-hpa\n  namespace: custom-metrics\nspec:\n  maxReplicas: 10\n  minReplicas: 1\n  scaleTargetRef:\n    apiVersion: apps/v1beta2\n    kind: Deployment\n    name: my-deployment\n  metrics:\n  - type: Object\n    object:\n      metricName: queue_length\n      targetValue: 1000\n      target:\n        apiVersion: extensions/v1beta1\n        kind: Service\n        name: api\n</code></pre>\n\n<p>When I describe the <code>HorizontalPodAutoscaler</code> via <code>kubectl describe hpa my-deployment-hpa -n custom-metrics</code>, I see <code>AbleToScale: False</code> because <code>FailedGetScale the HPA controller was unable to get the target's current scale: deployments/scale.extensions \"my-deployment\" not found</code>.</p>\n\n<p>Does Kubernetes expect that the custom metrics API, the scale target and the <code>HorizontalPodAutoscaler</code> all exist in the same namespace?</p>\n",
                    "OwnerUserId": "265312",
                    "LastEditorUserId": "7862821",
                    "LastEditDate": "2018-06-26T05:43:29.750",
                    "LastActivityDate": "2018-06-26T14:08:53.527",
                    "Title": "HorizontalPodAutoscaler - Scale Deployment in Another Namespace",
                    "Tags": "<kubernetes>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "FavoriteCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "51126941",
                "ParentRepo": "https://github.com/kubernetes/cloud-provider-openstack/blob/master/cluster/images/flex-volume-driver/flexvolume-ds.yaml",
                "StackOverflow_Post": {
                    "Id": "51126941",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "51161629",
                    "CreationDate": "2018-07-01T20:52:58.190",
                    "Score": "2",
                    "ViewCount": "1033",
                    "Body": "<p>Suppose I bootstrap a single master node with <code>kubelet</code> v1.10.3 in OpenStack cloud and I would like to have a \"self-hosted\" single etcd node for k8s necessities as a pod.</p>\n\n<p>Before starting <code>kube-apiserver</code> component you need a working etcd instance, but of course you can't just perform <code>kubectl apply -f</code> or put a manifest to <code>addon-manager</code> folder because cluster is not ready at all.\nThere is a way to start pods by kubelet without having a ready apiserver. It is called <strong>static</strong> pods (yaml Pod definitions usually located at <code>/etc/kubernetes/manifests/</code>). And it is the way I start \"system\" pods like apiserver, scheduler, controller-manager and etcd itself. Previously I just mounted a directory from node to persist etcd data, but now I would like to use OpenStack blockstorage resource. And here is the question: how can I attach, mount and use OpenStack cinder volume to persist etcd data from static pod?</p>\n\n<p>As I learned today there are at least 3 ways to attach OpenStack volumes:</p>\n\n<ul>\n<li><p><strong>CSI</strong> OpenStack cinder driver which is pretty much new way of managing volumes. And it won't fit my requirements, because in static pods manifests I can only declare Pods and not other resources like PVC/PV while CSI docs say:</p>\n\n<blockquote>\n  <p>The csi volume type does not support direct reference from Pod and may only be referenced in a Pod via a PersistentVolumeClaim object.</p>\n</blockquote></li>\n<li><p>before-csi way to attach volumes is: <strong>FlexVolume</strong>.</p>\n\n<blockquote>\n  <p>FlexVolume driver binaries must be installed in a pre-defined volume plugin path on each node (and in some cases master).</p>\n</blockquote></li>\n</ul>\n\n<p>Ok, I added those binaries to my node (<a href=\"https://github.com/kubernetes/cloud-provider-openstack/blob/master/cluster/images/flex-volume-driver/flexvolume-ds.yaml\" rel=\"nofollow noreferrer\">using this DS as a reference</a>), added volume to pod manifest like this:</p>\n\n<pre><code>volumes:\n- name: test\n  flexVolume:\n    driver: \"cinder.io/cinder-flex-volume-driver\"\n    fsType: \"ext4\"\n    options:\n      volumeID: \"$VOLUME_ID\"\n      cinderConfig: \"/etc/kubernetes/cloud-config\"\n</code></pre>\n\n<p>and got the following error from kubelet logs:</p>\n\n<blockquote>\n  <p>driver-call.go:258] mount command failed, status: Failure, reason: Volume 2c21311b-7329-4cf4-8230-f3ce2f23cf1a is not available</p>\n</blockquote>\n\n<p>which is weird because I am sure this Cinder volume is already attached to my CoreOS compute instance.</p>\n\n<ul>\n<li>and the last way to mount volumes I know is cinder in-tree support which should work since <a href=\"https://stackoverflow.com/a/42670021/3581539\">at least k8s 1.5</a> and does not have any special requirements besides <code>--cloud-provider=openstack</code> and <code>--cloud-config</code> kubelet options. </li>\n</ul>\n\n<p>The yaml manifest part for declaring volume for static pod looks like this:</p>\n\n<pre><code>volumes:\n  - name: html-volume\n    cinder:\n      # Enter the volume ID below\n      volumeID: \"$VOLUME_ID\"\n      fsType: ext4\n</code></pre>\n\n<p>Unfortunately when I try this method I get the following error from kubelet:</p>\n\n<blockquote>\n  <p>Volume has not been added to the list of VolumesInUse in the node's volume status for volume.</p>\n</blockquote>\n\n<p>Do not know what it means but sounds like the node status could not be updated (of course, there is no etcd and apiserver yet). Sad, it was the most promising option for me. </p>\n\n<p>Are there any other ways to attach OpenStack cinder volume to a static pod relying on kubelet only (when cluster is actually not ready)? Any ideas on what cloud I miss of got above errors?</p>\n",
                    "OwnerUserId": "3581539",
                    "LastActivityDate": "2018-07-03T19:21:21.210",
                    "Title": "How to attach OpenStack volume to a Kubernetes staic pod?",
                    "Tags": "<kubernetes><openstack><kubelet>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "51172225",
                "ParentRepo": "https://github.com/operator-framework/operator-sdk/blob/master/pkg/sdk/query.go",
                "StackOverflow_Post": {
                    "Id": "51172225",
                    "PostTypeId": "2",
                    "ParentId": "51158517",
                    "CreationDate": "2018-07-04T11:08:27.680",
                    "Score": "0",
                    "Body": "<p>solution is using Get function:\n<a href=\"https://github.com/operator-framework/operator-sdk/blob/master/pkg/sdk/query.go\" rel=\"nofollow noreferrer\">https://github.com/operator-framework/operator-sdk/blob/master/pkg/sdk/query.go</a></p>\n\n<p>example (<a href=\"https://github.com/operator-framework/operator-sdk/blob/master/doc/design/milestone-0.0.2/query-api.md\" rel=\"nofollow noreferrer\">https://github.com/operator-framework/operator-sdk/blob/master/doc/design/milestone-0.0.2/query-api.md</a>): </p>\n\n<pre><code>d := &amp;apps_v1.Deployment{\n    TypeMeta: meta_v1.TypeMeta{\n        Kind:       \"Deployment\",\n        APIVersion: \"apps/v1\",\n    }\n    ObjectMeta: metav_1.ObjectMeta{\n        Name:      \"example\",\n        Namespace: \"default\",\n    }\n}\n// Get with default options\nerr := sdk.Get(d)\n// Get with custom options \no := &amp;meta_v1.GetOptions{ResourceVersion: \"0\"}\nerr := sdk.Get(d, sdk.WithGetOptions(o))\n</code></pre>\n",
                    "OwnerUserId": "5272790",
                    "LastActivityDate": "2018-07-04T11:08:27.680",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "51246809",
                "ParentRepo": "https://github.com/digitalocean/digitalocean-cloud-controller-manager/tree/master/docs/controllers/services/examples",
                "StackOverflow_Post": {
                    "Id": "51246809",
                    "PostTypeId": "2",
                    "ParentId": "35884643",
                    "CreationDate": "2018-07-09T13:30:41.337",
                    "Score": "9",
                    "Body": "<p>Things have changed, DigitalOcean created their own cloud provider implementation as answered <a href=\"https://github.com/kubernetes/kubernetes/issues/34783#issuecomment-357974666\" rel=\"nofollow noreferrer\">here</a> and they are maintaining a Kubernetes \"<a href=\"https://kubernetes.io/docs/tasks/administer-cluster/running-cloud-controller/\" rel=\"nofollow noreferrer\">Cloud Controller Manager</a>\" implementation:</p>\n\n<blockquote>\n  <p><a href=\"https://github.com/digitalocean/digitalocean-cloud-controller-manager#kubernetes-cloud-controller-manager-for-digitalocean\" rel=\"nofollow noreferrer\">Kubernetes Cloud Controller Manager for DigitalOcean</a></p>\n  \n  <p>Currently digitalocean-cloud-controller-manager implements:</p>\n  \n  <ul>\n  <li><p>nodecontroller - updates nodes with cloud provider specific labels and\n  addresses, also deletes kubernetes nodes when deleted on the cloud\n  provider. </p></li>\n  <li><p><strong>servicecontroller - responsible for creating LoadBalancers\n  when a service of Type: LoadBalancer is created in Kubernete</strong>s.</p></li>\n  </ul>\n</blockquote>\n\n<p>To try it out clone the project on your master node.</p>\n\n<p>Next get the token key from <a href=\"https://cloud.digitalocean.com/settings/api/tokens\" rel=\"nofollow noreferrer\">https://cloud.digitalocean.com/settings/api/tokens</a> and run:</p>\n\n<pre><code>export DIGITALOCEAN_ACCESS_TOKEN=abc123abc123abc123\nscripts/generate-secret.sh\nkubectl apply -f do-cloud-controller-manager/releases/v0.1.6.yml\n</code></pre>\n\n<p>There more examples <a href=\"https://github.com/digitalocean/digitalocean-cloud-controller-manager/tree/master/docs/controllers/services/examples\" rel=\"nofollow noreferrer\">here</a></p>\n\n<p>What will happen once you do the above? DO's cloud manager will create a load balancer (that has a failover mechanism out of the box, more on it <a href=\"https://www.digitalocean.com/docs/networking/load-balancers/\" rel=\"nofollow noreferrer\">in the load balancer's documentation</a></p>\n\n<p>Things will change again soon as DigitalOcean are jumping on the Kubernetes bandwagon, check <a href=\"https://blog.digitalocean.com/introducing-digitalocean-kubernetes/\" rel=\"nofollow noreferrer\">here</a> and you will have a choice to let them manage your Kuberentes cluster instead of you worrying about a lot of the infrastructure (this is my understanding of the service, let's see how it works when it becomes available...)</p>\n",
                    "OwnerUserId": "7458162",
                    "LastEditorUserId": "7458162",
                    "LastEditDate": "2019-02-26T14:13:39.797",
                    "LastActivityDate": "2019-02-26T14:13:39.797",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "51420340",
                "ParentRepo": "https://github.com/appscode/kubed",
                "StackOverflow_Post": {
                    "Id": "51420340",
                    "PostTypeId": "2",
                    "ParentId": "50931520",
                    "CreationDate": "2018-07-19T10:30:25.623",
                    "Score": "0",
                    "Body": "<p>So there is no native handling of multiple clusters in cert-manager.</p>\n\n<p>That said, there is nothing to stop you copying across the resulting 'Secret' resource between clusters, either manually or automatically.</p>\n\n<p>The 'kubed' project (by appscode) has support for syncing Secrets between clusters: <a href=\"https://github.com/appscode/kubed\" rel=\"nofollow noreferrer\">https://github.com/appscode/kubed</a>. Full information can be found on their website: <a href=\"https://appscode.com/products/kubed/0.8.0/guides/config-syncer/inter-cluster/\" rel=\"nofollow noreferrer\">https://appscode.com/products/kubed/0.8.0/guides/config-syncer/inter-cluster/</a></p>\n\n<p>I hope this helps!</p>\n",
                    "OwnerUserId": "1144052",
                    "LastActivityDate": "2018-07-19T10:30:25.623",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "51481472",
                "ParentRepo": "https://github.com/kubernetes/cloud-provider-azure/blob/master/docs/cloud-provider-config.md",
                "StackOverflow_Post": {
                    "Id": "51481472",
                    "PostTypeId": "2",
                    "ParentId": "51444581",
                    "CreationDate": "2018-07-23T14:39:47.927",
                    "Score": "0",
                    "Body": "<p>It seems that <code>aadTenantId</code> option breaks parsing of the config file (azure.json). </p>\n\n<p>I found no such option among the available options for config:  </p>\n\n<ul>\n<li><a href=\"https://godoc.org/github.com/danielqsj/kubernetes/pkg/cloudprovider/providers/azure#Config\" rel=\"nofollow noreferrer\">type Config</a></li>\n<li><a href=\"https://github.com/kubernetes/cloud-provider-azure/blob/master/docs/cloud-provider-config.md\" rel=\"nofollow noreferrer\">Cloud provider config</a></li>\n</ul>\n",
                    "OwnerUserId": "9521610",
                    "LastEditorUserId": "9521610",
                    "LastEditDate": "2018-07-24T10:50:14.930",
                    "LastActivityDate": "2018-07-24T10:50:14.930",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "51519742",
                "ParentRepo": "https://github.com/google/go-cloud",
                "StackOverflow_Post": {
                    "Id": "51519742",
                    "PostTypeId": "1",
                    "CreationDate": "2018-07-25T13:10:43.007",
                    "Score": "-2",
                    "ViewCount": "90",
                    "Body": "<p>In terraform we get a state file, and CloudFormation also has a notion of a working state. How does <a href=\"https://blog.golang.org/go-cloud\" rel=\"nofollow noreferrer\">go cloud</a> handle the state, do we have to create it ourselves?</p>\n\n<p>For more info on Go Cloud </p>\n\n<ul>\n<li><a href=\"https://github.com/google/go-cloud\" rel=\"nofollow noreferrer\">https://github.com/google/go-cloud</a></li>\n<li><a href=\"https://godoc.org/github.com/google/go-cloud\" rel=\"nofollow noreferrer\">https://godoc.org/github.com/google/go-cloud</a></li>\n</ul>\n",
                    "OwnerUserId": "1963929",
                    "LastEditorUserId": "8206",
                    "LastEditDate": "2019-02-15T17:21:48.603",
                    "LastActivityDate": "2019-02-15T17:21:48.603",
                    "Title": "How is state handled in the go cloud?",
                    "Tags": "<go><go-cdk>",
                    "AnswerCount": "2",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "51920895",
                "ParentRepo": "https://github.com/lightningnetwork/lnd/blob/master/docs/INSTALL.md",
                "StackOverflow_Post": {
                    "Id": "51920895",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "51920979",
                    "CreationDate": "2018-08-19T18:58:33.843",
                    "Score": "0",
                    "ViewCount": "260",
                    "Body": "<p>I am trying to install btcd as part of LND. </p>\n\n<p>I've already installed LND successfully: <a href=\"https://github.com/lightningnetwork/lnd/blob/master/docs/INSTALL.md\" rel=\"nofollow noreferrer\">https://github.com/lightningnetwork/lnd/blob/master/docs/INSTALL.md</a></p>\n\n<p>But when I go to make btcd I get this error:</p>\n\n<pre><code># github.com/btcsuite/btcd\n../../btcsuite/btcd/server.go:1564: /\nmake: *** [btcd] Error 2\n</code></pre>\n\n<p>How do I correct this error so that I can install and run btcd?</p>\n",
                    "OwnerUserId": "1017466",
                    "LastActivityDate": "2018-08-19T19:10:26.743",
                    "Title": "go error on make btcd: undefined: time.Until",
                    "Tags": "<go><bitcoin>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "51928235",
                "ParentRepo": "https://github.com/gomods/athens/",
                "StackOverflow_Post": {
                    "Id": "51928235",
                    "PostTypeId": "2",
                    "ParentId": "51763494",
                    "CreationDate": "2018-08-20T09:57:07.587",
                    "Score": "1",
                    "Body": "<p>I found some projects which try to solve the mentioned issue by acting as central storage and proxy for dependencies. </p>\n\n<p>Most promesing are project Athens and Artifactory 5.11.</p>\n\n<p>Project Athens can work with go dep</p>\n\n<ul>\n<li><a href=\"https://github.com/gomods/athens/\" rel=\"nofollow noreferrer\">https://github.com/gomods/athens/</a></li>\n<li><a href=\"https://docs.gomods.io/faq/\" rel=\"nofollow noreferrer\">https://docs.gomods.io/faq/</a></li>\n</ul>\n\n<p>Artifactory 5.11 needs jfrog cli instead of go dep</p>\n\n<ul>\n<li><a href=\"https://jfrog.com/blog/goproxy-artifactory-go-registries/\" rel=\"nofollow noreferrer\">https://jfrog.com/blog/goproxy-artifactory-go-registries/</a></li>\n</ul>\n",
                    "OwnerUserId": "7508450",
                    "LastActivityDate": "2018-08-20T09:57:07.587",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "52030323",
                "ParentRepo": "https://github.com/kubernetes/dns/pull/25",
                "StackOverflow_Post": {
                    "Id": "52030323",
                    "PostTypeId": "2",
                    "ParentId": "51938261",
                    "CreationDate": "2018-08-26T21:15:15.103",
                    "Score": "3",
                    "Body": "<p>At this moment, the reverse DNS lookup or PTR type lookup for a POD IP is possible only in case of pods that are part of a headless service (details: <a href=\"https://github.com/kubernetes/dns/pull/25\" rel=\"nofollow noreferrer\">https://github.com/kubernetes/dns/pull/25</a>) but even that has it's limitations. Furthermore, kubernetes has no default per POD dns name at all, even inside kubernetes cluster you are not able to say <code>curl http://&lt;pod_name&gt;</code>. You have services for that. What you are asking for is not really achievable with kubernetes and DNS as it is now. Please do remember that PTR record (IP->name) should go hand in hand with regular record for resolving name (name->IP) which also makes things complicated, and means you can not have just <code>myservice-0dkd0</code> in there.</p>\n\n<p>That said, you can achieve what you want in a non-dns way here. Assuming you run on linux, you can use <code>/etc/hosts</code> to maintain a name-to-ip and ip-to-name list that is exclusive to that particular system, and does not need to adhere to all the limitations of real DNS.</p>\n\n<p>If, on your mysql host you run something like following say from cron every 1 min, you should get correctly mapped names in your <code>/etc/hosts</code> almost all the time :</p>\n\n<pre><code>NAMESPACE=default\nsed -i \"/^[0-9\\.]*\\t[a-zA-Z0-9-]*\\.$NAMESPACE/d\" /etc/hosts\nkubectl get pod --namespace default --field-selector=status.phase==Running -o jsonpath='{range .items[*]}{.status.podIP}{\"\\t\"}{.metadata.name}.{.metadata.namespace}{\"\\n\"}{end}' &gt;&gt; /etc/hosts\n</code></pre>\n",
                    "OwnerUserId": "3871750",
                    "LastActivityDate": "2018-08-26T21:15:15.103",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "52042477",
                "ParentRepo": "https://github.com/directxman12/k8s-prometheus-adapter",
                "StackOverflow_Post": {
                    "Id": "52042477",
                    "PostTypeId": "2",
                    "ParentId": "51840970",
                    "CreationDate": "2018-08-27T15:24:58.420",
                    "Score": "4",
                    "Body": "<p>This question turned out to be  much more complex than I expected, but finally here I am with the answer.</p>\n\n<ol>\n<li><p>First of all, you need to configure your application to provide custom metrics. It is on the developing application side. Here is an example, how to make it with Go language: <a href=\"https://mycodesmells.com/post/watching-metrics-with-prometheus\" rel=\"nofollow noreferrer\">Watching Metrics With Prometheus</a></p></li>\n<li><p>Secondly, you need to define and deploy a Deployment of the application (or a Pod, or whatever you want) to Kubernetes, example:</p>\n\n<pre><code>apiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  name: podinfo\nspec:\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        app: podinfo\n      annotations:\n        prometheus.io/scrape: 'true'\n    spec:\n      containers:\n      - name: podinfod\n        image: stefanprodan/podinfo:0.0.1\n        imagePullPolicy: Always\n        command:\n          - ./podinfo\n          - -port=9898\n          - -logtostderr=true\n          - -v=2\n        volumeMounts:\n          - name: metadata\n            mountPath: /etc/podinfod/metadata\n            readOnly: true\n        ports:\n        - containerPort: 9898\n          protocol: TCP\n        readinessProbe:\n          httpGet:\n            path: /readyz\n            port: 9898\n          initialDelaySeconds: 1\n          periodSeconds: 2\n          failureThreshold: 1\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 9898\n          initialDelaySeconds: 1\n          periodSeconds: 3\n          failureThreshold: 2\n        resources:\n          requests:\n            memory: \"32Mi\"\n            cpu: \"1m\"\n          limits:\n            memory: \"256Mi\"\n            cpu: \"100m\"\n      volumes:\n        - name: metadata\n          downwardAPI:\n            items:\n              - path: \"labels\"\n                fieldRef:\n                  fieldPath: metadata.labels\n              - path: \"annotations\"\n                fieldRef:\n                  fieldPath: metadata.annotations\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: podinfo\n  labels:\n    app: podinfo\nspec:\n  type: NodePort\n  ports:\n    - port: 9898\n      targetPort: 9898\n      nodePort: 31198\n      protocol: TCP\n  selector:\n    app: podinfo\n</code></pre>\n\n<p>Pay attention to the field <code>annotations: prometheus.io/scrape: 'true'</code>. It is required to request Prometheus to read metrics from the resource. Also note, there are two more annotations, which have default values; but if you change them in your application, you need to add them with the correct values: </p>\n\n<ul>\n<li><code>prometheus.io/path</code>: If the metrics path is not /metrics, define it with this annotation.</li>\n<li><code>prometheus.io/port</code>: Scrape the pod on the indicated port instead of the pod\u2019s declared ports (default is a port-free target if none are declared).</li>\n</ul></li>\n<li><p>Next, Prometheus in Istio uses its own modified for Istio purposes configuration, and by default it skips custom metrics from Pods. Therefore, you need to modify it a little.\nIn my case, I took configuration for Pod metrics from <a href=\"https://github.com/stefanprodan/k8s-prom-hpa/blob/master/prometheus/prometheus-cfg.yaml\" rel=\"nofollow noreferrer\">this example</a> and modified Istio's Prometheus configuration only for Pods:</p>\n\n<pre><code>kubectl edit configmap -n istio-system prometheus\n</code></pre>\n\n<p>I changed the order of labels according to the example mentioned before:</p>\n\n<pre><code># pod's declared ports (default is a port-free target if none are declared).\n- job_name: 'kubernetes-pods'\n  # if you want to use metrics on jobs, set the below field to\n  # true to prevent Prometheus from setting the `job` label\n  # automatically.\n  honor_labels: false\n  kubernetes_sd_configs:\n  - role: pod\n  # skip verification so you can do HTTPS to pods\n  tls_config:\n    insecure_skip_verify: true\n  # make sure your labels are in order\n  relabel_configs:\n  # these labels tell Prometheus to automatically attach source\n  # pod and namespace information to each collected sample, so\n  # that they'll be exposed in the custom metrics API automatically.\n  - source_labels: [__meta_kubernetes_namespace]\n    action: replace\n    target_label: namespace\n  - source_labels: [__meta_kubernetes_pod_name]\n    action: replace\n    target_label: pod\n  # these labels tell Prometheus to look for\n  # prometheus.io/{scrape,path,port} annotations to configure\n  # how to scrape\n  - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]\n    action: keep\n    regex: true\n  - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]\n    action: replace\n    target_label: __metrics_path__\n    regex: (.+)\n  - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]\n    action: replace\n    regex: ([^:]+)(?::\\d+)?;(\\d+)\n    replacement: $1:$2\n    target_label: __address__\n  - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scheme]\n    action: replace\n    target_label: __scheme__\n</code></pre>\n\n<p>After that, custom metrics appeared in Prometheus. But, <strong>be careful with changing Prometheus configuration</strong>, because some metrics required for Istio may disappear, check everything carefully.</p></li>\n<li><p>Now it is time to install <a href=\"https://github.com/directxman12/k8s-prometheus-adapter\" rel=\"nofollow noreferrer\">Prometheus custom metric adapter</a>. </p>\n\n<ul>\n<li>Download <a href=\"https://github.com/directxman12/k8s-prometheus-adapter\" rel=\"nofollow noreferrer\">this</a> repository</li>\n<li>Change the address for Prometheus server in the file <code>&lt;repository-directory&gt;/deploy/manifests/custom-metrics-apiserver-deployment.yaml</code>. Example, <code>- --prometheus-url=http://prometheus.istio-system:9090/</code> </li>\n<li>Run command <code>kubectl apply -f &lt;repository-directory&gt;/deploy/manifests</code>\nAfter some time, <code>custom.metrics.k8s.io/v1beta1</code> should appear in the output of a command 'kubectl api-vesions'.          </li>\n</ul>\n\n<p>Also, check the output of the custom API using commands <code>kubectl get --raw \"/apis/custom.metrics.k8s.io/v1beta1\" | jq .</code> and <code>kubectl get --raw \"/apis/custom.metrics.k8s.io/v1beta1/namespaces/default/pods/*/http_requests\" | jq .</code>\nThe output of the last one should look like in the following example:</p>\n\n<pre><code>{\n  \"kind\": \"MetricValueList\",\n  \"apiVersion\": \"custom.metrics.k8s.io/v1beta1\",\n  \"metadata\": {\n    \"selfLink\": \"/apis/custom.metrics.k8s.io/v1beta1/namespaces/default/pods/%2A/http_requests\"\n  },\n  \"items\": [\n    {\n      \"describedObject\": {\n        \"kind\": \"Pod\",\n        \"namespace\": \"default\",\n        \"name\": \"podinfo-6b86c8ccc9-kv5g9\",\n        \"apiVersion\": \"/__internal\"\n          },\n          \"metricName\": \"http_requests\",\n          \"timestamp\": \"2018-01-10T16:49:07Z\",\n          \"value\": \"901m\"    },\n        {\n      \"describedObject\": {\n        \"kind\": \"Pod\",\n        \"namespace\": \"default\",\n        \"name\": \"podinfo-6b86c8ccc9-nm7bl\",\n        \"apiVersion\": \"/__internal\"\n      },\n      \"metricName\": \"http_requests\",\n      \"timestamp\": \"2018-01-10T16:49:07Z\",\n      \"value\": \"898m\"\n    }\n  ]\n}\n</code></pre>\n\n<p>If it does, you can move to the next step. If it doesn\u2019t, look what APIs available for Pods in CustomMetrics <code>kubectl get --raw \"/apis/custom.metrics.k8s.io/v1beta1\" | jq . | grep \"pods/\"</code> and for http_requests <code>kubectl get --raw \"/apis/custom.metrics.k8s.io/v1beta1\" | jq . | grep \"http\"</code>. MetricNames are generating according to the metrics Prometheus gather from Pods and if they are empty, you need to look in that direction.</p></li>\n<li><p>The last step is the configuring HPA and test it. So in my case, I created HPA for the podinfo application, defined before:</p>\n\n<pre><code>apiVersion: autoscaling/v2beta1\nkind: HorizontalPodAutoscaler\nmetadata:\n  name: podinfo\nspec:\n  scaleTargetRef:\n    apiVersion: extensions/v1beta1\n    kind: Deployment\n    name: podinfo\n  minReplicas: 2\n  maxReplicas: 10\n  metrics:\n  - type: Pods\n    pods:\n      metricName: http_requests\n      targetAverageValue: 10\n</code></pre>\n\n<p>and used simple Go application to test load:</p>\n\n<pre><code>#install hey\ngo get -u github.com/rakyll/hey\n#do 10K requests rate limited at 25 QPS\nhey -n 10000 -q 5 -c 5 http://&lt;K8S-IP&gt;:31198/healthz\n</code></pre>\n\n<p>After some time, I saw changes in scaling by using commands <code>kubectl describe hpa</code> and <code>kubectl get hpa</code></p></li>\n</ol>\n\n<p>I used instruction about creating Custom Metrics from the article <a href=\"https://dzone.com/articles/ensure-high-availability-and-uptime-with-kubernete\" rel=\"nofollow noreferrer\">Ensure High Availability and Uptime With Kubernetes Horizontal Pod Autoscaler and Prometheus</a></p>\n\n<p>All useful links in one place:          </p>\n\n<ul>\n<li><a href=\"https://mycodesmells.com/post/watching-metrics-with-prometheus\" rel=\"nofollow noreferrer\">Watching Metrics With Prometheus</a> - the example of adding metrics to your application</li>\n<li><a href=\"https://github.com/stefanprodan/k8s-prom-hpa\" rel=\"nofollow noreferrer\">k8s-prom-hpa</a> - the example of creating Custom Metrics for Prometheus (the same as in the article above)</li>\n<li><a href=\"https://github.com/directxman12/k8s-prometheus-adapter\" rel=\"nofollow noreferrer\">Kubernetes Custom Metrics Adapter for Prometheus</a></li>\n<li><a href=\"https://github.com/luxas/kubeadm-workshop#deploying-a-custom-metrics-api-server-and-a-sample-app\" rel=\"nofollow noreferrer\">Setting up the custom metrics adapter and sample app</a></li>\n</ul>\n",
                    "OwnerUserId": "9524052",
                    "LastActivityDate": "2018-08-27T15:24:58.420",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "52713228",
                "ParentRepo": "https://github.com/hidevopsio/hiboot-data",
                "StackOverflow_Post": {
                    "Id": "52713228",
                    "PostTypeId": "2",
                    "ParentId": "38176356",
                    "CreationDate": "2018-10-09T04:06:42.260",
                    "Score": "1",
                    "Body": "<p><a href=\"https://github.com/hidevopsio/hiboot-data\" rel=\"nofollow noreferrer\">hiboot-data</a> provides out of the box  starter that meet your requirement, the starter is github.com/hidevopsio/hiboot-data/starter/gorm, or you can implement your own starter by using <a href=\"https://github.com/hidevopsio/hiboot\" rel=\"nofollow noreferrer\">hiboot</a> framework, then you can inject then anywhere to decouple from the creation of the database configuration.</p>\n\n<pre><code>package service\n\n\nimport (\n    \"errors\"\n    \"hidevops.io/hiboot-data/examples/gorm/entity\"\n    \"hidevops.io/hiboot-data/starter/gorm\"\n    \"hidevops.io/hiboot/pkg/app\"\n    \"hidevops.io/hiboot/pkg/utils/idgen\"\n)\n\ntype UserService interface {\n    AddUser(user *entity.User) (err error)\n    GetUser(id uint64) (user *entity.User, err error)\n    GetAll() (user *[]entity.User, err error)\n    DeleteUser(id uint64) (err error)\n}\n\ntype UserServiceImpl struct {\n    // add UserService, it means that the instance of UserServiceImpl can be found by UserService\n    UserService\n    repository gorm.Repository\n}\n\nfunc init() {\n    // register UserServiceImpl\n    app.Component(newUserService)\n}\n\n// will inject BoltRepository that configured in github.com/hidevopsio/hiboot/pkg/starter/data/bolt\nfunc newUserService(repository gorm.Repository) UserService {\n    repository.AutoMigrate(&amp;entity.User{})\n    return &amp;UserServiceImpl{\n        repository: repository,\n    }\n}\n\nfunc (s *UserServiceImpl) AddUser(user *entity.User) (err error) {\n    if user == nil {\n        return errors.New(\"user is not allowed nil\")\n    }\n    if user.Id == 0 {\n        user.Id, _ = idgen.Next()\n    }\n    err = s.repository.Create(user).Error()\n    return\n}\n\nfunc (s *UserServiceImpl) GetUser(id uint64) (user *entity.User, err error) {\n    user = &amp;entity.User{}\n    err = s.repository.Where(\"id = ?\", id).First(user).Error()\n    return\n}\n\nfunc (s *UserServiceImpl) GetAll() (users *[]entity.User, err error) {\n    users = &amp;[]entity.User{}\n    err = s.repository.Find(users).Error()\n    return\n}\n\nfunc (s *UserServiceImpl) DeleteUser(id uint64) (err error) {\n    err = s.repository.Where(\"id = ?\", id).Delete(entity.User{}).Error()\n    return\n}\n</code></pre>\n",
                    "OwnerUserId": "10472883",
                    "LastEditorUserId": "10472883",
                    "LastEditDate": "2018-11-30T03:51:42.650",
                    "LastActivityDate": "2018-11-30T03:51:42.650",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "52752966",
                "ParentRepo": "https://github.com/shunfei/cronsun",
                "StackOverflow_Post": {
                    "Id": "52752966",
                    "PostTypeId": "2",
                    "ParentId": "41710941",
                    "CreationDate": "2018-10-11T05:40:38.620",
                    "Score": "1",
                    "Body": "<p>Method 1: Ansible<br>\nAnsible can distribute machine configuration to remote machines. Please refer to:\n<a href=\"https://www.ansible.com/\" rel=\"nofollow noreferrer\">https://www.ansible.com/</a></p>\n\n<p>Method 2: Distributed Cron<br>\nYou can use distribted cron to assign cron job. It has a master node and you can config your job easily and monitor the running result.\n<a href=\"https://github.com/shunfei/cronsun\" rel=\"nofollow noreferrer\">https://github.com/shunfei/cronsun</a></p>\n",
                    "OwnerUserId": "371973",
                    "LastActivityDate": "2018-10-11T05:40:38.620",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "53129926",
                "ParentRepo": "https://github.com/signalfx/signalfx-agent/blob/master/docs/monitors/docker-container-stats.md",
                "StackOverflow_Post": {
                    "Id": "53129926",
                    "PostTypeId": "2",
                    "ParentId": "53057052",
                    "CreationDate": "2018-11-03T09:12:51.970",
                    "Score": "3",
                    "Body": "<p>You need to replicate that in a non-docker environment, because with docker, memory is <a href=\"https://stackoverflow.com/q/39457819/6309\">known to raise</a>.<br>\nAs I explained in \"<a href=\"https://stackoverflow.com/a/38670876/6309\">Difference between Resident Set Size (RSS) and Java total committed memory (NMT) for a JVM running in Docker container</a>\", docker has some bugs (like <a href=\"https://github.com/moby/moby/issues/10824\" rel=\"nofollow noreferrer\">issue 10824</a> and <a href=\"https://github.com/moby/moby/issues/15020\" rel=\"nofollow noreferrer\">issue 15020</a>) which prevent an accurate report of the memory consumed by a Java process within a Docker container.</p>\n\n<p>That is why a plugin like <a href=\"https://github.com/signalfx/docker-collectd-plugin\" rel=\"nofollow noreferrer\"><code>signalfx/docker-collectd-plugin</code></a> mentions (two weeks ago) in its <a href=\"https://github.com/signalfx/docker-collectd-plugin/pull/35\" rel=\"nofollow noreferrer\">PR -- Pull Request -- 35</a> to \"deduct the cache figure from the memory usage percentage metric\":</p>\n\n<blockquote>\n  <p>Currently the calculation for memory usage of a container/cgroup being returned to SignalFX includes the Linux page cache.<br>\n  This is generally considered to be incorrect, and may lead people to chase phantom memory leaks in their application.</p>\n  \n  <p>For a demonstration on why the current calculation is incorrect, you can run the following to see how I/O usage influences the overall memory usage in a cgroup:</p>\n\n<pre><code>docker run --rm -ti alpine\ncat /sys/fs/cgroup/memory/memory.stat\ncat /sys/fs/cgroup/memory/memory.usage_in_bytes\ndd if=/dev/zero of=/tmp/myfile bs=1M count=100\ncat /sys/fs/cgroup/memory/memory.stat\ncat /sys/fs/cgroup/memory/memory.usage_in_bytes\n</code></pre>\n  \n  <p>You should see that the <code>usage_in_bytes</code> value rises by 100MB just from creating a 100MB file. That file hasn't been loaded into anonymous memory by an application, but because it's now in the page cache, the container memory usage is appearing to be higher.<br>\n  Deducting the cache figure in memory.stat from the usage_in_bytes shows that the genuine use of anonymous memory hasn't risen.</p>\n  \n  <p>The signalFX metric now differs from what is seen when you run docker stats which uses the calculation I have here.<br>\n  It seems like knowing the page cache use for a container could be useful (though I am struggling to think of when), but knowing it as part of an overall percentage usage of the cgroup isn't useful, since it then disguises your actual RSS memory use.<br>\n  In a garbage collected application with a max heap size as large, or larger than the cgroup memory limit (e.g the -Xmx parameter for java, or .NET core in server mode), the tendency will be for the percentage to get close to 100% and then just hover there, assuming the runtime can see the cgroup memory limit properly.<br>\n  If you are using the Smart Agent, I would recommend using the <a href=\"https://github.com/signalfx/signalfx-agent/blob/master/docs/monitors/docker-container-stats.md\" rel=\"nofollow noreferrer\"><strong>docker-container-stats monitor</strong></a> (to which I will make the same modification to exclude cache memory).</p>\n</blockquote>\n",
                    "OwnerUserId": "6309",
                    "LastActivityDate": "2018-11-03T09:12:51.970",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "53227242",
                "ParentRepo": "https://github.com/virtual-kubelet/virtual-kubelet",
                "StackOverflow_Post": {
                    "Id": "53227242",
                    "PostTypeId": "2",
                    "ParentId": "53220454",
                    "CreationDate": "2018-11-09T14:06:11.813",
                    "Score": "0",
                    "Body": "<p>I think you have a fundamental misunderstanding of what kubernetes does. Kubernetes, as workloads, can only run containers. If you want to deploy a new kubernetes cluster within an existing cluster, it has to be run in containers. I don't understand how you plan to run a second cluster within the first if you don't want to provision new VMs or run in containers. Where do you see your cluster running? Here are some options as I see it:</p>\n\n<p><strong>Use case 1:</strong> \n  Test new version of kubernetes before upgrading productioncluster</p>\n\n<p><strong>Solution:</strong>\n  You should really be testing this on similar/identical hardware/VMs as production. You won't be able to fully validate if you spin it up within an exisitng cluster</p>\n\n<p><strong>User case 2:</strong>\n   Test new container versions, service setups, etc.</p>\n\n<p><strong>Solution:</strong>\n   Use a new namespace with some network policies to shield it from the rest of the cluster. You can go one step further and use node taints to only allow the namespaced pods run on specific worker nodes.</p>\n\n<p><strong>Use case 3:</strong>\n  You are trying to let developers play around without messing with production.</p>\n\n<p><strong>Solution:</strong>\n  I'd suggest a seperate sandbox cluster is warrented. However, if you're willing to accept the risk, see the solution for #2</p>\n\n<p><strong>Use case 4:</strong>\n  You're deploying new kubernetes clusters for CI/CD pipelines</p>\n\n<p><strong>Solution:</strong>\n  I'd recommend separating the jobs to testing kubernetes cluster creation seperately then the workloads it'll run. One job tests the cluster creation automation, if it passes, you can promote it to the staging cluster. Use the staging cluster to test your workload jobs.</p>\n\n<p><strong>Use case 5:</strong>\n  You really really just want to run multiple kubernetes clusters within them.</p>\n\n<p><strong>Solution:</strong>\n  It's quite a hack, and I don't see how you can avoid creating new VMs, but you can look into a mixture of custom automation and a <a href=\"https://github.com/virtual-kubelet/virtual-kubelet\" rel=\"nofollow noreferrer\">virtual-kubelete</a> to register your second cluster as a \"node\" on the first cluster. This will really only let you deploy pods though. Running duplicate kubernetes processes on the same VMs will be quite difficult to achieve, mainly from a networking perspective.</p>\n\n<p>If none of these apply, can you better describe your usecase?</p>\n",
                    "OwnerUserId": "1211778",
                    "LastActivityDate": "2018-11-09T14:06:11.813",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "53316990",
                "ParentRepo": "https://github.com/concourse/dex/commit/e1acb6d577111af69dd919712a70f3e952205fce",
                "StackOverflow_Post": {
                    "Id": "53316990",
                    "PostTypeId": "2",
                    "ParentId": "45605786",
                    "CreationDate": "2018-11-15T10:09:32.003",
                    "Score": "1",
                    "Body": "<p>Concourse master branch got BitBucket Cloud OAuth back, see</p>\n\n<ul>\n<li><a href=\"https://github.com/concourse/concourse/commit/265d35519442ff174a1036889b1910dc2f91d4c9\" rel=\"nofollow noreferrer\">https://github.com/concourse/concourse/commit/265d35519442ff174a1036889b1910dc2f91d4c9</a></li>\n<li><a href=\"https://github.com/concourse/dex/commit/e1acb6d577111af69dd919712a70f3e952205fce\" rel=\"nofollow noreferrer\">https://github.com/concourse/dex/commit/e1acb6d577111af69dd919712a70f3e952205fce</a></li>\n</ul>\n\n<p>As of today (2018-11-15), there is no release yet supporting BitBucket Cloud OAuth, but the next release, which is due soon, will :-)</p>\n",
                    "OwnerUserId": "561422",
                    "LastActivityDate": "2018-11-15T10:09:32.003",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "53578881",
                "ParentRepo": "https://github.com/GoogleContainerTools/kaniko",
                "StackOverflow_Post": {
                    "Id": "53578881",
                    "PostTypeId": "5",
                    "CreationDate": "2018-12-02T09:08:09.877",
                    "Score": "0",
                    "Body": "<p><a href=\"https://github.com/GoogleContainerTools/kaniko\" rel=\"nofollow noreferrer\">kaniko</a> is a tool to build container images from a Dockerfile, inside a container or Kubernetes cluster.</p>\n",
                    "OwnerUserId": "1807667",
                    "LastEditorUserId": "584192",
                    "LastEditDate": "2018-12-12T02:55:46.353",
                    "LastActivityDate": "2018-12-12T02:55:46.353",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "53656316",
                "ParentRepo": "https://github.com/kubernetes-incubator/apiserver-builder/issues/225",
                "StackOverflow_Post": {
                    "Id": "53656316",
                    "PostTypeId": "2",
                    "ParentId": "53645454",
                    "CreationDate": "2018-12-06T16:59:27.870",
                    "Score": "0",
                    "Body": "<p>Do you have RBAC enabled? If so by default your cluster should not allow full, unprivileged access any more. It seems like issue with clusterrolebinding. <a href=\"https://github.com/kubernetes-incubator/apiserver-builder/issues/225\" rel=\"nofollow noreferrer\">Here</a> is a similar reported issue got resolved upon creating clusterrolebinding for Anonymous requests. You can try the solution advised there and should resolve your problem.</p>\n",
                    "OwnerUserId": "9253606",
                    "LastActivityDate": "2018-12-06T16:59:27.870",
                    "CommentCount": "0",
                    "CommunityOwnedDate": "2018-12-06T16:59:27.870",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "53970378",
                "ParentRepo": "https://github.com/helm/chartmuseum/issues/129",
                "StackOverflow_Post": {
                    "Id": "53970378",
                    "PostTypeId": "2",
                    "ParentId": "53967841",
                    "CreationDate": "2018-12-29T14:20:14.943",
                    "Score": "9",
                    "Body": "<p>Helm expects semantic versions in order to use the latest one by not explicitly specifying a version in the install command - <a href=\"https://github.com/helm/chartmuseum/issues/129\" rel=\"noreferrer\">https://github.com/helm/chartmuseum/issues/129</a></p>\n\n<p>As you point out in the comments, it does retrieve if you specify the specific version</p>\n",
                    "OwnerUserId": "9705485",
                    "LastActivityDate": "2018-12-29T14:20:14.943",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "54094367",
                "ParentRepo": "https://github.com/grafana/loki",
                "StackOverflow_Post": {
                    "Id": "54094367",
                    "PostTypeId": "2",
                    "ParentId": "41596104",
                    "CreationDate": "2019-01-08T14:54:44.077",
                    "Score": "8",
                    "Body": "<p>Update: <a href=\"https://github.com/grafana/loki\" rel=\"noreferrer\">Loki</a> is a new project that claims \"like Prometheus, but for logs.\"</p>\n",
                    "OwnerUserId": "1873858",
                    "LastActivityDate": "2019-01-08T14:54:44.077",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "54106726",
                "ParentRepo": "https://github.com/kubernetes-sigs/metrics-server",
                "StackOverflow_Post": {
                    "Id": "54106726",
                    "PostTypeId": "2",
                    "ParentId": "54106725",
                    "CreationDate": "2019-01-09T09:21:54.877",
                    "Score": "36",
                    "Body": "<p>I finally got it working..\nHere are the full steps I took to get things working:</p>\n<ol>\n<li><p>Have Kubernetes running within Docker</p>\n</li>\n<li><p>Delete any previous instance of metrics-server from your Kubernetes instance with <code>kubectl delete -n kube-system deployments.apps metrics-server</code></p>\n</li>\n<li><p>Clone metrics-server with <code>git clone https://github.com/kubernetes-incubator/metrics-server.git</code></p>\n</li>\n<li><p>Edit the file <strong>deploy/1.8+/metrics-server-deployment.yaml</strong> to override the default command by adding a <strong>command</strong> section that didn't exist before. The new section will instruct metrics-server to allow for an insecure communications session (don't verify the certs involved). Do this only for Docker, and not for production deployments of metrics-server:</p>\n<pre><code>containers:\n- name: metrics-server\n    image: k8s.gcr.io/metrics-server-amd64:v0.3.1\n    command:\n      - /metrics-server\n      - --kubelet-insecure-tls\n</code></pre>\n</li>\n<li><p>Add metrics-server to your Kubernetes instance with <code>kubectl create -f deploy/1.8+</code> (if errors with the .yaml, write this instead: <code>kubectl apply -f deploy/1.8+</code>)</p>\n</li>\n<li><p>Remove and add the autoscaler to your deployment again. It should now show the current cpu usage.</p>\n</li>\n</ol>\n<p><strong>EDIT July 2020:</strong></p>\n<p>Most of the above steps hold true except the <a href=\"https://github.com/kubernetes-sigs/metrics-server\" rel=\"noreferrer\">metrics-server</a> has changed and that file does not exist anymore.</p>\n<p>The repo now recommends installing it like this:</p>\n<pre><code>apply -f https://github.com/kubernetes-sigs/metrics-server/releases/download/v0.3.6/components.yaml\n</code></pre>\n<p>So we can now download this file,</p>\n<pre><code>curl -L https://github.com/kubernetes-sigs/metrics-server/releases/download/v0.3.6/components.yaml --output components.yaml\n</code></pre>\n<p>add <code>--kubelet-insecure-tls</code> under <code>args</code> (L88) to the <code>metrics-server</code> deployment and run</p>\n<pre><code>kubectl apply -f components.yaml\n</code></pre>\n",
                    "OwnerUserId": "2291510",
                    "LastEditorUserId": "2649853",
                    "LastEditDate": "2020-07-04T21:42:17.793",
                    "LastActivityDate": "2020-07-04T21:42:17.793",
                    "CommentCount": "8",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "54189534",
                "ParentRepo": "https://github.com/evildecay/etcdkeeper",
                "StackOverflow_Post": {
                    "Id": "54189534",
                    "PostTypeId": "2",
                    "ParentId": "51585649",
                    "CreationDate": "2019-01-14T21:36:46.423",
                    "Score": "1",
                    "Body": "<p><strong>Do not attempt this if you don't know what you're doing</strong></p>\n\n<p>There is another fairly hacky way of undeleting PVs. Directly editing the objects in etcd. Note that the following steps work only if you have control over etcd - this may not be true on certain cloud providers or managed offerings. Also note that you can screw things up much worse easily; since objects in etcd were never meant to be edited directly - so please approach this with caution.</p>\n\n<p>We had a situation wherein our PVs had a policy of <code>delete</code> and I accidentally ran a command deleting a majority of them, on k8s 1.11. Thanks to <a href=\"https://kubernetes.io/docs/tasks/administer-cluster/storage-object-in-use-protection/\" rel=\"nofollow noreferrer\">storage-object-in-use</a> protection, they did not immediately disappear, but they hung around in a dangerous state. Any deletion or restarts of the pods that were binding the PVCs would have caused the <code>kubernetes.io/pvc-protection</code> finalizer to get removed and thereby deletion of the underlying volume (in our case, EBS). New finalizers also cannot be added when the resource is in terminating state - From a k8s design standpoint, this is necessary in order to prevent race conditions.</p>\n\n<p>Below are the steps I followed:</p>\n\n<ul>\n<li>Back up the storage volumes you care about. This is just to cover yourself against possible deletion - AWS, GCP, Azure all provide mechanisms to do this and create a new snapshot.</li>\n<li>Access etcd directly - if it's running as a static pod, you can ssh into it and check the http serving port. By default, this is 4001. If you're running multiple etcd nodes, use any one.</li>\n<li>Port-forward 4001 to your machine from the pod. </li>\n</ul>\n\n<pre><code>kubectl -n=kube-system port-forward etcd-server-ip-x.y.z.w-compute.internal 4001:4001 \n</code></pre>\n\n<ul>\n<li><p>Use the REST API, or a tool like <a href=\"https://github.com/evildecay/etcdkeeper\" rel=\"nofollow noreferrer\">etcdkeeper</a> to connect to the cluster. </p></li>\n<li><p>Navigate to <code>/registry/persistentvolumes/</code> and find the corresponding PVs. The deletion of resources by controllers in k8s is done by setting the <code>.spec.deletionTimeStamp</code> field in the controller spec. Delete this field in order to have the controllers stop trying to delete the PV. This will revert them to the <code>Bound</code> state, which is probably where they were before you ran a delete.</p></li>\n<li><p>You can also carefully edit the reclaimPolicy to <code>Retain</code> and then save the objects back to etcd. The controllers will re-read the state soon and you should see it reflected in <code>kubectl get pv</code> output as well shortly.</p></li>\n</ul>\n\n<p>Your PVs should go back to the old undeleted state:</p>\n\n<pre><code>$ kubectl get pv\n\nNAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS    CLAIM                                             STORAGECLASS                      REASON    AGE\npvc-b5adexxx   5Gi        RWO            Retain           Bound     zookeeper/datadir-zoo-0                           gp2                                         287d\npvc-b5ae9xxx   5Gi        RWO            Retain           Bound     zookeeper/datalogdir-zoo-0                        gp2                                         287d\n</code></pre>\n\n<p>As a general best practice, it is best to use <a href=\"https://kubernetes.io/docs/reference/access-authn-authz/rbac/\" rel=\"nofollow noreferrer\">RBAC</a> and the right persistent volume reclaim policy to prevent accidental deletion of PVs or the underlying storage.</p>\n",
                    "OwnerUserId": "759019",
                    "LastEditorUserId": "759019",
                    "LastEditDate": "2019-02-22T19:56:13.657",
                    "LastActivityDate": "2019-02-22T19:56:13.657",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "54543941",
                "ParentRepo": "https://github.com/operator-framework/operator-lifecycle-manager",
                "StackOverflow_Post": {
                    "Id": "54543941",
                    "PostTypeId": "1",
                    "CreationDate": "2019-02-05T22:19:41.587",
                    "Score": "4",
                    "ViewCount": "2033",
                    "Body": "<p>What is the difference and benefit of the Operator Lifecycle Manager (OLM) vs Helm?</p>\n\n<p>OLM - <a href=\"https://github.com/operator-framework/operator-lifecycle-manager\" rel=\"nofollow noreferrer\">https://github.com/operator-framework/operator-lifecycle-manager</a></p>\n\n<p>Helm - <a href=\"https://helm.sh/\" rel=\"nofollow noreferrer\">https://helm.sh/</a></p>\n\n<p>I understand that Helm is a general purpose package manager for Kubernetes where as OLM is specific to operators. But, Helm can be used to deploy operators. So, how is OLM different/better than Helm for operators?</p>\n",
                    "OwnerUserId": "1676293",
                    "LastEditorUserId": "-1",
                    "LastEditDate": "2019-03-18T19:07:12.097",
                    "LastActivityDate": "2020-10-27T12:54:59.387",
                    "Title": "Operator Lifecycle Manager (OLM) vs Helm",
                    "Tags": "<kubernetes><kubernetes-helm>",
                    "AnswerCount": "2",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "55027070",
                "ParentRepo": "https://github.com/rancher/k3s/blob/master/README.md",
                "StackOverflow_Post": {
                    "Id": "55027070",
                    "PostTypeId": "2",
                    "ParentId": "55024494",
                    "CreationDate": "2019-03-06T15:48:48.580",
                    "Score": "1",
                    "Body": "<p>Moving from Minikube or microk8s to On Premises Kubernetes is huge leapfrog.</p>\n\n<p>You are right about not using Minikube on production since according to Dan Lorenc (help create Minikube): </p>\n\n<blockquote>\n  <p>Anything that you need reliability for, like anything you're going to use in production, you should not use Minikube for. You should use something that has at least two or three nodes so, if something crashes, you don't lose all of your data. </p>\n</blockquote>\n\n<p>I would suggest if possible having managed kubernetes on some of the big cloud providers AWS, Azure, GCP , DigitalOcean and etc. This way you skip setting up Kuberenetes and you are provided by buildin cloud provider Load Balancer.</p>\n\n<p>If you are for option to start working on your Kubernetes in On Premises I would start from materials provided by Kelsey Hightower like material on <a href=\"https://github.com/kelseyhightower/kubernetes-the-hard-way\" rel=\"nofollow noreferrer\">this link</a>.</p>\n\n<p>Rancher labs have opensourced project k3s for easy installation of kubernetes for situations where a PhD in k8s clusterology is infeasible. Check their <a href=\"https://github.com/rancher/k3s/blob/master/README.md\" rel=\"nofollow noreferrer\">project on github.</a></p>\n",
                    "OwnerUserId": "5743886",
                    "LastEditorUserId": "5743886",
                    "LastEditDate": "2019-03-06T16:08:36.580",
                    "LastActivityDate": "2019-03-06T16:08:36.580",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "55040450",
                "ParentRepo": "https://github.com/kubernetes-sigs/cluster-api",
                "StackOverflow_Post": {
                    "Id": "55040450",
                    "PostTypeId": "2",
                    "ParentId": "55024494",
                    "CreationDate": "2019-03-07T09:36:46.420",
                    "Score": "2",
                    "Body": "<p>If you consider to bootstrap Kubernetes cluster on bare metal platform, then I would take a look at <a href=\"https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/\" rel=\"nofollow noreferrer\">kubeadm</a>. It is most suitable for Kubernetes clusters with multi nodes support and provides a lot of features and customization options. </p>\n\n<ul>\n<li>Infrastructure provisioning - <a href=\"https://github.com/kubernetes-sigs/cluster-api\" rel=\"nofollow noreferrer\">Cluster API</a></li>\n<li>Third-party network <a href=\"https://kubernetes.io/docs/concepts/extend-kubernetes/compute-storage-net/network-plugins/\" rel=\"nofollow noreferrer\">CNI</a> plugins support</li>\n<li>Addons for monitoring, logging, and visualization.</li>\n<li>Specific cloud provider integrations (Load balancers, Storage\nclasses, etc.)</li>\n</ul>\n\n<p>However, moving Kubernetes to cloud environment can bring a more efficient way for managing Kubernetes cluster. As most of cloud providers natively offer Kubernetes engine (<a href=\"https://cloud.google.com/kubernetes-engine/\" rel=\"nofollow noreferrer\">GKE</a>, <a href=\"https://www.google.com/aclk?sa=L&amp;ai=DChcSEwjIrean2O_gAhUP2bIKHdAKB0sYABAAGgJscg&amp;sig=AOD64_2b-rE2OHlvduVomGwt6MWOnyCJtQ&amp;q=&amp;ved=2ahUKEwjZ7eGn2O_gAhU0xMQBHT6lAPYQ0Qx6BAgGEAE&amp;adurl=\" rel=\"nofollow noreferrer\">EKS</a>, <a href=\"https://azure.microsoft.com/en-us/services/kubernetes-service/\" rel=\"nofollow noreferrer\">AKS</a>, etc.). </p>\n",
                    "OwnerUserId": "9928809",
                    "LastEditorUserId": "10462293",
                    "LastEditDate": "2019-03-13T14:41:25.333",
                    "LastActivityDate": "2019-03-13T14:41:25.333",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "56208198",
                "ParentRepo": "https://github.com/square/ghostunnel",
                "StackOverflow_Post": {
                    "Id": "56208198",
                    "PostTypeId": "1",
                    "CreationDate": "2019-05-19T13:18:26.830",
                    "Score": "3",
                    "ViewCount": "278",
                    "Body": "<p>I am setting up a rest client that must be trusted by a remote server using client certificate. Client written in python, running on windows 10. How can I use <strong>YubiKey 5</strong> to store private key to encrypt SSL connection? </p>\n\n<p>It seems like there is no off-the-shelf solution / python package that supports using pkcs11 for ssl context. \nWe were able to use <a href=\"https://github.com/square/ghostunnel\" rel=\"nofollow noreferrer\">https://github.com/square/ghostunnel</a> with yubikeys with client certificates, but it makes solution less secure and more complicated to deploy.</p>\n",
                    "OwnerUserId": "11523745",
                    "LastEditorUserId": "11523745",
                    "LastEditDate": "2019-05-20T15:09:46.873",
                    "LastActivityDate": "2019-05-20T15:09:46.873",
                    "Title": "Python: TLS session with Yubikey",
                    "Tags": "<python-3.x><windows><ssl><pkcs#11><yubico>",
                    "AnswerCount": "0",
                    "CommentCount": "2",
                    "FavoriteCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "56373777",
                "ParentRepo": "https://github.com/kubernetes/cloud-provider-gcp/blob/master/vendor/k8s.io/kubernetes/pkg/cloudprovider/providers/gce/gce.go#L352",
                "StackOverflow_Post": {
                    "Id": "56373777",
                    "PostTypeId": "2",
                    "ParentId": "56354235",
                    "CreationDate": "2019-05-30T07:37:41.063",
                    "Score": "1",
                    "Body": "<p>After several days' research, I found that the reason is:</p>\n\n<ol>\n<li>Master node is in <code>asia-northeast1-a</code> (Tokyo)</li>\n<li>Worker nodes are in <code>asia-east1-a</code> (Taiwan) and other zones</li>\n<li><a href=\"https://github.com/kubernetes/cloud-provider-gcp/blob/master/vendor/k8s.io/kubernetes/pkg/cloudprovider/providers/gce/gce.go#L352\" rel=\"nofollow noreferrer\"><code>cloud-provider-gcp</code></a> only search the zone in one region (normally the master node's zone, but you can specify it by setting <code>local-zone</code> in the cloud config file), which means it can only support one zone or multiple zones in one region by default</li>\n</ol>\n\n<p>Conclusion:</p>\n\n<p>In order to support multiple zones among multiple regions, we need to modify the gce provider code of configuration, like add another field to configure which zones should be searched.</p>\n\n<p>==========================UPDATE=========================</p>\n\n<p>I modified the k8s code to add a <code>extra-zones</code> config field like <a href=\"https://github.com/kubernetes/kubernetes/compare/release-1.14...kigawas:release-1.14\" rel=\"nofollow noreferrer\">this diff on github</a> to make it work on my use case.</p>\n",
                    "OwnerUserId": "3134333",
                    "LastEditorUserId": "3134333",
                    "LastEditDate": "2019-06-11T08:44:41.670",
                    "LastActivityDate": "2019-06-11T08:44:41.670",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "56418329",
                "ParentRepo": "https://github.com/kubernetes-incubator/custom-metrics-apiserver/blob/master/docs/getting-started.md",
                "StackOverflow_Post": {
                    "Id": "56418329",
                    "PostTypeId": "1",
                    "CreationDate": "2019-06-02T19:33:49.863",
                    "Score": "0",
                    "ViewCount": "85",
                    "Body": "<p>I want to implement custom metric API server to use with HPA. we have proprietary monitoring system that have client library in C# but all the implementation i saw online are in Go. </p>\n\n<p>Is there a definition of REST API (request and response) that the HPA call? or this can be only in Go (for some reason)?</p>\n\n<p>I can use <a href=\"https://github.com/kubernetes-incubator/custom-metrics-apiserver/blob/master/docs/getting-started.md\" rel=\"nofollow noreferrer\">this</a> to create a proxy server between Go and my C# server but i rather go straight to my server from HPA</p>\n",
                    "OwnerUserId": "11322465",
                    "LastActivityDate": "2019-06-07T14:48:11.113",
                    "Title": "Custom metric API server not in Go",
                    "Tags": "<kubernetes><kubernetes-hpa>",
                    "AnswerCount": "1",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "56523183",
                "ParentRepo": "https://github.com/kubermatic/kubeone",
                "StackOverflow_Post": {
                    "Id": "56523183",
                    "PostTypeId": "2",
                    "ParentId": "56517811",
                    "CreationDate": "2019-06-10T08:49:01.540",
                    "Score": "2",
                    "Body": "<p>This comes down to a debate over essential vs accidental complexity. The verdict is in from companies that k8s strikes a good balance vs swarm and other orchestrators are barely talked about in the industry.</p>\n\n<p><a href=\"https://www.reactiveops.com/blog/is-kubernetes-overkill\" rel=\"nofollow noreferrer\">https://www.reactiveops.com/blog/is-kubernetes-overkill</a></p>\n\n<p>The platforms that build on kubernetes are still emerging to offer a simpler interface for those wanting a higher level of abstraction but aren't mature enough yet. GKE offers a very easy way to just deal with workloads, AKS is still maturing so you will likely face some bugs but it is tightly integrated with Azure Devops. </p>\n\n<p>Microsoft is all-in on k8s although their on-prem offering doesn't seem fully fledged yet. GKE on-prem and Openshift 4.1 offer fully managed on-prem (if using vSphere) for list price of $1200/core/year. <a href=\"https://nedinthecloud.com/2019/02/19/azure-stack-kubernetes-cluster-is-not-aks/\" rel=\"nofollow noreferrer\">https://nedinthecloud.com/2019/02/19/azure-stack-kubernetes-cluster-is-not-aks/</a></p>\n\n<p>Other ways of deploying on prem are emerging so long as you're comfortable with managing the compute, storage and network yourself. Installing and upgrading are becoming easier (see e.g. <a href=\"https://github.com/kubermatic/kubeone\" rel=\"nofollow noreferrer\">https://github.com/kubermatic/kubeone</a> which builds on the cluster-api abstraction). For bare metal ambitious projects like talos are making k8s specific immutable OSes (<a href=\"https://github.com/talos-systems/talos\" rel=\"nofollow noreferrer\">https://github.com/talos-systems/talos</a>).</p>\n\n<p>AWS is still holding out hope for lock-in with ECS and Fargate but it remains to be seen if that will succeed.</p>\n",
                    "OwnerUserId": "578582",
                    "LastEditorUserId": "578582",
                    "LastEditDate": "2019-06-10T08:57:38.057",
                    "LastActivityDate": "2019-06-10T08:57:38.057",
                    "CommentCount": "8",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "56598636",
                "ParentRepo": "https://github.com/kedacore/keda",
                "StackOverflow_Post": {
                    "Id": "56598636",
                    "PostTypeId": "2",
                    "ParentId": "56552175",
                    "CreationDate": "2019-06-14T12:54:25.823",
                    "Score": "1",
                    "Body": "<p>You could consider approach using <strong>preStop hook</strong>.</p>\n\n<p>As per documentation <a href=\"https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#container-states\" rel=\"nofollow noreferrer\">Container States</a>, <a href=\"https://kubernetes.io/docs/tasks/configure-pod-container/attach-handler-lifecycle-event/#define-poststart-and-prestop-handlers\" rel=\"nofollow noreferrer\">Define postStart and preStop handlers</a>:</p>\n\n<blockquote>\n  <p>Before a container enters into Terminated, preStop hook (if any) is executed.</p>\n</blockquote>\n\n<p>So you can use in your deployment:</p>\n\n<pre><code>lifecycle:\n      preStop:\n        exec:\n          command: [\"your script\"]\n</code></pre>\n\n<p><code>###</code> <strong>update</strong>:</p>\n\n<ol>\n<li><p>I would like to provide more information due to some research:\nThere is an interesting <a href=\"https://github.com/kedacore/keda\" rel=\"nofollow noreferrer\">project</a>: </p>\n\n<blockquote>\n  <p>KEDA allows for fine grained autoscaling (including to/from zero) for event driven Kubernetes workloads. KEDA serves as a Kubernetes Metrics Server and allows users to define autoscaling rules using a dedicated Kubernetes custom resource definition.\n  KEDA can run on both the cloud and the edge, integrates natively with Kubernetes components such as the Horizontal Pod Autoscaler, and has no external dependencies.</p>\n</blockquote></li>\n<li><p>For the main question \"Kubernetes could terminate a pod that is still doing the processing of its own message\". </p>\n\n<p>As per documentation:</p>\n\n<blockquote>\n  <p>\"Deployment is a higher-level concept that manages ReplicaSets and provides declarative updates to Pods along with a lot of other useful features\"</p>\n</blockquote></li>\n</ol>\n\n<p>Deployment is backed by Replicaset. As per this controller code there exist function  \"<a href=\"https://github.com/kubernetes/kubernetes/blob/f794c824b1e6e68b302d94f42f60af4759e18c6d/pkg/controller/replicaset/replica_set.go#L684:6\" rel=\"nofollow noreferrer\">getPodsToDelete</a>\". In combination with \"<em>filteredPods</em>\" it gives the result: \"<strong>This ensures that we delete pods in the earlier stages whenever possible.</strong>\"</p>\n\n<p>So as proof of concept:</p>\n\n<p>You can create deployment with <strong>init container</strong>. Init container should check if there is a message in the queue and exit when at least one message appears. This will allow main container to start, take and process that message. In this case we will have <strong>two kinds of pods</strong> - those which <strong>process the message</strong> and consume CPU and those who are in the <strong>starting state</strong>, idle and waiting for the next message. In this case <strong>starting containers will be deleted at the first place</strong> when HPA decide to decrease number of replicas in the deployment. </p>\n\n<pre><code>apiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  labels:\n    app: complete\n  name: complete\nspec:\n  replicas: 5\n  revisionHistoryLimit: 10\n  selector:\n    matchLabels:\n      app: complete\n  template:\n    metadata:\n      creationTimestamp: null\n      labels:\n        app: complete\n    spec:\n      hostname: c1\n      containers:\n      - name: complete\n        command: \n        - \"bash\"\n        args:\n        - \"-c\"\n        - \"wa=$(shuf -i 15-30 -n 1)&amp;&amp; echo $wa &amp;&amp; sleep $wa\"\n        image: ubuntu\n        imagePullPolicy: IfNotPresent\n        resources: {}\n      initContainers:\n      - name: wait-for\n        image: ubuntu\n        command: ['bash', '-c', 'sleep 30']\n\n\n  dnsPolicy: ClusterFirst\n  restartPolicy: Always\n  terminationGracePeriodSeconds: 30\n</code></pre>\n\n<p>Hope this help.</p>\n",
                    "OwnerUserId": "11207414",
                    "LastEditorUserId": "11207414",
                    "LastEditDate": "2019-07-05T07:32:06.530",
                    "LastActivityDate": "2019-07-05T07:32:06.530",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "57100244",
                "ParentRepo": "https://github.com/openshift/router/blob/master/images/router/haproxy/conf/haproxy-config.template#L427",
                "StackOverflow_Post": {
                    "Id": "57100244",
                    "PostTypeId": "2",
                    "ParentId": "56920670",
                    "CreationDate": "2019-07-18T17:58:12.177",
                    "Score": "1",
                    "Body": "<p>The OpenShift router (which is what exposes the secured route you created) will set a number of <a href=\"https://github.com/openshift/router/blob/master/images/router/haproxy/conf/haproxy-config.template#L427\" rel=\"nofollow noreferrer\">headers</a> on the request to the backend pod running your Yii2 application.</p>\n\n<p>The first thing we have to do is trust these headers at Nginx so that it will relay them to the backend Yii2 application.</p>\n\n<pre><code>location ~ \\.php$ {\n    proxy_pass_header   X-Forwarded-Proto;\n    proxy_pass_header   X-Forwarded-Host;\n    proxy_pass_header   X-Forwarded-Port;\n    [...]\n</code></pre>\n\n<p><code>X-Forwarded-Proto</code> will be set to <code>https</code> and it looks like <a href=\"https://www.yiiframework.com/doc/guide/2.0/en/runtime-requests#trusted-proxies\" rel=\"nofollow noreferrer\">Yii2</a> will handle the header correctly but I have not used that PHP framework before. This would be the second step if it is required which would be to have the framework craft response url's with the protocol that is in the x-forwarded-proto header.</p>\n\n<p>It should be noted here that trusting these headers at the Nginx level can be dangerous if untrusted users can access Nginx directly. In this scenario they would be able to spoof requests and set these headers to be whatever they want.</p>\n",
                    "OwnerUserId": "3439967",
                    "LastActivityDate": "2019-07-18T17:58:12.177",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "57125755",
                "ParentRepo": "https://github.com/dexidp/dex/blob/master/Documentation/kubernetes.md#logging-into-the-cluster",
                "StackOverflow_Post": {
                    "Id": "57125755",
                    "PostTypeId": "1",
                    "CreationDate": "2019-07-20T14:43:47.090",
                    "Score": "0",
                    "ViewCount": "754",
                    "Body": "<p>I built a deploy pipeline to serve ML models using Kubeflow (v0.6) and Seldon Core, but now that models are deployed I can't figure out how to pass the auth. layer and consume the services.</p>\n\n<p>My kubernetes instance is on bare-metal and setup is identical to this: <a href=\"https://www.kubeflow.org/docs/started/getting-started-k8s/\" rel=\"nofollow noreferrer\">https://www.kubeflow.org/docs/started/getting-started-k8s/</a></p>\n\n<p>I was able to follow <a href=\"https://github.com/dexidp/dex/blob/master/Documentation/kubernetes.md#logging-into-the-cluster\" rel=\"nofollow noreferrer\">these instructions</a> launch example-app and issue an IDToken for a staticClient, but when I pass the token as 'Authorization: Bearer' I get redirected to dex logon page.</p>\n\n<p>(part of) Dex configMap:</p>\n\n<pre><code>staticClients:\n- id: kubeflow-authservice-oidc\n  redirectURIs:\n  # After authenticating and giving consent, dex will redirect to\n  # this url for the specific client.\n  - https://10.50.11.180/login/oidc\n  name: 'Kubeflow AuthService OIDC'\n  secret: [secret]\n- id: model-consumer-1\n  secret: [secret]\n  redirectURIs:\n  - 'http://127.0.0.1:5555/callback'\n</code></pre>\n\n<p>When I try to access the service:</p>\n\n<pre class=\"lang-sh prettyprint-override\"><code>curl -H \"Authorization: Bearer $token\" -k https://10.50.11.180/seldon/kubeflow/machine-failure-classifier-6e462a70-a995-11e9-b30b-080027dfd9f4/api/v0.1/predictions\n\n&lt;a href=\"https://10.50.11.180:5556/dex/auth?client_id=kubeflow-authservice-oidc&amp;amp;redirect_uri=https%3A%2F%2F10.50.11.180%2Flogin%2Foidc&amp;amp;response_type=code&amp;amp;scope=openid+profile+email+groups&amp;amp;state=X40FJuKC\"&gt;Found&lt;/a&gt;.\n</code></pre>\n\n<p>What am I missing? :(</p>\n",
                    "OwnerUserId": "2625708",
                    "LastEditorUserId": "531021",
                    "LastEditDate": "2019-07-20T20:31:37.487",
                    "LastActivityDate": "2022-10-17T18:11:58.673",
                    "Title": "How to access model microservice deployed behind Istio and Dex?",
                    "Tags": "<kubernetes><istio><kubeflow><openid-dex>",
                    "AnswerCount": "3",
                    "CommentCount": "0",
                    "FavoriteCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "57495031",
                "ParentRepo": "https://github.com/jpbetz/auger",
                "StackOverflow_Post": {
                    "Id": "57495031",
                    "PostTypeId": "2",
                    "ParentId": "45744534",
                    "CreationDate": "2019-08-14T12:47:36.550",
                    "Score": "3",
                    "Body": "<p>A bit late to the show but here is how I was able to do that.\nBecause in etcd pre-v3 the data was stored in plain <code>json</code> and since v3 it is in binary format the additional decode step is needed.</p>\n\n<p>You may check this repo for details: \n<a href=\"https://github.com/jpbetz/auger\" rel=\"nofollow noreferrer\">https://github.com/jpbetz/auger</a></p>\n\n<p>And <a href=\"https://kubernetes.io/docs/reference/using-api/api-concepts/#protobuf-encoding\" rel=\"nofollow noreferrer\">here</a> are Kubernetes docs regarding protobuf encoding</p>\n\n<p>And the working example is:</p>\n\n<pre><code>etcdctl get \"/registry/pods/default/nginx-dbddb74b8-62hh7\" --prefix -w simple | auger decode\n</code></pre>\n\n<p>Now the response is plain-text:</p>\n\n<pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  annotations:\n    kubernetes.io/limit-ranger: 'LimitRanger plugin set: cpu request for container\n      nginx'\n  creationTimestamp: 2019-08-12T14:11:57Z\n...\n</code></pre>\n",
                    "OwnerUserId": "2409848",
                    "LastEditorUserId": "2409848",
                    "LastEditDate": "2019-08-14T15:10:23.187",
                    "LastActivityDate": "2019-08-14T15:10:23.187",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "57621384",
                "ParentRepo": "https://github.com/sensu/sensu-go/issues/1890",
                "StackOverflow_Post": {
                    "Id": "57621384",
                    "PostTypeId": "1",
                    "CreationDate": "2019-08-23T07:09:22.913",
                    "Score": "1",
                    "ViewCount": "268",
                    "Body": "<p>I'm having an issue setting up my cluster according to the documents, as seen here: <a href=\"https://docs.sensu.io/sensu-go/5.5/guides/clustering/\" rel=\"nofollow noreferrer\">https://docs.sensu.io/sensu-go/5.5/guides/clustering/</a></p>\n\n<p>This is a non-https setup to get my feet wet, I'm not concerned with that at the moment. I just want a running cluster to begin with.</p>\n\n<p>I've set up sensu-backend on my three nodes, and have configured the backend configuration (backend.yml) accordingly on all three nodes through an ansible playbook. However, my cluster does not discover the other two nodes. It simply shows the following:</p>\n\n<p>For backend1: </p>\n\n<pre><code>=== Etcd Cluster ID: 3b0efc7b379f89be\n         ID                Name                Peer URLs              Client URLs       \n \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \n  8927110dc66458af   backend1   http://127.0.0.1:2380   http://localhost:2379\n\n</code></pre>\n\n<p>For backend2 and backend3, it's the same, except it shows those individual nodes as the only nodes in their cluster.</p>\n\n<p>I've tried both the configuration in the docs, as well as the configuration in this git issue: <a href=\"https://github.com/sensu/sensu-go/issues/1890\" rel=\"nofollow noreferrer\">https://github.com/sensu/sensu-go/issues/1890</a></p>\n\n<p>None of these have panned out for me. I've ensured all the ports are open, so that's not an issue. </p>\n\n<p>When I do a manual <code>sensuctl cluster member-add X X</code>, I get an error message and it results in the sensu-backend process failing. I can't remove the member, either, because it causes the entire process to not be able to start. I have to revert to an earlier snapshot to fix it.</p>\n\n<p>The configs on all machines are the same, except the IP's and names are appropriated for each machine</p>\n\n<pre><code>etcd-advertise-client-urls: \"http://XX.XX.XX.20:2379\"\netcd-listen-client-urls: \"http://XX.XX.XX.20:2379\"\netcd-listen-peer-urls: \"http://0.0.0.0:2380\"\netcd-initial-cluster: \"backend1=http://XX.XX.XX.20:2380,backend2=http://XX.XX.XX.31:2380,backend3=http://XX.XX.XX.32:2380\"\netcd-initial-advertise-peer-urls: \"http://XX.XX.XX.20:2380\"\netcd-initial-cluster-state: \"new\" # have also tried existing\netcd-initial-cluster-token: \"\"\netcd-name: \"backend1\"\n</code></pre>\n",
                    "OwnerUserId": "6865963",
                    "LastActivityDate": "2019-09-12T17:19:27.377",
                    "Title": "Setting up a Sensu-Go cluster - cluster is not synchronizing",
                    "Tags": "<ansible><cluster-computing><sensu>",
                    "AnswerCount": "1",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "57876172",
                "ParentRepo": "https://github.com/pingcap/tidb-operator/issues/674",
                "StackOverflow_Post": {
                    "Id": "57876172",
                    "PostTypeId": "2",
                    "ParentId": "57412297",
                    "CreationDate": "2019-09-10T18:08:10.967",
                    "Score": "0",
                    "Body": "<p>Just inspect your post command, it seems that you just easily copy the same command from the offical document <a href=\"https://learn.microsoft.com/en-us/azure/cognitive-services/form-recognizer/form-recognizer-container-howto#form-recognizer-1\" rel=\"nofollow noreferrer\"><code>Install and run Form Recognizer containers</code></a> and not to replace these arguments like <code>{FORM_RECOGNIZER_ENDPOINT_URI}</code> with your correct information. So the error message is </p>\n\n<blockquote>\n  <p>Error response from daemon: readlink /var/lib/docker/overlay2/l: <strong>invalid argument</strong></p>\n</blockquote>\n\n<p>If not as what I said above,  may you can get the useful issue fix solution from the same GitHub issue on MacOS <a href=\"https://github.com/pingcap/tidb-operator/issues/674\" rel=\"nofollow noreferrer\">https://github.com/pingcap/tidb-operator/issues/674</a>.</p>\n",
                    "OwnerUserId": "4989676",
                    "LastActivityDate": "2019-09-10T18:08:10.967",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "57908716",
                "ParentRepo": "https://github.com/openshift/console-operator",
                "StackOverflow_Post": {
                    "Id": "57908716",
                    "PostTypeId": "1",
                    "CreationDate": "2019-09-12T14:16:10.240",
                    "Score": "0",
                    "ViewCount": "206",
                    "Body": "<p>Recently I discovered, that is possible to run OpenShift Web UI on upstream k8s</p>\n\n<p>Is this possible? I understand that projects are defacto namespaces, but is there any fallback/callback to native k8s API ? ( at least routes will not definetily work ... )</p>\n\n<p><strong>For example:</strong></p>\n\n<ol>\n<li><a href=\"https://github.com/operator-framework/operator-lifecycle-manager#user-interface\" rel=\"nofollow noreferrer\">https://github.com/operator-framework/operator-lifecycle-manager#user-interface</a></li>\n<li><a href=\"https://github.com/kubevirt/web-ui#native-kubernetes\" rel=\"nofollow noreferrer\">https://github.com/kubevirt/web-ui#native-kubernetes</a></li>\n<li><a href=\"https://github.com/openshift/console#native-kubernetes\" rel=\"nofollow noreferrer\">https://github.com/openshift/console#native-kubernetes</a></li>\n</ol>\n\n<p>No mention about upstream k8s here: </p>\n\n<p><strong>console-operator:</strong>  <a href=\"https://github.com/openshift/console-operator\" rel=\"nofollow noreferrer\">https://github.com/openshift/console-operator</a> ( seems its > 4.X version )</p>\n\n<p>Registries: </p>\n\n<ul>\n<li><p><a href=\"https://hub.docker.com/r/openshift/origin-console-operator/tags\" rel=\"nofollow noreferrer\">https://hub.docker.com/r/openshift/origin-console-operator/tags</a> </p></li>\n<li><p><a href=\"https://quay.io/repository/openshift/origin-console-operator?tab=tags\" rel=\"nofollow noreferrer\">https://quay.io/repository/openshift/origin-console-operator?tab=tags</a></p></li>\n</ul>\n\n<p><strong>standalone:</strong> <a href=\"https://github.com/openshift/console\" rel=\"nofollow noreferrer\">https://github.com/openshift/console</a>  ( version >= 3.X )</p>\n\n<p>Registries:</p>\n\n<ul>\n<li><p><a href=\"https://hub.docker.com/r/openshift/origin-console/tags\" rel=\"nofollow noreferrer\">https://hub.docker.com/r/openshift/origin-console/tags</a></p></li>\n<li><p><a href=\"https://quay.io/repository/openshift/origin-console?tab=tags\" rel=\"nofollow noreferrer\">https://quay.io/repository/openshift/origin-console?tab=tags</a></p></li>\n</ul>\n\n<p>Can anyone tell me more? </p>\n\n<p>Or did anyone succeced with openshift ui on upstream k8s? </p>\n\n<p>P.S. I dont want to deploy openshift/okd solution.</p>\n\n<p>Thanks</p>\n",
                    "OwnerUserId": "3797368",
                    "LastActivityDate": "2019-09-12T16:39:31.287",
                    "Title": "OpenShift Web UI on upstream k8s",
                    "Tags": "<kubernetes><openshift><openshift-origin><okd>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "58659834",
                "ParentRepo": "https://github.com/kubernetes-sigs/descheduler",
                "StackOverflow_Post": {
                    "Id": "58659834",
                    "PostTypeId": "2",
                    "ParentId": "58657088",
                    "CreationDate": "2019-11-01T13:13:31.113",
                    "Score": "1",
                    "Body": "<p>Take a look at the <a href=\"https://github.com/kubernetes-sigs/descheduler\" rel=\"nofollow noreferrer\">Descheduler</a>. This project runs as a Kubernetes Job that aims at killing pods when it thinks the cluster is unbalanced.</p>\n\n<p>The <a href=\"https://github.com/kubernetes-sigs/descheduler#lownodeutilization\" rel=\"nofollow noreferrer\"><code>LowNodeUtilization</code></a> strategy seems to fit your case:</p>\n\n<blockquote>\n  <p>This strategy finds nodes that are under utilized and evicts pods, if\n  possible, from other nodes in the hope that recreation of evicted pods\n  will be scheduled on these underutilized nodes.</p>\n</blockquote>\n\n<hr>\n\n<p>Another option is to apply a little of chaos engineering manually, forcing a Rolling Update on your deployment, and hopefully, the scheduler will fix the balance problem when pods are recreated. </p>\n\n<p>You can use the <code>kubectl rollout restart my-deployment</code>. It's way better than simply deleting the pods with <code>kubectl delete pod</code>, as the rollout will ensure availability during the \"rebalancing\" (although deleting the pods altogether increases your chances for a better rebalance).</p>\n",
                    "OwnerUserId": "7641078",
                    "LastEditorUserId": "7641078",
                    "LastEditDate": "2019-11-01T13:30:09.733",
                    "LastActivityDate": "2019-11-01T13:30:09.733",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "58678622",
                "ParentRepo": "https://github.com/gojek/weaver",
                "StackOverflow_Post": {
                    "Id": "58678622",
                    "PostTypeId": "2",
                    "ParentId": "58675990",
                    "CreationDate": "2019-11-03T08:45:52.843",
                    "Score": "11",
                    "Body": "<h1>StatefulSet</h1>\n\n<p><a href=\"https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/\" rel=\"noreferrer\">StatefulSet</a> is a <em>building block</em> for stateful workload on Kubernetes with certain guarantees.</p>\n\n<h2>Stable and unique network identity</h2>\n\n<blockquote>\n  <p>StatefulSet Pods have a unique identity that is comprised of an ordinal, a stable network identity, and stable storage.</p>\n</blockquote>\n\n<p>As an example, if your StatefulSet has the name <code>sharded-svc</code></p>\n\n<pre><code>apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: sharded-svc\n</code></pre>\n\n<p>And you have e.g. 3 replicas, those will be named by <code>&lt;name&gt;-&lt;ordinal&gt;</code> where <em>ordinal</em> starts from 0 up to replicas-1.</p>\n\n<p>The name of your pods will be:</p>\n\n<pre><code>sharded-svc-0\nsharded-svc-1\nsharded-svc-2\n</code></pre>\n\n<p>and those pods can be reached with a dns-name:</p>\n\n<pre><code>sharded-svc-0.sharded-svc.your-namespace.svc.cluster.local\nsharded-svc-1.sharded-svc.your-namespace.svc.cluster.local\nsharded-svc-2.sharded-svc.your-namespace.svc.cluster.local\n</code></pre>\n\n<p>given that your <em>Headless Service</em> is named <code>sharded-svc</code> and you deploy it in namespace <code>your-namespace</code>.</p>\n\n<h1>Sharding or Partitioning</h1>\n\n<blockquote>\n  <p>given multiple replicas of the target service of a frontend -> backend call, I can reliably route traffic for a certain account to a certain endpoint instance.</p>\n</blockquote>\n\n<p>What you describe here is that your stateful service is what is called <em>sharded</em> or <em>partitioned</em>. This does not come out of the box from Kubernetes, but you have all the needed <em>building blocks</em> for this kind of service. <em>It may happen that it exists an 3rd party service providing this feature that you can deploy, or it can be developed.</em></p>\n\n<h2>Sharding Proxy</h2>\n\n<p>You can create a service <code>sharding-proxy</code> consisting of one of more pods (possibly from <a href=\"https://kubernetes.io/docs/concepts/workloads/controllers/deployment/\" rel=\"noreferrer\">Deployment</a> since it can be stateless). This app need to watch the pods/service/<a href=\"https://stackoverflow.com/questions/52857825/what-is-an-endpoint-in-kubernetes\">endpoints</a> in your <code>sharded-svc</code> to know where it can route traffic. This can be developed using <a href=\"https://github.com/kubernetes/client-go\" rel=\"noreferrer\">client-go</a> or other alternatives.</p>\n\n<p>This service implements the logic you want in your sharding, e.g. <em>account-nr</em> modulus 3 is routed to the corresponding pod <em>ordinal</em></p>\n\n<p><strong>Update:</strong> There are 3rd party proxies with <strong>sharding</strong> functionallity, e.g. <a href=\"https://github.com/gojek/weaver\" rel=\"noreferrer\">Weaver Proxy</a></p>\n\n<blockquote>\n  <p>Sharding request based on headers/path/body fields</p>\n</blockquote>\n\n<p>Recommended reading: <a href=\"https://medium.com/@rbshetty/weaver-proxying-at-scale-b3b8b425a58e\" rel=\"noreferrer\">Weaver: Sharding with simplicity</a></p>\n\n<h1>Consuming sharded service</h1>\n\n<p>To consume your sharded service, the clients send request to your <code>sharding-proxy</code> that then apply your <em>routing</em> or <em>sharding logic</em> (e.g. request with <em>account-nr</em> modulus 3 is routed to the corresponding pod <em>ordinal</em>) and forward the request to <em>the replica</em> of <code>sharded-svc</code> that match your logic.</p>\n\n<h1>Alternative Solutions</h1>\n\n<p><strong>Directory Service:</strong> It is probably easier to implement <code>sharded-proxy</code> as a <em>directory service</em> but it depends on your requirements. The clients can ask your <em>directory service</em> to what statefulSet replica should I send <em>account-nr X</em> and your serice reply with e.g. <code>sharded-svc-2</code></p>\n\n<p><strong>Routing logic in client:</strong> The probably most easy solution is to have your <em>routing logic</em>  in the client, and let this logic calculate to what statefulSet replica to send the request.</p>\n",
                    "OwnerUserId": "213269",
                    "LastEditorUserId": "213269",
                    "LastEditDate": "2019-11-04T17:18:09.480",
                    "LastActivityDate": "2019-11-04T17:18:09.480",
                    "CommentCount": "9",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "58964433",
                "ParentRepo": "https://github.com/cortexproject/cortex",
                "StackOverflow_Post": {
                    "Id": "58964433",
                    "PostTypeId": "2",
                    "ParentId": "58948167",
                    "CreationDate": "2019-11-20T22:33:37.010",
                    "Score": "6",
                    "Body": "<p>You are asking about hot/warm architecture high availability for Prometheus.</p>\n<p>There are two aspects to your question:</p>\n<ol>\n<li>The storage of data: Prometheus has the ability of using <a href=\"https://prometheus.io/docs/prometheus/latest/storage/\" rel=\"nofollow noreferrer\">remote storage</a> that can be used to provide HA for your data</li>\n<li>The scraping of targets: there is no builtin mechanism to scrape in cluster.</li>\n</ol>\n<ul>\n<li>Either both Prometheus scrape at the same time (but then you have hot/hot)</li>\n<li>or you find a way to detect a Prometheus is down (prometheus scrape each other) and trigger an action (quite easy to do with a webhook) - by example enabling config and triggering the reload</li>\n</ul>\n<p>If HA is really important for you, you'd rather:</p>\n<ul>\n<li>use a hot/hot setup with some proxy like <a href=\"https://github.com/Comcast/trickster\" rel=\"nofollow noreferrer\">Trikster</a> or clustering like <a href=\"https://github.com/thanos-io/thanos\" rel=\"nofollow noreferrer\">Thanos</a></li>\n<li>switch to <a href=\"https://github.com/cortexproject/cortex\" rel=\"nofollow noreferrer\">Cortex</a> which is like a de-structured Prometheus to provide scalability and HA</li>\n</ul>\n<p>If you can afford some small downtime of Prometheus, you can also just let the scheduler re-schedule Prometheus and persist the data (maybe with remote read/write).</p>\n",
                    "OwnerUserId": "3480808",
                    "LastEditorUserId": "3480808",
                    "LastEditDate": "2020-08-20T14:32:17.183",
                    "LastActivityDate": "2020-08-20T14:32:17.183",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "59073086",
                "ParentRepo": "https://github.com/kubernetes-sigs/external-dns/blob/master/docs/tutorials/gke.md",
                "StackOverflow_Post": {
                    "Id": "59073086",
                    "PostTypeId": "2",
                    "ParentId": "59011921",
                    "CreationDate": "2019-11-27T15:04:49.440",
                    "Score": "0",
                    "Body": "<p>Here is a step by step guide to <a href=\"https://github.com/kubernetes-sigs/external-dns/blob/master/docs/tutorials/gke.md\" rel=\"nofollow noreferrer\">configure ExternalDNS</a></p>\n\n<p><strong>1.Create a DNS zone which will contain the managed DNS records.</strong></p>\n\n<pre><code>$ gcloud dns managed-zones create \"external-dns-test-gcp-zalan-do\" \\\n    --dns-name \"external-dns-test.gcp.zalan.do.\" \\\n    --description \"Automatically managed zone by kubernetes.io/external-dns\"\n</code></pre>\n\n<p><strong>2.Make a note of the nameservers that were assigned to your new zone</strong></p>\n\n<pre><code>$ gcloud dns record-sets list \\\n    --zone \"external-dns-test-gcp-zalan-do\" \\\n    --name \"external-dns-test.gcp.zalan.do.\" \\\n    --type NS\nNAME                             TYPE  TTL    DATA\nexternal-dns-test.gcp.zalan.do.  NS    21600  ns-cloud-e1.googledomains.com.,ns-cloud-e2.googledomains.com.,ns-cloud-e3.googledomains.com.,ns-cloud-e4.googledomains.com.\n</code></pre>\n\n<p>Tell the parent zone where to find the DNS records for this zone by adding the corresponding NS records there. Assuming the parent zone is \"gcp-zalan-do\" and the domain is \"gcp.zalan.do\" and that it's also hosted at Google we would do the following.</p>\n\n<p>In this case it's ns-cloud-{e1-e4}.googledomains.com. but your's could slightly differ, e.g. {a1-a4}, {b1-b4} etc.</p>\n\n<p>Tell the parent zone where to find the DNS records for this zone by adding the corresponding NS records there. Assuming the parent zone is \"gcp-zalan-do\" and the domain is \"gcp.zalan.do\" and that it's also hosted at Google we would do the following.</p>\n\n<pre><code>$ gcloud dns record-sets transaction start --zone \"gcp-zalan-do\"\n$ gcloud dns record-sets transaction add ns-cloud-e{1..4}.googledomains.com. \\\n    --name \"external-dns-test.gcp.zalan.do.\" --ttl 300 --type NS --zone \"gcp-zalan-do\"\n$ gcloud dns record-sets transaction execute --zone \"gcp-zalan-do\"\n</code></pre>\n\n<p><strong>3.Deploy ExternalDNS</strong></p>\n\n<p>Because of the way Container Engine checks permissions when you create a Role or ClusterRole, you must first create a RoleBinding that grants you all of the permissions included in the role you want to create.</p>\n\n<p>kubectl create clusterrolebinding your-user-cluster-admin-binding --clusterrole=cluster-admin --user=your.google.cloud.email@example.org</p>\n\n<p>Then apply one of the following manifests file to deploy ExternalDNS.</p>\n\n<p><a href=\"https://github.com/kubernetes-sigs/external-dns/blob/master/docs/tutorials/gke.md#manifest-for-clusters-without-rbac-enabled\" rel=\"nofollow noreferrer\">Manifest (for clusters without RBAC enabled)</a></p>\n\n<p><a href=\"https://github.com/kubernetes-sigs/external-dns/blob/master/docs/tutorials/gke.md#manifest-for-clusters-with-rbac-enabled\" rel=\"nofollow noreferrer\">Manifest (for clusters with RBAC enabled)</a></p>\n\n<p>Use <code>--dry-run</code> if you want to be extra careful on the first run. Note, that you will not see any records created when you are running in dry-run mode. You can, however, inspect the logs and watch what would have been done.</p>\n\n<p>You can verify if it works following <a href=\"https://github.com/kubernetes-sigs/external-dns/blob/master/docs/tutorials/gke.md#verify-externaldns-works\" rel=\"nofollow noreferrer\">these instructions</a></p>\n",
                    "OwnerUserId": "11633487",
                    "LastActivityDate": "2019-11-27T15:04:49.440",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "59205913",
                "ParentRepo": "https://github.com/kubernetes-sigs/cloud-provider-azure/blob/master/docs/services/README.md",
                "StackOverflow_Post": {
                    "Id": "59205913",
                    "PostTypeId": "2",
                    "ParentId": "59149860",
                    "CreationDate": "2019-12-06T02:16:29.307",
                    "Score": "2",
                    "Body": "<p>You can take a look at <a href=\"https://github.com/kubernetes-sigs/cloud-provider-azure/blob/master/docs/services/README.md\" rel=\"nofollow noreferrer\">Cloud provider for Azure</a>. It provides an annotation to set the TCP reset of the load balancer rules, but it's only available for version 1.16 or later and the latest version for AKS is 1.15. </p>\n\n<p><a href=\"https://i.stack.imgur.com/YtJ9W.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/YtJ9W.png\" alt=\"enter image description here\"></a></p>\n\n<p>You can use aks-engine to achieve your purpose if you really want to use it. The aks-engine already supports version 1.16 for Kubernetes. Remember, create the aks-engine cluster with the standard load balancer.</p>\n",
                    "OwnerUserId": "9773937",
                    "LastActivityDate": "2019-12-06T02:16:29.307",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "59379973",
                "ParentRepo": "https://github.com/bitnami/kube-prod-runtime/blob/master/manifests/contrib/helpers.jsonnet",
                "StackOverflow_Post": {
                    "Id": "59379973",
                    "PostTypeId": "2",
                    "ParentId": "59376443",
                    "CreationDate": "2019-12-17T18:17:29.137",
                    "Score": "1",
                    "Body": "<p>Note I'm assuming that the user will need somehow to know where in the tree they'd want to overload the field(s).</p>\n\n<p>You can use <code>helpers.jsonnet</code> from <a href=\"https://github.com/bitnami/kube-prod-runtime/blob/master/manifests/contrib/helpers.jsonnet\" rel=\"nofollow noreferrer\">https://github.com/bitnami/kube-prod-runtime/blob/master/manifests/contrib/helpers.jsonnet</a> as:</p>\n\n<pre><code>$ wget https://raw.githubusercontent.com/bitnami/kube-prod-runtime/master/manifests/contrib/helpers.jsonnet\n\n$ cat 2.jsonnet\nlocal one = import'1.jsonnet';\nlocal helpers = import 'helpers.jsonnet';\n\nhelpers.mergeAtPath(one, 'a.b.b2', 2)\n\n$ jsonnet 2.jsonnet \n{\n   \"a\": {\n      \"b\": {\n         \"b1\": 1,\n         \"b2\": 2\n      }\n   }\n}\n</code></pre>\n\n<p>Note also that you could merge there any type of jsonnet object, e.g.</p>\n\n<pre><code>helpers.mergeAtPath(one, \"a.b.b2\", [1,2,3])\n</code></pre>\n",
                    "OwnerUserId": "9443059",
                    "LastActivityDate": "2019-12-17T18:17:29.137",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "59691735",
                "ParentRepo": "https://github.com/kopeio/etcd-manager/blob/master/docs/restore-troubleshooting.md",
                "StackOverflow_Post": {
                    "Id": "59691735",
                    "PostTypeId": "2",
                    "ParentId": "59687345",
                    "CreationDate": "2020-01-11T04:48:54.207",
                    "Score": "2",
                    "Body": "<p>The Kubelet is trying to register the master node us-east-1a with an API Server endpoint <a href=\"https://127.0.0.1:443\" rel=\"nofollow noreferrer\">https://127.0.0.1:443</a>. I believe this should be API server endpoint of any of the other two masters. Kubelet uses kubelet.conf file to talk to the API Server to register node.Change the <code>server</code> in kubelet.conf file located at <code>/etc/kubernetes</code> to point to one of the below:</p>\n\n<ol>\n<li>Elastic IP or public IP of master node at us-east-1b or  us-east-1c ex <a href=\"https://xx.xx.xx.xx:6443\" rel=\"nofollow noreferrer\">https://xx.xx.xx.xx:6443</a></li>\n<li>Private IP of current master node us-east-1b or us-east-1c ex <a href=\"https://xx.xx.xx.xx:6443\" rel=\"nofollow noreferrer\">https://xx.xx.xx.xx:6443</a></li>\n<li>FQDN of current master node if you have a Load balancer in-front of your master nodes running the kubernetes API server.</li>\n</ol>\n\n<p>After changing kubelet.conf restart kubelet.</p>\n\n<p>Edit: Since you are using etcd manager can you try the Kubernetes service unavailable / flannel issues troubleshooting step described <a href=\"https://github.com/kopeio/etcd-manager/blob/master/docs/restore-troubleshooting.md\" rel=\"nofollow noreferrer\">here</a></p>\n",
                    "OwnerUserId": "1839482",
                    "LastEditorUserId": "1839482",
                    "LastEditDate": "2020-01-14T14:50:33.397",
                    "LastActivityDate": "2020-01-14T14:50:33.397",
                    "CommentCount": "9",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "59963528",
                "ParentRepo": "https://github.com/helm/helm-2to3",
                "StackOverflow_Post": {
                    "Id": "59963528",
                    "PostTypeId": "2",
                    "ParentId": "59962753",
                    "CreationDate": "2020-01-29T08:57:02.353",
                    "Score": "4",
                    "Body": "<p>Helm 2 and Helm 3 can be installed concurrently to manage the same cluster. This works when Helm 2 uses ConfigMaps for storage as Helm 3 uses Secrets for storage. There is however a conflict when Helm 2 uses Secrets for storage and stores the release in the same namespace as the release. The conflict occurs because Helm 3 uses different tags and ownership for the secret objects that Helm 2 does. It can therefore try to create a release that it thinks does not exist but will fail then because Helm 2 already has a secret with that name in that namespace. </p>\n\n<p>Additionally, Helm 2 can be migrated to enable Helm 3 to manage releases previously handled by Helm 2 ref. <a href=\"https://github.com/helm/helm-2to3\" rel=\"nofollow noreferrer\">https://github.com/helm/helm-2to3</a>. This also works when Helm 2 uses ConfigMaps for storage as Helm 3 uses Secrets for storage. There is a conflict again however when using secrets because of the same naming convention. \nA possible solution around this would be for Helm 3 to use a different naming convention for release versions.</p>\n",
                    "OwnerUserId": "1208381",
                    "LastActivityDate": "2020-01-29T08:57:02.353",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "60058070",
                "ParentRepo": "https://github.com/openshift/cluster-monitoring-operator/blob/master/assets/prometheus-k8s/rules.yaml",
                "StackOverflow_Post": {
                    "Id": "60058070",
                    "PostTypeId": "2",
                    "ParentId": "60041305",
                    "CreationDate": "2020-02-04T13:04:30.300",
                    "Score": "0",
                    "Body": "<p>The <strong>RHS</strong> has no instance label, so it's trying to match all those series to one on the <strong>LHS</strong>.\nYou have to also add <strong>sum</strong> before listing <code>container_memory_usage_bytes</code> metric, - <code>sum(container_memory_usage_bytes)</code>.</p>\n\n<p>Please take a look here: <a href=\"https://github.com/openshift/cluster-monitoring-operator/blob/master/assets/prometheus-k8s/rules.yaml\" rel=\"nofollow noreferrer\">prometheus-metrics</a>.</p>\n\n<p>Useful article: <a href=\"https://www.robustperception.io/using-group_left-to-calculate-label-proportions\" rel=\"nofollow noreferrer\">label-proportions</a>.</p>\n",
                    "OwnerUserId": "11300382",
                    "LastActivityDate": "2020-02-04T13:04:30.300",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "60095195",
                "ParentRepo": "https://github.com/AmitKumarDas/metac/tree/master/examples/daemonjob#daemonjob",
                "StackOverflow_Post": {
                    "Id": "60095195",
                    "PostTypeId": "2",
                    "ParentId": "60082151",
                    "CreationDate": "2020-02-06T12:37:08.030",
                    "Score": "0",
                    "Body": "<p>If I understand you correctly you should consider using <a href=\"https://kubernetes.io/docs/concepts/workloads/controllers/daemonset/\" rel=\"nofollow noreferrer\">DaemonSet</a>:</p>\n\n<blockquote>\n  <p>A <code>DaemonSet</code> ensures that all (or some) Nodes run a copy of a Pod. As\n  nodes are added to the cluster, Pods are added to them. As nodes are\n  removed from the cluster, those Pods are garbage collected. Deleting a\n  <code>DaemonSet</code> will clean up the Pods it created.</p>\n</blockquote>\n\n<p>That way you could create a container with a job that would be run from a <code>DaemonSet</code>.</p>\n\n<p>Alternatively you could consider <a href=\"https://github.com/AmitKumarDas/metac/tree/master/examples/daemonjob#daemonjob\" rel=\"nofollow noreferrer\">DaemonJob</a>:</p>\n\n<blockquote>\n  <p>This is an example <code>CompositeController</code> that's similar to Job, except\n  that a pod will be scheduled to each node, similar to <code>DaemonSet</code>.</p>\n</blockquote>\n\n<p>Also there are:</p>\n\n<ul>\n<li><a href=\"https://github.com/kubernetes-sigs/kubebuilder#kubebuilder\" rel=\"nofollow noreferrer\">Kubebuilder</a> </li>\n</ul>\n\n<blockquote>\n  <p>Kubebuilder is a framework for building Kubernetes APIs using custom\n  resource definitions (CRDs).</p>\n</blockquote>\n\n<p>and:</p>\n\n<ul>\n<li><a href=\"https://github.com/GoogleCloudPlatform/metacontroller#metacontroller\" rel=\"nofollow noreferrer\">Metacontroller</a> </li>\n</ul>\n\n<blockquote>\n  <p>Metacontroller is an add-on for Kubernetes that makes it easy to write\n  and deploy custom controllers in the form of simple scripts.</p>\n</blockquote>\n\n<p>But the first option that I have provided would be easier to implement in my opinion.</p>\n\n<p>Please let me know if that helped. </p>\n",
                    "OwnerUserId": "11560878",
                    "LastActivityDate": "2020-02-06T12:37:08.030",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "60216518",
                "ParentRepo": "https://github.com/minio/minio-operator/blob/master/README.md",
                "StackOverflow_Post": {
                    "Id": "60216518",
                    "PostTypeId": "1",
                    "CreationDate": "2020-02-13T21:09:47.013",
                    "Score": "1",
                    "ViewCount": "1105",
                    "Body": "<p>I am trying to deploy MinIO on K8s cluster and have followed the guide on <a href=\"https://github.com/minio/minio-operator/blob/master/README.md\" rel=\"nofollow noreferrer\">https://github.com/minio/minio-operator/blob/master/README.md</a>.   </p>\n\n<p>After the installation the MinIO services does not get a ClusterIP: \n<a href=\"https://i.stack.imgur.com/Lgtpk.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/Lgtpk.png\" alt=\"enter image description here\"></a></p>\n\n<p>What am I doing wrong?</p>\n",
                    "OwnerUserId": "1743843",
                    "LastActivityDate": "2020-02-14T12:11:29.467",
                    "Title": "Why the service does not get an ClusterIP assigned?",
                    "Tags": "<kubernetes><minio>",
                    "AnswerCount": "1",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "60311579",
                "ParentRepo": "https://github.com/dingrui37/etcdagent",
                "StackOverflow_Post": {
                    "Id": "60311579",
                    "PostTypeId": "1",
                    "CreationDate": "2020-02-20T01:12:49.130",
                    "Score": "1",
                    "ViewCount": "846",
                    "Body": "<p>I wrote a go project, which is used to wrap the access to ETCD and provide interface to C language for use, <a href=\"https://github.com/dingrui37/etcdagent\" rel=\"nofollow noreferrer\">https://github.com/dingrui37/etcdagent</a>, (sorry for my poor English)\n<img src=\"https://user-images.githubusercontent.com/22718365/72782010-ae2c8600-3c5d-11ea-9eb5-835f331eadd6.png\" alt=\"compile\">\nAfter finishing the test of this project, I build it to a shared library:\n<code>go build -buildmode=c-shared -o cgo/libetcd.so main.go</code>\nBut when running, it <strong>sometimes</strong> gives an exception as follows, can someone give me a help?</p>\n\n<pre><code>[NewThread0x7fff9a7fc700(LWP1615)]\nruntime:unexpectedreturnpcforruntime.goparkcalledfrom0x0\nstack:frame={sp:0xc000062f90,fp:0xc000062fb0}stack=[0xc000062800,0xc000063000)\n000000c000062e90:00000000000000000000000000000000\n000000c000062ea0:00000000000000000000000000000000\n000000c000062eb0:00000000000000000000000000000000\n000000c000062ec0:00000000000000000000000000000000\n000000c000062ed0:00000000000000000000000000000000\n000000c000062ee0:00000000000000000000000000000000\n000000c000062ef0:00000000000000000000000000000000\n000000c000062f00:00000000000000000000000000000000\n000000c000062f10:00000000000000000000000000000000\n000000c000062f20:00000000000000000000000000000000\n000000c000062f30:00000000000000000000000000000000\n000000c000062f40:00000000000000000000000000000000\n000000c000062f50:00000000000000000000000000000000\n000000c000062f60:00000000000000000000000000000000\n000000c000062f70:00000000000000000000000000000000\n000000c000062f80:00000000000000000000000000000000\n000000c000062f90:&lt;00000000000000000000000000000000\n000000c000062fa0:0000000000000000!0000000000000000\n000000c000062fb0:&gt;00000000000000000000000000000000\n000000c000062fc0:00000000000000000000000000000000\n000000c000062fd0:0000000000000000000000000106e371&lt;runtime.goexit+1&gt;\n000000c000062fe0:00000000000000000000000000000000\n000000c000062ff0:00000000000000000000000000000000\nfatalerror:unknowncallerpc\nruntimestack:\nruntime.throw(0x1d15977,0x11)\n/usr/local/go/src/runtime/panic.go:774+0x74\nruntime.gentraceback(0xffffffffffffffff,0xffffffffffffffff,0x0,0xc000000a80,0x0,\n0x0,0x7fffffff,0x7fff9affb3c8,0x0,0x0,...)\n/usr/local/go/src/runtime/traceback.go:273+0x19e9\nruntime.scanstack(0xc000000a80,0xc000043270)\n/usr/local/go/src/runtime/mgcmark.go:711+0x161\nruntime.scang(0xc000000a80,0xc000043270)\n/usr/local/go/src/runtime/proc.go:886+0x1e5\nruntime.markroot.func1()\n/usr/local/go/src/runtime/mgcmark.go:221+0x71\nruntime.markroot(0xc000043270,0xc000000007)\n/usr/local/go/src/runtime/mgcmark.go:202+0x2f5\nruntime.gcDrain(0xc000043270,0x2)\n/usr/local/go/src/runtime/mgcmark.go:915+0x114\nruntime.gcBgMarkWorker.func2()\n/usr/local/go/src/runtime/mgc.go:1923+0x122\nruntime.systemstack(0x0)\n/usr/local/go/src/runtime/asm_amd64.s:370+0x63\nruntime.mstart()\n/usr/local/go/src/runtime/proc.go:1146\ngoroutine220[GCworker(idle)]:\nruntime.systemstack_switch()\n/usr/local/go/src/runtime/asm_amd64.s:330fp=0xc00033f760sp=0xc00033f758\npc=0x106c270\nruntime.gcBgMarkWorker(0xc000042000)\n/usr/local/go/src/runtime/mgc.go:1891+0x1c5fp=0xc00033f7d8\nsp=0xc00033f760pc=0x102ee15\nruntime.goexit()\n/usr/local/go/src/runtime/asm_amd64.s:1357+0x1fp=0xc00033f7e0\nsp=0xc00033f7d8pc=0x106e371\ncreatedbyruntime.gcBgMarkStartWorkers\n/usr/local/go/src/runtime/mgc.go:1785+0x79\ngoroutine4[syscall]:\nos/signal.signal_recv(0x0)\n/usr/local/go/src/runtime/sigqueue.go:147+0x9e\nos/signal.loop()\n/usr/local/go/src/os/signal/signal_unix.go:23+0x24\ncreatedbyos/signal.init.0\n/usr/local/go/src/os/signal/signal_unix.go:29+0x43\ngoroutine36[select]:\ngoogle.golang.org/grpc.(*ccBalancerWrapper).watcher(0xc000176280)\n/home/dingrui/go/pkg/mod/google.golang.org/grpc@v1.24.0/balancer_conn_wrappers.go:\n115+0x12e\ncreatedbygoogle.golang.org/grpc.newCCBalancerWrapper\n/home/dingrui/go/pkg/mod/google.golang.org/grpc@v1.24.0/balancer_conn_wrappers.go:\n106+0x16b\ngoroutine44[select]:\ngoogle.golang.org/grpc/internal/transport.(*controlBuffer).get(0xc000168230,0x1,\n0x0,0x0,0x0,0x0)\n/home/dingrui/go/pkg/mod/google.golang.org/grpc@v1.24.0/internal/transport/control\nbuf.go:395+0x124\ngoogle.golang.org/grpc/internal/transport.(*loopyWriter).run(0xc000174c00,0x0,\n0x0)\n/home/dingrui/go/pkg/mod/google.golang.org/grpc@v1.24.0/internal/transport/control\nbuf.go:513+0x1e5\ngoogle.golang.org/grpc/internal/transport.newHTTP2Client.func3(0xc00026e000)\n/home/dingrui/go/pkg/mod/google.golang.org/grpc@v1.24.0/internal/transport/http2_c\nlient.go:338+0x7d\ncreatedbygoogle.golang.org/grpc/internal/transport.newHTTP2Client\n/home/dingrui/go/pkg/mod/google.golang.org/grpc@v1.24.0/internal/transport/http2_c\nlient.go:336+0xebe\ngoroutine38[chanreceive]:\netcdagent/agent.(*Agent).Run(0xc000176380)\n/home/dingrui/Projects/etcdagent/agent/agent.go:75+0x14e\ncreatedbymain.EtcdAgentInit.func1\n/home/dingrui/Projects/etcdagent/main.go:62+0x203\ngoroutine39[select]:\netcdagent/agent/event.(*event).Watch(0xc0001720a0,0x248e520,0xc000176400,\n0xc000174600)\n/home/dingrui/Projects/etcdagent/agent/event/event.go:45+0x408\ncreatedbyetcdagent/agent.(*Agent).Run\n/home/dingrui/Projects/etcdagent/agent/agent.go:72+0x124\ngoroutine20[chanreceive]:\ngoogle.golang.org/grpc.(*addrConn).resetTransport(0xc00023c000)\n/home/dingrui/go/pkg/mod/google.golang.org/grpc@v1.24.0/clientconn.go:1077\n+0x6ae\ncreatedbygoogle.golang.org/grpc.(*addrConn).connect\n/home/dingrui/go/pkg/mod/google.golang.org/grpc@v1.24.0/clientconn.go:743\n+0x122\ngoroutine43[IOwait]:\ninternal/poll.runtime_pollWait(0x7ffff7f48dd8,0x72,0xffffffffffffffff)\n/usr/local/go/src/runtime/netpoll.go:184+0x57\ninternal/poll.(*pollDesc).wait(0xc00024e198,0x72,0x8000,0x8000,\n0xffffffffffffffff)\n/usr/local/go/src/internal/poll/fd_poll_runtime.go:87+0x47\ninternal/poll.(*pollDesc).waitRead(...)\n/usr/local/go/src/internal/poll/fd_poll_runtime.go:92\ninternal/poll.(*FD).Read(0xc00024e180,0xc000256000,0x8000,0x8000,0x0,0x0,0x0)\n/usr/local/go/src/internal/poll/fd_unix.go:169+0x1d1\nnet.(*netFD).Read(0xc00024e180,0xc000256000,0x8000,0x8000,0x0,0x800010601,0x0)\n/usr/local/go/src/net/fd_unix.go:202+0x51\nnet.(*conn).Read(0xc0001720c8,0xc000256000,0x8000,0x8000,0x0,0x0,0x0)\n/usr/local/go/src/net/net.go:184+0x6a\n</code></pre>\n\n<pre><code>dingrui@dingrui-PC:~$ go version\ngo version go1.13.1 linux/amd64\ndingrui@dingrui-PC:~$ go env\nGO111MODULE=\"\"\nGOARCH=\"amd64\"\nGOBIN=\"\"\nGOCACHE=\"/home/dingrui/.cache/go-build\"\nGOENV=\"/home/dingrui/.config/go/env\"\nGOEXE=\"\"\nGOFLAGS=\"\"\nGOHOSTARCH=\"amd64\"\nGOHOSTOS=\"linux\"\nGONOPROXY=\"\"\nGONOSUMDB=\"\"\nGOOS=\"linux\"\nGOPATH=\"/home/dingrui/go\"\nGOPRIVATE=\"\"\nGOPROXY=\"https://goproxy.cn,direct\"\nGOROOT=\"/usr/local/go\"\nGOSUMDB=\"sum.golang.org\"\nGOTMPDIR=\"\"\nGOTOOLDIR=\"/usr/local/go/pkg/tool/linux_amd64\"\nGCCGO=\"gccgo\"\nAR=\"ar\"\nCC=\"gcc\"\nCXX=\"g++\"\nCGO_ENABLED=\"1\"\nGOMOD=\"\"\nCGO_CFLAGS=\"-g -O2\"\nCGO_CPPFLAGS=\"\"\nCGO_CXXFLAGS=\"-g -O2\"\nCGO_FFLAGS=\"-g -O2\"\nCGO_LDFLAGS=\"-g -O2\"\nPKG_CONFIG=\"pkg-config\"\nGOGCCFLAGS=\"-fPIC -m64 -pthread -fmessage-length=0 -fdebug-prefix-map=/tmp/go-build180008548=/tmp/go-build -gno-record-gcc-switches\"\n</code></pre>\n",
                    "OwnerUserId": "3313450",
                    "LastEditorUserId": "3313450",
                    "LastEditDate": "2020-02-20T07:28:20.030",
                    "LastActivityDate": "2022-06-15T14:01:42.067",
                    "Title": "runtime:unexpected return pc for runtime.gopark called from0x0",
                    "Tags": "<go>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "60343466",
                "ParentRepo": "https://github.com/lazychanger/helm-viv",
                "StackOverflow_Post": {
                    "Id": "60343466",
                    "PostTypeId": "2",
                    "ParentId": "49958612",
                    "CreationDate": "2020-02-21T17:15:59.570",
                    "Score": "1",
                    "Body": "<p>Helm 3.x (Q4 2019) now includes more about this, but for chart only, not for subchart (see <a href=\"https://stackoverflow.com/users/166389/tbble\">TBBle</a>'s <a href=\"https://stackoverflow.com/questions/49958612/overriding-values-in-kubernetes-helm-subcharts/60343466#comment107337547_60343466\">comment</a>)</p>\n<p><strong><a href=\"https://github.com/MilanMasek\" rel=\"nofollow noreferrer\">Milan Masek</a></strong> adds as <a href=\"https://github.com/helm/helm/issues/2133#issuecomment-589695803\" rel=\"nofollow noreferrer\">a comment</a>:</p>\n<blockquote>\n<p>Thankfully, <a href=\"https://helm.sh/docs/howto/charts_tips_and_tricks/#using-the-tpl-function\" rel=\"nofollow noreferrer\">latest Helm manual says how to achieve this</a>.</p>\n<p>The trick is:</p>\n<ul>\n<li>enclosing variable in <code>&quot;</code> or in a yaml block <code>|-</code>, and</li>\n<li>then referencing it in a template as <code>{{ tpl .Values.variable . }}</code></li>\n</ul>\n<p>This seems to make Helm happy.</p>\n<p>Example:</p>\n<pre><code>$\u00a0cat Chart.yaml | grep appVersion\nappVersion: 0.0.1-SNAPSHOT-d2e2f42\n\n\n$\u00a0cat platform/shared/t/values.yaml | grep -A2 image:\nimage: \n  tag: |-\n    {{ .Chart.AppVersion }}\n\n\n$\u00a0cat templates/deployment.yaml | grep image:\n          image: &quot;{{ .Values.image.repository }}:{{ tpl .Values.image.tag . }}&quot;\n\n\n$\u00a0helm template . --values platform/shared/t/values.betradar.yaml | grep image\n          image: &quot;docker-registry.default.svc:5000/namespace/service:0.0.1-SNAPSHOT-d2e2f42&quot;\n          imagePullPolicy: Always\n      image: busybox\n</code></pre>\n<p>Otherwise there is an error thrown..</p>\n<pre><code>$\u00a0cat platform/shared/t/values.yaml | grep -A1 image:\nimage: \n  tag: {{ .Chart.AppVersion }}\n\n1\u00a0$\u00a0helm template . --values platform/shared/t/values.yaml | grep image\nError: failed to parse platform/shared/t/values.yaml: error converting YAML to JSON: yaml: invalid map key: map[interface {}]interface {}{&quot;.Chart.AppVersion&quot;:interface {}(nil)}\n</code></pre>\n</blockquote>\n<hr />\n<p>For Helm <em>subchart</em>, <a href=\"https://github.com/TBBle\" rel=\"nofollow noreferrer\">TBBle</a> adds to <a href=\"https://github.com/helm/helm/issues/2133#issuecomment-598658143\" rel=\"nofollow noreferrer\">issue 2133</a></p>\n<blockquote>\n<p>@MilanMasek 's solution won't work in general for subcharts, because the context <code>.</code> passed into <code>tpl</code> will have the subchart's values, not the parent chart's values.\n!&lt;\nIt happens to work in the specific example this ticket was opened for, because <code>.Release.Name</code> should be the same in all the subcharts.<br />\nIt won't work for <code>.Chart.AppVersion</code> as in the <code>tpl</code> example.</p>\n<p>There was a proposal to support tval in <a href=\"https://github.com/helm/helm/pull/3252\" rel=\"nofollow noreferrer\">#3252</a> for interpolating templates in values files, but that was dropped in favour of a lua-based Hook system which has been proposed for Helm v3: <a href=\"https://github.com/helm/helm/issues/2492#issuecomment-413635332\" rel=\"nofollow noreferrer\">#2492 (comment)</a></p>\n</blockquote>\n<p>That last issue 2492 include workarounds like <a href=\"https://github.com/helm/helm/issues/2492#issuecomment-567000244\" rel=\"nofollow noreferrer\">this one</a>:</p>\n<blockquote>\n<p>You can put a placeholder in the text that you want to template and then replace that placeholder with the template that you would like to use in yaml files in the template.</p>\n<p>For now, what I've done in the CI job is run helm template on the <code>values.yaml</code> file.<br />\nIt works pretty well atm.</p>\n<pre><code>cp values.yaml templates/\nhelm template $CI_BUILD_REF_NAME ./ | sed -ne '/^# Source: \ntemplates\\/values.yaml/,/^---/p' &gt; values.yaml\nrm templates/values.yaml\n\nhelm upgrade --install ...\n</code></pre>\n<p>This breaks if you have multiple <code>-f values.yml</code> files, but I'm thinking of writing a small helm wrapper that runs essentially runs that bash script for each <code>values.yaml</code> file.</p>\n</blockquote>\n<p><a href=\"https://github.com/fsniper\" rel=\"nofollow noreferrer\">fsniper</a> illustrates again <a href=\"https://github.com/helm/helm/issues/2492#issuecomment-596658964\" rel=\"nofollow noreferrer\">the issue</a>:</p>\n<blockquote>\n<p>There is a use case where you would need to pass deployment name to dependency charts where you have no control.</p>\n<p>For example I am trying to set <code>podAffinity</code> for zookeeper. And I have an application helm chart which sets zookeeper as a dependency.</p>\n<p>In this case, I am passing pod <code>antiaffinity</code> to zookeeper via values. So in my apps <code>values.yaml</code> file I have a <code>zookeeper.affinity</code> section.<br />\nIf I had the ability to get the release name inside the values yaml I would just set this as default and be done with it.</p>\n<p>But now for every deployment I have to override this value, which is a big problem.</p>\n</blockquote>\n<hr />\n<p>Update Oct. 2022, from <a href=\"https://github.com/helm/helm/issues/2133#issuecomment-1278410065\" rel=\"nofollow noreferrer\">issue 2133</a>:</p>\n<p><a href=\"https://github.com/lazychanger\" rel=\"nofollow noreferrer\"><code>lazychanger</code></a> proposes</p>\n<blockquote>\n<p>I submitted a plugin to override <code>values.yaml</code> with additional templates.</p>\n</blockquote>\n<p>See <a href=\"https://github.com/lazychanger/helm-viv\" rel=\"nofollow noreferrer\"><code>lazychanger/helm-viv</code>: &quot;Helm-variable-in-values&quot;</a> and <a href=\"https://github.com/lazychanger/helm-viv/tree/master/example/simple-example\" rel=\"nofollow noreferrer\">its example</a>.</p>\n",
                    "OwnerUserId": "6309",
                    "LastEditorUserId": "6309",
                    "LastEditDate": "2022-10-14T20:03:40.940",
                    "LastActivityDate": "2022-10-14T20:03:40.940",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "60449762",
                "ParentRepo": "https://github.com/hyperledger-labs/fabric-private-chaincode",
                "StackOverflow_Post": {
                    "Id": "60449762",
                    "PostTypeId": "2",
                    "ParentId": "60359582",
                    "CreationDate": "2020-02-28T10:25:35.253",
                    "Score": "1",
                    "Body": "<blockquote>\n  <p>How to prevent access to the state database outside the chaincode\n  process</p>\n</blockquote>\n\n<p>You need to ensure 2 things: </p>\n\n<ul>\n<li>Data that the chaincode reads cannot be used outside of the chaincode</li>\n<li>Data that the chaincode reads cannot be altered, and if it's altered then it can be detected.</li>\n</ul>\n\n<p>The first problem can be mitigated by encrypting the data, and the second problem can be mitigated by having the chaincode attach a MAC (Message Authentication Code) tag to every item it writes, and also validate the MAC tag of any item it reads, and if the tag is invalid then return an error.</p>\n\n<p>Worth to mention that you should MAC the ciphertext and not encrypt the MAC (first encrypt, then MAC).</p>\n\n<blockquote>\n  <p>also if I am publishing the database as a docker image, how do I make\n  sure that the peer uses that specific database image, and not a\n  tampered one.</p>\n</blockquote>\n\n<p>If the chaincode has the MAC key embedded inside of it, then the database image you publish will contain records that the chaincode did not produce (hence, did not attach appropritate MAC tags to it) then it will be detected.</p>\n\n<p>The problem is that a malicious administrator could also provide the peer with a valid database container but from the past.</p>\n\n<p>There is another option you can investigate which is <a href=\"https://github.com/hyperledger-labs/fabric-private-chaincode\" rel=\"nofollow noreferrer\">Fabric Private Chaincode</a> which uses the Intel SGX TEE(Trusted Execution Environment) feature.</p>\n",
                    "OwnerUserId": "8211613",
                    "LastActivityDate": "2020-02-28T10:25:35.253",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "60929453",
                "ParentRepo": "https://github.com/GoogleCloudPlatform/kaniko",
                "StackOverflow_Post": {
                    "Id": "60929453",
                    "PostTypeId": "2",
                    "ParentId": "60911478",
                    "CreationDate": "2020-03-30T11:21:41.233",
                    "Score": "1",
                    "Body": "<p>Kaniko is being introduced as a tool to <a href=\"https://cloud.google.com/blog/products/gcp/introducing-kaniko-build-container-images-in-kubernetes-and-google-container-builder-even-without-root-access\" rel=\"nofollow noreferrer\">Build container images in Kubernetes and Google Container Builder without privileges</a>.</p>\n\n<blockquote>\n  <p>we\u2019re excited to introduce <a href=\"https://github.com/GoogleCloudPlatform/kaniko\" rel=\"nofollow noreferrer\">kaniko</a>, an open-source tool for building container images from a Dockerfile even without privileged root access. With kaniko, we both build an image from a Dockerfile and push it to a registry. Since it doesn\u2019t require any special privileges or permissions, you can run kaniko in a standard Kubernetes cluster, <a href=\"https://cloud.google.com/kubernetes-engine/\" rel=\"nofollow noreferrer\">Google Kubernetes Engine</a>, or in any environment that can\u2019t have access to privileges or a Docker daemon.</p>\n</blockquote>\n\n<p>The issue you are experiencing was already mentioned at <a href=\"https://github.com/GoogleContainerTools/kaniko/issues/681\" rel=\"nofollow noreferrer\">GoogleContainerTools/kaniko</a> GitHub issue.</p>\n\n<p>On January 11 this issue was tagged as <code>Won't Fix</code> so the only way is to run Kaniko as root using <code>securityContext: runAsUser: 0</code></p>\n\n<p>This isn't secure as once would think, which is mentioned by <a href=\"https://kurtmadel.com/\" rel=\"nofollow noreferrer\">Kurt Madel</a> in his blog <a href=\"https://kurtmadel.com/posts/native-kubernetes-continuous-delivery/building-container-images-with-kubernetes\" rel=\"nofollow noreferrer\">Securely Building Container Images on Kubernetes</a>:</p>\n\n<blockquote>\n  <p>running as <code>root</code> is an attack vector that many consider to be an unacceptable security hole - but the use of Pod Security Policies will reduce the attack surface of the Kaniko container running as part of a K8s Pod and provides greater security than the Docker based approaches we have already dismissed.</p>\n</blockquote>\n\n<p>He also explains how one would use <a href=\"https://kurtmadel.com/posts/native-kubernetes-continuous-delivery/building-container-images-with-kubernetes/#kaniko-the-easy-way\" rel=\"nofollow noreferrer\">Kaniko the Easy Way</a></p>\n\n<blockquote>\n  <p>Jenkins X allows you to  <a href=\"https://jenkins-x.io/getting-started/create-cluster/#the-jx-create-cluster-gke-process\" rel=\"nofollow noreferrer\">enable Kaniko as the default way to build and push container images</a>  for all of your Jenkins X CD jobs and will be automatically configured to push to the default container registry of the cloud where you install Jenkins X and Kaniko caching is automatically set up for you - resulting in fast, secure container image builds that are pushed to your default Jenkins X container registry.</p>\n  \n  <p><strong>Important:</strong>  Jenkins X does not have OOTB support for Pod Security Policies as tracked by  <a href=\"https://github.com/jenkins-x/jx/issues/1074\" rel=\"nofollow noreferrer\">this GitHub issue</a>. In my next post we will take a look at using Pod Security Policies with Jenkins X - but not just for Kaniko, because once you enable Pod Security Policy every K8s  <code>Role</code>/<code>ClusterRole</code>  has to have a Pod Security Policy associated to it.</p>\n  \n  Drawbacks for Kaniko<a href=\"https://kurtmadel.com/posts/native-kubernetes-continuous-delivery/building-container-images-with-kubernetes/#drawbacks-for-kaniko\" rel=\"nofollow noreferrer\"></a>\n  \n  <ul>\n  <li>Requires running the Kaniko container as  <code>ROOT</code>  to execute most container builds</li>\n  <li>Doesn\u2019t work with all  <code>Dockerfiles</code>  but keeps improving</li>\n  <li>Is slightly more complicated to setup than the good old  <code>docker build</code></li>\n  </ul>\n</blockquote>\n",
                    "OwnerUserId": "3156333",
                    "LastActivityDate": "2020-03-30T11:21:41.233",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "60959605",
                "ParentRepo": "https://github.com/HeavyHorst/remco",
                "StackOverflow_Post": {
                    "Id": "60959605",
                    "PostTypeId": "2",
                    "ParentId": "60942785",
                    "CreationDate": "2020-03-31T20:45:56.873",
                    "Score": "1",
                    "Body": "<p>I tried using <code>RUNDECK_FEATURE_JOBLIFECYCLEPLUGIN_ENABLED: 'true'</code> on &quot;environment&quot; section on compose file like <a href=\"https://github.com/rundeck/docker-zoo/blob/master/config/docker-compose.yml\" rel=\"nofollow noreferrer\">this</a>, but that create this line on <code>rundeck-config.properties</code> file: <code>rundeck.feature.joblifecycleplugin.enabled=true</code> (all lowercase, and we need <code>rundeck.feature.jobLifecyclePlugin.enabled=true</code>, the configuration is case sensitive).</p>\n<p>You can add it using <a href=\"https://github.com/HeavyHorst/remco\" rel=\"nofollow noreferrer\">Remco</a>. Take a look at <a href=\"https://hub.docker.com/r/rundeck/rundeck\" rel=\"nofollow noreferrer\">this</a> (check the &quot;Extending Configuration&quot; section), <a href=\"https://github.com/rundeck/docker-zoo/tree/master/config\" rel=\"nofollow noreferrer\">here</a> a good example to test.</p>\n<p>In my case, I added this in the <code>rundeck-config-extra.properties</code> file (at <code>mydocker/remco/templates/</code> path).</p>\n<pre><code># adding extra stuff to rundeck-config.properties file\nrundeck.feature.jobLifecyclePlugin.enabled={{ getv(&quot;/rundeck/feature/joblifecycleplugin/enabled&quot;, &quot;true&quot;) }}\n</code></pre>\n<p>And this on <code>rundeck-config.properties-extra.toml</code> (at <code>mydocker/remco/resources.d/</code>      path)</p>\n<pre><code>[[template]]\n    src         = &quot;${REMCO_TEMPLATE_DIR}/rundeck-config-extra.properties&quot;\n    dst         = &quot;${REMCO_TMP_DIR}/rundeck-config/rundeck-config-extra.properties&quot;\n    mode        = &quot;0644&quot;\n</code></pre>\n<p>My <code>docker-compose.yaml</code> (at <code>mydocker/</code> path):</p>\n<pre class=\"lang-yaml prettyprint-override\"><code>version: '3'\n\nservices:\n  rundeckserver:\n    build:\n      context: .\n      dockerfile: Dockerfile\n      args:\n        url: http://localhost:4440\n    ports:\n      - &quot;4440:4440&quot;\n    restart: always\n</code></pre>\n<p>My <code>Dockerfile</code> (at <code>mydocker/</code> path, also copy an example plugin obtained <a href=\"https://github.com/rundeck/rundeck/tree/master/examples/example-java-job-lifecycle-plugin\" rel=\"nofollow noreferrer\">here</a>):</p>\n<pre><code>FROM rundeck/rundeck:3.2.4\n\nCOPY --chown=rundeck:root remco /etc/remco\nCOPY --chown=rundeck:root volume/job-lifecycle-3.2.3-20200221.jar /home/rundeck/libext/\nARG url=&quot;&quot;\nENV RUNDECK_SERVER_ADDRESS=0.0.0.0\nENV RUNDECK_GRAILS_URL=$url\n</code></pre>\n<p>Then you need to do (at <code>mydocker/</code> path):</p>\n<p><code>docker-compose build</code></p>\n<p>And later:</p>\n<p><code>docker-compose up</code></p>\n<p>That adds this line in the <code>rundeck-config.properties</code> file:</p>\n<pre><code># adding extra stuff to rundeck-config.properties file\nrundeck.feature.jobLifecyclePlugin.enabled=true\n</code></pre>\n<p>Finally, take a look at the <a href=\"https://imgur.com/4AwEHvr\" rel=\"nofollow noreferrer\">result</a>.</p>\n",
                    "OwnerUserId": "10426011",
                    "LastEditorUserId": "10426011",
                    "LastEditDate": "2022-09-14T20:30:10.297",
                    "LastActivityDate": "2022-09-14T20:30:10.297",
                    "CommentCount": "3",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "60991774",
                "ParentRepo": "https://github.com/zalando-incubator/kube-metrics-adapter",
                "StackOverflow_Post": {
                    "Id": "60991774",
                    "PostTypeId": "2",
                    "ParentId": "60990200",
                    "CreationDate": "2020-04-02T12:38:17.507",
                    "Score": "2",
                    "Body": "<p>I'm not exactly sure if this would fit your needs but you could use <a href=\"https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale-walkthrough/#autoscaling-on-metrics-not-related-to-kubernetes-objects\" rel=\"nofollow noreferrer\">Autoscaling on metrics not related to Kubernetes objects</a>.</p>\n\n<blockquote>\n  <p>Applications running on Kubernetes may need to autoscale based on metrics that don\u2019t have an obvious relationship to any object in the Kubernetes cluster, such as metrics describing a hosted service with no direct correlation to Kubernetes namespaces. In Kubernetes 1.10 and later, you can address this use case with  <em>external metrics</em>.</p>\n  \n  <p>Using external metrics requires knowledge of your monitoring system; the setup is similar to that required when using custom metrics. External metrics allow you to autoscale your cluster based on any metric available in your monitoring system. Just provide a  <code>metric</code>  block with a  <code>name</code>  and  <code>selector</code>, as above, and use the  <code>External</code>  metric type instead of  <code>Object</code>. If multiple time series are matched by the  <code>metricSelector</code>, the sum of their values is used by the HorizontalPodAutoscaler. External metrics support both the  <code>Value</code>  and  <code>AverageValue</code>  target types, which function exactly the same as when you use the  <code>Object</code>  type.</p>\n  \n  <p>For example if your application processes tasks from a hosted queue service, you could add the following section to your HorizontalPodAutoscaler manifest to specify that you need one worker per 30 outstanding tasks.</p>\n  \n  <pre class=\"lang-yaml prettyprint-override\"><code>- type: External\n external:\n   metric:\n     name: queue_messages_ready\n     selector: \"queue=worker_tasks\"\n   target:\n     type: AverageValue\n     averageValue: 30\n</code></pre>\n  \n  <p>When possible, it\u2019s preferable to use the custom metric target types instead of external metrics, since it\u2019s easier for cluster administrators to secure the custom metrics API. The external metrics API potentially allows access to any metric, so cluster administrators should take care when exposing it.</p>\n</blockquote>\n\n<p>You may also have a look at <a href=\"https://github.com/zalando-incubator/kube-metrics-adapter\" rel=\"nofollow noreferrer\">zalando-incubator/kube-metrics-adapter</a> and use Prometheus collector <a href=\"https://github.com/zalando-incubator/kube-metrics-adapter#example-external-metric\" rel=\"nofollow noreferrer\">external metrics</a>.</p>\n\n<blockquote>\n  <p>This is an example of an HPA configured to get metrics based on a Prometheus query. The query is defined in the annotation  <code>metric-config.external.prometheus-query.prometheus/processed-events-per-second</code>  where  <code>processed-events-per-second</code>  is the query name which will be associated with the result of the query. A matching  <code>query-name</code>  label must be defined in the  <code>matchLabels</code>  of the metric definition. This allows having multiple prometheus queries associated with a single HPA.</p>\n\n<pre><code>apiVersion: autoscaling/v2beta2\nkind: HorizontalPodAutoscaler\nmetadata:\n name: myapp-hpa\n annotations:\n   # This annotation is optional.\n   # If specified, then this prometheus server is used,\n   # instead of the prometheus server specified as the CLI argument `--prometheus-server`.\n   metric-config.external.prometheus-query.prometheus/prometheus-server: http://prometheus.my-&gt;namespace.svc\n   # metric-config.&lt;metricType&gt;.&lt;metricName&gt;.&lt;collectorName&gt;/&lt;configKey&gt;\n   # &lt;configKey&gt; == query-name\n   metric-config.external.prometheus-query.prometheus/processed-events-per-second: |\n     scalar(sum(rate(event-service_events_count{application=\"event-service\",processed=\"true\"}[1m])))\nspec:\n scaleTargetRef:\n   apiVersion: apps/v1\n   kind: Deployment\n   name: custom-metrics-consumer\n minReplicas: 1\n maxReplicas: 10\n metrics:\n - type: External\n   external:\n     metric:\n       name: prometheus-query\n       selector:\n         matchLabels:\n           query-name: processed-events-per-second\n     target:\n       type: AverageValue\n       averageValue: \"10\"\n</code></pre>\n</blockquote>\n",
                    "OwnerUserId": "3156333",
                    "LastActivityDate": "2020-04-02T12:38:17.507",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "61125666",
                "ParentRepo": "https://github.com/kubernetes/apiextensions-apiserver/blob/master/pkg/client/clientset/clientset/typed/apiextensions/v1beta1/customresourcedefinition.go",
                "StackOverflow_Post": {
                    "Id": "61125666",
                    "PostTypeId": "2",
                    "ParentId": "61124023",
                    "CreationDate": "2020-04-09T16:20:56.277",
                    "Score": "0",
                    "Body": "<p>It is possible to manage <strong>jobs</strong> programmatically using the kubernetes <code>client-go</code> project. </p>\n\n<p>Here are some <a href=\"https://github.com/kubernetes/client-go/tree/master/examples\" rel=\"nofollow noreferrer\">examples</a>.</p>\n\n<p>To create a job to completion, refer:</p>\n\n<ul>\n<li><a href=\"https://github.com/kubernetes/client-go/blob/master/kubernetes/typed/batch/v1/job.go\" rel=\"nofollow noreferrer\">Job APIs</a></li>\n<li><a href=\"https://godoc.org/k8s.io/client-go/kubernetes/typed/batch/v1#JobInterface\" rel=\"nofollow noreferrer\">JobInterface</a></li>\n<li><a href=\"https://github.com/kubernetes/client-go/blob/master/kubernetes/typed/batch/v1/batch_client.go\" rel=\"nofollow noreferrer\">Batch client APIs</a></li>\n</ul>\n\n<p><strong>Custom resources definitions</strong> can be managed using the kubernetes <code>apiextensions-apiserver</code> project.</p>\n\n<p>To manage <strong>custom resources definitions</strong>, refer:</p>\n\n<ul>\n<li><a href=\"https://github.com/kubernetes/apiextensions-apiserver/blob/master/pkg/client/clientset/clientset/typed/apiextensions/v1beta1/customresourcedefinition.go\" rel=\"nofollow noreferrer\">CRD APIs</a></li>\n<li><a href=\"https://github.com/kubernetes/apiextensions-apiserver/blob/master/test/integration/basic_test.go\" rel=\"nofollow noreferrer\">CRD API tests</a></li>\n</ul>\n\n<p>To create <strong>custom resources</strong>, refer:</p>\n\n<ul>\n<li><a href=\"https://kubernetes.io/docs/tasks/access-application-cluster/access-cluster/#accessing-the-api-from-a-pod\" rel=\"nofollow noreferrer\">This link</a> has steps to access kubernetes API from inside a pod</li>\n<li><a href=\"https://github.com/kubernetes/client-go/blob/master/examples/in-cluster-client-configuration/main.go\" rel=\"nofollow noreferrer\">Example</a></li>\n</ul>\n",
                    "OwnerUserId": "8645590",
                    "LastActivityDate": "2020-04-09T16:20:56.277",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "61127820",
                "ParentRepo": "https://github.com/kubernetes-sigs/custom-metrics-apiserver/blob/master/docs/getting-started.md#writing-a-provider",
                "StackOverflow_Post": {
                    "Id": "61127820",
                    "PostTypeId": "2",
                    "ParentId": "61123099",
                    "CreationDate": "2020-04-09T18:28:00.553",
                    "Score": "0",
                    "Body": "<p>It looks like you are interested in the Queue Bus metrics. </p>\n\n<p>I found this issue that is still open talking about a big delay in the <code>queue messages</code> metric to get populated.</p>\n\n<p><a href=\"https://github.com/Azure/azure-k8s-metrics-adapter/issues/63\" rel=\"nofollow noreferrer\">https://github.com/Azure/azure-k8s-metrics-adapter/issues/63</a></p>\n\n<p>the way custom-metric adapters work, they will query metrics from external services and make them available over a custom api on the Kubernetes API-server using a APiService resource.  </p>\n\n<p><a href=\"https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/#support-for-metrics-apis\" rel=\"nofollow noreferrer\">https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/#support-for-metrics-apis</a></p>\n\n<p><a href=\"https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale-walkthrough/#autoscaling-on-metrics-not-related-to-kubernetes-objects\" rel=\"nofollow noreferrer\">https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale-walkthrough/#autoscaling-on-metrics-not-related-to-kubernetes-objects</a></p>\n\n<p>The adapter implements a query to the external service (Service Bus in your case) \nbase on the spec, the get metric should never fail, so receiving a NULL could be because you don't have a valid connection OR there isn't available m metrics yet.</p>\n\n<p><a href=\"https://github.com/kubernetes-sigs/custom-metrics-apiserver/blob/master/docs/getting-started.md#writing-a-provider\" rel=\"nofollow noreferrer\">https://github.com/kubernetes-sigs/custom-metrics-apiserver/blob/master/docs/getting-started.md#writing-a-provider</a></p>\n\n<blockquote>\n  <p>First, there's a method for listing all metrics available at any point in time. It's used to populate the discovery information in the API, so that clients can know what metrics are available. It's not allowed to fail (it doesn't return any error), and it should return quickly, so it's suggested that you update it asynchronously in real-world code.</p>\n</blockquote>\n\n<p>Could you explain why you are looking to delete the metrics ? In the end, I don't think it is possible since the adapter is there to fetch and report. </p>\n",
                    "OwnerUserId": "2690525",
                    "LastActivityDate": "2020-04-09T18:28:00.553",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "61579047",
                "ParentRepo": "https://github.com/kubernetes/cloud-provider-vsphere/issues/299",
                "StackOverflow_Post": {
                    "Id": "61579047",
                    "PostTypeId": "2",
                    "ParentId": "61519057",
                    "CreationDate": "2020-05-03T17:45:23.290",
                    "Score": "2",
                    "Body": "<p>I believe this was already discussed in <a href=\"https://github.com/kubernetes/cloud-provider-vsphere/issues/299\" rel=\"nofollow noreferrer\">vsphere-cloud-controller-manager pod crashes with error</a>.</p>\n\n<p>As per frapposelli:</p>\n\n<blockquote>\n  <p>This was triaged also during the monthly vSphere provider call and it\n  was pointed out that there might be a fix for this behavior in 1.16,\n  see kubernetes/kubernetes#75229</p>\n</blockquote>\n\n<p>Also there is a confirmation in 1.17.3 this issue is no longer presents: <a href=\"https://github.com/kubernetes/cloud-provider-vsphere/issues/299#issuecomment-596575451\" rel=\"nofollow noreferrer\">github answer</a></p>\n\n<p>You provided not much info in question, but hope this will help you in  further resolution</p>\n",
                    "OwnerUserId": "9929015",
                    "LastActivityDate": "2020-05-03T17:45:23.290",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "61579047",
                "ParentRepo": "https://github.com/kubernetes/cloud-provider-vsphere/issues/299",
                "StackOverflow_Post": {
                    "Id": "61579047",
                    "PostTypeId": "2",
                    "ParentId": "61519057",
                    "CreationDate": "2020-05-03T17:45:23.290",
                    "Score": "2",
                    "Body": "<p>I believe this was already discussed in <a href=\"https://github.com/kubernetes/cloud-provider-vsphere/issues/299\" rel=\"nofollow noreferrer\">vsphere-cloud-controller-manager pod crashes with error</a>.</p>\n\n<p>As per frapposelli:</p>\n\n<blockquote>\n  <p>This was triaged also during the monthly vSphere provider call and it\n  was pointed out that there might be a fix for this behavior in 1.16,\n  see kubernetes/kubernetes#75229</p>\n</blockquote>\n\n<p>Also there is a confirmation in 1.17.3 this issue is no longer presents: <a href=\"https://github.com/kubernetes/cloud-provider-vsphere/issues/299#issuecomment-596575451\" rel=\"nofollow noreferrer\">github answer</a></p>\n\n<p>You provided not much info in question, but hope this will help you in  further resolution</p>\n",
                    "OwnerUserId": "9929015",
                    "LastActivityDate": "2020-05-03T17:45:23.290",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "61603843",
                "ParentRepo": "https://github.com/virtual-kubelet/azure-aci/pull/31",
                "StackOverflow_Post": {
                    "Id": "61603843",
                    "PostTypeId": "2",
                    "ParentId": "59968396",
                    "CreationDate": "2020-05-05T00:27:50.030",
                    "Score": "0",
                    "Body": "<p>Please use the enable-addons command instead of install-connector.</p>\n\n<p>You can follow the official instructions here:\n<a href=\"https://learn.microsoft.com/en-us/azure/aks/virtual-nodes-cli#enable-virtual-nodes-addon\" rel=\"nofollow noreferrer\">https://learn.microsoft.com/en-us/azure/aks/virtual-nodes-cli#enable-virtual-nodes-addon</a></p>\n\n<pre><code>az aks enable-addons \\\n    --resource-group myResourceGroup \\\n    --name myAKSCluster \\\n    --addons virtual-node \\\n    --subnet-name myVirtualNodeSubnet\n</code></pre>\n\n<p>The install-connector was a command set used during preview, which is set for removal.</p>\n\n<p>This has been called out on the virtual-kubelet project here as being a deprecated command: <a href=\"https://github.com/virtual-kubelet/azure-aci/pull/31\" rel=\"nofollow noreferrer\">https://github.com/virtual-kubelet/azure-aci/pull/31</a></p>\n",
                    "OwnerUserId": "2566430",
                    "LastActivityDate": "2020-05-05T00:27:50.030",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "61603910",
                "ParentRepo": "https://github.com/rancher/terraform-provider-rke/blob/master/README.md",
                "StackOverflow_Post": {
                    "Id": "61603910",
                    "PostTypeId": "2",
                    "ParentId": "61600637",
                    "CreationDate": "2020-05-05T00:35:28.447",
                    "Score": "7",
                    "Body": "<p>It turns out that the error message didn't tell the whole story. Terraform was finding the provider, but it didn't think it was a new enough version.</p>\n\n<p>According to <a href=\"https://www.terraform.io/docs/configuration/providers.html#third-party-plugins\" rel=\"noreferrer\">Terraform's documentation</a>, the provider needs to be named as <code>terraform-provider-&lt;NAME&gt;_vX.Y.Z</code>. The <a href=\"https://github.com/rancher/terraform-provider-rke/blob/master/README.md\" rel=\"noreferrer\">documentation for the RKE provider</a> said that the file should be called <code>terraform-provider-rke</code> (no version number). </p>\n\n<p>In a <a href=\"https://github.com/hashicorp/terraform/blob/master/plugin/discovery/find.go#L18\" rel=\"noreferrer\">comment in the Terraform source code for plugin discovery</a>, it says that this versionless format is supported for reverse compatibility. However, Terraform interprets the version to be <code>v0.0.0</code>. </p>\n\n<p>When I ran <code>terraform plan</code> after the failed <code>terraform init</code>, it gave me a more informative error message:</p>\n\n<pre><code>Error: provider.rke: no suitable version installed\n  version requirements: \"0.14.1\"\n  versions installed: \"0.0.0\"\n</code></pre>\n\n<p>That version is presumably a requirement from another provider that depends on the RKE provider. </p>\n\n<p>I went back and manually downloaded that exact version from the Github repo and copied it into the plugins directory with the name <code>terraform-provider-rke_v0.14.1</code>. It worked!</p>\n\n<p>So there you go. When in doubt, look at the source code. Now to submit an issue report to Rancher, telling them to update their documentation. :-)</p>\n",
                    "OwnerUserId": "2452762",
                    "LastEditorUserId": "2452762",
                    "LastEditDate": "2020-05-05T00:44:55.910",
                    "LastActivityDate": "2020-05-05T00:44:55.910",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "61629583",
                "ParentRepo": "https://github.com/kubernetes-sigs/apiserver-builder-alpha/issues/225",
                "StackOverflow_Post": {
                    "Id": "61629583",
                    "PostTypeId": "2",
                    "ParentId": "61629264",
                    "CreationDate": "2020-05-06T07:26:03.823",
                    "Score": "1",
                    "Body": "<p>The system:anonymous is not authorized to perform the list actions within your cluster.</p>\n\n<p>You can solve this case in 2 ways:</p>\n\n<p>1 - Using RBAC Authorization, described in <a href=\"https://kubernetes.io/docs/reference/access-authn-authz/rbac/\" rel=\"nofollow noreferrer\">k8s documentation here</a>.</p>\n\n<p>2 - A <strong>NOT recommended</strong> way is explained in this <a href=\"https://github.com/kubernetes-sigs/apiserver-builder-alpha/issues/225\" rel=\"nofollow noreferrer\">GitHub thread</a>:</p>\n\n<pre><code>kubectl create clusterrolebinding cluster-system-anonymous --clusterrole=dont-do-this --user=system:anonymous\n</code></pre>\n\n<p>At the end of the GitHub thread, the Kubernetes team explains why this is not a recommended approach:</p>\n\n<blockquote>\n  <p>[...] granting anonymous clients full access to the Kubernetes API [...] should not be considered as solutions to permission issues</p>\n</blockquote>\n\n<p>But if you are not in Production and would like to check if it works first, that can help.\nYou can double check and create the proper Cluster Role and Cluster Role Binding afterwards.</p>\n",
                    "OwnerUserId": "9291851",
                    "LastActivityDate": "2020-05-06T07:26:03.823",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "61957835",
                "ParentRepo": "https://github.com/kubernetes-sigs/bootkube",
                "StackOverflow_Post": {
                    "Id": "61957835",
                    "PostTypeId": "1",
                    "CreationDate": "2020-05-22T14:56:47.463",
                    "Score": "0",
                    "ViewCount": "336",
                    "Body": "<p>I am already running a single master kubernetes cluster now and I am doing research about setting up Highly available Kubernetes clusters. I was thinking of Multi master cluster setup then realized self-hosted cluster might be a better option to go future ready. </p>\n\n<p>Additional challenge is I am doing it in Bare Metal (Meaning, I am going to use cloud vms from these cloud provider, Hetzner, Linode, DigitialOcean and they have CSI driver, cloud controller manager etc., )  </p>\n\n<p>In this case, I see 2 options. </p>\n\n<ol>\n<li>Setup with bootkube (<a href=\"https://github.com/kubernetes-sigs/bootkube\" rel=\"nofollow noreferrer\">https://github.com/kubernetes-sigs/bootkube</a>)</li>\n<li>Setup with kubeadm self-hosting. (<a href=\"https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/self-hosting/\" rel=\"nofollow noreferrer\">https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/self-hosting/</a>)</li>\n</ol>\n\n<p>I assume this is still an early topic hence I am not able to find guidance to choose the right approach and then correct documentation.  I need this for a scalable production environment where I will start small with at least 8 nodes and can grow faster.  </p>\n\n<p>Is bootkube considerable for future readiness? \nor kubeadm self-hosting is still in alpha stage, am I getting into a risk running a production environment? \nAny good, documentation, blog, article to go in this direction? </p>\n",
                    "OwnerUserId": "2749993",
                    "LastActivityDate": "2020-05-27T13:45:20.387",
                    "Title": "High available kubernetes cluster? bootkube or kubeadm self-hosting",
                    "Tags": "<kubernetes><kubeadm><kubelet><kubernetes-ha>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "62136351",
                "ParentRepo": "https://github.com/m3db/m3/issues/1671#issuecomment-502243705",
                "StackOverflow_Post": {
                    "Id": "62136351",
                    "PostTypeId": "2",
                    "ParentId": "62127643",
                    "CreationDate": "2020-06-01T16:15:28.570",
                    "Score": "5",
                    "Body": "<blockquote>\n  <p>For example, If a Linux OS has <code>ulimit</code> nofile set to 1024 (soft) and Hard (4096) , and I run docker with <code>----ulimit nofile=10240:40960</code>, could the container use more nofiles than its host?</p>\n</blockquote>\n\n<ul>\n<li>Docker has the <code>CAP_SYS_RESOURCE</code> capability set on it's permissions.\nThis means that Docker is able to set an <code>ulimit</code> different from the host. according to <code>man 2 prlimit</code>:</li>\n</ul>\n\n<blockquote>\n  <p>A privileged process (under Linux: one with the CAP_SYS_RESOURCE capability in the initial user namespace) may make arbitrary changes to either limit value.</p>\n</blockquote>\n\n<ul>\n<li>So, for containers, the limits to be considered are the ones set by the docker daemon.\nYou can check the docker daemon limits with this command:</li>\n</ul>\n\n<pre><code>$ cat /proc/$(ps -A | grep dockerd | awk '{print $1}')/limits | grep \"files\"\nMax open files            1048576              1048576              files \n</code></pre>\n\n<ul>\n<li><p>As you can see, the docker 19 has a pretty high limit of <code>1048576</code> so your 40960 <strong>will work</strong> like a charm.</p></li>\n<li><p>And if you run a docker container with <code>--ulimit</code> set to be higher than the node but lower than the daemon itself, you won't find any problem, and won't need to give additional permissions like in the example bellow:</p></li>\n</ul>\n\n<pre><code>$ cat /proc/$(ps -A | grep dockerd | awk '{print $1}')/limits | grep \"files\"\nMax open files            1048576              1048576              files     \n\n$ docker run -d -it --rm --ulimit nofile=99999:99999 python python;\n354de39a75533c7c6e31a1773a85a76e393ba328bfb623069d57c38b42937d03\n\n$ cat /proc/$(ps -A | grep python | awk '{print $1}')/limits | grep \"files\"\nMax open files            99999                99999                files \n</code></pre>\n\n<ul>\n<li>You can set a new limit for dockerd on the file <code>/etc/init.d/docker</code>:</li>\n</ul>\n\n<pre><code>$ cat /etc/init.d/docker | grep ulimit\n                ulimit -n 1048576\n</code></pre>\n\n<ul>\n<li>As for the container itself having a <code>ulimit</code> higher than the docker daemon, it's a bit more tricky, but doable, refer <a href=\"https://github.com/m3db/m3/issues/1671#issuecomment-502243705\" rel=\"noreferrer\">here</a>.</li>\n<li>I saw you have tagged the Kubernetes tag, but didn't mention it in your question, but in order to make it work on Kubernetes, the container will need <code>securityContext.priviledged: true</code>, this way you can run the command <code>ulimit</code> as root inside the container, here an example:</li>\n</ul>\n\n<pre><code>image: image-name\n  command: [\"sh\", \"-c\", \"ulimit -n 65536\"]\n  securityContext:\n    privileged: true\n</code></pre>\n",
                    "OwnerUserId": "12524159",
                    "LastActivityDate": "2020-06-01T16:15:28.570",
                    "CommentCount": "3",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "62515946",
                "ParentRepo": "https://github.com/liyue201/grpc-lb/blob/master/balancer/consistent_hash.go",
                "StackOverflow_Post": {
                    "Id": "62515946",
                    "PostTypeId": "2",
                    "ParentId": "62474754",
                    "CreationDate": "2020-06-22T13:46:51.007",
                    "Score": "1",
                    "Body": "<p>For anyone looking at this. The trick is to pass the &quot;sharding key&quot; to the Picker in context, which can then use this to calculate hash and decide which subconnection to use. See <a href=\"https://github.com/liyue201/grpc-lb/blob/master/balancer/consistent_hash.go\" rel=\"nofollow noreferrer\">https://github.com/liyue201/grpc-lb/blob/master/balancer/consistent_hash.go</a> for an implementation example.</p>\n",
                    "OwnerUserId": "1419318",
                    "LastActivityDate": "2020-06-22T13:46:51.007",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "62687837",
                "ParentRepo": "https://github.com/Andrew-M-C/go.raftstudy/blob/master/main.go",
                "StackOverflow_Post": {
                    "Id": "62687837",
                    "PostTypeId": "1",
                    "CreationDate": "2020-07-02T02:00:58.253",
                    "Score": "1",
                    "ViewCount": "53",
                    "Body": "<p>I am new to etfd/raft. I managed to make a simplest raft demo to create a cluster and make them sync proposal. The nodes in the cluster are pre-configured in peers of raft.StartNode(...)</p>\n<p>However, when I tried to dynamically add a new node to a running cluster, although I managed to make the cluster recognized the new node, new proposals are not sent to the new node.</p>\n<p>Here is my code: <a href=\"https://github.com/Andrew-M-C/go.raftstudy/blob/master/main.go\" rel=\"nofollow noreferrer\">main.go</a></p>\n<p>For short:</p>\n<ol>\n<li>I did got entries from Ready(), and invoke ApplyConfChange() when I got raftpb.EntryConfChange type from CommittedEntries</li>\n<li>Messages to each nodes are sent by channel, simulating a network RPC</li>\n<li>Advance() and Step() are invoked make the state machines work.</li>\n</ol>\n<p>And how I add the new node? Also for short:</p>\n<ol>\n<li>Each node has another indivisual channel to receive conf change message</li>\n<li>I send raftpb.ConfChange type to every cond change channels</li>\n<li>Watching stdout, this new node is reconized by all previous nodes because they all got EntryConfChange in CommittedEntries</li>\n<li>Then I make another proposal. All previous nodes received the proposal from leader node, but the new one did not.</li>\n</ol>\n<p>I must had miss something or made sonething wrong, but I cannot figure out.\nAnyone help? Thank you in ahead!</p>\n",
                    "OwnerUserId": "2003558",
                    "LastActivityDate": "2020-07-02T02:00:58.253",
                    "Title": "Newly added Raft node cannot receive proposal?",
                    "Tags": "<go><distributed-computing><etcd><raft>",
                    "AnswerCount": "0",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "62771673",
                "ParentRepo": "https://github.com/databus23/helm-diff",
                "StackOverflow_Post": {
                    "Id": "62771673",
                    "PostTypeId": "2",
                    "ParentId": "62770290",
                    "CreationDate": "2020-07-07T09:03:46.123",
                    "Score": "10",
                    "Body": "<p>On <a href=\"https://helm.sh/docs/community/related/\" rel=\"noreferrer\">helm website</a> you can find some plugins.\nOne of them called <a href=\"https://github.com/databus23/helm-diff\" rel=\"noreferrer\">helm-diff</a>, and it can generate diffs between releases.</p>\n<p>Here is how to use this plugin:</p>\n<pre><code>$ helm diff release -h\n\nThis command compares the manifests details of a different releases created from the same chart\n\nIt can be used to compare the manifests of\n\n - release1 with release2\n    $ helm diff release [flags] release1 release2\n   Example:\n    $ helm diff release my-prod my-stage\n</code></pre>\n<p><a href=\"https://github.com/databus23/helm-diff#install\" rel=\"noreferrer\">Here is explained how to install the plugin</a>.\nTLDR: if you are using helm version &gt; 2.3.x jest run:</p>\n<pre><code>helm plugin install https://github.com/databus23/helm-diff\n</code></pre>\n<p>Let me know it this solves your problem. If you have any further questions I'd be happy to answer them.</p>\n",
                    "OwnerUserId": "12201084",
                    "LastActivityDate": "2020-07-07T09:03:46.123",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "63527631",
                "ParentRepo": "https://github.com/google/certificate-transparency-go",
                "StackOverflow_Post": {
                    "Id": "63527631",
                    "PostTypeId": "2",
                    "ParentId": "63527542",
                    "CreationDate": "2020-08-21T17:40:53.940",
                    "Score": "1",
                    "Body": "<p>There are two aspects here:</p>\n<ol>\n<li>retrieving SCTs from the TLS connection</li>\n<li>verifying the SCTs against CT logs</li>\n</ol>\n<p><strong>Retrieving SCTs</strong> is easily done in the standard library, with three different cases per <a href=\"https://www.rfc-editor.org/rfc/rfc6962.html#page-13\" rel=\"nofollow noreferrer\">RFC 6962</a>:</p>\n<ul>\n<li>as an extension in the leaf certificate itself</li>\n<li>as a TLS extension in the handshake</li>\n<li>in the OCSP response</li>\n</ul>\n<p>All of them are available through the <a href=\"https://golang.org/pkg/crypto/tls/#ConnectionState\" rel=\"nofollow noreferrer\">tls.ConnectionState</a> in their respective fields:</p>\n<ul>\n<li><code>state.PeerCertificates[0].Extensions</code>, under the extension with ID <code>asn1.ObjectIdentifier{1, 3, 6, 1, 4, 1, 11129, 2, 4, 2}</code></li>\n<li><code>state.SignedCertificateTimestamps</code></li>\n<li><code>state.OCSPResponse</code></li>\n</ul>\n<p>Those still need to be parsed properly.</p>\n<p><strong>Verifying SCTs</strong> is trickier and is <strong>not</strong> part of the standard library. This involves the following:</p>\n<ul>\n<li>having a list of trusted CT logs</li>\n<li>finding the CT log whose public key was used to sign the SCT</li>\n<li>verifying the signature</li>\n<li>verifying inclusion of the certificate in the CT's merkle tree and checking timestamps</li>\n</ul>\n<p>This can be cobbled together using the <a href=\"https://github.com/google/certificate-transparency-go\" rel=\"nofollow noreferrer\">certificate-transparency-go</a> utilities, but they have not included a quick and easy way to use it as a library.</p>\n<p>One library that attempts to make all of this easier is available at <a href=\"https://github.com/mberhault/go-sct\" rel=\"nofollow noreferrer\">github.com/mberhault/go-sct</a>. It can be used as follows to verify the SCTs after a HTTPS GET:</p>\n<p><strong>Disclaimer</strong>: I am the author of <code>github.com/mberhault/go-sct</code>.</p>\n<pre class=\"lang-golang prettyprint-override\"><code>import &quot;github.com/mberhault/go-sct&quot;\n\n// Verifying the SCTs after a HTTPS GET request.\nresp, err := http.Get(&quot;https://www.certificate-transparency.org&quot;)\nif err != nil {\n    panic(&quot;get failed &quot; + err.Error())\n}\n\nerr = sct.CheckConnectionState(resp.TLS)\nif err != nil {\n    panic(&quot;SCT check failed &quot; + err.Error())\n}\n</code></pre>\n<p>The same can be done on the tls.ConnectionState obtained through other methods (on a <code>tls.Conn</code>, or in the <code>tls.Config.VerifyConnection</code> callback).</p>\n",
                    "OwnerUserId": "4966953",
                    "LastEditorUserId": "4966953",
                    "LastEditDate": "2020-08-22T13:43:20.127",
                    "LastActivityDate": "2020-08-22T13:43:20.127",
                    "CommentCount": "7",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "63527631",
                "ParentRepo": "https://github.com/mberhault/go-sct",
                "StackOverflow_Post": {
                    "Id": "63527631",
                    "PostTypeId": "2",
                    "ParentId": "63527542",
                    "CreationDate": "2020-08-21T17:40:53.940",
                    "Score": "1",
                    "Body": "<p>There are two aspects here:</p>\n<ol>\n<li>retrieving SCTs from the TLS connection</li>\n<li>verifying the SCTs against CT logs</li>\n</ol>\n<p><strong>Retrieving SCTs</strong> is easily done in the standard library, with three different cases per <a href=\"https://www.rfc-editor.org/rfc/rfc6962.html#page-13\" rel=\"nofollow noreferrer\">RFC 6962</a>:</p>\n<ul>\n<li>as an extension in the leaf certificate itself</li>\n<li>as a TLS extension in the handshake</li>\n<li>in the OCSP response</li>\n</ul>\n<p>All of them are available through the <a href=\"https://golang.org/pkg/crypto/tls/#ConnectionState\" rel=\"nofollow noreferrer\">tls.ConnectionState</a> in their respective fields:</p>\n<ul>\n<li><code>state.PeerCertificates[0].Extensions</code>, under the extension with ID <code>asn1.ObjectIdentifier{1, 3, 6, 1, 4, 1, 11129, 2, 4, 2}</code></li>\n<li><code>state.SignedCertificateTimestamps</code></li>\n<li><code>state.OCSPResponse</code></li>\n</ul>\n<p>Those still need to be parsed properly.</p>\n<p><strong>Verifying SCTs</strong> is trickier and is <strong>not</strong> part of the standard library. This involves the following:</p>\n<ul>\n<li>having a list of trusted CT logs</li>\n<li>finding the CT log whose public key was used to sign the SCT</li>\n<li>verifying the signature</li>\n<li>verifying inclusion of the certificate in the CT's merkle tree and checking timestamps</li>\n</ul>\n<p>This can be cobbled together using the <a href=\"https://github.com/google/certificate-transparency-go\" rel=\"nofollow noreferrer\">certificate-transparency-go</a> utilities, but they have not included a quick and easy way to use it as a library.</p>\n<p>One library that attempts to make all of this easier is available at <a href=\"https://github.com/mberhault/go-sct\" rel=\"nofollow noreferrer\">github.com/mberhault/go-sct</a>. It can be used as follows to verify the SCTs after a HTTPS GET:</p>\n<p><strong>Disclaimer</strong>: I am the author of <code>github.com/mberhault/go-sct</code>.</p>\n<pre class=\"lang-golang prettyprint-override\"><code>import &quot;github.com/mberhault/go-sct&quot;\n\n// Verifying the SCTs after a HTTPS GET request.\nresp, err := http.Get(&quot;https://www.certificate-transparency.org&quot;)\nif err != nil {\n    panic(&quot;get failed &quot; + err.Error())\n}\n\nerr = sct.CheckConnectionState(resp.TLS)\nif err != nil {\n    panic(&quot;SCT check failed &quot; + err.Error())\n}\n</code></pre>\n<p>The same can be done on the tls.ConnectionState obtained through other methods (on a <code>tls.Conn</code>, or in the <code>tls.Config.VerifyConnection</code> callback).</p>\n",
                    "OwnerUserId": "4966953",
                    "LastEditorUserId": "4966953",
                    "LastEditDate": "2020-08-22T13:43:20.127",
                    "LastActivityDate": "2020-08-22T13:43:20.127",
                    "CommentCount": "7",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "63571372",
                "ParentRepo": "https://github.com/jianz/k8s-reset-terminating-pv",
                "StackOverflow_Post": {
                    "Id": "63571372",
                    "PostTypeId": "2",
                    "ParentId": "51585649",
                    "CreationDate": "2020-08-25T02:50:19.587",
                    "Score": "2",
                    "Body": "<p>You can check out <a href=\"https://github.com/jianz/k8s-reset-terminating-pv\" rel=\"nofollow noreferrer\">this tool</a>, it will update the <code>Terminating</code> PV's status in etcd back to <code>Bound</code>.</p>\n<p>The way it works has been mentioned by Anirudh Ramanathan in his answer.</p>\n<p>Be sure to back up your PV first.</p>\n",
                    "OwnerUserId": "3030303",
                    "LastActivityDate": "2020-08-25T02:50:19.587",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "64127123",
                "ParentRepo": "https://github.com/hetznercloud/hcloud-cloud-controller-manager",
                "StackOverflow_Post": {
                    "Id": "64127123",
                    "PostTypeId": "1",
                    "CreationDate": "2020-09-29T20:24:01.610",
                    "Score": "0",
                    "ViewCount": "463",
                    "Body": "<p>I am kind of lost right now. I set up a Kubernetes Cluster, deployed a Spring Boot API and a LoadBalancer which worked fine. Now I want to enable proxy protocol on the LoadBalancer to preserve the real clients IP, but once I do this my Spring Boot API always returns with a <code>400 Bad Request</code> and an <code>IllegalArgumentException</code> is thrown.</p>\n<p>Here is the short stack trace (I masked the ip addresses):</p>\n<pre><code>2020-09-29 20:05:58.382  INFO 1 --- [nio-8080-exec-1] o.apache.coyote.http11.Http11Processor   : Error parsing HTTP request header\n Note: further occurrences of HTTP request parsing errors will be logged at DEBUG level.\n\njava.lang.IllegalArgumentException: Invalid character found in the HTTP protocol [255.255.255.253 255.255.255.254]\n        at org.apache.coyote.http11.Http11InputBuffer.parseRequestLine(Http11InputBuffer.java:560) ~[tomcat-embed-core-9.0.37.jar!/:9.0.37]\n        at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:260) ~[tomcat-embed-core-9.0.37.jar!/:9.0.37]\n        at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65) ~[tomcat-embed-core-9.0.37.jar!/:9.0.37]\n        at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:868) ~[tomcat-embed-core-9.0.37.jar!/:9.0.37]\n        at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1589) ~[tomcat-embed-core-9.0.37.jar!/:9.0.37]\n        at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49) ~[tomcat-embed-core-9.0.37.jar!/:9.0.37]\n        at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[na:na]\n        at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[na:na]\n        at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) ~[tomcat-embed-core-9.0.37.jar!/:9.0.37]\n        at java.base/java.lang.Thread.run(Unknown Source) ~[na:na]\n</code></pre>\n<p>I am using the <a href=\"https://github.com/hetznercloud/hcloud-cloud-controller-manager\" rel=\"nofollow noreferrer\">hcloud-cloud-controller-manager</a> from Hetzner.</p>\n<p>Here is my LoadBalancer:</p>\n<pre class=\"lang-yaml prettyprint-override\"><code>apiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    service: auth-service\n  name: auth-service-service\n  annotations:\n    load-balancer.hetzner.cloud/name: &quot;lb-backend&quot;\n    load-balancer.hetzner.cloud/health-check-port: &quot;80&quot;\n    load-balancer.hetzner.cloud/uses-proxyprotocol: &quot;true&quot;\nspec:\n  ports:\n    - name: http\n      port: 80\n      targetPort: 8080\n  selector:\n    service: auth-service\n  externalTrafficPolicy: Local\n  type: LoadBalancer\n</code></pre>\n<p>Here is my Spring Config:</p>\n<pre class=\"lang-yaml prettyprint-override\"><code>spring:\n  datasource:\n    platform: postgres\n    url: ${DATABASE_CS}\n    username: ${DATABASE_USERNAME}\n    password: ${DATABASE_PASSWORD}\n    driver-class-name: org.postgresql.Driver\n  flyway:\n    schemas: authservice\n  jpa:\n    show-sql: false\n    properties:\n      hibernate:\n        dialect: org.hibernate.dialect.PostgreSQLDialect\n        jdbc:\n          lob:\n            non_contextual_creation: true\n    hibernate:\n      ddl-auto: validate\n\nsecurity:\n  jwt:\n    secret-key: ${JWT_SECRET_KEY}\n    expires: ${JWT_EXPIRES:300000}\n\nmail:\n  from: ${MAIL_FROM}\n  fromName: ${MAIL_FROM_NAME}\n  smtp:\n    host: ${SMTP_HOST}\n    username: ${SMTP_USERNAME}\n    password: ${SMTP_PASSWORD}\n    port: ${SMTP_PORT:25}\n  mjml:\n    app-id: ${MJML_APP_ID}\n    app-secret: ${MJML_SECRET_KEY}\nstripe:\n  keys:\n    secret: ${STRIPE_SECRET_KEY}\n    public: ${STRIPE_PUBLIC_KEY}\nserver:\n  forward-headers-strategy: native\n</code></pre>\n<p>As you may have noticed I already tried to enable the forward-headers based on <a href=\"https://github.com/spring-projects/spring-boot/issues/19333\" rel=\"nofollow noreferrer\">this issue</a>.</p>\n<p>Thanks for your help!</p>\n",
                    "OwnerUserId": "7986452",
                    "LastEditorUserId": "7986452",
                    "LastEditDate": "2020-09-29T21:05:29.710",
                    "LastActivityDate": "2020-09-29T21:37:33.697",
                    "Title": "Kubernetes: Tomcat throws Exception when enabling proxy protocol",
                    "Tags": "<spring-boot><tomcat><kubernetes><load-balancing><proxy-protocol>",
                    "AnswerCount": "1",
                    "CommentCount": "4",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "64214948",
                "ParentRepo": "https://github.com/electron-userland/electron-build-service/issues/5",
                "StackOverflow_Post": {
                    "Id": "64214948",
                    "PostTypeId": "2",
                    "ParentId": "63073160",
                    "CreationDate": "2020-10-05T19:25:35.117",
                    "Score": "3",
                    "Body": "<p>Unfortunately it doesn't seem that such issue will be fixed anytime soon, as we can see from the amount of (mostly open) GitHub issues that have been opened from users that are trying to deal with such problem in the past months:</p>\n<ul>\n<li><a href=\"https://github.com/electron-userland/electron-build-service/issues/5\" rel=\"nofollow noreferrer\">service.electron.build is unavailable</a></li>\n<li><a href=\"https://github.com/electron-userland/electron-build-service/issues/9\" rel=\"nofollow noreferrer\">Error: Cannot get, wait error=Get https://service.electron.build/find-build-agent</a></li>\n<li><a href=\"https://github.com/electron-userland/electron-build-service/issues/8\" rel=\"nofollow noreferrer\">service.electron.build is unavailable - Urgently please suggest an alternate</a></li>\n<li><a href=\"https://github.com/electron-userland/electron-build-service/issues/7\" rel=\"nofollow noreferrer\">Local build service not detected</a></li>\n<li><a href=\"https://github.com/electron-userland/electron-builder/issues/4318\" rel=\"nofollow noreferrer\">Unable to build AppImage on Windows - service.electron.build</a></li>\n<li><a href=\"https://github.com/electron-userland/electron-builder/issues/3569\" rel=\"nofollow noreferrer\">Connection to remote builder refused, while building linux package</a></li>\n</ul>\n<p>That said, I used the following workarond using Docker that made me able to build a Linux redistributable <code>.deb</code> package for my Electron App from Windows 10 in less than 5 minutes:</p>\n<ul>\n<li>Install Docker (<a href=\"https://docs.docker.com/get-docker/\" rel=\"nofollow noreferrer\">link</a>)</li>\n<li>Download the <a href=\"https://hub.docker.com/r/electronuserland/builder/\" rel=\"nofollow noreferrer\">electronuserland/builder</a> Docker image with the following console command:</li>\n</ul>\n<p><code>docker pull electronuserland/builder</code></p>\n<ul>\n<li>From the Electron project's root folder (such as <code>C:\\MyApp</code>), type the following command-line command to run the container and map the Electron project's root folder to the <code>/project</code> virtual path:</li>\n</ul>\n<p><code>docker run -rm -ti -v C:\\MyApp\\:/project -w /project electronuserland/builder</code></p>\n<ul>\n<li>From inside the container, type the following commands to upgrade the Electron project's Yarn packages, globally install the electron-builder package and build the Linux redistributable package:</li>\n</ul>\n<p><code>cd /project</code></p>\n<p><code>yarn upgrade</code></p>\n<p><code>yarn global add electron-builder</code></p>\n<p><code>electron-builder -l</code></p>\n<p>If everything went smooth, you should be able to locate your <code>MyApp.deb</code> file (or <code>rpm</code>, <code>AppImage</code>, or anything you've configured within the electron-builder's <code>package.json</code> file) inside the Electron project's <code>/dist/</code> folder.</p>\n<p>For further info about this whole procedure and a bit of background, check out <a href=\"https://www.ryadel.com/en/electron-build-linux-package-from-windows/\" rel=\"nofollow noreferrer\">this post</a> on my blog.</p>\n",
                    "OwnerUserId": "1233379",
                    "LastEditorUserId": "1233379",
                    "LastEditDate": "2020-10-06T06:48:20.340",
                    "LastActivityDate": "2020-10-06T06:48:20.340",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "64827502",
                "ParentRepo": "https://github.com/minio/operator",
                "StackOverflow_Post": {
                    "Id": "64827502",
                    "PostTypeId": "1",
                    "CreationDate": "2020-11-13T20:17:15.920",
                    "Score": "0",
                    "ViewCount": "721",
                    "Body": "<p>i've setup a minio tenant using the <a href=\"https://github.com/minio/operator\" rel=\"nofollow noreferrer\">minio operator</a> and was following the getting started guide.\nNow if i create an IngressRoute to for the ui i'm just getting redirected to 0.0.0.0:9443.</p>\n<p>This is the IngressRoute:</p>\n<pre><code>apiVersion: traefik.containo.us/v1alpha1\nkind: IngressRoute\nmetadata:\n  name: minio-console-ui-http\n  namespace: default\nspec:\n  entryPoints:\n    - web\n  routes:\n    - match: Host(`minio-console.mysecretdomain.tld`)\n      kind: Rule\n      services:\n        - name: minio-cluster-console\n          port: 9090\n</code></pre>\n<p>do i miss a config parameter for the console?</p>\n",
                    "OwnerUserId": "3993597",
                    "LastActivityDate": "2021-02-16T06:57:21.660",
                    "Title": "Kubernetes Minio tenant ui redirects to 0.0.0.0:9443",
                    "Tags": "<kubernetes><operators><minio>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "65150516",
                "ParentRepo": "https://github.com/kubernetes-sigs/kube-batch",
                "StackOverflow_Post": {
                    "Id": "65150516",
                    "PostTypeId": "1",
                    "CreationDate": "2020-12-04T20:48:05.137",
                    "Score": "0",
                    "ViewCount": "184",
                    "Body": "<p>I have a k8 job that brings up multiple pods. This job is used for load testing so all the pods need to come up at the same time. Job shouldn't be started until nodes are available for all pods to be scheduled.\nI came across kube-batch <a href=\"https://github.com/kubernetes-sigs/kube-batch\" rel=\"nofollow noreferrer\">https://github.com/kubernetes-sigs/kube-batch</a> to do this scheduling. I have couple of questions:</p>\n<p><strong>1.</strong> How to enable kube-batch for only one namespace in a cluster?</p>\n<p><strong>2.</strong> Installed kube-batch by following the tutorial. But pods are failing on startup with below error. How to resolve this error?</p>\n<pre><code>I1204 20:07:55.911393       1 allocate.go:96] Queue &lt;default&gt; is overused, ignore it.\n\nI1204 20:07:55.911399       1 allocate.go:194] Leaving Allocate ...\n\nI1204 20:07:55.911407       1 backfill.go:41] Enter Backfill ...\n\nI1204 20:07:55.911413       1 backfill.go:71] Leaving Backfill ...\n\nE1204 20:07:55.911521       1 runtime.go:69] Observed a panic: &quot;invalid memory address or nil pointer dereference&quot; (runtime error: invalid memory address or nil pointer dereference)\n\n/home/root1/servicecomb/go/src/github.com/kubernetes-sigs/kube-batch/vendor/k8s.io/apimachinery/pkg/util/runtime/runtime.go:76\n\n/home/root1/servicecomb/go/src/github.com/kubernetes-sigs/kube-batch/vendor/k8s.io/apimachinery/pkg/util/runtime/runtime.go:65\n\n/home/root1/servicecomb/go/src/github.com/kubernetes-sigs/kube-batch/vendor/k8s.io/apimachinery/pkg/util/runtime/runtime.go:51\n\n/usr/local/go/src/runtime/asm_amd64.s:522\n\n/usr/local/go/src/runtime/panic.go:513\n\n/usr/local/go/src/runtime/panic.go:82\n\n/usr/local/go/src/runtime/signal_unix.go:390\n\n/home/root1/servicecomb/go/src/github.com/kubernetes-sigs/kube-batch/pkg/scheduler/framework/session.go:368\n\n/home/root1/servicecomb/go/src/github.com/kubernetes-sigs/kube-batch/pkg/scheduler/plugins/gang/gang.go:154\n\n/home/root1/servicecomb/go/src/github.com/kubernetes-sigs/kube-batch/pkg/scheduler/framework/framework.go:58\n\n/home/root1/servicecomb/go/src/github.com/kubernetes-sigs/kube-batch/pkg/scheduler/scheduler.go:102\n\n/home/root1/servicecomb/go/src/github.com/kubernetes-sigs/kube-batch/pkg/scheduler/scheduler.go:85\n\n/home/root1/servicecomb/go/src/github.com/kubernetes-sigs/kube-batch/vendor/k8s.io/apimachinery/pkg/util/wait/wait.go:133\n\n/home/root1/servicecomb/go/src/github.com/kubernetes-sigs/kube-batch/vendor/k8s.io/apimachinery/pkg/util/wait/wait.go:134\n\n/home/root1/servicecomb/go/src/github.com/kubernetes-sigs/kube-batch/vendor/k8s.io/apimachinery/pkg/util/wait/wait.go:88\n\n/usr/local/go/src/runtime/asm_amd64.s:1333\n\npanic: runtime error: invalid memory address or nil pointer dereference [recovered]\n        panic: runtime error: invalid memory address or nil pointer dereference\n[signal SIGSEGV: segmentation violation code=0x1 addr=0x148 pc=0x10ab979]\n</code></pre>\n",
                    "OwnerUserId": "2596613",
                    "LastEditorUserId": "11300382",
                    "LastEditDate": "2020-12-07T11:45:01.737",
                    "LastActivityDate": "2020-12-07T11:45:01.737",
                    "Title": "Enable custom kubernetes scheduler for a namespace",
                    "Tags": "<kubernetes><kubernetes-jobs><kube-scheduler>",
                    "AnswerCount": "1",
                    "CommentCount": "5",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "65805335",
                "ParentRepo": "https://github.com/Mirantis/cri-dockerd",
                "StackOverflow_Post": {
                    "Id": "65805335",
                    "PostTypeId": "1",
                    "CreationDate": "2021-01-20T08:02:47.337",
                    "Score": "0",
                    "ViewCount": "194",
                    "Body": "<p>As far I know, current <a href=\"https://kubernetes.io/blog/2020/12/02/dockershim-faq/\" rel=\"nofollow noreferrer\">dockershim has been deprecated</a> by Kubernetes maintainers. As a result <a href=\"https://www.mirantis.com/blog/mirantis-to-take-over-support-of-kubernetes-dockershim-2/\" rel=\"nofollow noreferrer\">Mirantis has taken over support of Kubernetes dockershim</a>, the github repo seems to be in <a href=\"https://github.com/Mirantis/cri-dockerd\" rel=\"nofollow noreferrer\">https://github.com/Mirantis/cri-dockerd</a> which <a href=\"https://github.com/Mirantis/cri-dockerd/issues/1#issue-781683915\" rel=\"nofollow noreferrer\">minikube seems to want to support as well</a>. I also know that <a href=\"https://www.infoq.com/news/2020/12/k0s-kubernetes-distribution/\" rel=\"nofollow noreferrer\">Mirantis announces a new kubernetes distribution named k0s</a>.</p>\n<p>What I am interested to know is, does docker get special treatment when using k0s? I mean out of the box support for docker or something like that?</p>\n<p>What I found so far is<sup><a href=\"https://docs.k0sproject.io/latest/custom-cri-runtime/\" rel=\"nofollow noreferrer\">1</a></sup>,</p>\n<blockquote>\n<p>k0s supports users bringing their own CRI runtime (for example,\ndocker).</p>\n</blockquote>\n<p>However, I was expecting docker swarm level integration when using k0s. Am I missing something?</p>\n",
                    "OwnerUserId": "1772898",
                    "LastEditorUserId": "1772898",
                    "LastEditDate": "2021-01-20T08:28:54.853",
                    "LastActivityDate": "2021-01-20T08:28:54.853",
                    "Title": "does k0s support docker out of the box",
                    "Tags": "<docker><kubernetes><minikube><k0s>",
                    "AnswerCount": "0",
                    "CommentCount": "5",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "65824334",
                "ParentRepo": "https://github.com/milvus-io/milvus",
                "StackOverflow_Post": {
                    "Id": "65824334",
                    "PostTypeId": "2",
                    "ParentId": "64741397",
                    "CreationDate": "2021-01-21T09:17:57.563",
                    "Score": "1",
                    "Body": "<p>Try <a href=\"https://github.com/milvus-io/milvus\" rel=\"nofollow noreferrer\">Milvus</a> database for storing and searching similar embeddings</p>\n",
                    "OwnerUserId": "5160111",
                    "LastActivityDate": "2021-01-21T09:17:57.563",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "66010368",
                "ParentRepo": "https://github.com/k0sproject/k0s/issues/665",
                "StackOverflow_Post": {
                    "Id": "66010368",
                    "PostTypeId": "2",
                    "ParentId": "65938104",
                    "CreationDate": "2021-02-02T13:05:58.487",
                    "Score": "1",
                    "Body": "<p>Workaround is to just remove the file.</p>\n<p><code>/var/lib/k0s/run/konnectivity-server/konnectivity-server.sock</code> and restart the server.</p>\n<p>Currenlty my github issue is still open.</p>\n<p><a href=\"https://github.com/k0sproject/k0s/issues/665\" rel=\"nofollow noreferrer\">https://github.com/k0sproject/k0s/issues/665</a></p>\n",
                    "OwnerUserId": "2948238",
                    "LastActivityDate": "2021-02-02T13:05:58.487",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "66379717",
                "ParentRepo": "https://github.com/vearch/vearch",
                "StackOverflow_Post": {
                    "Id": "66379717",
                    "PostTypeId": "2",
                    "ParentId": "49529193",
                    "CreationDate": "2021-02-26T03:29:23.813",
                    "Score": "1",
                    "Body": "<p><a href=\"https://github.com/nmslib/nmslib\" rel=\"nofollow noreferrer\">nmslib</a> supports adding new vectors. It's used by OpenSearch as part their <a href=\"https://opensearch.org/blog/odfe-updates/2020/04/Building-k-Nearest-Neighbor-(k-NN)-Similarity-Search-Engine-with-Elasticsearch/\" rel=\"nofollow noreferrer\">Similarity Search Engine</a>, and it's <a href=\"https://pub.towardsai.net/knn-k-nearest-neighbors-is-dead-fc16507eb3e\" rel=\"nofollow noreferrer\">very fast</a>.</p>\n<p>One caveat:</p>\n<blockquote>\n<p>While the HNSW algorithm allows incremental addition of points, it forbids deletion and modification of indexed points.</p>\n</blockquote>\n<p>You can also look into solutions like <a href=\"https://milvus.io/docs/overview.md\" rel=\"nofollow noreferrer\">Milvus</a> or <a href=\"https://github.com/vearch/vearch\" rel=\"nofollow noreferrer\">Vearch</a>.</p>\n",
                    "OwnerUserId": "9762732",
                    "LastEditorUserId": "9762732",
                    "LastEditDate": "2022-09-21T03:21:07.357",
                    "LastActivityDate": "2022-09-21T03:21:07.357",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "66419083",
                "ParentRepo": "https://github.com/kubernetes-sigs/prometheus-adapter",
                "StackOverflow_Post": {
                    "Id": "66419083",
                    "PostTypeId": "2",
                    "ParentId": "66404470",
                    "CreationDate": "2021-03-01T08:51:18.160",
                    "Score": "1",
                    "Body": "<p>If you want to be sure your pod/deployment won't consume more than <code>1.0Gi</code> of memory then setting that <code>MemoryLimit</code> will do job just fine.</p>\n<p>Once you set that limits and your container exceed it it becomes a potential candidate for termination. If it continues to consume memory beyond its limit, the Container will be terminated. If a terminated Container can be restarted, kubelet restarts it, as with any other type of runtime container failure.</p>\n<p>For more readying please visit section <a href=\"https://kubernetes.io/docs/tasks/configure-pod-container/assign-memory-resource/#exceed-a-container-s-memory-limit\" rel=\"nofollow noreferrer\">exceeding a container's memory limit</a></p>\n<p>Moving on if you wish to scale your deployment based on requests you would require to have custom metrics to be provided by external adapter such as <a href=\"https://github.com/kubernetes-sigs/prometheus-adapter\" rel=\"nofollow noreferrer\">prometheus</a>. Horizontal pod autoascaler natively provides you scaling based only on CPU and Memory (based on the metrics from metrics server).</p>\n<p>The adapter documents provides you <a href=\"https://github.com/kubernetes-sigs/prometheus-adapter/blob/master/docs/walkthrough.md\" rel=\"nofollow noreferrer\">walkthrough</a> how to configure it with Kubernetes API and HPA.  The list of other adapters can be found <a href=\"https://github.com/kubernetes/metrics/blob/master/IMPLEMENTATIONS.md\" rel=\"nofollow noreferrer\">here</a>.</p>\n<p>Then you can scale your deployment based on the <code>http_requests</code> metric as showed <a href=\"https://github.com/stefanprodan/k8s-prom-hpa#auto-scaling-based-on-custom-metrics\" rel=\"nofollow noreferrer\">here</a> or <code>request-per-seconds</code> as described <a href=\"https://www.weave.works/blog/kubernetes-horizontal-pod-autoscaler-and-prometheus\" rel=\"nofollow noreferrer\">here</a>.</p>\n",
                    "OwnerUserId": "12186585",
                    "LastActivityDate": "2021-03-01T08:51:18.160",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "66495119",
                "ParentRepo": "https://github.com/flannel-io/flannel/blob/master/Documentation/troubleshooting.md#vagrant",
                "StackOverflow_Post": {
                    "Id": "66495119",
                    "PostTypeId": "2",
                    "ParentId": "66449289",
                    "CreationDate": "2021-03-05T15:18:19.520",
                    "Score": "9",
                    "Body": "<p>The problem was resolved in the comments section but for better visibility I decided to provide an answer.</p>\n<p>As we can see in the <a href=\"https://rancher.com/docs/k3s/latest/en/installation/network-options/#:%7E:text=By%20default%2C%20K3s%20will%20run,VXLAN%20as%20the%20default%20backend.\" rel=\"noreferrer\">K3s documentation</a>, K3s uses flannel as the CNI by default:</p>\n<blockquote>\n<p>By default, K3s will run with flannel as the CNI, using VXLAN as the default backend. To change the CNI, refer to the section on configuring a custom CNI.</p>\n</blockquote>\n<p>By default, flannel selects the first interface on a host (look at the <a href=\"https://github.com/flannel-io/flannel/blob/master/Documentation/troubleshooting.md#vagrant\" rel=\"noreferrer\">flannel documentation</a>), but we can override this behavior with the <a href=\"https://rancher.com/docs/k3s/latest/en/installation/install-options/server-config/#agent-networking\" rel=\"noreferrer\">--flannel-iface</a> flag.<br />\nAdditionally we can explicitly set IP address to advertise for node using the <a href=\"https://rancher.com/docs/k3s/latest/en/installation/install-options/server-config/#agent-networking\" rel=\"noreferrer\">--node-ip</a> flag.</p>\n<hr />\n<p>I've created a simple example to illustrate how it works.</p>\n<p>On my host machine I have two network interfaces (<code>ens4</code> and <code>ens5</code>):</p>\n<pre><code>kmaster:~# ip a s | grep -i &quot;UP\\|inet&quot;\n1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000\n    inet 127.0.0.1/8 scope host lo\n2: ens4: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1460 qdisc pfifo_fast state UP group default qlen 1000\n    inet 10.156.15.197/32 brd 10.156.15.197 scope global dynamic ens4\n3: ens5: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1460 qdisc pfifo_fast state UP group default qlen 1000\n    inet 192.168.0.2/32 brd 192.168.0.2 scope global dynamic ens5\n</code></pre>\n<p>Without setting  the <code>--flannel-iface</code> and <code>--node-ip</code> flags, flannel will select the first interface (<code>ens4: 10.156.15.197</code>):</p>\n<pre><code>kmaster:~# curl -sfL https://get.k3s.io |  sh -\n[INFO]  Finding release for channel stable\n[INFO]  Using v1.20.4+k3s1 as release\n...\n[INFO]  systemd: Starting k3s\nkmaster:~# kubectl get nodes -o wide  \nNAME      STATUS   ROLES                  AGE   VERSION        INTERNAL-IP     \nkmaster   Ready    control-plane,master   97s   v1.20.4+k3s1   10.156.15.197\n</code></pre>\n<p>But as I mentioned before we are able to override default flannel interface with the <code>--flannel-iface</code> flag:</p>\n<pre><code>kmaster:~# curl -sfL https://get.k3s.io | INSTALL_K3S_EXEC=&quot;--node-ip=192.168.0.2 --flannel-iface=ens5&quot; sh -\n[INFO]  Finding release for channel stable\n[INFO]  Using v1.20.4+k3s1 as release\n...\n[INFO]  systemd: Starting k3s\nkmaster:~# kubectl get nodes -o wide\nNAME      STATUS   ROLES                  AGE   VERSION        INTERNAL-IP   \nkmaster   Ready    control-plane,master   64s   v1.20.4+k3s1   192.168.0.2 \n</code></pre>\n",
                    "OwnerUserId": "14801225",
                    "LastActivityDate": "2021-03-05T15:18:19.520",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "66637260",
                "ParentRepo": "https://github.com/gardener/gardener/blob/bf32324d9d1a366d8a0a7514956dc39c2f22f7b7/pkg/apis/core/v1beta1/types_shoot.go#L945",
                "StackOverflow_Post": {
                    "Id": "66637260",
                    "PostTypeId": "1",
                    "CreationDate": "2021-03-15T11:38:09.870",
                    "Score": "3",
                    "ViewCount": "1420",
                    "Body": "<p>We are using <a href=\"https://github.com/kubernetes-sigs/kubebuilder\" rel=\"nofollow noreferrer\">kubebuilder</a> to build our custom controller, the problem is we are not able to parse <strong>raw data</strong> as it comes empty when you apply the file.</p>\n<p>I\u2019ve created very minimal example which describe the issue.</p>\n<p>apiVersion: mygroup.test.com/v1alpha1</p>\n<pre><code>kind: Rawtest\nmetadata:\n  name: rawtest-sample\nspec:\n  system:\n    type: test\n    provider:\n      type: aws\n      infrastructureConfig:\n        kind: InfrastructureConfig\n        apiVersion: v1alpha1\n        networks:\n          vpc:\n            cidr: aaa\n          zones:\n            - name: abc\n              internal: 123\n      workers:\n        - name: myworker\n          machine:\n            type: &quot;mt&quot;\n            image:\n              name: name1\n              version: &quot;2&quot;\n          maximum: 2\n          minimum: 1\n          maxUnavailable: 0\n          volume:\n            type: a1\n            size: 20Gi\n          zones:\n            - zone1\n</code></pre>\n<p>In runtime I was able to get the the <code>spec.system.type</code> value=test and <code>spec.system.provider.type</code> value=&quot;aws&quot;, however I wasn\u2019t able to get all the data under the <code>infrastructureConfig:</code> (line 10)  any idea how can I overcome this ?</p>\n<p>I\u2019ve created this very simple project to demonstrate the issue ,\nSee the api/type folder,  after getting the reconcile object (after apply the config/sample/ file ,you see that the <code>infrastructureconfig</code> and all related data are</p>\n<p><a href=\"https://github.com/JennyMet/\" rel=\"nofollow noreferrer\">https://github.com/JennyMet/</a></p>\n<p>Here is the code which is trying to read the raw value\n<a href=\"https://github.com/JennyMet/kuberaw/blob/master/controllers/rawtest_controller.go#L57\" rel=\"nofollow noreferrer\">https://github.com/JennyMet/kuberaw/blob/master/controllers/rawtest_controller.go#L57</a></p>\n<p><code> &amp;rawtest</code> should contain all the data</p>\n<p>please see the type\n<a href=\"https://github.com/JennyMet/kuberaw/blob/master/api/v1alpha1/rawtest_types.go#L32\" rel=\"nofollow noreferrer\">https://github.com/JennyMet/kuberaw/blob/master/api/v1alpha1/rawtest_types.go#L32</a></p>\n<p><strong>raw type</strong>\n<a href=\"https://github.com/gardener/gardener/blob/bf32324d9d1a366d8a0a7514956dc39c2f22f7b7/pkg/apis/core/v1beta1/types_shoot.go#L945\" rel=\"nofollow noreferrer\">https://github.com/gardener/gardener/blob/bf32324d9d1a366d8a0a7514956dc39c2f22f7b7/pkg/apis/core/v1beta1/types_shoot.go#L945</a></p>\n<p><a href=\"https://github.com/gardener/gardener/blob/bf32324d9d1a366d8a0a7514956dc39c2f22f7b7/pkg/apis/core/types_shoot.go#L774\" rel=\"nofollow noreferrer\">https://github.com/gardener/gardener/blob/bf32324d9d1a366d8a0a7514956dc39c2f22f7b7/pkg/apis/core/types_shoot.go#L774</a></p>\n<p><a href=\"https://github.com/gardener/gardener/blob/bf32324d9d1a366d8a0a7514956dc39c2f22f7b7/vendor/k8s.io/apimachinery/pkg/runtime/types.go#L94:6\" rel=\"nofollow noreferrer\">https://github.com/gardener/gardener/blob/bf32324d9d1a366d8a0a7514956dc39c2f22f7b7/vendor/k8s.io/apimachinery/pkg/runtime/types.go#L94:6</a></p>\n<p>I need a way to make it work in the kubebuilder, as while I apply the file I dont get the values in debug ...</p>\n<p>debug pic</p>\n<p><a href=\"https://i.stack.imgur.com/1lijb.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/1lijb.png\" alt=\"enter image description here\" /></a></p>\n<p>if something is missing please let me know.</p>\n",
                    "OwnerUserId": "10817276",
                    "LastEditorUserId": "10817276",
                    "LastEditDate": "2021-03-24T07:26:20.433",
                    "LastActivityDate": "2021-03-24T07:26:20.433",
                    "Title": "Parse byte array for yaml value - kubebuilder",
                    "Tags": "<json><go><kubernetes><yaml>",
                    "AnswerCount": "1",
                    "CommentCount": "9",
                    "FavoriteCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "66707211",
                "ParentRepo": "https://github.com/k3s-io/k3s/issues/1652",
                "StackOverflow_Post": {
                    "Id": "66707211",
                    "PostTypeId": "1",
                    "CreationDate": "2021-03-19T11:21:51.530",
                    "Score": "2",
                    "ViewCount": "1275",
                    "Body": "<p>I have gone through many blog posts and SO questions as well as k3s documentation and am still coming up short getting the real ip address of clients rather than the internal cluster ip address.</p>\n<p>I have a standard k3s install using Traefik 1.8. As indicated in several github issues, I have set all my services to use Clusterip and I set externalTrafficPolicy: Local for my Traefik and apache services per this: <a href=\"https://github.com/k3s-io/k3s/issues/1652\" rel=\"nofollow noreferrer\">https://github.com/k3s-io/k3s/issues/1652</a></p>\n<p>The strange thing is, it seems that Traefik is passing along any headers like x-forwarded-for because if I manually add an x-forwarded-for with my ip address into my browser request, the result in the apache logs has my ip as well as the internal cluster ip separated by commas.</p>\n<p>Is there something that gets hit before the Traefik instance when traffic comes in to the cluster that should be injecting the ip address?</p>\n",
                    "OwnerUserId": "6202077",
                    "LastActivityDate": "2022-09-13T07:47:35.553",
                    "Title": "How can I get the real ip address of a client when using Traefik on k3s?",
                    "Tags": "<traefik><traefik-ingress><k3s>",
                    "AnswerCount": "2",
                    "CommentCount": "0",
                    "FavoriteCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "66875958",
                "ParentRepo": "https://github.com/kubernetes-sigs/scheduler-plugins/tree/6b7e77af527d8db82afb5060e5474ed524bdc0d6/kep/61-Trimaran-real-load-aware-scheduling",
                "StackOverflow_Post": {
                    "Id": "66875958",
                    "PostTypeId": "2",
                    "ParentId": "66873881",
                    "CreationDate": "2021-03-30T17:45:50.720",
                    "Score": "7",
                    "Body": "<blockquote>\n<p>I put all services in a virtual machine with two cpus, and scale by cpu usage, there are two virtual machine at the busiest time, but most of the time there is only one.</p>\n</blockquote>\n<p>First, if you have any availability requirements, I would recommend to always have at least <strong>two</strong> nodes. If you have only one node and that one crash (e.g. hardware failure or kernel panic) it will take some minutes before this is detected and it will take some minutes before a new node is up.</p>\n<blockquote>\n<p>The inactive service requests cpu is set to 100m because it will not work well if it is less than 100m when it is busy.</p>\n</blockquote>\n<blockquote>\n<p>I think the problem is that although these services require 100m of cpu to work properly, they are mostly idle.</p>\n</blockquote>\n<p>The CPU <em>request</em> is a guaranteed reserved resource amount. Here you reserve too much resources for your almost idling services. Set the CPU request lower, maybe as low as <code>20m</code> or even <code>5m</code>? But since these services will need more resources during busy periods, set a higher <em>limit</em> so that the container can &quot;burst&quot; and also use <a href=\"https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/\" rel=\"nofollow noreferrer\">Horizontal Pod Autoscaler</a> for these. When using the Horizontal Pod Autoscaler more replicas will be created and the traffic will be load balanced across all replicas. Also see <a href=\"https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/\" rel=\"nofollow noreferrer\">Managing Resources for Containers</a>.</p>\n<p>This is also true for your &quot;busy services&quot;, reserve less CPU resources and use Horizontal Pod Autoscaling more actively so that the traffic is spread to more nodes during high load, but can scale down and save cost when the traffic is low.</p>\n<blockquote>\n<p>I really hope that all services can autoscaling, I think this is the benefit of kubernetes, which can help me assign pods more flexibly. Is my idea wrong?</p>\n</blockquote>\n<p>Yes, I agree with you.</p>\n<blockquote>\n<p>Shouldn't I set a request cpu for an inactive service?</p>\n</blockquote>\n<p>It is a good practice to always set some value for <em>request</em> and <em>limit</em>, at least for a production environment. The scheduling and autoscaling will not work well without <em>resource requests</em>.</p>\n<blockquote>\n<p>If I have more active services, even in off-peak hours, the requests cpu will exceed 2000m. Is there any solution?</p>\n</blockquote>\n<p>In general, try to use lower <em>resource requests</em> and use Horizontal Pod Autoscaling more actively. This is true for both your &quot;busy services&quot; and your &quot;inactive services&quot;.</p>\n<blockquote>\n<p>I find that kubernetes more often has more than two nodes.</p>\n</blockquote>\n<p>Yes, there are two aspects of this.</p>\n<p>If you only use two nodes, your environment probably is small and the Kubernetes control plane probably consists of more nodes and is the majority of the cost. For very small environments, Kubernetes may be expensive and it would be more attractive to use e.g. a serverless alternative like <a href=\"https://cloud.google.com/run\" rel=\"nofollow noreferrer\">Google Cloud Run</a></p>\n<p>Second, for availability. It is good to have at least two nodes in case of an abrupt crash e.g. hardware failure or a kernel panic, so that your &quot;service&quot; is still available meanwhile the node autoscaler scales up a new node. This is also true for the number of <em>replicas</em> for a <code>Deployment</code>, if availability is important, use at least two replicas. When you e.g. <a href=\"https://kubernetes.io/docs/concepts/workloads/pods/disruptions/\" rel=\"nofollow noreferrer\">drain a node</a> for maintenance or node upgrade, the pods will be evicted - but not created on a different node first. The control plane will detect that the <code>Deployment</code> (technically ReplicaSet) has less than the desired number of replicas and create a new pod. But when a new Pod is created on a new node, the container image will first be pulled before the Pod is running. To avoid downtime during these events, use at least two replicas for your <code>Deployment</code> and <a href=\"https://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/\" rel=\"nofollow noreferrer\">Pod Topology Spread Constraints</a> to make sure that those two replicas run on different nodes.</p>\n<hr />\n<p>Note: You might run into the same problem as <a href=\"https://stackoverflow.com/questions/66879191/how-to-use-k8s-hpa-and-autoscaler-when-pods-normally-need-low-cpu-but-periodical\">How to use K8S HPA and autoscaler when Pods normally need low CPU but periodically scale</a> and that should be mitigated by an upcoming Kubernetes feature: <a href=\"https://github.com/kubernetes-sigs/scheduler-plugins/tree/6b7e77af527d8db82afb5060e5474ed524bdc0d6/kep/61-Trimaran-real-load-aware-scheduling\" rel=\"nofollow noreferrer\">KEP - Trimaran: Real Load Aware Scheduling</a></p>\n",
                    "OwnerUserId": "213269",
                    "LastEditorUserId": "213269",
                    "LastEditDate": "2021-03-30T23:46:10.590",
                    "LastActivityDate": "2021-03-30T23:46:10.590",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "66892117",
                "ParentRepo": "https://github.com/ori-edge/k8s_gateway",
                "StackOverflow_Post": {
                    "Id": "66892117",
                    "PostTypeId": "2",
                    "ParentId": "55834721",
                    "CreationDate": "2021-03-31T16:58:41.497",
                    "Score": "2",
                    "Body": "<p>coredns will return cluster internal IP addresses that are normally unreachable from outside the cluster. The correct answer is the deleted by MichaelK suggesting to use coredns addon k8s_external <a href=\"https://coredns.io/plugins/k8s_external/\" rel=\"nofollow noreferrer\">https://coredns.io/plugins/k8s_external/</a> .</p>\n<p>k8s_external is already part of coredns. Just edit with\n<code>kubectl -n kube-system edit configmap coredns</code> and add k8s_external after kubernetes directive per docs.</p>\n<pre><code>   kubernetes cluster.local\n   k8s_external example.org\n</code></pre>\n<p>k8s_gateway also handles dns for ingress resources</p>\n<ul>\n<li><a href=\"https://coredns.io/explugins/k8s_gateway/\" rel=\"nofollow noreferrer\">https://coredns.io/explugins/k8s_gateway/</a></li>\n<li><a href=\"https://github.com/ori-edge/k8s_gateway\" rel=\"nofollow noreferrer\">https://github.com/ori-edge/k8s_gateway</a> (includes helm chart)</li>\n</ul>\n<p>You'll also want something like metallb or rancher/klipper-lb handling services with <code>type: LoadBalancer</code> as k8s_gateway won't resolve NodePort services.</p>\n<p>MichaelK is the author of k8s_gateway not sure why his reply is deleted by moderator.</p>\n",
                    "OwnerUserId": "34516",
                    "LastEditorUserId": "34516",
                    "LastEditDate": "2021-04-04T08:01:19.900",
                    "LastActivityDate": "2021-04-04T08:01:19.900",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "66914691",
                "ParentRepo": "https://github.com/oracle/oci-cloud-controller-manager/blob/master/container-storage-interface.md",
                "StackOverflow_Post": {
                    "Id": "66914691",
                    "PostTypeId": "2",
                    "ParentId": "66886661",
                    "CreationDate": "2021-04-02T05:04:19.260",
                    "Score": "2",
                    "Body": "<p>It is not required to deploy <code>oci-block-volume-provisioner</code> and <code>oci-flexvolume-driver</code> to use OCI CSI driver.</p>\n<p>Please refer <a href=\"https://github.com/oracle/oci-cloud-controller-manager/blob/master/container-storage-interface.md\" rel=\"nofollow noreferrer\">https://github.com/oracle/oci-cloud-controller-manager/blob/master/container-storage-interface.md</a> for steps on setting up OCI CSI driver.</p>\n<p>You can also check the fully-managed, scalable, and highly available Container Engine for Kubernetes(OKE) service from OCI which comes pre-installed with the OCI CSI driver &amp; the associated StorageClass at <a href=\"https://www.oracle.com/cloud-native/container-engine-kubernetes/\" rel=\"nofollow noreferrer\">https://www.oracle.com/cloud-native/container-engine-kubernetes/</a> &amp; <a href=\"https://docs.oracle.com/en-us/iaas/Content/ContEng/Concepts/contengoverview.htm\" rel=\"nofollow noreferrer\">https://docs.oracle.com/en-us/iaas/Content/ContEng/Concepts/contengoverview.htm</a>.</p>\n",
                    "OwnerUserId": "5538671",
                    "LastActivityDate": "2021-04-02T05:04:19.260",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "67382305",
                "ParentRepo": "https://github.com/gardener/etcd-backup-restore/issues/2",
                "StackOverflow_Post": {
                    "Id": "67382305",
                    "PostTypeId": "2",
                    "ParentId": "67190040",
                    "CreationDate": "2021-05-04T09:40:47.970",
                    "Score": "0",
                    "Body": "<p>You can backup your Kubernetes cluster by command: <code>etcdctl backup</code>. Here is completely guide, how to use <a href=\"https://etcd.io/docs/v2.3/admin_guide/#disaster-recovery\" rel=\"nofollow noreferrer\">etcdctl backup command</a>.</p>\n<p>Alternatively you can also make a <a href=\"https://kubernetes.io/docs/tasks/administer-cluster/configure-upgrade-etcd/#built-in-snapshot\" rel=\"nofollow noreferrer\">snapshot</a> of your cluster:  <code>etcdctl snapshot save</code>.<br />\nThis command will let you create <strong>incremental backup</strong>.</p>\n<blockquote>\n<p>Incremental backup of etcd, where full snapshot is taken first and then we apply watch and persist the logs accumulated over certain period to snapshot store. Restore process, restores from the full snapshot, start the embedded etcd and apply the logged events one by one.</p>\n</blockquote>\n<p>You can find more about incremental backup function <a href=\"https://github.com/gardener/etcd-backup-restore/issues/2\" rel=\"nofollow noreferrer\">here</a>.</p>\n",
                    "OwnerUserId": "15407542",
                    "LastActivityDate": "2021-05-04T09:40:47.970",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "67531337",
                "ParentRepo": "https://github.com/metalmatze/alertmanager-bot",
                "StackOverflow_Post": {
                    "Id": "67531337",
                    "PostTypeId": "2",
                    "ParentId": "67330560",
                    "CreationDate": "2021-05-14T08:32:14.477",
                    "Score": "1",
                    "Body": "<p>it seems there are a lot of projects to connect telegram, many docker based but none of them is just that easy to setup anyway. Just as an example</p>\n<p><a href=\"https://github.com/metalmatze/alertmanager-bot\" rel=\"nofollow noreferrer\">https://github.com/metalmatze/alertmanager-bot</a></p>\n",
                    "OwnerUserId": "13220079",
                    "LastActivityDate": "2021-05-14T08:32:14.477",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "68065556",
                "ParentRepo": "https://github.com/tikv/client-go",
                "StackOverflow_Post": {
                    "Id": "68065556",
                    "PostTypeId": "2",
                    "ParentId": "68061826",
                    "CreationDate": "2021-06-21T09:29:31.267",
                    "Score": "0",
                    "Body": "<blockquote>\n<ol>\n<li>What's the difference between optimistic and pessimistic in tikv?</li>\n</ol>\n</blockquote>\n<p>TiKV adopts Google\u2019s Percolator transaction model to implement the optimistic transaction model. Clients don't write data until the transaction commits.</p>\n<p>The pessimistic transaction model is built on the optimistic transaction model which can lock keys before committing the transaction to prevent concurrent modifications.</p>\n<blockquote>\n<ol start=\"2\">\n<li>What's the difference between tikv's pessimistic-lock and mysql/tidb's pessimistic-lock?</li>\n</ol>\n</blockquote>\n<p>TiDB follows the protocol of TiKV's pessimistic transaction model to implement the pessimistic-lock. The different between MySQL and TiDB is documented <a href=\"https://docs.pingcap.com/tidb/stable/pessimistic-transaction#behaviors\" rel=\"nofollow noreferrer\">here</a>.</p>\n<p>The <code>kv.Pessimistic</code> option just indicates the transaction is a pessimistic one. Doesn't affect its behavior.</p>\n<p>Pessimistic transaction in <a href=\"https://github.com/tikv/client-go\" rel=\"nofollow noreferrer\">client-go</a> is not an out-of-the-box feature for now(2021.06). It just provides the basic toolkit and users have to follow the undocumented pessimistic transaction protocol to use it which is error-prone. AFAIK, the only user is TiDB, and it's recommended to use the optimistic transaction model instead.</p>\n",
                    "OwnerUserId": "6683249",
                    "LastActivityDate": "2021-06-21T09:29:31.267",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "68117504",
                "ParentRepo": "https://github.com/traefik/traefik-migration-tool",
                "StackOverflow_Post": {
                    "Id": "68117504",
                    "PostTypeId": "2",
                    "ParentId": "68108556",
                    "CreationDate": "2021-06-24T14:16:55.920",
                    "Score": "1",
                    "Body": "<p>Posting this as a community wiki, feel free to edit and expand.</p>\n<p>First from your question about <code>job run</code>, you can see in output that traefik had chart for 1.18.0 version:</p>\n<pre><code>CHART:             https://%{KUBERNETES_API}%/static/charts/traefik-1.81.0.tgz\n</code></pre>\n<p>Related to <code>traefik</code> I found some information in k3s documentation:</p>\n<blockquote>\n<p>If Traefik is not disabled K3s versions 1.20 and earlier will install\nTraefik v1, while K3s versions 1.21 and later will install Traefik v2\nif v1 is not already present.</p>\n<p>To migrate from an older Traefik v1 instance please refer to the\n<a href=\"https://doc.traefik.io/traefik/migration/v1-to-v2/\" rel=\"nofollow noreferrer\">Traefik documentation</a> and <a href=\"https://github.com/traefik/traefik-migration-tool\" rel=\"nofollow noreferrer\">migration tool</a>.</p>\n</blockquote>\n<p><a href=\"https://rancher.com/docs/k3s/latest/en/networking/#traefik-ingress-controller\" rel=\"nofollow noreferrer\">Reference for the above</a></p>\n<p>Based on my research, <a href=\"https://rancher.com/docs/k3s/latest/en/upgrades/basic/\" rel=\"nofollow noreferrer\">upgrading using command line</a> works only for system components of kubernetes as there is no word about addons while for <code>RKE</code> it's clearly stated that addons are updated:</p>\n<blockquote>\n<p>When a cluster is upgraded with rke up, using the default options, the\nfollowing process is used:</p>\n<p>1 - The etcd plane gets get updated, one node at a time.</p>\n<p>2 -Controlplane nodes get updated, one node at a time. This includes the controlplane components and worker plane components of the controlplane nodes.</p>\n<p>3 - Worker plane components of etcd nodes get updated, one node at a time.</p>\n<p>4 - Worker nodes get updated in batches of a configurable size. The\ndefault configuration for the maximum number of unavailable nodes is\nten percent, rounded down to the nearest node, with a minimum batch\nsize of one node.</p>\n<p>5 - <strong>Addons get upgraded one by one</strong>.</p>\n</blockquote>\n<p><a href=\"https://rancher.com/docs/rke/latest/en/upgrades/how-upgrades-work/\" rel=\"nofollow noreferrer\">Reference for RKE</a></p>\n",
                    "OwnerUserId": "15537201",
                    "LastActivityDate": "2021-06-24T14:16:55.920",
                    "CommentCount": "1",
                    "CommunityOwnedDate": "2021-06-24T14:16:55.920",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "68321483",
                "ParentRepo": "https://github.com/pixie-labs/pixie-demos/blob/main/simple-gotracing/app/app.go",
                "StackOverflow_Post": {
                    "Id": "68321483",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "68321542",
                    "CreationDate": "2021-07-09T18:44:22.387",
                    "Score": "2",
                    "ViewCount": "132",
                    "Body": "<p>I'm following <a href=\"https://blog.px.dev/ebpf-function-tracing/post/\" rel=\"nofollow noreferrer\">this article</a> to understand how eBPF tracing works, one of the first steps is to identify the symbol for the function, example code is picked up from here: <a href=\"https://github.com/pixie-labs/pixie-demos/blob/main/simple-gotracing/app/app.go\" rel=\"nofollow noreferrer\">https://github.com/pixie-labs/pixie-demos/blob/main/simple-gotracing/app/app.go</a></p>\n<p>However, after doing the build, I'm unable to find the symbol. <strong>Why is that the case?</strong></p>\n<pre><code>$ ls\ngo.mod  main.go\n$ grep func main.go\nfunc computeE(iterations int64) float64 {\nfunc main() {\n        http.HandleFunc(&quot;/e&quot;, func(w http.ResponseWriter, r *http.Request) {\n$ go build\n$ objdump --syms ./demowebservice | grep compute\n0000000000840a40 g     O .bss   0000000000000008              crypto/elliptic.p256Precomputed\n00000000008704c0 g     O .noptrbss      000000000000000c              crypto/elliptic.precomputeOnce\n$\n</code></pre>\n<p>Go version:-</p>\n<pre><code>$ go version\ngo version go1.16.5 linux/amd64\n</code></pre>\n",
                    "OwnerUserId": "167814",
                    "LastEditorUserId": "167814",
                    "LastEditDate": "2021-07-09T20:36:36.497",
                    "LastActivityDate": "2021-07-09T20:59:02.283",
                    "Title": "No symbol in binary after \"go build\"",
                    "Tags": "<go>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "68400556",
                "ParentRepo": "https://github.com/polycube-network/polycube",
                "StackOverflow_Post": {
                    "Id": "68400556",
                    "PostTypeId": "2",
                    "ParentId": "68399366",
                    "CreationDate": "2021-07-15T20:43:26.077",
                    "Score": "0",
                    "Body": "<p>If you just want to share a BPF map, you can do that in bcc without explicitly pinning the map. In that case, you need to <strong>use <code>BPF_TABLE_SHARED</code> and <code>BPF_TABLE(&quot;extern&quot;</code></strong>. For example (drawn from <a href=\"https://github.com/polycube-network/polycube\" rel=\"nofollow noreferrer\">the BPF project polycube</a>):</p>\n<pre><code># In first program\nBPF_TABLE_SHARED(&quot;lru_hash&quot;, struct st_k, struct st_v, egress_session_table, NAT_MAP_DIM);\n\n# In second program\nBPF_TABLE(&quot;extern&quot;, struct st_k, struct st_v, egress_session_table,\n      NAT_MAP_DIM);\n</code></pre>\n",
                    "OwnerUserId": "6884590",
                    "LastActivityDate": "2021-07-15T20:43:26.077",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "68415643",
                "ParentRepo": "https://github.com/kubernetes-sigs/azurefile-csi-driver/blob/master/docs/driver-parameters.md#dynamic-provision",
                "StackOverflow_Post": {
                    "Id": "68415643",
                    "PostTypeId": "2",
                    "ParentId": "68401308",
                    "CreationDate": "2021-07-16T21:58:15.250",
                    "Score": "0",
                    "Body": "<p>so I actually managed to figure this out using a dynamically allocated Azure file share. I'm writing an internal documentation for this, but I thought I'd post the relevant bit here. I hope this helps people!</p>\n<h3 id=\"dynamically-creating-an-azure-file-share-and-storage-account-by-defining-a-pvc-and-storage-class-jdpl\">Dynamically creating an Azure file share and storage account by defining a PVC and storage class</h3>\n<p>Here, we're mainly following the documentation for <a href=\"https://learn.microsoft.com/en-us/azure/aks/azure-files-dynamic-pv\" rel=\"nofollow noreferrer\">dynamically creating a PV with Azure Files in AKS</a>. The general idea is to create a storage class that will define what kind of Azure file share we want to create (premium vs. standard and the different redundancy modes) and then create a PVC (persistent volume claim) that adheres to that storage class. Consequently, when JupyterHub tries to mount the PVC we created, it will automatically create a PV (persistent volume) for the PVC to bind to, which will then automatically create a storage account and file share for the PV to actually store filese in. This will all be done in the resource group that backs the one we're already using (these generally start with &quot;MC_&quot;). Here, we will be using the premium storage class with zone reduntant storage. First, create the storage class to be used (more info on the available tags here can be found in <a href=\"https://github.com/kubernetes-sigs/azurefile-csi-driver/blob/master/docs/driver-parameters.md#dynamic-provision\" rel=\"nofollow noreferrer\">this repository</a>) with the following YAML</p>\n<pre class=\"lang-yaml prettyprint-override\"><code>kind: StorageClass\napiVersion: storage.k8s.io/v1\nmetadata:\n  name: shared-premium-azurefile\nprovisioner: kubernetes.io/azure-file\nmountOptions:\n  - dir_mode=0777\n  - file_mode=0777\n  - uid=0\n  - gid=0\n  - mfsymlinks\n  - cache=strict\n  - actimeo=30\nparameters:\n  skuName: Premium_ZRS\n</code></pre>\n<p>Name this file <code>azure-file-sc.yaml</code> and run</p>\n<pre class=\"lang-sh prettyprint-override\"><code>kubectl apply -f azure-file-sc.yaml\n</code></pre>\n<p>Next, we will create a PVC which will dynamically provision from our Azure file share (it automatically creates a PV for us). Create the file <code>azure-file-pvc.yaml</code> with the following code</p>\n<pre class=\"lang-yaml prettyprint-override\"><code>apiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: shared-premium-azurefile-pvc\nspec:\n  accessModes:\n    - ReadWriteMany\n  storageClassName: shared-premium-azurefile\n  resources:\n    requests:\n      storage: 100Gi\n</code></pre>\n<p>and apply it with</p>\n<pre class=\"lang-sh prettyprint-override\"><code>kubectl apply -f azure-file-pvc.yaml\n</code></pre>\n<p>This will create the file share and the corresponding PV. We can check that our PVC and storage class were successfully created with</p>\n<pre class=\"lang-sh prettyprint-override\"><code>kubectl get storageclass\nkubectl get pvc\n</code></pre>\n<p>It might take a couple of minutes for the PVC to bind.</p>\n<p>On the Azure side, this is all that has to be done, and the dynamic allocation of the PV and file share are taken care of for us.</p>\n<h3 id=\"mounting-the-pvc-to-jupyterhub-in-the-home-directory-la07\">Mounting the PVC to JupyterHub in the home directory</h3>\n<p>JupyterHub, by default, creates a PVC of 10Gi for each new user, but we can also tell it to mount existing PVCs as external volumes (think of this as just plugging in your computer to a shared USB drive). To mount our previously created PVC in the home folder of all of our JupyterHub users, we simply add the following to our <code>config.py</code> Helm config:</p>\n<pre class=\"lang-yaml prettyprint-override\"><code>singleuser:\n  storage:\n    extraVolumes:\n      - name: azure\n        persistentVolumeClaim:\n          claimName: shared-premium-azurefile-pvc\n    extraVolumeMounts:\n      - name: azure\n        mountPath: /home/jovyan/shared\n</code></pre>\n<p>Now, when JupyterHub starts up, all users should have a shared directory in their home folders with read and write permission.</p>\n",
                    "OwnerUserId": "4642763",
                    "LastActivityDate": "2021-07-16T21:58:15.250",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "68765508",
                "ParentRepo": "https://github.com/tilt-dev/tilt",
                "StackOverflow_Post": {
                    "Id": "68765508",
                    "PostTypeId": "2",
                    "ParentId": "31881904",
                    "CreationDate": "2021-08-13T00:23:30.647",
                    "Score": "3",
                    "Body": "<p>I got frustrated enough that I made a small NodeJS utility to help with this: <a href=\"https://github.com/Venryx/file-syncer\" rel=\"nofollow noreferrer\">file-syncer</a></p>\n<p>Given the existing directory structure:</p>\n<pre><code>parent_dir\n    - common_files\n        - file.txt\n    - my-app\n        - Dockerfile\n        - common_files -&gt; symlink to ../common_files\n</code></pre>\n<p>Basic usage:</p>\n<pre><code>cd parent_dir\n\n// starts live-sync of files under &quot;common_files&quot; to &quot;my-app/HardLinked/common_files&quot;\nnpx file-syncer --from common_files --to my-app/HardLinked\n</code></pre>\n<p>Then in your <code>Dockerfile</code>:</p>\n<pre><code>[regular commands here...]\n\n# have docker copy/overlay the HardLinked folder's contents (common_files) into my-app itself\nCOPY HardLinked /\n</code></pre>\n<p><strong>Q/A</strong></p>\n<ul>\n<li>How is this better than just copying <code>parent_dir/common_files</code> to <code>parent_dir/my-app/common_files</code> before Docker runs?</li>\n</ul>\n<blockquote>\n<p>That would mean giving up the regular symlink, which would be a loss, since symlinks are helpful and work fine with most tools. For example, it would mean you can't see/edit the source files of <code>common_files</code> from the in-my-app copy, which has some drawbacks. (see below)</p>\n</blockquote>\n<ul>\n<li>How is this better than copying <code>parent_dir/common-files</code> to <code>parent_dir/my-app/common_files_Copy</code> before Docker runs, then having Docker copy that over to <code>parent_dir/my-app/common_files</code> at build time?</li>\n</ul>\n<blockquote>\n<p>There are two advantages:</p>\n<ol>\n<li><code>file-syncer</code> does not &quot;copy&quot; the files in the regular sense. Rather, it creates <a href=\"https://www.geeksforgeeks.org/soft-hard-links-unixlinux\" rel=\"nofollow noreferrer\">hard links</a> from the source folder's files. This means that if you edit the files under <code>parent_dir/my-app/HardLinked/common_files</code>, the files under <code>parent_dir/common_files</code> are instantly updated, and vice-versa, because they reference the same file/inode. (this can be helpful for debugging purposes and cross-project editing [especially if the folders you are syncing are symlinked node-modules that you're actively editing], and ensures that your version of the files is always in-sync/identical-to the source files)</li>\n<li>Because <code>file-syncer</code> only updates the hard-link files for the exact files that get changed, file-watcher tools like <a href=\"https://github.com/tilt-dev/tilt\" rel=\"nofollow noreferrer\">Tilt</a> or <a href=\"https://github.com/GoogleContainerTools/skaffold\" rel=\"nofollow noreferrer\">Skaffold</a> detect changes for the minimal set of files, which can mean faster live-update-push times than you'd get with a basic &quot;copy whole folder on file change&quot; tool would.</li>\n</ol>\n</blockquote>\n<ul>\n<li>How is this better than a regular file-sync tool like Syncthing?</li>\n</ul>\n<blockquote>\n<p>Some of those tools may be usable, but most have issues of one kind or another. The most common one is that the tool either cannot produce hard-links of existing files, or it's unable to &quot;push an update&quot; for a file that is already hard-linked (since hard-linked files do not notify file-watchers of their changes automatically, if the edited-at and watched-at paths differ). Another is that many of these sync tools are not designed for instant responding, and/or do not have run flags that make them easy to use in restricted build tools. (eg. for Tilt, the <code>--async</code> flag of <code>file-syncer</code> enables it to be used in a <code>local(...)</code> invokation in the project's <code>Tiltfile</code>)</p>\n</blockquote>\n",
                    "OwnerUserId": "2441655",
                    "LastEditorUserId": "2441655",
                    "LastEditDate": "2021-08-13T18:55:52.203",
                    "LastActivityDate": "2021-08-13T18:55:52.203",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "69097530",
                "ParentRepo": "https://github.com/v6d-io/v6d",
                "StackOverflow_Post": {
                    "Id": "69097530",
                    "PostTypeId": "2",
                    "ParentId": "50671270",
                    "CreationDate": "2021-09-08T05:42:30.240",
                    "Score": "4",
                    "Body": "<p>For people who still stuck on this issue, we have recently implemented a custom XCom backend for airflow, backed by <a href=\"https://github.com/v6d-io/v6d\" rel=\"nofollow noreferrer\">vineyard</a>, to support such kind of cases.</p>\n<p>The provider is opensource there: <a href=\"https://github.com/v6d-io/v6d/tree/main/python/vineyard/contrib/airflow\" rel=\"nofollow noreferrer\">https://github.com/v6d-io/v6d/tree/main/python/vineyard/contrib/airflow</a></p>\n<p>With the Vineyard XCom backend, users could have dag that produces and consumes <code>pandas.DataFrame</code> directly, without any &quot;to_csv&quot; + &quot;from_csv&quot; hacks,</p>\n<pre class=\"lang-py prettyprint-override\"><code>import numpy as np\nimport pandas as pd\n\nfrom airflow.decorators import dag, task\nfrom airflow.utils.dates import days_ago\n\ndefault_args = {\n    'owner': 'airflow',\n}\n\n@dag(default_args=default_args, schedule_interval=None, start_date=days_ago(2), tags=['example'])\ndef taskflow_etl_pandas():\n    @task()\n    def extract():\n        order_data_dict = pd.DataFrame({\n            'a': np.random.rand(100000),\n            'b': np.random.rand(100000),\n        })\n        return order_data_dict\n\n    @task(multiple_outputs=True)\n    def transform(order_data_dict: dict):\n        return {&quot;total_order_value&quot;: order_data_dict[&quot;a&quot;].sum()}\n\n    @task()\n    def load(total_order_value: float):\n        print(f&quot;Total order value is: {total_order_value:.2f}&quot;)\n\n    order_data = extract()\n    order_summary = transform(order_data)\n    load(order_summary[&quot;total_order_value&quot;])\n\ntaskflow_etl_pandas_dag = taskflow_etl_pandas()\n</code></pre>\n<p>Hope that helps in your cases.</p>\n",
                    "OwnerUserId": "5080177",
                    "LastActivityDate": "2021-09-08T05:42:30.240",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "69209560",
                "ParentRepo": "https://github.com/kubernetes-csi/external-provisioner/blob/master/deploy/kubernetes/rbac.yaml",
                "StackOverflow_Post": {
                    "Id": "69209560",
                    "PostTypeId": "2",
                    "ParentId": "69209307",
                    "CreationDate": "2021-09-16T13:42:53.273",
                    "Score": "1",
                    "Body": "<p>The answer is yes, you do need to supply the <code>ClusterRole</code></p>\n<h3>Here is an example of whats need to be done</h3>\n<ul>\n<li>Follow those objects to have a full understanding of the required resources\n<a href=\"https://github.com/kubernetes-csi/external-provisioner/blob/master/deploy/kubernetes/rbac.yaml\" rel=\"nofollow noreferrer\">https://github.com/kubernetes-csi/external-provisioner/blob/master/deploy/kubernetes/rbac.yaml</a></li>\n</ul>\n",
                    "OwnerUserId": "1755598",
                    "LastActivityDate": "2021-09-16T13:42:53.273",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "69366871",
                "ParentRepo": "https://github.com/bridgecrewio/yor",
                "StackOverflow_Post": {
                    "Id": "69366871",
                    "PostTypeId": "2",
                    "ParentId": "67784819",
                    "CreationDate": "2021-09-28T18:32:01.330",
                    "Score": "1",
                    "Body": "<p>I think you might benefit from using something like <a href=\"https://github.com/bridgecrewio/yor\" rel=\"nofollow noreferrer\">yor</a> from <a href=\"https://bridgecrew.io/\" rel=\"nofollow noreferrer\">Bridge Crew</a>.</p>\n<p>From the project's README:</p>\n<blockquote>\n<p>Yor is an open-source tool that helps add informative and consistent tags across infrastructure-as-code frameworks such as Terraform, CloudFormation, and Serverless.</p>\n<p>Yor is built to run as a GitHub Action automatically adding consistent tagging logics to your IaC. Yor can also run as a pre-commit hook and a standalone CLI.</p>\n</blockquote>\n<p>So basically, it updates your resources tags with things like:</p>\n<pre><code>   tags   = {\n      env                  = var.env\n      yor_trace            = &quot;912066a1-31a3-4a08-911b-0b06d9eac64e&quot;\n      git_repo             = &quot;example&quot;\n      git_org              = &quot;bridgecrewio&quot;\n      git_file             = &quot;applyTag.md&quot;\n      git_commit           = &quot;COMMITHASH&quot;\n      git_modifiers        = &quot;bana/gandalf&quot;\n      git_last_modified_at = &quot;2021-01-08 00:00:00&quot;\n      git_last_modified_by = &quot;bana@bridgecrew.io&quot;\n   }\n</code></pre>\n<p>Maybe that would be good enough to provide what you're trying to do?</p>\n<p>As far as my testimony, I have not used <code>yor</code> since my tagging uses a different approach.  Instead of having &quot;raw&quot; tags, we use a label module that builds the tags for us and then merges in local tags.</p>\n<p>Just sharing this info FYI in case it helps.</p>\n",
                    "OwnerUserId": "2308522",
                    "LastEditorUserId": "2308522",
                    "LastEditDate": "2021-11-19T19:08:54.497",
                    "LastActivityDate": "2021-11-19T19:08:54.497",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "69601897",
                "ParentRepo": "https://github.com/topfreegames/libpitaya-cluster/blob/99152fd062591a4f8abdf93d3022462fdb47e9a0/cpp-lib/Makefile#L36",
                "StackOverflow_Post": {
                    "Id": "69601897",
                    "PostTypeId": "2",
                    "ParentId": "68698750",
                    "CreationDate": "2021-10-17T06:38:27.453",
                    "Score": "0",
                    "Body": "<p><code>-H</code> is indeed the flag for displaying the help docs, as @<a href=\"https://stackoverflow.com/users/2137996/alex-reinking\">Alex Reinking</a>, but there is another undocumented meaning.</p>\n<p>While looking for good resources for learning CMake, I stumbled across <a href=\"https://cgold.readthedocs.io/en/latest/\" rel=\"nofollow noreferrer\">CGold</a>, which <a href=\"https://cgold.readthedocs.io/en/latest/glossary/-H.html\" rel=\"nofollow noreferrer\">also mentions the <code>-H</code> flag as a way to supply the path to the source</a>.</p>\n<blockquote>\n<p>Add <code>-H&lt;path-to-source-tree&gt;</code> to set directory with <code>CMakeLists.txt</code>. This internal option is not documented but <a href=\"https://cgold.readthedocs.io/en/latest/glossary/-H.html\" rel=\"nofollow noreferrer\">widely used by community</a>. There must be no spaces between <code>-H</code> and <code>&lt;path-to-source-tree&gt;</code> (otherwise option will be interpreted as synonym to <code>--help</code>). Always must be used with <code>-B</code> option.</p>\n</blockquote>\n<p>Here are <a href=\"https://github.com/topfreegames/libpitaya-cluster/blob/99152fd062591a4f8abdf93d3022462fdb47e9a0/cpp-lib/Makefile#L36\" rel=\"nofollow noreferrer\">some</a> <a href=\"https://github.com/MoDeNa-EUProject/MoDeNa/blob/ba08ebbfed25bec742316dcd665c0b9941658232/applications/PUfoam/foamExpansion/build#L7\" rel=\"nofollow noreferrer\">specific</a> <a href=\"https://github.com/NLESC-JCER/EigenCuda/blob/be5935f9c0010f666d925e426f013480d3c876cc/README.md?plain=1#L12\" rel=\"nofollow noreferrer\">pointers</a> to projects which use (or recommend using) the <code>-H</code> flag to point to the source directory.</p>\n<p>In fact, as CGold suggests, there was a patch submitted a long time ago which aimed to <a href=\"https://www.mail-archive.com/cmake-developers@cmake.org/msg16693.html\" rel=\"nofollow noreferrer\">actually document the internal <code>-H</code> flag</a>.</p>\n<p>However, it should be noted that one of the developers replied with</p>\n<blockquote>\n<p>These are undocumented because they are internal options that\nare not meant for public use.</p>\n</blockquote>\n<p>So, we should <em>not</em> use those flags, and stick to the functionally equivalent (as pointed out by @Alex Reinking) <code>-S</code> flag if we need to pass in the source directory.</p>\n",
                    "OwnerUserId": "12591388",
                    "LastActivityDate": "2021-10-17T06:38:27.453",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "69644718",
                "ParentRepo": "https://github.com/linode/linode-cloud-controller-manager",
                "StackOverflow_Post": {
                    "Id": "69644718",
                    "PostTypeId": "1",
                    "CreationDate": "2021-10-20T10:55:30.803",
                    "Score": "3",
                    "ViewCount": "189",
                    "Body": "<p>I have created a server named <a href=\"https://github.com/CyBear-Jinni/cbj_remote-pipes\" rel=\"nofollow noreferrer\">Remote Pipes</a> that get clients connections with streams and transfer data between them.</p>\n<p>On one side there is a computer Hub and on the other side there are a number of App clients.</p>\n<p>The Hub client connects to the Remote Pipes and a two-way stream remains open.</p>\n<p>All the Apps clients connect to the Remote Pipes and a <a href=\"https://github.com/CyBear-Jinni/cbj_remote-pipes/blob/main/lib/domain/hube_server/smart_server_u.dart\" rel=\"nofollow noreferrer\">two-way stream remains open</a>.</p>\n<p>Whenever the Hub wants to send data for the Apps clients he sends it to the Remote Pipes, and the Remote pipes send each connected App client the data through (already opened) opened stream.</p>\n<p>Whenever one of the app clients wants to send data for the Hub he sends it to the Remote Pipes which combines all streams from the Apps and sends them through a single (already opened) stream to the Hub.</p>\n<p><a href=\"https://i.stack.imgur.com/fbpjym.jpg\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/fbpjym.jpg\" alt=\"enter image description here\" /></a></p>\n<p>Remote Pipes do not store data nor use local storage nor use local DB and each instance is intended for one family.</p>\n<p>So I want to create a Kubernetes pod with Remote Pipes for each family and all family members need to connect to the same pod.</p>\n<p>No need for a persistent pod, if one pod gets deleted (in case there are no connections) a new one is ok as long as all the family members Apps clients and the Hub client connect to the same pod.</p>\n<p><strong>The Question:</strong></p>\n<p>Searching for a way to make <strong>multiple users connect to the same kubernetes pod</strong> (like game/zoom lobbies?) and I am not sure what is the best option.</p>\n<p>The routing must be created <strong>dynamically and be scalable</strong> so routing based on ports and Name-based routing are not a good fit.</p>\n<p>Here are a number of terms that I found that may be related</p>\n<ol>\n<li>Stateful application</li>\n<li>Headless services</li>\n<li>Auto-labeling</li>\n<li><a href=\"https://github.com/linode/linode-cloud-controller-manager\" rel=\"nofollow noreferrer\">kube-proxy</a></li>\n<li>Host based routing</li>\n<li>Path based routing</li>\n<li>Header based routing</li>\n<li>Software/Application Load balancer</li>\n</ol>\n<p>I am using Linode so using Linode NodeBalancers is preferable if load balancer is required.</p>\n",
                    "OwnerUserId": "10242854",
                    "LastEditorUserId": "10242854",
                    "LastEditDate": "2021-10-20T11:17:45.867",
                    "LastActivityDate": "2021-10-20T11:20:15.160",
                    "Title": "Connect multiple users to the same kubernetes pod",
                    "Tags": "<kubernetes><stream><devops><kubernetes-pod><linode>",
                    "AnswerCount": "1",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "69766550",
                "ParentRepo": "https://github.com/crossplane-contrib/provider-helm/blob/master/examples/in-composition/composition.yaml#L147",
                "StackOverflow_Post": {
                    "Id": "69766550",
                    "PostTypeId": "2",
                    "ParentId": "69764792",
                    "CreationDate": "2021-10-29T09:28:15.917",
                    "Score": "4",
                    "Body": "<p>As you've noticed, <code>ProviderConfig</code> with <code>InjectedIdentity</code> is for the case where <code>provider-helm</code> installs the helm release into the same cluster.</p>\n<p>To deploy to other clusters, provider-helm needs a <code>kubeconfig</code> file of the remote cluster which needs to be provided as a Kubernetes secret and referenced from <code>ProviderConfig</code>. So, as long as you've provided a <strong>proper</strong> <code>kubeconfig</code> to an external cluster that is <strong>accessible</strong> from your Crossplane cluster (a.k.a. control plane), provider-helm should be able to deploy the release to the remote cluster.</p>\n<p>So, it looks like you're on the right track regarding configuring provider-helm, and since you observed something getting deployed to the external cluster, you provided a valid <code>kubeconfig</code>, and provider-helm could access and authenticate to the cluster.</p>\n<p><em>The last error you're getting sounds like some incompatibility between your cluster and release</em>, e.g. the external cluster only allows pods with <code>gvisor</code> and the application that you want to install with provider helm does not have some labels accordingly.</p>\n<p>As a troubleshooting step, you might try installing that helm chart with exactly same configuration to the external cluster via helm cli, using the same kubeconfig you built.</p>\n<p>Regarding the inconvenience of building the Kubeconfig you mentioned, provider-helm needs a way to access to that external Kubernetes cluster, and since <code>kubeconfig</code> is the most common way for this purpose. However, if you see another alternative that makes things easier for some common use cases, this could be implemented and it would be great if you could create a feature request in the repo for this.</p>\n<p>Finally, I am wondering how you're creating those external clusters. If it makes sense to create them with Crossplane as well, e.g. if GKE with provider-gcp, then, you can <a href=\"https://crossplane.io/docs/v1.4/concepts/terminology.html#composition\" rel=\"nofollow noreferrer\">compose</a> a helm <code>ProviderConfig</code> together with a GKE Cluster resource which would just create the appropriate secret and <code>ProviderConfig</code> when you create a new cluster, you can check this as an example: <a href=\"https://github.com/crossplane-contrib/provider-helm/blob/master/examples/in-composition/composition.yaml#L147\" rel=\"nofollow noreferrer\">https://github.com/crossplane-contrib/provider-helm/blob/master/examples/in-composition/composition.yaml#L147</a></p>\n",
                    "OwnerUserId": "4124416",
                    "LastActivityDate": "2021-10-29T09:28:15.917",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "70013062",
                "ParentRepo": "https://github.com/volterraedge/terraform-provider-volterra/blob/main/volterra/resource_auto_volterra_http_loadbalancer.go#L3501",
                "StackOverflow_Post": {
                    "Id": "70013062",
                    "PostTypeId": "1",
                    "CreationDate": "2021-11-18T00:07:27.973",
                    "Score": "1",
                    "ViewCount": "219",
                    "Body": "<p>I have a custom terraform provider with a resource that takes a list as one of its inputs.</p>\n<p>Here is the list in question: <a href=\"https://github.com/volterraedge/terraform-provider-volterra/blob/main/volterra/resource_auto_volterra_http_loadbalancer.go#L3501\" rel=\"nofollow noreferrer\">https://github.com/volterraedge/terraform-provider-volterra/blob/main/volterra/resource_auto_volterra_http_loadbalancer.go#L3501</a></p>\n<p>When I declare the list, it needs to be set as multiple blocks like the following:</p>\n<pre><code>  active_service_policies {\n    policies {\n      name      = &quot;foobar&quot;\n      namespace = &quot;shared&quot;\n    }\n    policies {\n      name      = &quot;batz&quot;\n      namespace = &quot;shared&quot;\n    }\n  }\n</code></pre>\n<p>Instead, I want to be able to declare it like the following:</p>\n<pre><code>  active_service_policies {\n    policies = [\n    {\n      name      = &quot;foobar&quot;\n      namespace = &quot;shared&quot;\n    },\n    {\n      name      = &quot;batz&quot;\n      namespace = &quot;shared&quot;\n    }\n    ]\n  }\n</code></pre>\n<p>This causes the following error:</p>\n<pre><code>Error: Unsupported argument\n  on main.tf line 79, in resource &quot;volterra_http_loadbalancer&quot; &quot;sp&quot;:\n  79:     policies = [\nAn argument named &quot;policies&quot; is not expected here. Did you mean to define a block\nof type &quot;policies&quot;?\n</code></pre>\n<p>Why cant I use an ordered list and how can I allow its use?</p>\n<p>Is this issue becaue the <code>policies</code> is a <code>Type: schema.TypeList,</code> should this be a <code>TypeSet</code> or some other object instead?</p>\n",
                    "OwnerUserId": "5314903",
                    "LastEditorUserId": "5314903",
                    "LastEditDate": "2021-11-18T15:34:58.740",
                    "LastActivityDate": "2021-11-18T16:51:24.177",
                    "Title": "How to allow an ordered list in a custom terraform provider resource?",
                    "Tags": "<terraform><hcl><terraform-provider>",
                    "AnswerCount": "1",
                    "CommentCount": "3",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "70113511",
                "ParentRepo": "https://github.com/oom-ai/oomstore/tree/e527df579e0381b4852a136a96e3a1516cfddf45/sdk/python",
                "StackOverflow_Post": {
                    "Id": "70113511",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "70115953",
                    "CreationDate": "2021-11-25T15:14:27.323",
                    "Score": "1",
                    "ViewCount": "89",
                    "Body": "<p>I want to package <a href=\"https://github.com/oom-ai/oomstore/tree/e527df579e0381b4852a136a96e3a1516cfddf45/sdk/python\" rel=\"nofollow noreferrer\">my python code</a> and upload it to PyPI so that people can use it easily. I followed the <a href=\"https://packaging.python.org/tutorials/packaging-projects/#\" rel=\"nofollow noreferrer\">documentation</a> for packaging python projects and eventually uploaded it to the <a href=\"https://test.pypi.org/project/oomstore/\" rel=\"nofollow noreferrer\">PyPI test website</a>. I ran pip install to try and install it.</p>\n<p>Strangely enough, after installing it, I couldn't find the package:</p>\n<pre><code>(base) \u279c  ~ python3 -m pip install --index-url https://test.pypi.org/simple/  oomstore==0.0.4\nLooking in indexes: https://test.pypi.org/simple/\nCollecting oomstore==0.0.4\n  Downloading https://test-files.pythonhosted.org/packages/4f/a5/4e7089a1ecb36a59f7f0852a5f96a6054daf886d97132060a7efcda5f04f/oomstore-0.0.4-py3-none-any.whl (12 kB)\nInstalling collected packages: oomstore\nSuccessfully installed oomstore-0.0.4\n(base) \u279c  ~ python3\nPython 3.8.5 (default, Sep  4 2020, 02:22:02)\n[Clang 10.0.0 ] :: Anaconda, Inc. on darwin\nType &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.\n&gt;&gt;&gt; import oomstore\nTraceback (most recent call last):\n  File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;\nModuleNotFoundError: No module named 'oomstore'\n&gt;&gt;&gt;\n</code></pre>\n<p>I went to the installation path of the package and found no python files in it:</p>\n<pre><code>(base) \u279c  ~ cd ~/miniconda3/lib/python3.8/site-packages/oomstore-0.0.4.dist-info\n(base) \u279c  oomstore-0.0.4.dist-info ls\nINSTALLER     LICENSE       METADATA      RECORD        REQUESTED     WHEEL         top_level.txt\n(base) \u279c  oomstore-0.0.4.dist-info\n\n</code></pre>\n<p>Did I do something wrong? Is there something wrong with my setup.cfg file? Forgive me for asking such an ignorant question, I'm new to python...</p>\n",
                    "OwnerUserId": "16428442",
                    "LastEditorUserId": "1032785",
                    "LastEditDate": "2021-11-25T15:23:14.637",
                    "LastActivityDate": "2021-11-25T18:42:04.273",
                    "Title": "packaging python projects failed",
                    "Tags": "<python><python-3.x><setuptools><setup.py><miniconda>",
                    "AnswerCount": "1",
                    "CommentCount": "4",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "70241951",
                "ParentRepo": "https://github.com/google/trillian",
                "StackOverflow_Post": {
                    "Id": "70241951",
                    "PostTypeId": "2",
                    "ParentId": "70240909",
                    "CreationDate": "2021-12-06T07:14:19.107",
                    "Score": "2",
                    "Body": "<p>You might consider a library like <a href=\"https://github.com/google/trillian\" rel=\"nofollow noreferrer\"><code>google/trillian</code></a>, which does include a <a href=\"https://github.com/google/trillian/blob/57e4a52d22ef65805363b8e6bea4089a72003c62/crypto/keys/testonly/keys.go#L36-L50\" rel=\"nofollow noreferrer\"><code>MustMarshalPublicPEMToDER(keyPEM string) []byte</code></a> function.</p>\n<pre class=\"lang-golang prettyprint-override\"><code>// MustMarshalPublicPEMToDER reads a PEM-encoded public key and returns it in DER encoding.\n// If an error occurs, it panics.\nfunc MustMarshalPublicPEMToDER(keyPEM string) []byte {\n    block, _ := pem.Decode([]byte(keyPEM))\n    key, err := x509.ParsePKIXPublicKey(block.Bytes)\n    if err != nil {\n        panic(err)\n    }\n\n    keyDER, err := x509.MarshalPKIXPublicKey(key)\n    if err != nil {\n        panic(err)\n    }\n    return keyDER\n}\n</code></pre>\n<p>As the comment of this function shows, this reads a PEM-encoded public key.</p>\n<p>As noted by <a href=\"https://stackoverflow.com/users/9014097/topaco\">Topaco</a>, you would need <a href=\"https://pkg.go.dev/crypto/x509#ParsePKCS8PrivateKey\" rel=\"nofollow noreferrer\"><code>crypto/x509#ParsePKCS8PrivateKey</code></a> in order to read a private PKCS#8 PEM encoded key.<br />\nThe marshal part does not change.</p>\n",
                    "OwnerUserId": "6309",
                    "LastEditorUserId": "6309",
                    "LastEditDate": "2021-12-06T08:56:40.193",
                    "LastActivityDate": "2021-12-06T08:56:40.193",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "70402489",
                "ParentRepo": "https://github.com/senthilrch/kube-fledged",
                "StackOverflow_Post": {
                    "Id": "70402489",
                    "PostTypeId": "2",
                    "ParentId": "70402209",
                    "CreationDate": "2021-12-18T10:06:18.907",
                    "Score": "0",
                    "Body": "<p>Via <a href=\"https://www.reddit.com/r/kubernetes/comments/oeruh9/can_kubernetes_prepull_and_cache_images/\" rel=\"nofollow noreferrer\">https://www.reddit.com/r/kubernetes/comments/oeruh9/can_kubernetes_prepull_and_cache_images/</a>, I've found these ideas:</p>\n<ul>\n<li>Implement a DaemonSet that runs a &quot;sleep&quot; loop on all the images I need.</li>\n<li>Use <a href=\"http://github.com/mattmoor/warm-image\" rel=\"nofollow noreferrer\">http://github.com/mattmoor/warm-image</a>, which has no Windows support.</li>\n<li>Use <a href=\"https://github.com/ContainerSolutions/ImageWolf\" rel=\"nofollow noreferrer\">https://github.com/ContainerSolutions/ImageWolf</a>, which says, &quot;ImageWolf is currently alpha software and intended as a PoC - please don't run it in production!&quot;</li>\n<li>Use <a href=\"https://github.com/uber/kraken\" rel=\"nofollow noreferrer\">https://github.com/uber/kraken</a>, which seems to be a registry, not a pre-pulling solution.</li>\n<li>Use <a href=\"https://github.com/dragonflyoss/Dragonfly\" rel=\"nofollow noreferrer\">https://github.com/dragonflyoss/Dragonfly</a> (now <a href=\"https://github.com/dragonflyoss/Dragonfly2\" rel=\"nofollow noreferrer\">https://github.com/dragonflyoss/Dragonfly2</a>), which also seems to do somethings completely different.</li>\n<li>Use <a href=\"https://github.com/senthilrch/kube-fledged\" rel=\"nofollow noreferrer\">https://github.com/senthilrch/kube-fledged</a>, which looks exactly right and more mature than the others, but <a href=\"https://github.com/senthilrch/kube-fledged/issues/118\" rel=\"nofollow noreferrer\">has no Windows support</a>.</li>\n<li>Use <a href=\"https://github.com/dcherman/image-cache-daemon\" rel=\"nofollow noreferrer\">https://github.com/dcherman/image-cache-daemon</a>, which <a href=\"https://hub.docker.com/r/exiges/image-cache-daemon/tags\" rel=\"nofollow noreferrer\">has no Windows support</a>.</li>\n<li>Use <a href=\"https://goharbor.io/blog/harbor-2.1/\" rel=\"nofollow noreferrer\">https://goharbor.io/blog/harbor-2.1/</a>, which also seems to be a registry, not a pre-pulling solution.</li>\n<li>Use <a href=\"https://openkruise.io/docs/user-manuals/imagepulljob/\" rel=\"nofollow noreferrer\">https://openkruise.io/docs/user-manuals/imagepulljob/</a>, which also looks right, but a) OpenKruise is huge and I'm not sure I want to install this just to preload images, and b) it seems <a href=\"https://hub.docker.com/r/openkruise/kruise-manager/tags\" rel=\"nofollow noreferrer\">it has no Windows support</a>.</li>\n</ul>\n<p>So, it seems I have to implement this on my own, with a DaemonSet. I still hope someone can provide a better answer than this one  .</p>\n",
                    "OwnerUserId": "62838",
                    "LastActivityDate": "2021-12-18T10:06:18.907",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "70457866",
                "ParentRepo": "https://github.com/knadh/koanf/",
                "StackOverflow_Post": {
                    "Id": "70457866",
                    "PostTypeId": "2",
                    "ParentId": "63696952",
                    "CreationDate": "2021-12-23T05:06:32.827",
                    "Score": "0",
                    "Body": "<p>Viper &amp; HCL don't integrate and play well, like the example you aleady have</p>\n<p>You can use <a href=\"https://github.com/knadh/koanf/\" rel=\"nofollow noreferrer\">koanf</a> as alternative to overcome above issue</p>\n<p>see this example.</p>\n<pre><code>package main\nimport (\n  &quot;fmt&quot;\n  &quot;github.com/knadh/koanf&quot;\n  &quot;github.com/knadh/koanf/parsers/hcl&quot;\n  &quot;github.com/knadh/koanf/providers/file&quot;\n)\n\nvar Conf = koanf.New(&quot;.&quot;)\n\nfunc main() {\n   Conf.Load(file.Provider(&quot;/etc/app/config.hcl&quot;),hcl.Parser(true))\n\n   fmt.Println(&quot;host.address =&quot;, Conf.Get(&quot;host.address&quot;))\n   fmt.Println(&quot;host.port =&quot;, Conf.Get(&quot;host.port&quot;))\n  \n}\n</code></pre>\n",
                    "OwnerUserId": "1435800",
                    "LastEditorUserId": "1435800",
                    "LastEditDate": "2021-12-31T06:05:40.377",
                    "LastActivityDate": "2021-12-31T06:05:40.377",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "70614373",
                "ParentRepo": "https://github.com/cert-manager/webhook-example/tree/master/deploy/example-webhook",
                "StackOverflow_Post": {
                    "Id": "70614373",
                    "PostTypeId": "1",
                    "CreationDate": "2022-01-06T22:25:59.447",
                    "Score": "3",
                    "ViewCount": "694",
                    "Body": "<p>I am trying to deploy <a href=\"https://github.com/cert-manager/webhook-example/tree/master/deploy/example-webhook\" rel=\"nofollow noreferrer\">cert-manager/webhook-example</a> using helm chart.</p>\n<p>But getting following error.</p>\n<pre><code>% helm install cert-manager-webhook ./cert-manager-webhook\nError: INSTALLATION FAILED: Internal error occurred: failed calling webhook &quot;webhook.cert-manager.io&quot;: Post &quot;https://cert-manager-webhook.cert-manager.svc:443/mutate?timeout=10s&quot;: service &quot;cert-manager-webhook&quot; not found\n</code></pre>\n<p>What I am missing here ?</p>\n",
                    "OwnerUserId": "3579198",
                    "LastEditorUserId": "3579198",
                    "LastEditDate": "2022-01-06T22:46:38.927",
                    "LastActivityDate": "2022-10-05T06:51:54.923",
                    "Title": "helm chart failing with service \"cert-manager-webhook\" not found",
                    "Tags": "<kubernetes-helm><cert-manager>",
                    "AnswerCount": "0",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "70618706",
                "ParentRepo": "https://github.com/ConsenSys/quorum/blob/master/core/state/snapshot/snapshot.go",
                "StackOverflow_Post": {
                    "Id": "70618706",
                    "PostTypeId": "1",
                    "CreationDate": "2022-01-07T08:48:25.520",
                    "Score": "0",
                    "ViewCount": "90",
                    "Body": "<p>Im new in Go-EVM, and some time ago I got a source code to get transaction tracking. But some functions in the source codes have been updated and changed, here are some questions I wanna ask:</p>\n<p>The first one is:  How to get *snapshot.Tree?</p>\n<pre><code>stateDB, err := state.New(block.Root(), state.NewDatabase(db))   \n</code></pre>\n<p>Now this statements need three parameter and the lost parameter's type is *sanpshot.Tree. It is a struct, here is the link to its <a href=\"https://github.com/ConsenSys/quorum/blob/master/core/state/snapshot/snapshot.go\" rel=\"nofollow noreferrer\">source code</a>, in line 164.</p>\n<p>The second one is: What are AsseccList and GasTipFee?</p>\n<pre><code>message := types.NewMessage(from, tx.To(), 0, tx.Value(), tx.Gas(), from Address, to Address, nonce, amount, gasLimit, tx.GasPrice(), GasTopfee, GasTipFee, tx.Data(), accesslist AccessList, false)   \n</code></pre>\n<p>AccessList is also a struct. You can see its struct from <a href=\"https://github.com/ConsenSys/quorum/blob/master/core/state/access_list.go\" rel=\"nofollow noreferrer\">here</a>. What should I input into AccessList and GasTipFee?<br />\nReally appreciate it if you can help me solve these questions.</p>\n",
                    "OwnerUserId": "15736562",
                    "LastActivityDate": "2022-01-07T11:02:25.207",
                    "Title": "two unknow parameters in Go-Ethereum function",
                    "Tags": "<go><go-ethereum>",
                    "AnswerCount": "1",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "70849545",
                "ParentRepo": "https://github.com/bumi/lnme",
                "StackOverflow_Post": {
                    "Id": "70849545",
                    "PostTypeId": "2",
                    "ParentId": "70845653",
                    "CreationDate": "2022-01-25T13:35:18.573",
                    "Score": "1",
                    "Body": "<p>On my donation site at <a href=\"https://donate.ln.rene-pickhardt.de/\" rel=\"nofollow noreferrer\">https://donate.ln.rene-pickhardt.de/</a> you can see that I use an adopted version of lnme <a href=\"https://github.com/bumi/lnme\" rel=\"nofollow noreferrer\">https://github.com/bumi/lnme</a> which is a widget that allows users to request an invoice from your node for a certain amount.</p>\n<p>The propper why of doing this would be via BOLT 12 offers which are currently being standardized and are similar to keysend not yet supported by all wallets / implementations.</p>\n<p>Another way of achieving your goal is by <a href=\"https://github.com/fiatjaf/awesome-lnurl\" rel=\"nofollow noreferrer\">using LNURL</a> or <a href=\"https://github.com/andrerfneves/lightning-address\" rel=\"nofollow noreferrer\">lightning-address</a> which are currently widely supported but not part of the spec. Similar to my own solution based on lnme you need a webserver for LNURL or lightning-address.</p>\n",
                    "OwnerUserId": "1512538",
                    "LastActivityDate": "2022-01-25T13:35:18.573",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "70860685",
                "ParentRepo": "https://github.com/Charlie-belmer/nosqli",
                "StackOverflow_Post": {
                    "Id": "70860685",
                    "PostTypeId": "1",
                    "CreationDate": "2022-01-26T08:48:05.297",
                    "Score": "-2",
                    "ViewCount": "2062",
                    "Body": "<p>Hello guys decided to download one tool - <a href=\"https://github.com/Charlie-belmer/nosqli\" rel=\"nofollow noreferrer\">https://github.com/Charlie-belmer/nosqli</a> (wrote on GO) for my pentest practice (it's made the nosqli directory in my /home/user).\nAnd found out that it's doesn't work. So I've started to fix this problem and stucked:</p>\n<p>when I did &quot;<code>go install</code>&quot; it did nothing I mean literally without error msg etc. Now it gaves me that:</p>\n<pre><code>go install main.go:19:8: cannot find package &quot;github.com/Charlie-belmer/nosqli/cmd&quot; in any of: /usr/lib/go-1.17/src/github.com/Charlie-belmer/nosqli/cmd (from $GOROOT) /root/go/src/github.com/Charlie-belmer/nosqli/cmd (from $GOPATH)\n</code></pre>\n<p>And same situation with go build.</p>\n<pre><code>**# go version\ngo version go1.17.6 linux/amd64**\n\n**go env** (output):\n\nGO111MODULE=&quot;off&quot;\nGOARCH=&quot;amd64&quot;\nGOBIN=&quot;&quot;\nGOCACHE=&quot;/root/.cache/go-build&quot;\nGOENV=&quot;/root/.config/go/env&quot;\nGOEXE=&quot;&quot;\nGOEXPERIMENT=&quot;&quot;\nGOFLAGS=&quot;&quot;\nGOHOSTARCH=&quot;amd64&quot;\nGOHOSTOS=&quot;linux&quot;\nGOINSECURE=&quot;&quot;\nGOMODCACHE=&quot;/root/go/pkg/mod&quot;\nGONOPROXY=&quot;&quot;\nGONOSUMDB=&quot;&quot;\nGOOS=&quot;linux&quot;\nGOPATH=&quot;/root/go&quot;\nGOPRIVATE=&quot;&quot;\nGOPROXY=&quot;https://proxy.golang.org,direct&quot;\nGOROOT=&quot;/usr/lib/go-1.17&quot;\nGOSUMDB=&quot;sum.golang.org&quot;\nGOTMPDIR=&quot;&quot;\nGOTOOLDIR=&quot;/usr/lib/go-1.17/pkg/tool/linux_amd64&quot;\nGOVCS=&quot;&quot;\nGOVERSION=&quot;go1.17.6&quot;\nGCCGO=&quot;gccgo&quot;\nAR=&quot;ar&quot;\nCC=&quot;gcc&quot;\nCXX=&quot;g++&quot;\nCGO_ENABLED=&quot;1&quot;\nGOMOD=&quot;&quot;\nCGO_CFLAGS=&quot;-g -O2&quot;\nCGO_CPPFLAGS=&quot;&quot;\nCGO_CXXFLAGS=&quot;-g -O2&quot;\nCGO_FFLAGS=&quot;-g -O2&quot;\nCGO_LDFLAGS=&quot;-g -O2&quot;\nPKG_CONFIG=&quot;pkg-config&quot;\nGOGCCFLAGS=&quot;-fPIC -m64 -pthread -fmessage-length=0 -fdebug-prefix-map=/tmp/go-build3159993699=/tmp/go-build -gno-record-gcc-switches&quot;\n</code></pre>\n<p>I've never used Go before and absolutely stucked, tried to read so guids but resultless.</p>\n",
                    "OwnerUserId": "17962016",
                    "LastEditorUserId": "497127",
                    "LastEditDate": "2022-01-26T09:29:30.397",
                    "LastActivityDate": "2022-01-26T09:41:56.870",
                    "Title": "How I can fix the trouble with go build and go install doesnt work",
                    "Tags": "<go><kali-linux>",
                    "AnswerCount": "2",
                    "CommentCount": "6",
                    "ClosedDate": "2022-01-26T10:31:26.223",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "71125645",
                "ParentRepo": "https://github.com/minio/console",
                "StackOverflow_Post": {
                    "Id": "71125645",
                    "PostTypeId": "1",
                    "CreationDate": "2022-02-15T11:27:12.330",
                    "Score": "1",
                    "ViewCount": "279",
                    "Body": "<p>I have deployed Minio on a Kubernetes cluster of 3 nodes:</p>\n<pre><code>NAME           STATUS   ROLES                  AGE     VERSION\nraspberrypi2   Ready    &lt;none&gt;                 4h32m   v1.22.6+k3s1\nantonis-dell   Ready    control-plane,master   4h36m   v1.22.6+k3s1\nraspberrypi    Ready    &lt;none&gt;                 4h32m   v1.22.6+k3s1\n</code></pre>\n<p>The architecture is presented in the image below.</p>\n<p><a href=\"https://i.stack.imgur.com/Hmr3n.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/Hmr3n.png\" alt=\"enter image description here\" /></a></p>\n<p>I have access to the Minio browser but I cannot figure out how I can setup the Minio console inside the cluster. In Minio Console official repo <a href=\"https://github.com/minio/console\" rel=\"nofollow noreferrer\">https://github.com/minio/console</a>, some steps are presented.</p>\n<p>For example step <strong>1. Create a user console using mc</strong>:</p>\n<pre><code>mc admin user add myminio/\nEnter Access Key: console\nEnter Secret Key: xxxxxxxx\n</code></pre>\n<p><strong>setp 2. Create a policy for console with admin access to all resources (for testing)</strong></p>\n<pre><code>cat &gt; admin.json &lt;&lt; EOF\n\n{\n    &quot;Version&quot;: &quot;2012-10-17&quot;,\n    &quot;Statement&quot;: [{\n            &quot;Action&quot;: [\n                &quot;admin:*&quot;\n            ],\n            &quot;Effect&quot;: &quot;Allow&quot;,\n            &quot;Sid&quot;: &quot;&quot;\n        },\n        {\n            &quot;Action&quot;: [\n                &quot;s3:*&quot;\n            ],\n            &quot;Effect&quot;: &quot;Allow&quot;,\n            &quot;Resource&quot;: [\n                &quot;arn:aws:s3:::*&quot;\n            ],\n            &quot;Sid&quot;: &quot;&quot;\n        }\n    ]\n}\nEOF\n</code></pre>\n<p>How I can create the user and the policy, if minio runs inside a container? How to access and where?</p>\n",
                    "OwnerUserId": "4132795",
                    "LastActivityDate": "2022-02-15T11:27:12.330",
                    "Title": "How to setup Minio Console on a Kubernetes cluster",
                    "Tags": "<kubernetes><minio><k3s>",
                    "AnswerCount": "0",
                    "CommentCount": "3",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "71152162",
                "ParentRepo": "https://github.com/cert-manager/cert-manager/blob/master/deploy/charts/cert-manager/values.yaml",
                "StackOverflow_Post": {
                    "Id": "71152162",
                    "PostTypeId": "2",
                    "ParentId": "66341446",
                    "CreationDate": "2022-02-17T03:30:16.403",
                    "Score": "0",
                    "Body": "<p>A year late, but adding another solution in case it helps others finding this. I had the same issue of the challenge pod being blocked by PSP, but really didn't want to have to recreate/reconfigure my cluster, so I eventually solved the issue by adding this to the helm chart values.yaml:\n<a href=\"https://github.com/cert-manager/cert-manager/blob/master/deploy/charts/cert-manager/values.yaml\" rel=\"nofollow noreferrer\">https://github.com/cert-manager/cert-manager/blob/master/deploy/charts/cert-manager/values.yaml</a></p>\n<pre><code>  global:\n    podSecurityPolicy:\n      enabled: true \n      useAppArmor: false\n</code></pre>\n<p>In my case, this is part of a Gitlab deployment so I added it under the certmanager key, as follows:</p>\n<pre><code>certmanager:\n  install: true\n  global:\n    podSecurityPolicy:\n      enabled: true \n      useAppArmor: false\n</code></pre>\n<p>(tags for search: gitlab helm chart certmanager PodSecurityPolicy &quot;unable to admit pod&quot; blocked)</p>\n",
                    "OwnerUserId": "866759",
                    "LastActivityDate": "2022-02-17T03:30:16.403",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "71177840",
                "ParentRepo": "https://github.com/ghostunnel/ghostunnel",
                "StackOverflow_Post": {
                    "Id": "71177840",
                    "PostTypeId": "2",
                    "ParentId": "71177667",
                    "CreationDate": "2022-02-18T17:49:27.107",
                    "Score": "0",
                    "Body": "<p>There might be mainly three options</p>\n<ol>\n<li>Local or external firewall, as already mentioned in your question</li>\n<li>Setting up an encryption proxy (<a href=\"https://github.com/hoffie/sshified\" rel=\"nofollow noreferrer\"><code>sshified</code></a>) on your Prometheus Server, which encrypts the outgoing session over SSH to the <code>node_exporter</code> nodes</li>\n<li>Setting up an encryption proxy (<code>stunnel</code>) on your Prometheus Nodes, which let you  only make an encrypted session, see <a href=\"https://0x63.me/tls-between-prometheus-and-its-exporters/\" rel=\"nofollow noreferrer\">Authentication and encryption for Prometheus and its exporters</a></li>\n</ol>\n<p>Option 3 can be easily added to the solution of <a href=\"https://stackoverflow.com/questions/70650714/running-node-exporter-with-ansible/70650885#70650885\">Running <code>node_exporter</code> with Ansible</a>.</p>\n<p>Option 2 is also quite simple and can be done via Ansible easily.</p>\n<p>Option 1 can be done via Ansible modules available for (local) firewall configuration like <code>firewalld</code>.</p>\n<p>There might be more solutions possible like <a href=\"https://github.com/ghostunnel/ghostunnel\" rel=\"nofollow noreferrer\">ghostunnel</a>, ...</p>\n",
                    "OwnerUserId": "6771046",
                    "LastEditorUserId": "6771046",
                    "LastEditDate": "2022-02-18T18:02:31.797",
                    "LastActivityDate": "2022-02-18T18:02:31.797",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "71346576",
                "ParentRepo": "https://github.com/cybertec-postgresql/pgwatch2",
                "StackOverflow_Post": {
                    "Id": "71346576",
                    "PostTypeId": "1",
                    "CreationDate": "2022-03-04T04:20:51.090",
                    "Score": "0",
                    "ViewCount": "395",
                    "Body": "<p>I'm using <a href=\"https://github.com/cybertec-postgresql/pgwatch2\" rel=\"nofollow noreferrer\">PGWatch2</a> monitoring for a master(write) and two replication(read) servers. This monitoring uses <a href=\"https://github.com/cybertec-postgresql/pgwatch2/blob/master/pgwatch2/metrics/stat_statements/9.4/metric.sql\" rel=\"nofollow noreferrer\">this function</a> to get query information. There is no errors on master server but replications have this error:</p>\n<pre><code>pgwatch2@database ERROR:  canceling statement due to statement timeout\npgwatch2@database STATEMENT:  \n        with q_data as (\n          select\n    ...\n\n</code></pre>\n<p>This query takes about 7s on master and\nboth replication servers and master has <code>statement_timeout=0</code>:</p>\n<pre class=\"lang-sh prettyprint-override\"><code> statement_timeout \n-------------------\n 0\n(1 row)\n</code></pre>\n<p>I'm using <strong>PostgreSQL 12.9</strong> on <strong>UBUNTU 20.04.1</strong></p>\n",
                    "OwnerUserId": "2085899",
                    "LastActivityDate": "2022-03-04T04:20:51.090",
                    "Title": "PostgreSQL statement timeout error on a function when \"statement_timeout = 0\"",
                    "Tags": "<postgresql><timeout>",
                    "AnswerCount": "0",
                    "CommentCount": "3",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "71392693",
                "ParentRepo": "https://github.com/vmware-archive/kube-prod-runtime/issues/532",
                "StackOverflow_Post": {
                    "Id": "71392693",
                    "PostTypeId": "2",
                    "ParentId": "71363959",
                    "CreationDate": "2022-03-08T09:27:19.250",
                    "Score": "2",
                    "Body": "<p>\u2022   It can be due to the misinterpretation that the certificate is issued by the staging environment or vice versa. Thus, for that purpose, I would suggest you to please check the <strong>\u2018stable/wordpress\u2019</strong> helm chart with the ingress annotation <strong>'certmanager.k8s.io/cluster-issuer': 'letsencrypt-staging'</strong>. This will result in being issued a certificate from the fake issuer. Thus, even if your certificate is ingressed in your AKS as a secret, it will be shown as being issued from a fake issuer since the chain of certificate hash validation is broken in between. Please find below the curl for that purpose: -</p>\n<pre><code>   \u2018 # curl -vkI https://blog.my-domain.com/\n     ...\n     * Server certificate:\n     *  subject: CN=blog.my-domain.com\n     *  start date: May 13 08:51:13 2019 GMT\n     *  expire date: Aug 11 08:51:13 2019 GMT\n     *  issuer: CN=Fake LE Intermediate X1\n     ... \u2018\n</code></pre>\n<p>Then, list the ingresses as follows: -</p>\n<pre><code>  \u2018 # kubectl get ing\n    NAME             HOSTS                              ADDRESS          PORTS     AGE\n    blog-wordpress   blog.my-domain.com   35.200.214.186   80, 443   8m48s \u2019\n</code></pre>\n<p>and the certificates too: -</p>\n<pre><code>  \u2018 # kubectl get certificates\n    NAME                  READY   SECRET                AGE\n    wordpress.local-tls   True    wordpress.local-tls   9m \u2019\n</code></pre>\n<p>Then, switch the issuer of the certificate to the one that has issued the certificate originally as below: -</p>\n<pre><code>   \u2018 # kubectl edit ing blog-wordpress \u2019\n</code></pre>\n<p>And update the annotation as below: -</p>\n<pre><code>  \u2018 certmanager.k8s.io/cluster-issuer: letsencrypt-prod \u2019\n</code></pre>\n<p>Once the ingress manifest is updated, then the certificate manifest will automatically be updated. To verify it, open the manifest for <strong>\u2018wordpress.local-tls\u2019</strong> certificate resource as below: -</p>\n<pre><code> \u2018 kubectl edit certificate wordpress.local-tls \u2019\n</code></pre>\n<p>The issuer will be seen as updated as below: -</p>\n<pre><code>\u2018 kubectl edit certificate wordpress.local-tls \u2019\n</code></pre>\n<p>Thus, in this way, you will be able to import a certificate secret in AKS. For more details, I would suggest you to please refer the below link for more details: -</p>\n<p><a href=\"https://github.com/vmware-archive/kube-prod-runtime/issues/532\" rel=\"nofollow noreferrer\">https://github.com/vmware-archive/kube-prod-runtime/issues/532</a></p>\n",
                    "OwnerUserId": "16526895",
                    "LastActivityDate": "2022-03-08T09:27:19.250",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "71599365",
                "ParentRepo": "https://github.com/caddyserver/cache-handler",
                "StackOverflow_Post": {
                    "Id": "71599365",
                    "PostTypeId": "1",
                    "CreationDate": "2022-03-24T08:47:03.433",
                    "Score": "0",
                    "ViewCount": "309",
                    "Body": "<p>Currently I'm investigating a setup backed by api-platform with the following goals:</p>\n<ul>\n<li>the PHP backend MUST yield minimal resource payloads, thus I do not want to embed relations at all</li>\n<li>the PHP backend SHOULD be able to run in alternative runtimes, e.g. Swoole</li>\n<li>the webserver should push related resources via HTTP2 Push leveraging the built in vulcain support of the api-platform distribution</li>\n</ul>\n<p>I cannot find that many resources about those setups - at least not in such a form that they answer subsequent questions sufficiently.</p>\n<p>My starting setup was simply based on the <a href=\"https://github.com/api-platform/api-platform/releases/tag/v2.6.8\" rel=\"nofollow noreferrer\">api-platform distribution 2.6.8</a></p>\n<p>So, until now I've learned the following things:</p>\n<ul>\n<li>out of the box, the caddy + http2 push setup works with the PHP container being based on <code>php:8.1-fpm-alpine</code> - while caddy is obviously directly using <code>php_fastcgi</code></li>\n<li>when I was fooling around with the currently available <a href=\"https://github.com/caddyserver/cache-handler\" rel=\"nofollow noreferrer\">cache-handler</a> I was able to get the http cache working but I was struggling to find any information about cache invalidation works. The api-platform docs mostly focus on varnish; there is also only a <code>VarnishPurger</code> shipped in the api-platform core. Wring a custom one should not be that hard <em>if</em> the caddy cache-handler somehow allows <code>BAN</code> requests or something similar - where to find info about that? I see that the handler is based on <a href=\"https://github.com/darkweak/souin\" rel=\"nofollow noreferrer\">Souin</a> - but as unfamiliar as I am I have no clue how (and if) Souin supports cache invalidation after all.</li>\n<li>when changing the php container to be (in my current testing scenario) based on <a href=\"https://openswoole.com/\" rel=\"nofollow noreferrer\">Swoole</a> then <code>php_fastcgi</code> cannot be used in caddy - instead, I ended up using <code>reverse_proxy</code> (as described in <a href=\"https://github.com/dunglas/vulcain/blob/main/docs/caddy.md#configuration\" rel=\"nofollow noreferrer\">vulcain docs</a>) which basically works and serves proper http responses but does not push any resources requested with <code>Preload</code> headers (as I said, it worked when the PHP backend was based on PHP-FPM). How can I debug what happens here? Caddy does not yield any info about the <code>push</code> handling - nor does the vulcain caddy module</li>\n</ul>\n<p>Long story short(er): to sum up my questions</p>\n<ul>\n<li>how can I figure out why caddy + vulcain is not working in a reverse_proxy setup?</li>\n<li>is the current state of the caddy cache handler functional / supported by the api-platform distribution</li>\n<li>how to implement/support <code>BAN</code> requests (or other fine grained cache invalidation) for caddy cache handler?</li>\n</ul>\n",
                    "OwnerUserId": "2749730",
                    "LastEditorUserId": "1908967",
                    "LastEditDate": "2022-04-28T05:17:35.037",
                    "LastActivityDate": "2022-07-19T13:22:36.600",
                    "Title": "API Platform with alternative Runtime, Caddy, Vulcain, Cache ecosystem",
                    "Tags": "<varnish><http2><api-platform.com><caddy><swoole>",
                    "AnswerCount": "1",
                    "CommentCount": "3",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "71655146",
                "ParentRepo": "https://github.com/giongto35/cloud-morph",
                "StackOverflow_Post": {
                    "Id": "71655146",
                    "PostTypeId": "1",
                    "CreationDate": "2022-03-29T00:28:43.140",
                    "Score": "0",
                    "ViewCount": "17",
                    "Body": "<p>I am using <a href=\"https://github.com/giongto35/cloud-morph\" rel=\"nofollow noreferrer\">Cloudmorph</a> as a framework to build my cloud streaming app. I have run into a roadblock, first, when I run Live Server in VS Code, it opens as a Directory. I fixed that by having index.html as an open editor. But now the system won't work. I am fairly new to coding.</p>\n<p>Here is how it looks:\n<a href=\"https://i.stack.imgur.com/HbnlU.png\" rel=\"nofollow noreferrer\">Here</a></p>\n<p>And this is how it SHOULD look:\n<a href=\"https://i.stack.imgur.com/eQqo2.png\" rel=\"nofollow noreferrer\">Here</a></p>\n",
                    "OwnerUserId": "18105745",
                    "LastActivityDate": "2022-03-29T00:28:43.140",
                    "Title": "Cloudmorph VSCODE framework?",
                    "Tags": "<javascript><go><visual-studio-code><cloud><webrtc>",
                    "AnswerCount": "0",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "71936216",
                "ParentRepo": "https://github.com/dtm-labs/dtm",
                "StackOverflow_Post": {
                    "Id": "71936216",
                    "PostTypeId": "2",
                    "ParentId": "69156072",
                    "CreationDate": "2022-04-20T08:10:55.660",
                    "Score": "0",
                    "Body": "<p>Here is an article explaining how to do distributed transactions across different kinds of databases: <a href=\"https://betterprogramming.pub/how-to-implement-a-distributed-transaction-across-mysql-redis-and-mongo-9f6c7448b3b5\" rel=\"nofollow noreferrer\">https://betterprogramming.pub/how-to-implement-a-distributed-transaction-across-mysql-redis-and-mongo-9f6c7448b3b5</a></p>\n<p>MongoDB do not support XA, so <a href=\"https://github.com/dtm-labs/dtm\" rel=\"nofollow noreferrer\">dtm-labs/dtm</a> provide Saga pattern to solve the problem like this. If you want more control on data isolation, you can use TCC pattern instead of Saga pattern.</p>\n",
                    "OwnerUserId": "17132585",
                    "LastEditorUserId": "17132585",
                    "LastEditDate": "2022-05-05T08:56:25.220",
                    "LastActivityDate": "2022-05-05T08:56:25.220",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "72176463",
                "ParentRepo": "https://github.com/sigstore/rekor",
                "StackOverflow_Post": {
                    "Id": "72176463",
                    "PostTypeId": "2",
                    "ParentId": "69000536",
                    "CreationDate": "2022-05-09T18:10:24.440",
                    "Score": "0",
                    "Body": "<p>This should be what <a href=\"https://www.sigstore.dev/\" rel=\"nofollow noreferrer\">Sigstore</a> is for. It is made up of three projects:</p>\n<ul>\n<li><a href=\"https://github.com/sigstore/cosign\" rel=\"nofollow noreferrer\">Cosign</a>, which signs software.</li>\n<li><a href=\"https://github.com/sigstore/fulcio\" rel=\"nofollow noreferrer\">Fulcio</a>, a certificate authority that lets anyone access short-lived certificates via OpenID Connect.</li>\n<li><a href=\"https://github.com/sigstore/rekor\" rel=\"nofollow noreferrer\">Rekor</a>, a secure log of signing events that allows you to verify the provenance of software artifacts.</li>\n</ul>\n<p>You can then follow &quot;<a href=\"https://www.appvia.io/blog/tutorial-keyless-sign-and-verify-your-container-images\" rel=\"nofollow noreferrer\">Keyless Sign and Verify Your Container Images With Cosign</a>&quot; (<a href=\"https://www.appvia.io/blog/tutorial-keyless-sign-and-verify-your-container-images\" rel=\"nofollow noreferrer\">Chris Nesbitt-Smith</a>)</p>\n<blockquote>\n<p>Behind the scenes, cosign creates the keypair ephemerally (they last 20 minutes) and gets them signed by Fulcio using your authenticated OIDC identity.<br />\nThat is OIDC: OpenID Connect 1.0 is a simple identity layer on top of the OAuth 2.0 protocol.</p>\n<p>OIDC allows:</p>\n<ul>\n<li>Clients to verify the identity of the End-User based on the authentication performed by an Authorization Server,</li>\n<li>as well as to obtain basic profile information about the End-User in an interoperable and REST-like manner.</li>\n</ul>\n<p><a href=\"https://i.stack.imgur.com/h2vqK.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/h2vqK.png\" alt=\"https://www.appvia.io/media/pages/blog/tutorial-keyless-sign-and-verify-your-container-images/b34510f730-1636070503/keyless-signing-1600x.png\" /></a></p>\n</blockquote>\n<pre><code>COSIGN_EXPERIMENTAL=1 cosign sign image:tag\nCOSIGN_EXPERIMENTAL=1 cosign verify image:tag\n</code></pre>\n<p>But you would need to setup your own local OCI registry in order to keep the all toolchain local, since cosign stores signatures in an OCI registry, and uses a naming convention (tag based on the sha256 of what we're signing) for locating the signature index.</p>\n<p><a href=\"https://i.stack.imgur.com/YVxqy.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/YVxqy.png\" alt=\"oci registry -- https://github.com/sigstore/cosign/raw/main/images/signatures.dot.svg\" /></a></p>\n",
                    "OwnerUserId": "6309",
                    "LastEditorUserId": "6309",
                    "LastEditDate": "2022-05-09T18:15:27.450",
                    "LastActivityDate": "2022-05-09T18:15:27.450",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "72751642",
                "ParentRepo": "https://github.com/beego/beego/issues/2520",
                "StackOverflow_Post": {
                    "Id": "72751642",
                    "PostTypeId": "2",
                    "ParentId": "71828458",
                    "CreationDate": "2022-06-25T06:11:27.210",
                    "Score": "0",
                    "Body": "<p>Check the file named <strong>commentsRouter_controller.go</strong>\nSeems this file is missing in your project.</p>\n<p>commentsRouter_controller.go is generated automatically. If not please check this link for more info <a href=\"https://github.com/beego/beego/issues/2520\" rel=\"nofollow noreferrer\">https://github.com/beego/beego/issues/2520</a></p>\n",
                    "OwnerUserId": "18463161",
                    "LastActivityDate": "2022-06-25T06:11:27.210",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "72810836",
                "ParentRepo": "https://github.com/rancher/rke2/issues/2603#issuecomment-1067434942=",
                "StackOverflow_Post": {
                    "Id": "72810836",
                    "PostTypeId": "2",
                    "ParentId": "72810626",
                    "CreationDate": "2022-06-30T05:47:32.183",
                    "Score": "0",
                    "Body": "<p>Your command seems to have two issues:</p>\n<pre><code>INSTALL_K3S_EXEC=\u201c\u2014write-kubeconfig=/home/ubuntu/.kube/config  --write-kubeconfig-mode=644\u201d \n</code></pre>\n<ul>\n<li>using <code>\u201c</code> instead of <code>&quot;</code> can be misinterpreted by the shell</li>\n<li>an option like <code>\u2014write-kubeconfig</code> should use <code>--</code> (as in <code>\u2014-write-kubeconfig</code>)</li>\n</ul>\n<p>Since the error message is <code>flag provided but not defined: --write-kube-config</code> (and has <code>--</code>), it is possible the above is just a font/display issue.<br />\nIn that case, check if this is an <a href=\"https://github.com/rancher/rke2/issues/2603#issuecomment-1067434942=\" rel=\"nofollow noreferrer\">option order issue as described here</a>.</p>\n",
                    "OwnerUserId": "6309",
                    "LastEditorUserId": "6309",
                    "LastEditDate": "2022-06-30T05:53:27.163",
                    "LastActivityDate": "2022-06-30T05:53:27.163",
                    "CommentCount": "11",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "72900288",
                "ParentRepo": "https://github.com/vmware-tanzu/carvel-kapp-controller",
                "StackOverflow_Post": {
                    "Id": "72900288",
                    "PostTypeId": "2",
                    "ParentId": "50452665",
                    "CreationDate": "2022-07-07T15:11:42.197",
                    "Score": "1",
                    "Body": "<p>You could do something like this in HELM:</p>\n<pre><code>{{- define &quot;getValueFromSecret&quot; }}\n{{- $len := (default 16 .Length) | int -}}\n{{- $obj := (lookup &quot;v1&quot; &quot;Secret&quot; .Namespace .Name).data -}}\n{{- if $obj }}\n{{- index $obj .Key | b64dec -}}\n{{- else -}}\n{{- randAlphaNum $len -}}\n{{- end -}}\n{{- end }}\n</code></pre>\n<p>Then you could do something like this in configmap:</p>\n<pre><code>{{- include &quot;getValueFromSecret&quot; (dict &quot;Namespace&quot; .Release.Namespace &quot;Name&quot; &quot;&lt;secret_name&gt;&quot; &quot;Length&quot; 10 &quot;Key&quot; &quot;&lt;key&gt;&quot;)  -}}\n</code></pre>\n<p>The secret should be already present while deploying; or you can control the order of deployment using <a href=\"https://github.com/vmware-tanzu/carvel-kapp-controller\" rel=\"nofollow noreferrer\">https://github.com/vmware-tanzu/carvel-kapp-controller</a></p>\n",
                    "OwnerUserId": "2704032",
                    "LastActivityDate": "2022-07-07T15:11:42.197",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "72935127",
                "ParentRepo": "https://github.com/azure/aks-periscope//deployment/base?ref=v0.9",
                "StackOverflow_Post": {
                    "Id": "72935127",
                    "PostTypeId": "1",
                    "CreationDate": "2022-07-11T07:35:48.520",
                    "Score": "0",
                    "ViewCount": "53",
                    "Body": "<p>When trying to deploy AKS Periscope via <code>aks command invoke</code>, I am seeing the following error.\nCommand:</p>\n<pre><code>az aks command invoke --resource-group &lt;&gt; --name &lt;&gt; --command &quot;kubectl apply -k .&quot; --file\n</code></pre>\n<p>Error:</p>\n<blockquote>\n<p>rawResources failed to read Resources: Load from path <a href=\"https://github.com/azure/aks-periscope//deployment/base?ref=v0.9\" rel=\"nofollow noreferrer\">https://github.com/azure/aks-periscope//deployment/base?ref=v0.9</a> failed: evalsymlink failure on '/command-files/https:/github.com/azure/aks-periscope/deployment/base?ref=v0.9' : lstat /command-files/https:: no such file or directory</p>\n</blockquote>\n<p>Directly running the command works but via command invoke it fails</p>\n",
                    "OwnerUserId": "5400997",
                    "LastEditorUserId": "6083675",
                    "LastEditDate": "2022-07-12T10:11:33.980",
                    "LastActivityDate": "2022-07-12T10:11:33.980",
                    "Title": "aks command invoke: evalsymlink failure on '/command-files/https:/github.com/",
                    "Tags": "<azure-aks>",
                    "AnswerCount": "0",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "72989275",
                "ParentRepo": "https://github.com/kserve/modelmesh-serving/blob/main/docs/quickstart.md",
                "StackOverflow_Post": {
                    "Id": "72989275",
                    "PostTypeId": "1",
                    "CreationDate": "2022-07-15T05:08:01.640",
                    "Score": "2",
                    "ViewCount": "2599",
                    "Body": "<p>I am following the tutorial here about kserve <a href=\"https://github.com/kserve/modelmesh-serving/blob/main/docs/quickstart.md\" rel=\"nofollow noreferrer\">https://github.com/kserve/modelmesh-serving/blob/main/docs/quickstart.md</a></p>\n<p>Is this my docker&amp;k8s issue? I have spent hours trying to debug but to no avail.</p>\n<p>I am getting the following error:</p>\n<pre><code>\nEvents:\n  Type     Reason     Age    From               Message\n  ----     ------     ----   ----               -------\n  Normal   Scheduled  4m20s  default-scheduler  Successfully assigned modelmesh-serving/modelmesh-serving-mlserver-0.x-77cc8fd548-xdgvr to minikube\n  Normal   Pulling    4m18s  kubelet            Pulling image &quot;kserve/modelmesh:v0.9.0-rc0&quot;\n  Normal   Pulled     3m18s  kubelet            Successfully pulled image &quot;kserve/modelmesh:v0.9.0-rc0&quot; in 59.419620166s\n  Normal   Created    3m18s  kubelet            Created container mm\n  Normal   Started    3m17s  kubelet            Started container mm\n  Normal   Pulling    3m17s  kubelet            Pulling image &quot;seldonio/mlserver:0.5.2&quot;\n  Warning  Failed     68s    kubelet            Failed to pull image &quot;seldonio/mlserver:0.5.2&quot;: rpc error: code = Unknown desc = context deadline exceeded\n  Warning  Failed     68s    kubelet            Error: ErrImagePull\n  Normal   Pulling    68s    kubelet            Pulling image &quot;kserve/modelmesh-runtime-adapter:v0.9.0-rc0&quot;\n\n</code></pre>\n",
                    "OwnerUserId": "16228929",
                    "LastActivityDate": "2022-09-03T18:47:33.250",
                    "Title": "Failed to pull image",
                    "Tags": "<docker><kubernetes><kubeflow>",
                    "AnswerCount": "3",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "73209436",
                "ParentRepo": "https://github.com/loft-sh/vcluster/blob/main/CONTRIBUTING.md#setup-vcluster-for-development",
                "StackOverflow_Post": {
                    "Id": "73209436",
                    "PostTypeId": "1",
                    "CreationDate": "2022-08-02T14:38:43.993",
                    "Score": "0",
                    "ViewCount": "163",
                    "Body": "<p>I am setting up vcluster for development: <a href=\"https://github.com/loft-sh/vcluster/blob/main/CONTRIBUTING.md#setup-vcluster-for-development\" rel=\"nofollow noreferrer\">docs</a></p>\n<pre><code>devspace run dev\n\n....\n[info]   Using namespace 'vcluster'\n[info]   Using kube context 'vhost'\n[done] \u221a Created namespace: vcluster\n[info]   Rebuild image  because tag is missing                      \n[info]   Building image 'ghcr.io/loft-sh/loft-enterprise/dev-vcluster:kSukXFs' with engine 'buildkit'\n[info]   Execute BuildKit command with: docker buildx build --tag ghcr.io/loft-sh/loft-enterprise/dev-vcluster:kSukXFs --push --file Dockerfile --target builder -\nunknown flag: --tag\nSee 'docker --help'.\n\nUsage:  docker [OPTIONS] COMMAND\n...\nRun 'docker COMMAND --help' for more information on a command.\n\nTo get more help with docker, check out our guides at https://docs.docker.com/go/guides/\n\n[fatal]  error building image ghcr.io/loft-sh/loft-enterprise/dev-vcluster:kSukXFs: exit status 125\n</code></pre>\n<p>Is my version of docker too old?</p>\n<p>I am using <code>Docker version 20.10.12</code></p>\n",
                    "OwnerUserId": "633961",
                    "LastActivityDate": "2022-08-02T14:38:43.993",
                    "Title": "vcluster development install: docker: unknown flag: --tag",
                    "Tags": "<docker><vcluster>",
                    "AnswerCount": "0",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "73860588",
                "ParentRepo": "https://github.com/cilium/tetragon",
                "StackOverflow_Post": {
                    "Id": "73860588",
                    "PostTypeId": "2",
                    "ParentId": "71152250",
                    "CreationDate": "2022-09-26T22:31:37.353",
                    "Score": "2",
                    "Body": "<p>The BPF helper function <code>bpf_send_signal()</code> can be used to send a signal to the process of the monitored task, see its <a href=\"https://man7.org/linux/man-pages/man7/bpf-helpers.7.html\" rel=\"nofollow noreferrer\">documentation</a>:</p>\n<pre><code>       long bpf_send_signal(u32 sig)\n              Description\n                     Send signal sig to the process of the current task.\n                     The signal may be delivered to any of this\n                     process's threads.\n              Return\n                     0 on success or successfully queued.\n                     -EBUSY if work queue under nmi is full.\n                     -EINVAL if sig is invalid.\n                     -EPERM if no permission to send the sig.\n                     -EAGAIN if bpf program can try again.\n</code></pre>\n<p>The signal to pass can be <code>SIGKILL</code>, for example.</p>\n<p>Some projects use it already: <a href=\"https://github.com/cilium/tetragon\" rel=\"nofollow noreferrer\">Tetragon</a>, a tool based on eBPF for \u201csecurity observability and runtime enforcement\u201d, <a href=\"https://github.com/cilium/tetragon/blob/v0.8.2/bpf/process/types/basic.h#L1034\" rel=\"nofollow noreferrer\">can call it</a> to terminate processes.</p>\n<p>This helper is available starting with Linux 5.3.</p>\n",
                    "OwnerUserId": "3716552",
                    "LastActivityDate": "2022-09-26T22:31:37.353",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "73943674",
                "ParentRepo": "https://github.com/kubeedge/kubeedge/tree/master/manifests/charts/cloudcore",
                "StackOverflow_Post": {
                    "Id": "73943674",
                    "PostTypeId": "1",
                    "CreationDate": "2022-10-04T06:02:44.263",
                    "Score": "0",
                    "ViewCount": "82",
                    "Body": "<p>I'm trying to setup kubeedge, with <strong>cloudcore in aws</strong> and <strong>edgecore in local</strong>. I already have a cluster setup in the <strong>aws</strong> with <strong>k8s version 1.21</strong>.</p>\n<p>Following is my setup:</p>\n<pre><code>k8s: 1.21\nkubeedge: 1.12.0\n  (it includes cloudcore, edgecore and keadm)\n</code></pre>\n<p>I've installed cloudcore using helm template provided here <a href=\"https://github.com/kubeedge/kubeedge/tree/master/manifests/charts/cloudcore\" rel=\"nofollow noreferrer\">https://github.com/kubeedge/kubeedge/tree/master/manifests/charts/cloudcore</a>.\n(Instead of IP, i'm using dns)</p>\n<p>At the edgecore side, I used keadm to join the cloud cluster. I got the token from cloudcore and used cloudcore url with the token from cloud cluster.</p>\n<pre><code>[root@mymachine1 edge]./keadm join --cloudcore-ipport=mycloudcore.xx.xx.local:10000 --edgenode-name=edge-node-01 --token=MYTOKEFROMCLOUDCORE\nI1004 15:59:11.033612  903445 command.go:845] 1. Check KubeEdge edgecore process status\nI1004 15:59:11.052472  903445 command.go:845] 2. Check if the management directory is clean\nW1004 15:59:11.143464  903445 common.go:232] could not fetch a KubeEdge version from the internet: failed to get latest version from https://kubeedge.io/latestversion: Get &quot;https://kubeedge.io/latestversion&quot;: x509: certificate signed by unknown authority\nW1004 15:59:11.143482  903445 common.go:233] falling back to the local client version: v1.12.0\nI1004 15:59:11.143508  903445 join.go:100] 3. Create the necessary directories\nI1004 15:59:11.145422  903445 join.go:176] 4. Pull Images\nPulling kubeedge/pause:3.1 ...\nPulling kubeedge/installation-package:v1.12.0 ...\nPulling eclipse-mosquitto:1.6.15 ...\nI1004 15:59:11.147932  903445 join.go:176] 5. Copy resources from the image to the management directory\nI1004 15:59:11.829935  903445 join.go:176] 6. Start the default mqtt service\nI1004 15:59:12.132809  903445 join.go:100] 7. Generate systemd service file\nI1004 15:59:12.132983  903445 join.go:100] 8. Generate EdgeCore default configuration\nI1004 15:59:12.133071  903445 join.go:230] The configuration does not exist or the parsing fails, and the default configuration is generated\nW1004 15:59:12.134417  903445 validation.go:71] NodeIP is empty , use default ip which can connect to cloud.\nI1004 15:59:12.136006  903445 join.go:100] 9. Run EdgeCore daemon\nI1004 15:59:12.528922  903445 join.go:317]\nI1004 15:59:12.528939  903445 join.go:318] KubeEdge edgecore is running, For logs visit: journalctl -u edgecore.service -xe\n</code></pre>\n<p>On checking the edgecore server I got the following error:</p>\n<pre><code>$journalctl -u edgecore.service -xe\n..\n77  903680 certmanager.go:161] Certificate rotation is enabled.\n17  903680 websocket.go:51] Websocket start to connect Access\n29  903680 ws.go:78] dial websocket error(x509: certificate signed by unknown authority), response message:\n48  903680 websocket.go:90] Init websocket connection failed x509: certificate signed by unknown authority\n72  903680 kubelet_network_linux.go:56] &quot;Initialized protocol iptables rules.&quot; protocol=IPv4\n98  903680 kubelet_network_linux.go:56] &quot;Initialized protocol iptables rules.&quot; protocol=IPv6\n23  903680 status_manager.go:158] &quot;Starting to sync pod status with apiserver&quot;\n36  903680 kubelet.go:1807] &quot;Starting kubelet main sync loop&quot;\n74  903680 kubelet.go:1831] &quot;Skipping pod synchronization&quot; err=&quot;[container runtime status check may not have completed yet, PLEG is not healthy: pleg has yet to&gt;\n35  903680 kubelet_node_status.go:69] &quot;Attempting to register node&quot; node=&quot;edge-node-01&quot;\n35  903680 imitator.go:235] failed to unmarshal message content to unstructured obj: Object 'Kind' is missing in '{&quot;metadata&quot;:{&quot;name&quot;:&quot;edge-node-01&quot;,....\n62  903680 cpu_manager.go:209] &quot;Starting CPU manager&quot; policy=&quot;none&quot;\n80  903680 cpu_manager.go:210] &quot;Reconciling&quot; reconcilePeriod=&quot;10s&quot;\n96  903680 state_mem.go:36] &quot;Initialized new in-memory state store&quot;\n26  903680 state_mem.go:88] &quot;Updated default CPUSet&quot; cpuSet=&quot;&quot;\n36  903680 state_mem.go:96] &quot;Updated CPUSet assignments&quot; assignments=map[]\n42  903680 policy_none.go:49] &quot;None policy: Start&quot;\n96  903680 memory_manager.go:168] &quot;Starting memorymanager&quot; policy=&quot;None&quot;\n22  903680 state_mem.go:35] &quot;Initializing new in-memory state store&quot;\n42  903680 state_mem.go:75] &quot;Updated machine memory state&quot;\n14  903680 manager.go:609] &quot;Failed to read data from checkpoint&quot; checkpoint=&quot;kubelet_internal_checkpoint&quot; err=&quot;checkpoint is not found&quot;\n58  903680 plugin_manager.go:114] &quot;Starting Kubelet Plugin Manager&quot;\n85  903680 ws.go:78] dial websocket error(x509: certificate signed by unknown authority), response message:\n10  903680 websocket.go:90] Init websocket connection failed x509: certificate signed by unknown authority\n</code></pre>\n<pre><code>$systemctl status edgecore\n...\nmachine1.local edgecore[903680]: E1004 16:07:44.185942  903680 websocket.go:90] Init websocket connection failed x509: certificate signed by unknown authority\nmachine1.local edgecore[903680]: E1004 16:07:49.202231  903680 ws.go:78] dial websocket error(x509: certificate signed by unknown authority), response message:\nmachine1.local edgecore[903680]: E1004 16:07:49.202264  903680 websocket.go:90] Init websocket connection failed x509: certificate signed by unknown authority\nmachine1.local edgecore[903680]: E1004 16:07:54.203350  903680 edgehub.go:107] connection failed: max retry count reached when connecting to cloud, will reconnect after 30s\nmachine1.local edgecore[903680]: E1004 16:08:15.984055  903680 metaclient.go:117] send sync message default/node/edge-node-01 failed error:timeout to get response for message\n</code></pre>\n<p>The new CA and edge certs are generated at cloud side when I tried helm install cloudcore.\nAnyidea why I'm getting the cert issue at edge? Is there anyway I can resolve this?</p>\n<p>Thanks in advance,\nAkhil</p>\n",
                    "OwnerUserId": "5662951",
                    "LastActivityDate": "2022-10-04T06:02:44.263",
                    "Title": "Edgecore not getting connected to cloudhub : websocket connection failed x509: certificate signed by unknown authority",
                    "Tags": "<kubernetes><websocket><kubernetes-helm><kubectl>",
                    "AnswerCount": "0",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "74121942",
                "ParentRepo": "https://github.com/kubernetes/pod-security-admission/blob/master/webhook/manifests/20-configmap.yaml",
                "StackOverflow_Post": {
                    "Id": "74121942",
                    "PostTypeId": "2",
                    "ParentId": "74098851",
                    "CreationDate": "2022-10-19T08:10:13.380",
                    "Score": "2",
                    "Body": "<p>I don't think there is any way <a href=\"https://github.com/aws/containers-roadmap/issues/1822\" rel=\"nofollow noreferrer\">currently</a> in EKS to provide configuration for the built-in PSA controller (Pod Security Admission controller).</p>\n<p>But if you want to implement a cluster-wide default for PSS (Pod Security Standards) you can do that by installing the the official <code>pod-security-webhook</code> as a <a href=\"https://aws.amazon.com/about-aws/whats-new/2018/10/amazon-eks-enables-support-for-kubernetes-dynamic-admission-cont/\" rel=\"nofollow noreferrer\">Dynamic Admission Controller in EKS</a>.</p>\n<pre><code>git clone https://github.com/kubernetes/pod-security-admission\ncd pod-security-admission/webhook\nmake certs\nkubectl apply -k . \n\n</code></pre>\n<p>The default <code>podsecurityconfiguration.yaml</code> in <a href=\"https://github.com/kubernetes/pod-security-admission/blob/master/webhook/manifests/20-configmap.yaml\" rel=\"nofollow noreferrer\"><code>pod-security-admission/webhook/manifests/020-configmap.yaml</code></a> allows EVERYTHING so you should edit it and write something like</p>\n<pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: pod-security-webhook\n  namespace: pod-security-webhook\ndata:\n  podsecurityconfiguration.yaml: |\n    apiVersion: pod-security.admission.config.k8s.io/v1beta1\n    kind: PodSecurityConfiguration\n    defaults:\n      enforce: &quot;restricted&quot;\n      enforce-version: &quot;latest&quot;\n      audit: &quot;restricted&quot;\n      audit-version: &quot;latest&quot;\n      warn: &quot;restricted&quot;\n      warn-version: &quot;latest&quot;\n    exemptions:\n      # Array of authenticated usernames to exempt.\n      usernames: []\n      # Array of runtime class names to exempt.\n      runtimeClasses: []\n      # Array of namespaces to exempt.\n      namespaces: [&quot;policy-test2&quot;]\n\n</code></pre>\n<p>then</p>\n<pre><code>kubectl apply -k . \nkubectl -n pod-security-webhook rollout restart deployment/pod-security-webhook # otherwise the pods won't reread the configuration changes\n</code></pre>\n<p>After those changes you can verify that the default forbids privileged pods with:</p>\n<pre><code>kubectl --context aihub-eks-terraform create ns policy-test1\nkubectl --context aihub-eks-terraform -n policy-test1 run --image=ecerulm/ubuntu-tools:latest --rm -ti rubelagu-$RANDOM  --privileged\nError from server (Forbidden): admission webhook &quot;pod-security-webhook.kubernetes.io&quot; denied the request: pods &quot;rubelagu-32081&quot; is forbidden: violates PodSecurity &quot;restricted:latest&quot;: privileged (container &quot;rubelagu-32081&quot; must not set securityContext.privileged=true), allowPrivilegeEscalation != false (container &quot;rubelagu-32081&quot; must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container &quot;rubelagu-32081&quot; must set securityContext.capabilities.drop=[&quot;ALL&quot;]), runAsNonRoot != true (pod or container &quot;rubelagu-32081&quot; must set securityContext.runAsNonRoot=true), seccompProfile (pod or container &quot;rubelagu-32081&quot; must set securityContext.seccompProfile.type to &quot;RuntimeDefault&quot; or &quot;Localhost&quot;)\n</code></pre>\n<p>Note: that you get the error forbidding privileged pods even when the namespace <code>policy-test1</code> has no label <code>pod-security.kubernetes.io/enforce</code>, so you know that <strong>this rule comes from the pod-security-webhook that we just installed and configured</strong>.</p>\n<p>Now if you want to create a pod you will be forced to create in a way that complies with the <code>restricted</code> PSS, by specifying <code>runAsNonRoot</code>, <code>seccompProfile.type</code> and <code>capabilities</code> and For example:</p>\n<pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: test-1\nspec:\n  restartPolicy: Never\n  securityContext:\n    runAsNonRoot: true\n    runAsUser: 1000\n    runAsGroup: 3000\n    fsGroup: 2000\n    seccompProfile:\n      type: RuntimeDefault\n  containers:\n    - name: test\n      image: ecerulm/ubuntu-tools:latest\n      imagePullPolicy: Always\n      command: [&quot;/bin/bash&quot;, &quot;-c&quot;, &quot;--&quot;, &quot;sleep 900&quot;]\n      securityContext:\n        privileged: false\n        allowPrivilegeEscalation: false\n        capabilities:\n          drop:\n            - ALL\n\n</code></pre>\n",
                    "OwnerUserId": "90580",
                    "LastActivityDate": "2022-10-19T08:10:13.380",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "74148691",
                "ParentRepo": "https://github.com/slicen/cert-manager-webhook-linode/blob/master/main_test.go",
                "StackOverflow_Post": {
                    "Id": "74148691",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "74156196",
                    "CreationDate": "2022-10-21T04:13:22.813",
                    "Score": "1",
                    "ViewCount": "35",
                    "Body": "<p>I completely make a config and create a token on linode\nbut i got this error when try to test my fetch-test-binaries.sh</p>\n<p>this is the message</p>\n<pre><code>go test -v\n# github.com/slicen/cert-manager-webhook-linode [github.com/slicen/cert-manager-webhook-linode.test]\n./main_test.go:20:7: undefined: dns.SetBinariesPath\n./main_test.go:20:23: undefined: kubeBuilderBinPath\nFAIL    github.com/slicen/cert-manager-webhook-linode [build failed]\nmake: *** [Makefile:15: verify] Error 2\n</code></pre>\n<p>can someone help me to resolve please ?</p>\n<p>The error on file\nmain_test.go line 7 &amp; 23 Link FIle : <a href=\"https://github.com/slicen/cert-manager-webhook-linode/blob/master/main_test.go\" rel=\"nofollow noreferrer\">https://github.com/slicen/cert-manager-webhook-linode/blob/master/main_test.go</a></p>\n<p>and makefile line 15 Link File : <a href=\"https://github.com/slicen/cert-manager-webhook-linode/blob/master/Makefile\" rel=\"nofollow noreferrer\">https://github.com/slicen/cert-manager-webhook-linode/blob/master/Makefile</a></p>\n<p>The Repository Link : <a href=\"https://github.com/slicen/cert-manager-webhook-linode\" rel=\"nofollow noreferrer\">https://github.com/slicen/cert-manager-webhook-linode</a></p>\n<p>I have tried to resolve with downgrade or upgrade my Go Version and searching but i found nothing,</p>\n<p>I tried to just go test -v(not doing anything, just clone &amp; go test) but i got same error</p>\n<p>Please Help me, Thanks</p>\n",
                    "OwnerUserId": "20043595",
                    "LastActivityDate": "2022-10-23T00:10:45.617",
                    "Title": "Error go test -v on https://github.com/slicen/cert-manager-webhook-linode",
                    "Tags": "<go><webhooks><linode><cert-manager>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "74467743",
                "ParentRepo": "https://github.com/grafana/tempo",
                "StackOverflow_Post": {
                    "Id": "74467743",
                    "PostTypeId": "2",
                    "ParentId": "74462196",
                    "CreationDate": "2022-11-16T21:58:20.963",
                    "Score": "0",
                    "Body": "<p><a href=\"https://github.com/OpenObservability/OpenMetrics/blob/main/specification/OpenMetrics.md#exemplars\" rel=\"nofollow noreferrer\">Exemplars</a> are data types which are used to create references to data outside of the <a href=\"https://github.com/OpenObservability/OpenMetrics/blob/main/specification/OpenMetrics.md#metricset\" rel=\"nofollow noreferrer\">MetricSet</a>. So the assumption above that exemplars are for identifying metrics is not right rather it is for linking the metrics with external information (common use case is linking to the program traces) that will help SRE's/Engineers to debug faster.</p>\n<p>For example, if you have exemplars setup within your metrics and if you are using <a href=\"https://github.com/grafana/tempo\" rel=\"nofollow noreferrer\">Tempo</a>, then Grafana will give you the ability to directly open traces from your grafana panel. <a href=\"https://grafana.com/docs/grafana/latest/fundamentals/exemplars/\" rel=\"nofollow noreferrer\">example</a></p>\n<p><a href=\"https://github.com/OpenObservability/OpenMetrics/blob/main/specification/OpenMetrics.md#label\" rel=\"nofollow noreferrer\">Labels</a> are another datatype, they are used to differentiate various characteristic within a <a href=\"https://prometheus.io/docs/tutorials/understanding_metric_types/#types-of-metrics\" rel=\"nofollow noreferrer\">metric</a>.</p>\n",
                    "OwnerUserId": "1766402",
                    "LastActivityDate": "2022-11-16T21:58:20.963",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "74591111",
                "ParentRepo": "https://github.com/suvvm/ToadOCREngine",
                "StackOverflow_Post": {
                    "Id": "74591111",
                    "PostTypeId": "2",
                    "ParentId": "74579996",
                    "CreationDate": "2022-11-27T15:05:45.187",
                    "Score": "1",
                    "Body": "<p>Yes it means the same directory. Let's look at the following code.</p>\n<h2>Directory Structure</h2>\n<pre><code>.\n\u251c\u2500\u2500 go.mod\n\u251c\u2500\u2500 greet\n\u2502   \u2514\u2500\u2500 greet.go\n\u2514\u2500\u2500 main.go\n</code></pre>\n<h2>Content in <strong><code>greet.go</code></strong></h2>\n<pre><code>package __\n\nimport &quot;fmt&quot;\n\nfunc Hello(name string) {\n    fmt.Printf(&quot;Hello %s\\n&quot;, name)\n}\n</code></pre>\n<h2>Content in <strong><code>main.go</code></strong></h2>\n<pre><code>package main\n\nimport greet &quot;playground/greet&quot;\n\nfunc main() {\n    greet.Hello(&quot;Eric&quot;)\n}\n</code></pre>\n<h2>Current Directory</h2>\n<pre><code>$ pwd\n/Users/thedatageek/Codes/go-playground\n</code></pre>\n<p>Unfortunately I also couldn't find any docs for go.</p>\n<p>But it seems that its kinda good thing. You really don't need to name the package. You just name the directory and the package name would be automatically the same.</p>\n<p><strong>Note:</strong> This is definitely not the <code>grpc</code> or <code>protobuf</code> thing. It is however a customary that if you have generated proto stub from a proto file and if you add some additional utility file you may put those into a dir and then import it directly via directory name. For example the following github repos</p>\n<p><a href=\"https://github.com/Ash110/gRPC-Logger\" rel=\"nofollow noreferrer\">https://github.com/Ash110/gRPC-Logger</a>\n<a href=\"https://github.com/dist1ll/cache-prototype\" rel=\"nofollow noreferrer\">https://github.com/dist1ll/cache-prototype</a>\n<a href=\"https://github.com/kamensotirov99/int-gateway\" rel=\"nofollow noreferrer\">https://github.com/kamensotirov99/int-gateway</a>\n<a href=\"https://github.com/rachaelyychen/go-gee\" rel=\"nofollow noreferrer\">https://github.com/rachaelyychen/go-gee</a>\n<a href=\"https://github.com/suvvm/ToadOCREngine\" rel=\"nofollow noreferrer\">https://github.com/suvvm/ToadOCREngine</a>\n<a href=\"https://github.com/denyami/drawing-api\" rel=\"nofollow noreferrer\">https://github.com/denyami/drawing-api</a></p>\n",
                    "OwnerUserId": "4037927",
                    "LastEditorUserId": "4037927",
                    "LastEditDate": "2022-11-27T15:26:15.697",
                    "LastActivityDate": "2022-11-27T15:26:15.697",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            }
        ],
        "Type": 2
    },
    "https://github.com/rs/node-netmask": {
        "CVE Description": [
            "Improper input validation of octal strings in netmask npm package v1.0.6 and below allows unauthenticated remote attackers to perform indeterminate SSRF, RFI, and LFI attacks on many of the dependent packages. A remote unauthenticated attacker can bypass packages relying on netmask to filter IPs and reach critical VPN or LAN hosts."
        ],
        "Edges": [
            {
                "ParentSID": "3381935",
                "ParentRepo": "https://github.com/mozilla/addons-server",
                "StackOverflow_Post": {
                    "Id": "3381935",
                    "PostTypeId": "2",
                    "ParentId": "886221",
                    "CreationDate": "2010-08-01T12:03:20.697",
                    "Score": "185",
                    "Body": "<p>Not sure about the number of daily visits but here are a few examples of large Django sites:</p>\n<ul>\n<li><a href=\"http://disqus.com/\" rel=\"nofollow noreferrer\">disqus.com</a> (<a href=\"http://djangocon.blip.tv/file/4135225/\" rel=\"nofollow noreferrer\">talk from djangocon</a>)</li>\n<li><a href=\"http://bitbucket.org\" rel=\"nofollow noreferrer\">bitbucket.org</a> (<a href=\"https://web.archive.org/web/20110521024332/http://code.djangoproject.com/wiki/DjangoSuccessStoryBitbucket\" rel=\"nofollow noreferrer\">write up</a>)</li>\n<li><a href=\"http://lanyrd.com/\" rel=\"nofollow noreferrer\">lanyrd.com</a> (<a href=\"http://lanyrd.com/colophon/\" rel=\"nofollow noreferrer\">source</a>)</li>\n<li><a href=\"http://support.mozilla.com/\" rel=\"nofollow noreferrer\">support.mozilla.com</a> (<a href=\"https://github.com/mozilla/kitsune\" rel=\"nofollow noreferrer\">source code</a>)</li>\n<li><a href=\"https://addons.mozilla.org/\" rel=\"nofollow noreferrer\">addons.mozilla.org</a> (<a href=\"https://github.com/mozilla/addons-server\" rel=\"nofollow noreferrer\">source code</a>) (<a href=\"http://python.mirocommunity.org/video/1866/djangocon-2010-switching-addon\" rel=\"nofollow noreferrer\">talk from djangocon</a>)</li>\n<li><a href=\"http://www.theonion.com/\" rel=\"nofollow noreferrer\">theonion.com</a> (<a href=\"http://www.reddit.com/r/django/comments/bhvhz/the_onion_uses_django_and_why_it_matters_to_us\" rel=\"nofollow noreferrer\">write up</a>)</li>\n<li>The <a href=\"http://www.guardian.co.uk/\" rel=\"nofollow noreferrer\">guardian.co.uk</a> comment system uses Django (<a href=\"http://www.guardian.co.uk/info/developer-blog/2011/feb/08/computing-apps\" rel=\"nofollow noreferrer\">source</a>)</li>\n<li><a href=\"http://instagr.am/\" rel=\"nofollow noreferrer\">instagram</a></li>\n<li><a href=\"https://pinterest.com\" rel=\"nofollow noreferrer\">pinterest</a></li>\n<li><a href=\"http://www.rdio.com/\" rel=\"nofollow noreferrer\">rdio</a></li>\n</ul>\n<p>Here is a link to list of <a href=\"http://www.quora.com/Django/What-is-the-highest-traffic-website-built-on-top-of-Django\" rel=\"nofollow noreferrer\">high traffic Django sites on Quora</a>.</p>\n",
                    "OwnerUserId": "288424",
                    "LastEditorUserId": "11624105",
                    "LastEditDate": "2021-10-28T10:35:40.697",
                    "LastActivityDate": "2021-10-28T10:35:40.697",
                    "CommentCount": "0",
                    "CommunityOwnedDate": "2012-08-06T09:52:15.267",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "11692463",
                "ParentRepo": "https://github.com/rs/pushd",
                "StackOverflow_Post": {
                    "Id": "11692463",
                    "PostTypeId": "2",
                    "ParentId": "9801720",
                    "CreationDate": "2012-07-27T17:09:56.747",
                    "Score": "10",
                    "Body": "<p>Also, take a look at this github projects:</p>\n\n<ul>\n<li><p><a href=\"https://github.com/Redth/PushSharp/\" rel=\"noreferrer\" title=\"PushSharp\">PushSharp</a>: It was made in C#, but seems to be solid.</p></li>\n<li><p><a href=\"https://github.com/rs/pushd\" rel=\"noreferrer\">pushd</a>: It was made using Javascript (actually coffeescript), and requires Node.js.</p></li>\n</ul>\n\n<p>Both of them supports Andoird, Windows Phone and iOS. I haven't tested them, so I can't give you more insights.</p>\n",
                    "OwnerUserId": "263808",
                    "LastEditorUserId": "263808",
                    "LastEditDate": "2012-07-27T17:25:37.860",
                    "LastActivityDate": "2012-07-27T17:25:37.860",
                    "CommentCount": "5",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "14933735",
                "ParentRepo": "https://github.com/arangodb/arangodb",
                "StackOverflow_Post": {
                    "Id": "14933735",
                    "PostTypeId": "5",
                    "CreationDate": "2013-02-18T10:06:24.610",
                    "Score": "0",
                    "Body": "<p>ArangoDB is a multi-model NoSQL database with a flexible data model for documents, graphs, and key-values collections. It targets high-performance applications using a convenient declarative query language AQL and JavaScript extensions.</p>\n<h3>Useful links</h3>\n<ul>\n<li><a href=\"http://www.arangodb.com/\" rel=\"nofollow noreferrer\">ArangoDB Homepage</a></li>\n<li><a href=\"http://www.arangodb.org/download\" rel=\"nofollow noreferrer\">Downloads</a></li>\n<li><a href=\"http://www.arangodb.org/documentation\" rel=\"nofollow noreferrer\">Documentation</a></li>\n<li><a href=\"http://www.arangodb.org/drivers\" rel=\"nofollow noreferrer\">Drivers</a></li>\n<li><a href=\"http://www.arangodb.org/blog\" rel=\"nofollow noreferrer\">Blog</a></li>\n<li><a href=\"https://github.com/arangodb/arangodb\" rel=\"nofollow noreferrer\">Github project page</a></li>\n</ul>\n<h3>Articles</h3>\n<ul>\n<li><a href=\"https://www.sqlshack.com/migrating-sql-server-graph-databases-to-arangodb/\" rel=\"nofollow noreferrer\">Migrating SQL Server graph databases to ArangoDB</a></li>\n</ul>\n<hr />\n<h3>Related tags :</h3>\n<p><a href=\"/questions/tagged/databases\" class=\"post-tag\" title=\"show questions tagged &#39;databases&#39;\" rel=\"tag\">databases</a><a href=\"/questions/tagged/graph-databases\" class=\"post-tag\" title=\"show questions tagged &#39;graph-databases&#39;\" rel=\"tag\">graph-databases</a></p>\n",
                    "OwnerUserId": "39444",
                    "LastEditorUserId": "7031230",
                    "LastEditDate": "2022-01-23T11:49:25.067",
                    "LastActivityDate": "2022-01-23T11:49:25.067",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "SID": "19532819",
                "StackOverflow_Post": {
                    "Id": "19532819",
                    "PostTypeId": "2",
                    "ParentId": "19532210",
                    "CreationDate": "2013-10-23T04:28:57.323",
                    "Score": "1",
                    "Body": "<p>Given that you have mentioned using node.js to implement this, I'm assuming you're looking for a way to run this server side in javascript, as opposed to client side. If that's correct, does the <a href=\"https://github.com/rs/node-netmask\" rel=\"nofollow\">netmask</a> npm module cover what you need to do?</p>\n",
                    "OwnerUserId": "2658793",
                    "LastActivityDate": "2013-10-23T04:28:57.323",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "24864927",
                "ParentRepo": "https://github.com/jas-/node-libnmap",
                "StackOverflow_Post": {
                    "Id": "24864927",
                    "PostTypeId": "2",
                    "ParentId": "24433580",
                    "CreationDate": "2014-07-21T12:18:28.883",
                    "Score": "1",
                    "Body": "<p>I use <a href=\"http://nmap.org/\" rel=\"nofollow\">nmap</a> on a Unix system to get a list of devices on a network. There exists a NodeJS library for interacting with nmap (<a href=\"https://www.npmjs.org/package/node-libnmap\" rel=\"nofollow\">npm link</a> | <a href=\"https://github.com/jas-/node-libnmap\" rel=\"nofollow\">github</a>); so you should be able to get a list of IPs using the following code:</p>\n\n<pre><code>require('node-libnmap').nmap('discover', function(err, report){\n    if (err) throw err\n    console.log(report)\n});\n</code></pre>\n\n<p>and you will see the following output:</p>\n\n<pre><code>{\n    adapter: 'eth0',\n    properties: {\n        address: '10.0.2.15',\n        netmask: '255.255.255.0',\n        family: 'IPv4',\n        mac: '52:54:00:12:34:56',\n        internal: false,\n        cidr: '10.0.2.0/24',\n        hosts: 256,\n        range: { start: '10.0.2.1', end: '10.0.2.254' }\n    },\n    neighbors: [ '10.0.2.2', '10.0.2.3', '10.0.2.15' ]\n}\n</code></pre>\n\n<p>Hope that helps :)</p>\n\n<p><strong>UPDATE:</strong> I found nmap a little unreliable and found an alternative in the <a href=\"https://github.com/TheThingSystem/node-arp-a/blob/master/index.js\" rel=\"nofollow\">node-arp library</a>, the following snippet outputs an array of IPs and Mac Addresses parsed from the <code>/proc/net/arp</code> file:</p>\n\n<pre><code>var fs = require('fs');\n\nfs.readFile('/proc/net/arp', function(err, data) {\n    if (!!err) return done(err, null);\n\n    var output = [];\n    var devices = data.toString().split('\\n');\n    devices.splice(0,1);\n\n    for (i = 0; i &lt; devices.length; i++) {\n        var cols = devices[i].replace(/ [ ]*/g, ' ').split(' ');\n\n        if ((cols.length &gt; 3) &amp;&amp; (cols[0].length !== 0) &amp;&amp; (cols[3].length !== 0) &amp;&amp; cols[3] !== '00:00:00:00:00:00') {\n            output.push({\n                ip: cols[0],\n                mac: cols[3]\n            });\n        }\n    }\n\n    console.log(output);\n});\n</code></pre>\n",
                    "OwnerUserId": "1732761",
                    "LastEditorUserId": "1732761",
                    "LastEditDate": "2014-07-21T21:54:33.637",
                    "LastActivityDate": "2014-07-21T21:54:33.637",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "25069642",
                "ParentRepo": "https://github.com/quentinrossetti/version-sort",
                "StackOverflow_Post": {
                    "Id": "25069642",
                    "PostTypeId": "2",
                    "ParentId": "6832596",
                    "CreationDate": "2014-07-31T21:58:58.023",
                    "Score": "1",
                    "Body": "<p>I wrote a node module for sorting versions, you can find it here: <a href=\"https://github.com/quentinrossetti/version-sort\" rel=\"nofollow\">version-sort</a></p>\n\n<p><strong>Features</strong>:</p>\n\n<ul>\n<li>no limit of sequences '1.0.1.5.53.54654.114.1.154.45' works</li>\n<li>no limit of sequence length: '1.1546515465451654654654654138754431574364321353734' works</li>\n<li>can sort objects by version (see README)</li>\n<li>stages (like alpha, beta, rc1, rc2)</li>\n</ul>\n\n<p>Do not hesitate to open an issue if you need an other feature.</p>\n",
                    "OwnerUserId": "2352801",
                    "LastActivityDate": "2014-07-31T21:58:58.023",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "25814698",
                "ParentRepo": "https://github.com/nikestep/grunt-html-angular-validate",
                "StackOverflow_Post": {
                    "Id": "25814698",
                    "PostTypeId": "2",
                    "ParentId": "24128547",
                    "CreationDate": "2014-09-12T18:37:27.927",
                    "Score": "1",
                    "Body": "<p>From what I've found this exact error can also be caused by incorrectly closed tags deep in a template's DOM tree ex:</p>\n\n<pre><code>&lt;div&gt;\n    &lt;div&gt;\n        &lt;div&gt;&lt;/strong&gt; &lt;!-- ERROR! --&gt;\n    &lt;/div&gt;\n&lt;/div&gt;\n</code></pre>\n\n<p>use something like this to prevent this from happening at build time:</p>\n\n<p><a href=\"https://github.com/nikestep/grunt-html-angular-validate\" rel=\"nofollow\">https://github.com/nikestep/grunt-html-angular-validate</a></p>\n",
                    "OwnerUserId": "455556",
                    "LastActivityDate": "2014-09-12T18:37:27.927",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "25924812",
                "ParentRepo": "https://github.com/driftyco/ionic-cli",
                "StackOverflow_Post": {
                    "Id": "25924812",
                    "PostTypeId": "2",
                    "ParentId": "25920097",
                    "CreationDate": "2014-09-19T01:09:03.073",
                    "Score": "0",
                    "Body": "<p>Ionic has a <a href=\"http://learn.ionicframework.com/videos/\" rel=\"nofollow\">website</a> with some tutorial videos</p>\n\n<p>Also, they have a <a href=\"https://github.com/driftyco/ionic-cli\" rel=\"nofollow\">CLI</a> (command line interface), like Phonegap/Cordova but with some extra features</p>\n",
                    "OwnerUserId": "2734665",
                    "LastActivityDate": "2014-09-19T01:09:03.073",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "26634303",
                "ParentRepo": "https://github.com/LiamKarlMitchell/InfiniteSky/tree/master/vmscript",
                "StackOverflow_Post": {
                    "Id": "26634303",
                    "PostTypeId": "2",
                    "ParentId": "26633901",
                    "CreationDate": "2014-10-29T15:26:14.910",
                    "Score": "16",
                    "Body": "<p>If I understood your question correctly. You can check the <a href=\"http://nodejs.org/api/vm.html\" rel=\"noreferrer\">vm</a> module out.</p>\n\n<p>Or if you want to be able to reload <code>required</code> files, you must clear the cache and reload the file, something <a href=\"https://www.npmjs.org/package/hotload\" rel=\"noreferrer\">this package</a> can do. Check the code, you'll get the idea.</p>\n\n<blockquote>\n  <p>Modules are cached after the first time they are loaded. This means\n  (among other things) that every call to require('foo') will get\n  exactly the same object returned, if it would resolve to the same\n  file.</p>\n  \n  <p>Multiple calls to require('foo') may not cause the module code to be\n  executed multiple times. This is an important feature. With it,\n  \"partially done\" objects can be returned, thus allowing transitive\n  dependencies to be loaded even when they would cause cycles.</p>\n</blockquote>\n\n<p>More information can be found <a href=\"http://nodejs.org/docs/latest/api/modules.html#modules_caching\" rel=\"noreferrer\">here</a>.</p>\n\n<ol>\n<li><p>Delete the cached module:</p>\n\n<pre><code>delete require.cache[require.resolve('./mymodule.js')]\n</code></pre></li>\n<li><p>Require it again. <em>(maybe a <code>require</code> inside a function you can call)</em></p></li>\n</ol>\n\n<p><strong>update</strong></p>\n\n<p>Someone I know is implementing a similar approach. You can find the code <a href=\"https://github.com/LiamKarlMitchell/InfiniteSky/tree/master/vmscript\" rel=\"noreferrer\">here</a>.</p>\n",
                    "OwnerUserId": "3134069",
                    "LastEditorUserId": "3134069",
                    "LastEditDate": "2014-10-29T15:37:35.183",
                    "LastActivityDate": "2014-10-29T15:37:35.183",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "27984673",
                "ParentRepo": "https://github.com/1lobby/mailgun-js",
                "StackOverflow_Post": {
                    "Id": "27984673",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "27989304",
                    "CreationDate": "2015-01-16T13:09:38.003",
                    "Score": "14",
                    "ViewCount": "3356",
                    "Body": "<p>I'am trying to handle http post message from Mailgun bounce webhook. When sending it to Mailgun's Postbin service all data is found of course. But I'm now sending that POST to my localhost server for development purposes and all I get is empty json array. I use Test Webhook.</p>\n\n<p>Intent is to keep this simple as possible besides our main service. That for I started using nodejs/expressjs to create stand alone webservice to work as relay to receive POST messages of email bounces from Mailgun and inform admins about bounced email addresses. </p>\n\n<p>Now I can't figure why I don't get the same data as is visible in Postbin. </p>\n\n<pre><code>var express = require('express');\nvar app = express();\nvar bodyParser = require('body-parser');\nvar mailgun = require('mailgun-js')({apiKey: 'key-...', domain: 'mymailgundomain.com'});\n\napp.use(bodyParser.urlencoded({\n  extended: true\n}));\n\nfunction router(app) {\n  app.post('/webhooks/*', function (req, res, next) {\n    var body = req.body;\n\n    if (!mailgun.validateWebhook(body.timestamp, body.token, body.signature)) {\n      console.error('Request came, but not from Mailgun');\n      res.send({ error: { message: 'Invalid signature. Are you even Mailgun?' } });\n      return;\n    }\n\n    next();\n  });\n\n  app.post('/webhooks/mailgun/', function (req, res) {\n    // actually handle request here\n    console.log(\"got post message\");\n    res.send(\"ok 200\");\n  });\n}\n\napp.listen(5000, function(){\n  router(app);\n  console.log(\"listening post in port 5000\");\n});\n</code></pre>\n\n<p>I'm running this from Mailgun's Test Webhook using url like <a href=\"http://mylocalhostwithpublicip.com:5000/webhooks/mailgun\" rel=\"noreferrer\">http://mylocalhostwithpublicip.com:5000/webhooks/mailgun</a></p>\n\n<p>Code structure is copied from <a href=\"https://github.com/1lobby/mailgun-js\" rel=\"noreferrer\">https://github.com/1lobby/mailgun-js</a>. Probably I'm missing something fundamental here as I can't figure it out myself.</p>\n",
                    "OwnerUserId": "3297125",
                    "LastActivityDate": "2017-11-15T09:15:14.750",
                    "Title": "Mailgun webhook POST body seems empty",
                    "Tags": "<node.js><webhooks><mailgun>",
                    "AnswerCount": "5",
                    "CommentCount": "2",
                    "FavoriteCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "29050391",
                "ParentRepo": "https://github.com/bvaughn/jasmine-es6-promise-matchers",
                "StackOverflow_Post": {
                    "Id": "29050391",
                    "PostTypeId": "2",
                    "ParentId": "25342129",
                    "CreationDate": "2015-03-14T15:06:09.720",
                    "Score": "3",
                    "Body": "<p>Little late to the party here, but in case others find this question (as did I) - here's a new answer: Use my '<a href=\"https://github.com/bvaughn/jasmine-es6-promise-matchers\" rel=\"nofollow\">jasmine-es6-promise-matchers</a>' component. Using it, your test above would look like this:</p>\n\n<pre><code>var promise = functionThatReturnsAPromise();\nexpect(promise).toBeResolvedWith(\"Hello World\");\n</code></pre>\n\n<p>It's available on Bower and NPM (just <code>install jasmine-es6-promise-matchers</code>).</p>\n",
                    "OwnerUserId": "1123805",
                    "LastActivityDate": "2015-03-14T15:06:09.720",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "30302396",
                "ParentRepo": "https://github.com/ionic-team/ionic-cli/issues/2254#issuecomment-300654855",
                "StackOverflow_Post": {
                    "Id": "30302396",
                    "PostTypeId": "2",
                    "ParentId": "30267858",
                    "CreationDate": "2015-05-18T11:47:03.953",
                    "Score": "1",
                    "Body": "<p>I was facing the same issue and I think I've found a workable solution (even though I rather see a solution within cordova itself).</p>\n\n<p>The problem is that the cordova build script (in the run phase) assumes that if you have multiple APK's (which is the case if you add ProductFlavors) one of them must be architecture specific. Which results in an empty list:</p>\n\n<blockquote>\n  <p>Built the following apk(s):</p>\n  \n  <p>cordova-app/platforms/android/cordova/node_modules/q/q.js:126\n                      throw e;</p>\n  \n  <p>^ Error: Could not find apk architecture: x86 build-type: debug</p>\n</blockquote>\n\n<p>What I've done now is add the following to my <strong>build-extras.gradle</strong>:</p>\n\n<pre><code>android.variantFilter { variant -&gt;\n  def flavor = variant.flavors.get(0).name\n  if (project.hasProperty(\"activeFlavor\")) {\n    if (flavor != project.getProperty(\"activeFlavor\")) {\n      variant.setIgnore(true)\n    }\n  }\n  else {\n    if (flavor != \"mydefaultproductflavor\") {\n      variant.setIgnore(true)\n    }\n  }\n}\n</code></pre>\n\n<p>And I when I don't want my default flavor I need to specify the flavor using:</p>\n\n<pre><code>cordova run android -- --gradleArg=\"-PactiveFlavor=myotherflavor\"\n</code></pre>\n\n<p>For those that don't know, the <code>--</code> separator is a special symbol that, by convention, tells the program to stop parsing args afterwards. Cordova states you should use double <code>--</code> to indicate that these are platform-specific arguments.[1] Nice to know if you need to pass arguments to cordova from ionic. [2]</p>\n\n<p>Unfortunately, the cordova build process doesn't like me switching flavors without a clean (since then I've multiple .apk files again in my output directory). So when you switch first do a <code>./platforms/android/cordova/clean</code> to remove the old .apk files.</p>\n\n<p>[1] <a href=\"https://cordova.apache.org/docs/en/latest/guide/platforms/android/#using-flags\" rel=\"nofollow noreferrer\">See the note for using flags when signing an app</a></p>\n\n<p>[2] <a href=\"https://github.com/ionic-team/ionic-cli/issues/2254#issuecomment-300654855\" rel=\"nofollow noreferrer\">See for more details the comment of dwieeb on ionic-cli issue 2254.</a></p>\n",
                    "OwnerUserId": "244748",
                    "LastEditorUserId": "244748",
                    "LastEditDate": "2019-07-29T17:01:45.103",
                    "LastActivityDate": "2019-07-29T17:01:45.103",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "31437182",
                "ParentRepo": "https://github.com/Microsoft/react-native-code-push",
                "StackOverflow_Post": {
                    "Id": "31437182",
                    "PostTypeId": "2",
                    "ParentId": "31428012",
                    "CreationDate": "2015-07-15T17:30:35.587",
                    "Score": "2",
                    "Body": "<p>This is my previous answer, which is getting downvoted into oblivion because it didn't predict something cool like CodePush coming to React Native :)</p>\n\n<blockquote>\n  <p>React Native compiles to an iOS binary. Updates need to be sent to the\n  App Store, unless you're simply using React Native for its <code>WebView</code>\n  and rendering an existing webpage on the client.</p>\n</blockquote>\n\n<p><strong>Updated 6/2/16</strong></p>\n\n<p>It looks like Microsoft has a sweet plugin for CodePush <a href=\"https://github.com/Microsoft/react-native-code-push\" rel=\"nofollow\">found here</a> that lets you push changes remotely to your React Native app without having to send the update through the App Store.</p>\n\n<p>Here's a quote from the README docs:</p>\n\n<blockquote>\n  <p>NOTE: While Apple's developer agreement fully allows performing\n  over-the-air updates of JavaScript and assets (which is what enables\n  CodePush!), it is against their policy for an app to display an update\n  prompt. Because of this, we recommend that App Store-distributed apps\n  don't enable the updateDialog option when calling sync, whereas Google\n  Play and internally distributed apps (e.g. Enterprise, Fabric,\n  HockeyApp) can choose to enable/customize it.</p>\n</blockquote>\n",
                    "OwnerUserId": "2694800",
                    "LastEditorUserId": "2694800",
                    "LastEditDate": "2016-06-02T23:53:04.057",
                    "LastActivityDate": "2016-06-02T23:53:04.057",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "31598447",
                "ParentRepo": "https://github.com/azukiapp/azk",
                "StackOverflow_Post": {
                    "Id": "31598447",
                    "PostTypeId": "5",
                    "CreationDate": "2015-07-23T21:34:59.603",
                    "Score": "0",
                    "Body": "<p><code>azk</code> is an open-source orchestration tool for development environments that allows developers to install, configure and run commonly used tools for developing web applications with different open-source technologies.</p>\n\n<p>Further information about <code>azk</code> can be found at the <a href=\"http://www.azk.io/\" rel=\"nofollow noreferrer\">azk website</a>, <a href=\"http://docs.azk.io/en/index.html\" rel=\"nofollow noreferrer\">documentation </a>and <a href=\"https://github.com/azukiapp/azk\" rel=\"nofollow noreferrer\">GitHub</a>.</p>\n",
                    "OwnerUserId": "380588",
                    "LastEditorUserId": "5957979",
                    "LastEditDate": "2018-05-27T21:35:04.623",
                    "LastActivityDate": "2018-05-27T21:35:04.623",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "33242862",
                "ParentRepo": "https://github.com/hayesmaker/phase-2-e",
                "StackOverflow_Post": {
                    "Id": "33242862",
                    "PostTypeId": "2",
                    "ParentId": "6969973",
                    "CreationDate": "2015-10-20T17:18:10.420",
                    "Score": "0",
                    "Body": "<p>You can use Nightwatchjs for this... <a href=\"http://nightwatchjs.org/\" rel=\"nofollow\">http://nightwatchjs.org/</a>\nIt has an api for interacting with DOM elements, but it is also extendable.  I've written some example custom commands and assertions which you can use to end-to-end test Canvas based Phaser games, but you can see how it's done and create your own tests which execute calls to the canvas drawing api.</p>\n\n<p>see some examples here: <a href=\"https://github.com/hayesmaker/phase-2-e\" rel=\"nofollow\">https://github.com/hayesmaker/phase-2-e</a></p>\n",
                    "OwnerUserId": "467371",
                    "LastActivityDate": "2015-10-20T17:18:10.420",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "34171262",
                "ParentRepo": "https://github.com/A21z/node-cd",
                "StackOverflow_Post": {
                    "Id": "34171262",
                    "PostTypeId": "2",
                    "ParentId": "33199479",
                    "CreationDate": "2015-12-09T05:19:00.523",
                    "Score": "1",
                    "Body": "<p>You can use a post-commit Webhook from Bitbucket (see <a href=\"https://confluence.atlassian.com/bitbucket/manage-webhooks-735643732.html\" rel=\"nofollow\">documentation</a>).</p>\n\n<p>To handle the Webhook, you'll need a server that receives it, then pull the changes and executes whatever you want (your database import).</p>\n\n<p>I made a small node app that receives these hooks if you're interested in re-using it: <a href=\"https://github.com/A21z/node-cd\" rel=\"nofollow\">node-cd</a></p>\n",
                    "OwnerUserId": "681986",
                    "LastActivityDate": "2015-12-09T05:19:00.523",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "34437696",
                "ParentRepo": "https://github.com/mozilla/olympia/issues/1071",
                "StackOverflow_Post": {
                    "Id": "34437696",
                    "PostTypeId": "2",
                    "ParentId": "34332450",
                    "CreationDate": "2015-12-23T14:21:47.503",
                    "Score": "3",
                    "Body": "<p>These posts (<a href=\"https://github.com/mozilla/olympia/issues/1071\" rel=\"nofollow noreferrer\">1</a>), (<a href=\"https://github.com/mozilla/olympia/issues/1072\" rel=\"nofollow noreferrer\">2</a>) show that this error can occur if your local clock is off by more than 60 seconds with the Mozilla server.</p>\n<p>This is also documented in the <a href=\"http://olympia.readthedocs.org/en/latest/topics/api/auth.html\" rel=\"nofollow noreferrer\">Olympia 3.0 Authentication API</a> (see <code>exp</code> parameter):</p>\n<blockquote>\n<p><strong>iat</strong></p>\n<p>This is a standard JWT claim indicating the issued at time. It should be a Unix epoch timestamp and must be in UTC time.</p>\n<p><strong>exp</strong></p>\n<p>This is a standard JWT claim indicating the expiration time. It should be a Unix epoch timestamp in UTC time and must be <strong>no longer\nthan 60 seconds</strong> past the issued at time.</p>\n<h3>Note:</h3>\n<p>If you\u2019re having trouble authenticating, make sure your system clock\nis correct and consider synchronizing it with something like NTP\n(Network Time Protocol).</p>\n</blockquote>\n",
                    "OwnerUserId": "2074605",
                    "LastEditorUserId": "-1",
                    "LastEditDate": "2020-06-20T09:12:55.060",
                    "LastActivityDate": "2015-12-23T17:50:33.503",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "35821718",
                "ParentRepo": "https://github.com/mycargus/docker-grid-nightwatch",
                "StackOverflow_Post": {
                    "Id": "35821718",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "35821915",
                    "CreationDate": "2016-03-06T00:41:47.977",
                    "Score": "18",
                    "ViewCount": "6253",
                    "Body": "<p>I have a suite of tests that I want to execute in a dockerized Selenium Grid. The tests are written in Ruby using RSpec and Capybara. Also worth noting: I'm using <a href=\"https://github.com/codekitchen/dinghy\" rel=\"noreferrer\">dinghy</a> as a wrapper for docker-machine.</p>\n<p>A couple weeks ago I built a <a href=\"https://github.com/mycargus/docker-grid-nightwatch\" rel=\"noreferrer\">proof of concept</a> but with Nightwatch instead of RSpec+Capybara. That works fine but getting Capybara to work with the dockerized Selenium Grid has proven difficult.</p>\n<p>I've tried numerous configurations without success. I think the closest I've gotten to a successful configuration is the following...</p>\n<pre><code># docker-compose.yml\n\nweb:\n  image: web:latest  # built on my machine\n  environment:\n    VIRTUAL_HOST: app.under.test\n\nrspec:\n  build: .\n  dockerfile: Dockerfile\n  environment:\n    APP_HOST: app.under.test\n  volumes:\n    - .:/usr/src/app\n  links:\n    - web\n    - hub\n\nhub:\n  image: selenium/hub:latest\n  environment:\n    VIRTUAL_HOST: selenium.hub.docker\n  ports:\n    - 4444:4444\n\nnode-firefox:\n  image: selenium/node-firefox:latest\n  environment:\n    VIRTUAL_HOST: firefox.docker\n  links:\n    - hub\n\nnode-chrome:\n  image: selenium/node-chrome:latest\n  environment:\n    VIRTUAL_HOST: chrome.docker\n  links:\n    - hub\n</code></pre>\n<pre class=\"lang-sh prettyprint-override\"><code># Dockerfile for the rspec image\n\nFROM instructure/ruby-passenger:2.3\n\nUSER root\n\nENV APP_HOME /usr/src/app\nRUN mkdir -p $APP_HOME\nWORKDIR $APP_HOME\n\nCOPY Gemfile Gemfile.lock $APP_HOME/\nRUN chown -R docker:docker $APP_HOME\n\nUSER docker\nRUN bundle install --quiet --jobs 8\nUSER root\n\nCOPY . $APP_HOME\nRUN chown -R docker:docker $APP_HOME\n\nUSER docker\n</code></pre>\n<pre class=\"lang-rb prettyprint-override\"><code># spec/example_test.rb:\n\nrequire 'rspec'\nrequire 'capybara'\nrequire 'capybara/dsl'\nrequire 'selenium-webdriver'\n\nRSpec.configure do |config|\n  config.include Capybara::DSL\nend\n\ndef setup\n  url = 'http://selenium.hub.docker'\n  capabilities = Selenium::WebDriver::Remote::Capabilities.firefox\n  Capybara.app_host = ENV['APP_HOST']\n\n  Capybara.register_driver :remote_browser do |app|\n    Capybara::Selenium::Driver.new(\n      app,\n      :browser =&gt; :remote,\n      url: url,\n      desired_capabilities: capabilities\n    )\n  end\n\n  Capybara.default_driver = :remote_browser\n  Capybara.javascript_driver = :remote_browser\nend\n\ndescribe 'This is an example' do\n  it 'and it works' do\n    setup\n    visit '/'\n    expect(page.title).to eq 'Home'\n  end\nend\n</code></pre>\n<p>But this ^ configuration yields the following error upon starting the tests:</p>\n<pre class=\"lang-sh prettyprint-override\"><code>1) This is an example and it works\n     Failure/Error: visit '/'\n\n Selenium::WebDriver::Error::WebDriverError:\n   unexpected response, code=200, content-type=&quot;text/html&quot;\n   &lt;html&gt;&lt;head&gt;&lt;title&gt;Selenium Grid2.0 help&lt;/title&gt;&lt;/head&gt;&lt;body&gt;You are using grid 2.52.0&lt;br&gt;Find help on the official selenium wiki : &lt;a href='https://github.com/SeleniumHQ/selenium/wiki/Grid2' &gt;more help here&lt;/a&gt;&lt;br&gt;default monitoring page : &lt;a href='/grid/console' &gt;console&lt;/a&gt;&lt;/body&gt;&lt;/html&gt;\n # /home/docker/.gem/ruby/2.3.0/gems/selenium-webdriver-2.52.0/lib/selenium/webdriver/remote/http/common.rb:85:in `create_response'\n # /home/docker/.gem/ruby/2.3.0/gems/selenium-webdriver-2.52.0/lib/selenium/webdriver/remote/http/default.rb:90:in `request'\n # /home/docker/.gem/ruby/2.3.0/gems/selenium-webdriver-2.52.0/lib/selenium/webdriver/remote/http/common.rb:59:in `call'\n # /home/docker/.gem/ruby/2.3.0/gems/selenium-webdriver-2.52.0/lib/selenium/webdriver/remote/bridge.rb:645:in `raw_execute'\n # /home/docker/.gem/ruby/2.3.0/gems/selenium-webdriver-2.52.0/lib/selenium/webdriver/remote/bridge.rb:123:in `create_session'\n # /home/docker/.gem/ruby/2.3.0/gems/selenium-webdriver-2.52.0/lib/selenium/webdriver/remote/bridge.rb:87:in `initialize'\n # /home/docker/.gem/ruby/2.3.0/gems/selenium-webdriver-2.52.0/lib/selenium/webdriver/common/driver.rb:59:in `new'\n # /home/docker/.gem/ruby/2.3.0/gems/selenium-webdriver-2.52.0/lib/selenium/webdriver/common/driver.rb:59:in `for'\n # /home/docker/.gem/ruby/2.3.0/gems/selenium-webdriver-2.52.0/lib/selenium/webdriver.rb:86:in `for'\n # /home/docker/.gem/ruby/2.3.0/gems/capybara-2.6.2/lib/capybara/selenium/driver.rb:13:in `browser'\n # /home/docker/.gem/ruby/2.3.0/gems/capybara-2.6.2/lib/capybara/selenium/driver.rb:45:in `visit'\n # /home/docker/.gem/ruby/2.3.0/gems/capybara-2.6.2/lib/capybara/session.rb:232:in `visit'\n # /home/docker/.gem/ruby/2.3.0/gems/capybara-2.6.2/lib/capybara/dsl.rb:51:in `block (2 levels) in &lt;module:DSL&gt;'\n # ./spec/example_test.rb:31:in `block (2 levels) in &lt;top (required)&gt;'\n</code></pre>\n<p>Any ideas? What am I missing?</p>\n<h2>Update</h2>\n<p>Got it!</p>\n<pre class=\"lang-rb prettyprint-override\"><code>def setup\n  url = 'http://selenium.hub.docker/wd/hub'\n  capabilities = Selenium::WebDriver::Remote::Capabilities.firefox\n  Capybara.app_host = &quot;http://#{ENV['APP_HOST']}&quot;\n  Capybara.run_server = false\n\n  Capybara.register_driver :remote_browser do |app|\n    Capybara::Selenium::Driver.new(\n      app,\n      :browser =&gt; :remote,\n      url: url,\n      desired_capabilities: capabilities\n    )\n  end\n\n  Capybara.default_driver = :remote_browser\n  Capybara.javascript_driver = :remote_browser\nend\n</code></pre>\n<p>The key---in addition to <code>Capybara.run_server = false</code> and prepending <code>http://</code> to the app_host---was specifying <code>/wd/hub</code> on the url.</p>\n<p><strong>Working solution <a href=\"https://github.com/mycargus/docker-grid-rspec-capybara\" rel=\"noreferrer\">here</a>.</strong></p>\n",
                    "OwnerUserId": "3038677",
                    "LastEditorUserId": "-1",
                    "LastEditDate": "2020-06-20T09:12:55.060",
                    "LastActivityDate": "2017-02-24T11:52:27.047",
                    "Title": "How to configure Capybara to run tests in a dockerized Selenium Grid?",
                    "Tags": "<rspec><capybara><docker-compose><selenium-grid><dinghy>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "FavoriteCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "36513492",
                "ParentRepo": "https://github.com/jkutianski/meetup-api/wiki#limits",
                "StackOverflow_Post": {
                    "Id": "36513492",
                    "PostTypeId": "2",
                    "ParentId": "35121504",
                    "CreationDate": "2016-04-09T06:25:54.940",
                    "Score": "2",
                    "Body": "<p>It seems the maximum number of results you can get <strong>at once</strong> through the API is 200 - see <a href=\"https://github.com/jkutianski/meetup-api/wiki#limits\" rel=\"nofollow\">https://github.com/jkutianski/meetup-api/wiki#limits</a>.</p>\n\n<p>You can however make multiple requests as per <a href=\"http://www.meetup.com/meetup_api/#making_request\" rel=\"nofollow\">http://www.meetup.com/meetup_api/#making_request</a>. It says you need to use the page and offset parameters. From the meetup.com link:</p>\n\n<p><em>page -- the page size (maximum number of results in each response) to use on the results</em></p>\n\n<p><em>offset -- the starting page for results to return. For example, when page = 10, specifying \"offset=0\" will bring back records 1-10, \"offset=1\" will bring records 11-20, etc.</em></p>\n",
                    "OwnerUserId": "1276467",
                    "LastEditorUserId": "1276467",
                    "LastEditDate": "2016-04-09T07:44:09.173",
                    "LastActivityDate": "2016-04-09T07:44:09.173",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "36569740",
                "ParentRepo": "https://github.com/motdotla/node-lambda",
                "StackOverflow_Post": {
                    "Id": "36569740",
                    "PostTypeId": "2",
                    "ParentId": "36489958",
                    "CreationDate": "2016-04-12T09:53:02.417",
                    "Score": "1",
                    "Body": "<p>I suspect you wanted to use a form of git-deployment and run the <code>aws cli</code> commands mentioned in the tutorials as post-commit hooks? CodeCommit offers <em>only</em> source control, without hooks or shell access, so it can't act as the packaging/deployment machine. </p>\n\n<p>The easiest solution would be to use a local machine to do this, optionally cloning contents from CodeCommit or a local repository. There are tools to automate this like <a href=\"https://github.com/motdotla/node-lambda\" rel=\"nofollow\">node-lambda</a> or <a href=\"https://github.com/ThoughtWorksStudios/node-aws-lambda\" rel=\"nofollow\">node-aws-lambda</a></p>\n\n<p>The alternative, as mentioned in the comments, would be to create a small EC2 instance to act as the packaging machine.</p>\n",
                    "OwnerUserId": "134204",
                    "LastActivityDate": "2016-04-12T09:53:02.417",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "36904756",
                "ParentRepo": "https://github.com/Microsoft/code-push",
                "StackOverflow_Post": {
                    "Id": "36904756",
                    "PostTypeId": "2",
                    "ParentId": "36892747",
                    "CreationDate": "2016-04-28T03:30:57.257",
                    "Score": "1",
                    "Body": "<p>I worked for react native for several months\uff0cand here is my answer:</p>\n\n<blockquote>\n  <p>Is it possible to use a third party's React component in a React Native rendering view?</p>\n</blockquote>\n\n<p>No,react component for Browser cannot use for mobile.but there are many mobile specific component.You can find here:<a href=\"https://react.parts/native\" rel=\"nofollow\">React.parts</a></p>\n\n<blockquote>\n  <p>What do I lose in terms of backward compatibility and UI performance to fully utilize React Native in mobile? Do low-end devices handle it well?</p>\n</blockquote>\n\n<p>You can test <a href=\"https://facebook.github.io/react-native/showcase.html\" rel=\"nofollow\">these apps</a> on low-end devices to see whether react native can meet your need.</p>\n\n<blockquote>\n  <p>Is debugging React and React Native a pain? This question may and should be responded subjectively.</p>\n</blockquote>\n\n<p>No,debug React Native code is really easy and efficient.</p>\n\n<blockquote>\n  <p>When I use React Native, is it possible to push updates to my app's that specific part without publishing an update to Google Play or Apple App Store?</p>\n</blockquote>\n\n<p>Yes,you can do these things easily with <a href=\"https://github.com/Microsoft/code-push\" rel=\"nofollow\">Code Push</a>.</p>\n\n<blockquote>\n  <p>Is React or React Native incompatible with CoffeeScript on the server side? If so, can I avoid that with a custom build flow to ultimately end up with only Javascript files which contain all the server code?</p>\n</blockquote>\n\n<p>There isn't server side code in React Native,all your js code is in a single js file called bundle.js. the compile process is automatic with packager.sh witch provided from React Native,check this <a href=\"https://github.com/facebook/react-native/tree/master/packager\" rel=\"nofollow\">link</a>.</p>\n",
                    "OwnerUserId": "663540",
                    "LastActivityDate": "2016-04-28T03:30:57.257",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "37176887",
                "ParentRepo": "https://github.com/bojand/mailgun-js",
                "StackOverflow_Post": {
                    "Id": "37176887",
                    "PostTypeId": "2",
                    "ParentId": "37176821",
                    "CreationDate": "2016-05-12T03:46:24.253",
                    "Score": "3",
                    "Body": "<p>Checkout mailgun:</p>\n\n<p><a href=\"https://github.com/bojand/mailgun-js\" rel=\"nofollow\">https://github.com/bojand/mailgun-js</a></p>\n\n<p>It's really easy to setup and use! Here's a snippet from their documentation:</p>\n\n<pre><code>var filepath = path.join(__dirname, 'mailgun_logo.png');\nvar file = fs.readFileSync(filepath);\n\nvar data = {\n  from: 'Excited User &lt;me@samples.mailgun.org&gt;',\n  to: 'serobnic@mail.ru',\n  subject: 'Hello',\n  text: 'Testing some Mailgun awesomness!',\n  attachment: file\n};\n\nmailgun.messages().send(data, function (error, body) {\n  console.log(body);\n});\n</code></pre>\n\n<p>You can do a lot with the package, includes the ability to attach files!</p>\n",
                    "OwnerUserId": "4140346",
                    "LastActivityDate": "2016-05-12T03:46:24.253",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "38301984",
                "ParentRepo": "https://github.com/jonkemp/inline-css",
                "StackOverflow_Post": {
                    "Id": "38301984",
                    "PostTypeId": "1",
                    "CreationDate": "2016-07-11T08:06:40.687",
                    "Score": "0",
                    "ViewCount": "344",
                    "Body": "<p>I'm using standalone js script in nashron and in browser. Why in nashron I'm getting  </p>\n\n<pre><code>javax.script.ScriptException: TypeError: Cannot read property \"prototype\" from undefined in &lt;eval&gt; at line number 21571 \n</code></pre>\n\n<p>while in browser console script is working perfectly fine?\ncode i'm talking about is browserified <a href=\"https://github.com/jonkemp/inline-css\" rel=\"nofollow\">https://github.com/jonkemp/inline-css</a>\nit's about 36k lines. This question is not about how to fix the code it's, rather about how to force nashorn to act like a browser interpreter</p>\n",
                    "OwnerUserId": "3642353",
                    "LastEditorUserId": "3642353",
                    "LastEditDate": "2016-07-11T08:23:56.007",
                    "LastActivityDate": "2016-11-15T23:26:45.703",
                    "Title": "Nashorn vs browser script",
                    "Tags": "<javascript><java><nashorn>",
                    "AnswerCount": "1",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "38471404",
                "ParentRepo": "https://github.com/tnguyen14/auth/blob/master/index.js",
                "StackOverflow_Post": {
                    "Id": "38471404",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "38758325",
                    "CreationDate": "2016-07-20T02:36:34.263",
                    "Score": "0",
                    "ViewCount": "2421",
                    "Body": "<p>I am trying to implement a simple Google OAuth for my Express.js app using passport.js following this guide (just replace <code>facebook</code> with <code>google</code>) <a href=\"https://github.com/passport/express-4.x-facebook-example/blob/master/server.js\" rel=\"nofollow\">https://github.com/passport/express-4.x-facebook-example/blob/master/server.js</a></p>\n\n<p>When I try it locally, things seem to be working well. When I deploy it to my Ubuntu production server, I get a <code>502 Bad Gateway</code> error during the redirect callback from Google to the <code>/login/google/return</code> endpoint.</p>\n\n<pre><code>app.get('/login/google/return', \n  passport.authenticate('google', { failureRedirect: '/login' }),\n  function(req, res) {\n    res.redirect('/');\n  });\n</code></pre>\n\n<p>If I comment out the the line <code>passport.authenticate('google', {..})</code>, then the error goes away. Upon inspecting nginx error log, I see this error</p>\n\n<pre><code>upstream sent too big header while reading response header from upstream\n</code></pre>\n\n<p>Here's the server configuration block for nginx:</p>\n\n<pre><code>location /auth/ {\n   proxy_pass http://0.0.0.0:3000/;\n}\n</code></pre>\n\n<p>Which means that I would log in to google by going to <code>https://example.com/auth/login/google</code>, being redirected to <code>https://example.com/auth/login/google/return?code=4/adasfdafdsfd#</code>, and then the 502 error happens.</p>\n\n<p>I have tried setting up a similar nginx environment on my OS X development machine, but the problem does not occur there.</p>\n\n<p>I have also tried to add the following to the nginx block configuration, but that doesn't seem to help either</p>\n\n<pre><code>proxy_buffers 8 16k;\n</code></pre>\n\n<p>I am at my wit's end as to how to debug/ solve this problem. Anyone's suggestion would be greatly appreciated. Here's the link to my project so far <a href=\"https://github.com/tnguyen14/auth/blob/master/index.js\" rel=\"nofollow\">https://github.com/tnguyen14/auth/blob/master/index.js</a></p>\n",
                    "OwnerUserId": "1368032",
                    "LastActivityDate": "2022-08-26T00:13:29.850",
                    "Title": "Passport.js express google oauth 502 Bad Gateway on nginx",
                    "Tags": "<node.js><express><nginx><oauth><passport.js>",
                    "AnswerCount": "1",
                    "CommentCount": "3",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "39203407",
                "ParentRepo": "https://github.com/steemit/steemit.com",
                "StackOverflow_Post": {
                    "Id": "39203407",
                    "PostTypeId": "1",
                    "CreationDate": "2016-08-29T09:56:58.070",
                    "Score": "1",
                    "ViewCount": "3460",
                    "Body": "<p>I am setting up a copy of steemit cllient from <a href=\"https://github.com/steemit/steemit.com\" rel=\"nofollow noreferrer\">https://github.com/steemit/steemit.com</a>.</p>\n\n<p>everything works in development environment but when I try to run same in production following steps provided in github repo, it gives error in console : \"Failed to load resource: net::ERR_CONNECTION_REFUSED\" <a href=\"https://i.stack.imgur.com/T8L6u.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/T8L6u.png\" alt=\"(screenshot attached)\"></a></p>\n\n<p>I am unable to relate this issue to anything.  I am relatively new to webpack. Any help will be appreciated.</p>\n",
                    "OwnerUserId": "4371424",
                    "LastEditorUserId": "18846",
                    "LastEditDate": "2016-08-30T16:00:09.767",
                    "LastActivityDate": "2016-08-30T16:00:09.767",
                    "Title": "\"Failed to load resource: net::ERR_CONNECTION_REFUSED\" for assets, css, app.js and vendor.js in production (react, babel, webpack)",
                    "Tags": "<node.js><reactjs><webpack><babeljs>",
                    "AnswerCount": "1",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "40184234",
                "ParentRepo": "https://github.com/marcelklehr/smokesignal",
                "StackOverflow_Post": {
                    "Id": "40184234",
                    "PostTypeId": "2",
                    "ParentId": "15619006",
                    "CreationDate": "2016-10-21T19:33:27.760",
                    "Score": "0",
                    "Body": "<p>This package lets you build a simple p2p message passing network over TCP; I've never tried it. It seems quite simple compared to JGroups but can be a starting point:</p>\n\n<p><a href=\"https://github.com/marcelklehr/smokesignal\" rel=\"nofollow\">smokesignal</a></p>\n",
                    "OwnerUserId": "659165",
                    "LastEditorUserId": "2267723",
                    "LastEditDate": "2016-10-21T19:57:19.870",
                    "LastActivityDate": "2016-10-21T19:57:19.870",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "43614914",
                "ParentRepo": "https://github.com/sebsylvester/parse-server-mailgun",
                "StackOverflow_Post": {
                    "Id": "43614914",
                    "PostTypeId": "2",
                    "ParentId": "43362200",
                    "CreationDate": "2017-04-25T15:25:59.413",
                    "Score": "0",
                    "Body": "<p>You can provide custom templates in the mailgun-adapter configuration, as described in the <a href=\"https://github.com/sebsylvester/parse-server-mailgun\" rel=\"nofollow noreferrer\">docs</a>.</p>\n\n<p>Currently there is no built-in way to support multiple languages. And since Mustache is used as templating engine, it's also not possible to have any custom i18n logic inside the templates. However, recently there was a discussion in the <em>parseopensource</em> Slack channel where some users were talking about plans to contribute such a feature. </p>\n",
                    "OwnerUserId": "5471218",
                    "LastActivityDate": "2017-04-25T15:25:59.413",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "44725909",
                "ParentRepo": "https://github.com/sendgrid/sendgrid-oai",
                "StackOverflow_Post": {
                    "Id": "44725909",
                    "PostTypeId": "2",
                    "ParentId": "44684016",
                    "CreationDate": "2017-06-23T16:12:44.677",
                    "Score": "1",
                    "Body": "<p>Another option is to use <a href=\"http://stoplight.io/platform/prism\" rel=\"nofollow noreferrer\">Prism</a> in conjunction with our <a href=\"https://github.com/sendgrid/sendgrid-oai\" rel=\"nofollow noreferrer\">Open API definition</a>. This will create a local mocked version of the SendGrid API so you can test against any of our endpoints.</p>\n\n<p>Then you can run <code>prism run --mock --list --spec https://raw.githubusercontent.com/sendgrid/sendgrid-oai/master/oai_stoplight.json</code> from your command line.</p>\n\n<p>To have Prism auto-start, please see <a href=\"https://github.com/sendgrid/sendgrid-python/blob/master/test/test_sendgrid.py#L18\" rel=\"nofollow noreferrer\">this example</a>.</p>\n",
                    "OwnerUserId": "1538597",
                    "LastActivityDate": "2017-06-23T16:12:44.677",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "45233845",
                "ParentRepo": "https://github.com/TooTallNate/superagent-proxy",
                "StackOverflow_Post": {
                    "Id": "45233845",
                    "PostTypeId": "1",
                    "CreationDate": "2017-07-21T09:18:28.440",
                    "Score": "2",
                    "ViewCount": "4147",
                    "Body": "<p>I find it hard to use <a href=\"https://github.com/TooTallNate/superagent-proxy\" rel=\"nofollow noreferrer\">superagent-proxy</a>, just with the simple code:</p>\n\n<pre><code>const superagent = require('superagent')\nrequire('superagent-proxy')(superagent)\n\nlet proxy = 'http://221.237.122.22:8118' // \u8bbe\u7f6e\u4ee3\u7406\n\nsuperagent\n  .get('http://sf.gg')\n  .proxy(proxy)\n  .timeout(3600*1000)\n  .end((err, res) =&gt; {\n    console.log(res)\n    console.log(res.status, res.headers);\n    console.log(res.body);\n  })\n</code></pre>\n\n<p>but when run, it cannot get an reply, why?</p>\n",
                    "OwnerUserId": "5064385",
                    "LastActivityDate": "2021-11-12T08:24:08.670",
                    "Title": "how to use superagent-proxy?",
                    "Tags": "<node.js><superagent>",
                    "AnswerCount": "2",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "45621367",
                "ParentRepo": "https://github.com/tcarlsen/atom-htmlhint",
                "StackOverflow_Post": {
                    "Id": "45621367",
                    "PostTypeId": "2",
                    "ParentId": "45621308",
                    "CreationDate": "2017-08-10T18:45:12.840",
                    "Score": "1",
                    "Body": "<p>you can use the below package for Atom to validate HTML</p>\n\n<ol>\n<li><a href=\"https://atom.io/packages/w3c-validation\" rel=\"nofollow noreferrer\">https://atom.io/packages/w3c-validation</a> </li>\n<li>HTMLhint(<a href=\"https://github.com/tcarlsen/atom-htmlhint\" rel=\"nofollow noreferrer\">https://github.com/tcarlsen/atom-htmlhint</a>)</li>\n<li><a href=\"https://github.com/atom/bracket-matcher\" rel=\"nofollow noreferrer\">https://github.com/atom/bracket-matcher</a></li>\n</ol>\n",
                    "OwnerUserId": "3162724",
                    "LastActivityDate": "2017-08-10T18:45:12.840",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "45822169",
                "ParentRepo": "https://github.com/Tachyus/gluon/issues/47#issuecomment-324064763",
                "StackOverflow_Post": {
                    "Id": "45822169",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "45822711",
                    "CreationDate": "2017-08-22T15:51:33.600",
                    "Score": "3",
                    "ViewCount": "143",
                    "Body": "<p>Consider the following TypeScript:</p>\n\n<pre><code>export namespace Test {\n    export const test = \"test\";\n}\nexport namespace Wrapper {\n    export namespace Test {\n        export const value = Test.test; // \"&lt;script&gt;\".Wrapper.Test has no exported member 'test'.\n    }\n}\n</code></pre>\n\n<p>Due to the way TypeScript compiles to JavaScript, the second declaration of <code>Test</code> within <code>Wrapper</code> will create a new scope where <code>Test</code> will refer only to itself. The top-level <code>Test</code> is unavailable within that scope, at least according to the TypeScript type checker.</p>\n\n<p>I'm generating the TypeScript from another language where this sort of namespace collision is no big deal. In TypeScript, however, it results in a compilation error. The application still runs, so this seems to be a TypeScript type checking issue and not a real JavaScript runtime issue.</p>\n\n<p>Are there any known workarounds within TypeScript?</p>\n\n<p>I've got a repro set up in a <a href=\"https://github.com/Tachyus/gluon/issues/47#issuecomment-324064763\" rel=\"nofollow noreferrer\">Gluon issue</a>.</p>\n",
                    "OwnerUserId": "2089257",
                    "LastEditorUserId": "2089257",
                    "LastEditDate": "2017-08-22T16:06:38.210",
                    "LastActivityDate": "2017-08-22T16:22:09.723",
                    "Title": "How can you reference a namespace declared outside the current namespace with the same name?",
                    "Tags": "<typescript><namespaces>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "45925799",
                "ParentRepo": "https://github.com/mucsi96/nightwatch-cucumber/tree/master/examples/babel-example",
                "StackOverflow_Post": {
                    "Id": "45925799",
                    "PostTypeId": "2",
                    "ParentId": "45813468",
                    "CreationDate": "2017-08-28T19:07:45.167",
                    "Score": "0",
                    "Body": "<p>To be able to use complex asynchronous operations I suggest to use the new <code>async</code> functions. If your NodeJs version does not support it natively I suggest to use Babel. There is an example for that in the <code>nightwatch-cucumber</code> <a href=\"https://github.com/mucsi96/nightwatch-cucumber/tree/master/examples/babel-example\" rel=\"nofollow noreferrer\">example folder</a>. To be able to refresh the page until some condition you can use the following example.</p>\n\n<pre><code>When(/^\"([^\"]*)\" task status changed$/, async (taskName) =&gt; {\n  let needRefresh = true;\n\n  do {\n    await client.refresh();\n    await client.pause(10000);\n\n    needRefresh = await client.getTagName(...\n  } while (!needRefresh)\n});    \n</code></pre>\n",
                    "OwnerUserId": "4776810",
                    "LastActivityDate": "2017-08-28T19:07:45.167",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "46066946",
                "ParentRepo": "https://github.com/mucsi96/nightwatch-cucumber-example",
                "StackOverflow_Post": {
                    "Id": "46066946",
                    "PostTypeId": "2",
                    "ParentId": "45937104",
                    "CreationDate": "2017-09-06T04:45:17.313",
                    "Score": "1",
                    "Body": "<p>In my personal experience, the best way to do BDD is adding cucumber that uses <a href=\"https://github.com/cucumber/cucumber/wiki/Gherkin\" rel=\"nofollow noreferrer\">gherkin</a> syntax. It is clearer and helps a lot to reduce redundant code if you know to use it well. There is a <a href=\"https://github.com/mucsi96/nightwatch-cucumber\" rel=\"nofollow noreferrer\">Nightwatch npm plugin</a> to add cucumber, once you have added it you have to create your .feature file like the following</p>\n\n<pre><code>Feature: Check elements are present\nScenario Outline:\nGiven the user enters on a &lt;page&gt;\nThen .footer-top, .footer-middle and .footer-bottom class should be enabled\n\nExamples:\n|page|\n|page.com/page1|\n|page.com/page2|\n|page.com/page3|\n</code></pre>\n\n<p>And your step definitions (where you declare what will do each step) it automatically will run each step for each url provided in the examples (note the <code>&lt;page&gt;</code> flag that will be replaced on the example, first row is the name of the tag).</p>\n\n<p>Take a look to the <a href=\"https://github.com/mucsi96/nightwatch-cucumber-example\" rel=\"nofollow noreferrer\">examples</a></p>\n",
                    "OwnerUserId": "4637140",
                    "LastActivityDate": "2017-09-06T04:45:17.313",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "46275704",
                "ParentRepo": "https://github.com/marmelab/comfygure",
                "StackOverflow_Post": {
                    "Id": "46275704",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "46275705",
                    "CreationDate": "2017-09-18T09:17:41.950",
                    "Score": "1",
                    "ViewCount": "24",
                    "Body": "<p>Using <a href=\"https://github.com/marmelab/comfygure\" rel=\"nofollow noreferrer\">comfy</a>, how can I add a new configuration to my environment ?</p>\n\n<ul>\n<li>Environment: production</li>\n<li>Configuration file: config.json</li>\n</ul>\n",
                    "OwnerUserId": "1665540",
                    "LastActivityDate": "2017-09-18T09:17:41.950",
                    "Title": "How do I add a new configuration to my environment using comfy?",
                    "Tags": "<configuration>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "46630886",
                "ParentRepo": "https://github.com/metaburn/doocrate",
                "StackOverflow_Post": {
                    "Id": "46630886",
                    "PostTypeId": "2",
                    "ParentId": "46629170",
                    "CreationDate": "2017-10-08T12:02:15.097",
                    "Score": "5",
                    "Body": "<p>So the way I've solved it is I've created another <code>Collection</code> Called <code>admins</code></p>\n\n<p>Then I've just added the <code>uid</code> of the user I needed there as such -\n Here is my database structure - <a href=\"https://i.imgur.com/RFxrKYT.png\" rel=\"noreferrer\">https://i.imgur.com/RFxrKYT.png</a></p>\n\n<p>And here is the rules</p>\n\n<pre><code>service cloud.firestore {\n  match /databases/{database}/documents {\n\n    function isAdmin() {\n      return exists(/databases/$(database)/documents/admins/$(request.auth.uid));\n    }\n\n    match /tasks/{anyTask} {\n    allow read: if request.auth != null;\n      allow create: if request.auth != null;\n      allow update: if request.auth != null &amp;&amp; isAdmin();\n      allow delete: if request.auth != null &amp;&amp; isAdmin();\n    }\n  }\n}\n</code></pre>\n\n<p>You can view my full Open Source project here:\n<a href=\"https://github.com/metaburn/doocrate\" rel=\"noreferrer\">https://github.com/metaburn/doocrate</a></p>\n",
                    "OwnerUserId": "395804",
                    "LastActivityDate": "2017-10-08T12:02:15.097",
                    "CommentCount": "7",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "46829045",
                "ParentRepo": "https://github.com/firebase/friendlypix-web/blob/master/database-rules.json",
                "StackOverflow_Post": {
                    "Id": "46829045",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "46830800",
                    "CreationDate": "2017-10-19T11:40:27.167",
                    "Score": "0",
                    "ViewCount": "37",
                    "Body": "<p>I have used the FriendlyPix database as a base for my database.</p>\n\n<p>I have tried to apply the following security rule to:</p>\n\n<ol>\n<li>Only allow authenticated user to insert new post</li>\n<li>Edit or delete existing post can only be performed by post creator</li>\n</ol>\n\n<p>I have used the security rule from the <a href=\"https://github.com/firebase/friendlypix-web/blob/master/database-rules.json\" rel=\"nofollow noreferrer\">FriendlyPix GitHub repository</a>, however when I run the simulator I always get \"Write Denied\" error message.</p>\n\n<p>I have tried various versions of the write rule, but all fail.</p>\n\n<p><a href=\"https://i.stack.imgur.com/7Uk0h.jpg\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/7Uk0h.jpg\" alt=\"enter image description here\"></a></p>\n\n<p><a href=\"https://i.stack.imgur.com/LQemg.jpg\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/LQemg.jpg\" alt=\"enter image description here\"></a></p>\n\n<p><a href=\"https://i.stack.imgur.com/QzHbE.jpg\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/QzHbE.jpg\" alt=\"enter image description here\"></a></p>\n\n<p><a href=\"https://i.stack.imgur.com/FfXF2.jpg\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/FfXF2.jpg\" alt=\"enter image description here\"></a></p>\n\n<p><a href=\"https://i.stack.imgur.com/UaZMl.jpg\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/UaZMl.jpg\" alt=\"enter image description here\"></a></p>\n\n<p>Can someone please tell me what I am doing wrong?</p>\n",
                    "OwnerUserId": "1576800",
                    "LastEditorUserId": "209103",
                    "LastEditDate": "2017-10-19T13:11:46.403",
                    "LastActivityDate": "2017-10-19T13:16:30.607",
                    "Title": "FriendlyPix secruity write rule not working",
                    "Tags": "<firebase><firebase-realtime-database><firebase-security>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "47002401",
                "ParentRepo": "https://github.com/sibartlett/homebridge-wink3/blob/master/src/devices/shade.js",
                "StackOverflow_Post": {
                    "Id": "47002401",
                    "PostTypeId": "1",
                    "CreationDate": "2017-10-29T16:14:41.477",
                    "Score": "5",
                    "ViewCount": "468",
                    "Body": "<p>I am trying to modify the <code>homebridge-wink3</code> code to add a variable so I can track the state in. I have 5 shades in my house, so each instance of the variable needs to be unique.</p>\n\n<p>In the <code>shade.js</code> file, it has;</p>\n\n<pre><code>exports.default = ({ Characteristic, Service }) =&gt; {\n  return {\n    type: \"shade\",\n    group: \"shades\",\n    services: [{\n      service: Service.WindowCovering,\n      characteristics: [{\n        characteristic: Characteristic.TargetPosition,\n        get: (state, desired_state) =&gt; desired_state.position * 100,\n</code></pre>\n\n<p>I'd like to change the <code>get</code> (and <code>set</code> elsewhere in the code) so it uses a local variable <code>lastState</code> to track state.</p>\n\n<pre><code>    get: (state, desired_state) =&gt; { \n                if (desired_state.position != null) {\n                        lastState = desired_state.position * 100;\n                }\n                else if (lastState != undefined) {\n                        desired_state.position = lastState / 100;\n                }\n                return lastState;\n</code></pre>\n\n<p>I've spent hours trying to work out how to have the code maintain individual variables per shade (object instance), but they always seem to be sharing the same instance of the <code>lastState</code> variable.</p>\n\n<p>What do I need to do here?</p>\n\n<p>See <a href=\"https://github.com/sibartlett/homebridge-wink3/blob/master/src/devices/shade.js\" rel=\"noreferrer\">https://github.com/sibartlett/homebridge-wink3/blob/master/src/devices/shade.js</a> for the code.</p>\n",
                    "OwnerUserId": "3583987",
                    "LastActivityDate": "2017-11-04T12:53:47.663",
                    "Title": "Javascript Export - Instantiate Variables/Objects",
                    "Tags": "<javascript><export>",
                    "AnswerCount": "2",
                    "CommentCount": "4",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "47259217",
                "ParentRepo": "https://github.com/Microsoft/code-push-vsts-extension/issues/27",
                "StackOverflow_Post": {
                    "Id": "47259217",
                    "PostTypeId": "2",
                    "ParentId": "47220441",
                    "CreationDate": "2017-11-13T07:38:27.900",
                    "Score": "0",
                    "Body": "<p>The <a href=\"https://marketplace.visualstudio.com/items?itemName=ms-vsclient.code-push\" rel=\"nofollow noreferrer\">CodePush - Release (Cordova)</a> task is using the default working directory, and the directory can not be specify for this task. </p>\n\n<p>I add an issue <a href=\"https://github.com/Microsoft/code-push-vsts-extension/issues/27\" rel=\"nofollow noreferrer\">Can not specity the directory to execute the command code-push release-cordova</a>, you can follow up.</p>\n\n<p>The work around for now is using <strong>Command Line task</strong> instead. Settings for the Command Line task as below:</p>\n\n<p>Tool: <code>cd</code> </p>\n\n<p>Arguments: <code>path/to/your/cordova/app &amp; code-push login &lt;token&gt; &amp; code-push release-cordova AppName OS</code></p>\n\n<p><strong>Besides:</strong> CodePush task also can parse the variable <code>Build.SourceDirectory</code>, so you can define this variable with the value  <code>$(Build.SourcesDirectory)\\path\\to\\cordova\\app</code> in Variables Tab (below is an example).</p>\n\n<p><a href=\"https://i.stack.imgur.com/a2cAA.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/a2cAA.png\" alt=\"enter image description here\"></a></p>\n",
                    "OwnerUserId": "6936103",
                    "LastEditorUserId": "6936103",
                    "LastEditDate": "2017-11-15T09:43:50.240",
                    "LastActivityDate": "2017-11-15T09:43:50.240",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "47404735",
                "ParentRepo": "https://github.com/anatoliyarkhipov/nightwatch-firefox",
                "StackOverflow_Post": {
                    "Id": "47404735",
                    "PostTypeId": "1",
                    "CreationDate": "2017-11-21T03:33:35.210",
                    "Score": "0",
                    "ViewCount": "507",
                    "Body": "<p>Here is a reproduction repo:\n<a href=\"https://github.com/anatoliyarkhipov/nightwatch-firefox\" rel=\"nofollow noreferrer\">https://github.com/anatoliyarkhipov/nightwatch-firefox</a></p>\n\n<p>It's a clear installation of <code>nightwatch</code> and <code>webdriver-manager</code>. The test opens <a href=\"http://example.com\" rel=\"nofollow noreferrer\">http://example.com</a>, clicks on the link and checks some content on the next page.</p>\n\n<p>The problem is that if I run it in Firefox, it fails on the first step where we check that <code>&lt;body&gt;</code> is visible. If we change <code>firefox</code> to <code>chrome</code> in <code>nightwatch.conf.js</code>, then the test will pass.</p>\n\n<p>I run it on Windows 10, Firefox 57.0 (64-bit).</p>\n\n<p>What am I doing wrong?</p>\n",
                    "OwnerUserId": "1663736",
                    "LastEditorUserId": "1663736",
                    "LastEditDate": "2017-11-21T03:43:26.510",
                    "LastActivityDate": "2017-11-22T15:14:40.417",
                    "Title": "A minimal Nightwatch test doesn't work with Firefox 57",
                    "Tags": "<nightwatch.js><webdriver-manager>",
                    "AnswerCount": "3",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "47490875",
                "ParentRepo": "https://github.com/abauzac/nightwatch-typescript",
                "StackOverflow_Post": {
                    "Id": "47490875",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "47490888",
                    "CreationDate": "2017-11-25T21:54:49.760",
                    "Score": "1",
                    "ViewCount": "1198",
                    "Body": "<p>Before exposing the problem, the project I'm referring is here : <a href=\"https://github.com/abauzac/nightwatch-typescript\" rel=\"nofollow noreferrer\">https://github.com/abauzac/nightwatch-typescript</a></p>\n\n<p>My problem is with the Nightwatch definitions, it export a lot of interfaces globally (not inside a namespace or module <a href=\"https://github.com/DefinitelyTyped/DefinitelyTyped/blob/38bd4efd5dc8c666f70d77b020a0b64a13ce3980/types/nightwatch/index.d.ts\" rel=\"nofollow noreferrer\">https://github.com/DefinitelyTyped/DefinitelyTyped/blob/38bd4efd5dc8c666f70d77b020a0b64a13ce3980/types/nightwatch/index.d.ts</a>), including : </p>\n\n<p>./node_modules/@types/nightwatch:</p>\n\n<pre><code>export interface NightwatchCustomCommands { /* empty interface */ }\nexport interface NightwatchCustomAssertions { /* empty interface */ }\n\nexport interface NightwatchBrowser extends NightwatchCustomCommands, NightwatchCustomAssertions, ... { ... }\n\nexport interface NightwatchAssertions extends NightwatchBrowser { ... }\n</code></pre>\n\n<p>I have added custom commands and assertions to Nightwatch and tried to merge NightwatchCustomCommands and NightwatchCustomAssertions:</p>\n\n<p>./types/index.d.ts</p>\n\n<pre><code>import {   NightwatchAssertions, NightwatchBrowser } from \"nightwatch\";\n\n// merge interfaces with nightwatch types\n\ninterface NightwatchCustomAssertions  {\n    compareScreenshot(this: NightwatchBrowser, filename: string, expected: number, callback: Function);\n}\n\ninterface NightwatchCustomCommands  {\n    wplogin(this: NightwatchBrowser, callback?: Function):this;\n\n    compareScreenshot(this: NightwatchBrowser, filename: string, expected?: number, callback?: Function)\n}\n</code></pre>\n\n<p>but it seems the interfaces are not merged when compiling :</p>\n\n<pre><code>Property 'wplogin' does not exist on type 'NightwatchBrowser'.\nProperty 'compareScreenshot' does not exist on type 'NightwatchAssertions'.\n</code></pre>\n\n<p>both @types and types folder are included in tsconfig \"typeRoots\". So far I tried adding \"export\" to the interfaces, namespacing... Don't know what I'm missing.</p>\n",
                    "OwnerUserId": "4739462",
                    "LastActivityDate": "2017-11-26T14:00:10.687",
                    "Title": "Merging typescript external global interfaces and inheritance",
                    "Tags": "<typescript><typescript-typings>",
                    "AnswerCount": "1",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "47600437",
                "ParentRepo": "https://github.com/kennu/cwtail",
                "StackOverflow_Post": {
                    "Id": "47600437",
                    "PostTypeId": "2",
                    "ParentId": "34018931",
                    "CreationDate": "2017-12-01T19:44:43.717",
                    "Score": "13",
                    "Body": "<p>I've just discovered <a href=\"https://github.com/kennu/cwtail\" rel=\"noreferrer\">cwtail</a> and it works well (to watch a lambda function's CloudWatch logs).</p>\n\n<p>To install:</p>\n\n<pre><code>npm install -g cwtail\n</code></pre>\n\n<p>To list log groups:</p>\n\n<pre><code>cwtail -l\n</code></pre>\n\n<p>Then, once you've picked which log group to 'tail':</p>\n\n<pre><code>cwtail -f /aws/lambda/ExampleFunction\n</code></pre>\n",
                    "OwnerUserId": "426790",
                    "LastActivityDate": "2017-12-01T19:44:43.717",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "47731167",
                "ParentRepo": "https://github.com/Microsoft/appcenter-cli",
                "StackOverflow_Post": {
                    "Id": "47731167",
                    "PostTypeId": "2",
                    "ParentId": "47730034",
                    "CreationDate": "2017-12-09T17:24:17.950",
                    "Score": "2",
                    "Body": "<p>I've worked around this issue for the moment by replacing the built-in task with the App Center CLI and a simple powershell script to archive the same. </p>\n\n<pre><code>param(\n    [Parameter(Mandatory=$true)]\n    [String]\n    $Token,\n    # Name of the App, e.g. 'org/app'\n    [Parameter(Mandatory=$true)]\n    [String]\n    $App,\n    # Name of the distribution Group, e.g. 'Collaborators'\n    [Parameter(Mandatory=$true)]\n    [String]\n    $Group\n)\n\n$binaryFile = (Get-ChildItem MyApp_*_x64.appxbundle -Recurse).FullName\nappcenter distribute release -g $Group -f \"$binaryFile\" -a $App --debug --token $Token\n</code></pre>\n\n<p>To make this script work, you need the latest version of App Center CLI which can be found <a href=\"https://github.com/Microsoft/appcenter-cli\" rel=\"nofollow noreferrer\">here</a>.</p>\n\n<p>On a build agent with NPM package manager present, you can simply run <code>npm install -g appcenter-cli</code> to install the latest version. Afterwards the above script should execute. </p>\n",
                    "OwnerUserId": "2715229",
                    "LastEditorUserId": "2715229",
                    "LastEditDate": "2018-10-30T08:15:48.970",
                    "LastActivityDate": "2018-10-30T08:15:48.970",
                    "CommentCount": "8",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "48021295",
                "ParentRepo": "https://github.com/TooTallNate/node-pac-resolver",
                "StackOverflow_Post": {
                    "Id": "48021295",
                    "PostTypeId": "2",
                    "ParentId": "48019996",
                    "CreationDate": "2017-12-29T10:41:16.430",
                    "Score": "0",
                    "Body": "<p>Replace <code>pacVariable = new pacfile()</code> with</p>\n\n<pre><code>var FindProxyForURL = pac(fs.readFileSync('pacfile.pac'));\nFindProxyForURL('https://domain.name.com/#/random/login').then((res) =&gt; {\n  console.log(res);      \n\n});\n</code></pre>\n\n<p>refer the <a href=\"https://github.com/TooTallNate/node-pac-resolver\" rel=\"nofollow noreferrer\">docs</a> for API</p>\n\n<p>FindProxyForURL is a promise, so you'll have to write the code that requires the response inside the <code>.then</code>.</p>\n",
                    "OwnerUserId": "5893921",
                    "LastActivityDate": "2017-12-29T10:41:16.430",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "48168426",
                "ParentRepo": "https://github.com/dtjohnson/aws-azure-login",
                "StackOverflow_Post": {
                    "Id": "48168426",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "48467635",
                    "CreationDate": "2018-01-09T12:39:36.013",
                    "Score": "0",
                    "ViewCount": "555",
                    "Body": "<p>Can adal.js library or adal-node.js library can be used to retrieve SAML2 token from Azure AD? If so, how?</p>\n\n<p>I've tried using the example provided <a href=\"https://github.com/dtjohnson/aws-azure-login\" rel=\"nofollow noreferrer\">here</a>. Although the solution works, I was not able to integrate it with express.</p>\n",
                    "OwnerUserId": "5291708",
                    "LastActivityDate": "2018-01-26T18:44:07.393",
                    "Title": "Retrieve SAML using ADAL library",
                    "Tags": "<adal><adal.js>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "49794560",
                "ParentRepo": "https://github.com/ttulka/aws-samples/tree/master/cross-account-pipeline",
                "StackOverflow_Post": {
                    "Id": "49794560",
                    "PostTypeId": "2",
                    "ParentId": "48362572",
                    "CreationDate": "2018-04-12T10:46:31.930",
                    "Score": "12",
                    "Body": "<p>Generally, if you want to do anything across multiple accounts you have to allow this on the both sides. This is done via <em>role-assuming</em>.</p>\n\n<p>The pipeline distributed parts communicate via pipeline artifacts which are saved in a S3 bucket and de/encrypted with a KMS encryption key. This key must be accesible from all the accounts where the pipeline is distributed in.</p>\n\n<p><em>key in the CI account</em></p>\n\n<pre><code>KMSKey:\n  Type: AWS::KMS::Key\n  Properties:\n    EnableKeyRotation: true\n    KeyPolicy:\n      Version: \"2012-10-17\"\n      Id: pipeline-kms-key\n      Statement:\n        - Sid: Allows admin of the key\n          Effect: Allow\n          Principal:\n            AWS: !Sub \"arn:aws:iam::${AWS::AccountId}:root\"\n          Action: [\"kms:*\"]\n          Resource: \"*\"\n        - Sid: Allow use of the key from the other accounts\n          Effect: Allow\n          Principal:\n            AWS:\n              - !Sub \"arn:aws:iam::${DevAccountId}:root\"\n              - !GetAtt CodePipelineRole.Arn\n          Action:\n            - kms:Encrypt\n            - kms:Decrypt\n            - kms:ReEncrypt*\n            - kms:GenerateDataKey*\n            - kms:DescribeKey\n          Resource: \"*\"\nKMSAlias:\n  Type: AWS::KMS::Alias\n  Properties:\n    AliasName: !Sub alias/codepipeline-crossaccounts\n    TargetKeyId: !Ref KMSKey\n</code></pre>\n\n<p>The S3 bucket must allow the access from different accounts via a policy:</p>\n\n<p><em>pipeline stack in the CI account</em></p>\n\n<pre><code>S3ArtifactBucketPolicy:\n  Type: AWS::S3::BucketPolicy\n  Properties:\n    Bucket: !Ref S3ArtifactBucket\n    PolicyDocument:\n      Statement:\n      - Action: [\"s3:*\"]\n        Effect: Allow\n        Resource:\n        - !Sub \"arn:aws:s3:::${S3ArtifactBucket}\"\n        - !Sub \"arn:aws:s3:::${S3ArtifactBucket}/*\"\n        Principal:\n          AWS:\n          - !GetAtt CodePipelineRole.Arn\n          - !Sub \"arn:aws:iam::${DevAccountId}:role/cross-account-role\"\n          - !Sub \"arn:aws:iam::${DevAccountId}:role/cloudformation-role\"\n\nCodePipeline:\n  Type: AWS::CodePipeline::Pipeline\n  Properties:\n    ArtifactStore:\n      Type: S3\n      Location: !Ref S3ArtifactBucket\n      EncryptionKey:\n        Id: !Ref KMSKey\n        Type: KMS\n    ...\n</code></pre>\n\n<p>The pipeline (CI account) has to have a permission to assume a role in the other (DEV) account:</p>\n\n<p><em>pipeline stack in the CI account</em></p>\n\n<pre><code>CodePipelinePolicy:\n  Type: AWS::IAM::Policy\n  Properties:\n     PolicyDocument:\n        Statement:\n          - Action: [\"sts:AssumeRole\"]\n            Resource: !Sub \"arn:aws:iam::${DevAccountId}:role/cross-account-role\n            Effect: Allow\n          ...\n</code></pre>\n\n<p>And that role has to allow to be assumed to the pipeline:</p>\n\n<p><em>pipeline stack in the DEV account</em></p>\n\n<pre><code>CrossAccountRole:\n  Type: AWS::IAM::Role\n  Properties:\n    RoleName: cross-account-role\n    Path: /\n    AssumeRolePolicyDocument:\n      Version: 2012-10-17\n      Statement:\n        - Effect: Allow\n          Principal:\n            AWS: !Sub \"arn:aws:iam::${CIAccountId}:root\"\n          Action: sts:AssumeRole\n\nCrossAccountPolicy:\n  Type: AWS::IAM::Policy\n  Properties:\n    PolicyName: CrossAccountPolicy\n    PolicyDocument:\n      Version: 2012-10-17\n      Statement:\n        - Effect: Allow\n          Action:\n            - cloudformation:*\n            - codebuild:*\n            - s3:*\n            - iam:PassRole\n          Resource: \"*\"\n        - Effect: Allow\n          Action: [\"kms:Decrypt\", \"kms:Encrypt\"]\n          Resource: !Ref KMSKey\n    Roles: [!Ref CrossAccountRole]\n</code></pre>\n\n<p>The pipeline (managed and executed from the CI account) must assume a role from the other account to execute the action from within the account:</p>\n\n<p><em>pipeline stack in the CI account</em></p>\n\n<pre><code>CodePipeline:\n  Type: AWS::CodePipeline::Pipeline\n  Properties:\n    Name: pipeline\n    RoleArn: !GetAtt CodePipelineRole.Arn\n    Stages:\n      ...\n      - Name: StagingDev\n      Actions:\n      - Name: create-changeset\n        InputArtifacts:\n        - Name: BuildArtifact\n        OutputArtifacts: []\n        ActionTypeId:\n          Category: Deploy\n          Owner: AWS\n          Version: \"1\"\n          Provider: CloudFormation\n        Configuration:\n          StackName: app-stack-dev\n          ActionMode: CHANGE_SET_REPLACE\n          ChangeSetName: app-changeset-dev\n          Capabilities: CAPABILITY_NAMED_IAM\n          TemplatePath: \"BuildArtifact::template.yml\"\n          RoleArn: !Sub \"arn:aws:iam::${DevAccountId}:role/cloudformation-role\"  # the action will be executed with this role\n        RoleArn: !Sub \"arn:aws:iam::${DevAccountId}:role/cross-account-role\" # the pipeline assume this role to execute this action\n  ...\n</code></pre>\n\n<p>The code above shows how to execute a CloudFormation action in a different account, the approach is the same for different actions like CodeBuild or CodeDeploy.</p>\n\n<p>There is a nice sample <a href=\"https://github.com/awslabs/aws-refarch-cross-account-pipeline\" rel=\"noreferrer\">https://github.com/awslabs/aws-refarch-cross-account-pipeline</a> from AWS team.</p>\n\n<p>Another example is here <a href=\"https://github.com/adcreare/cloudformation/tree/master/code-pipeline-cross-account\" rel=\"noreferrer\">https://github.com/adcreare/cloudformation/tree/master/code-pipeline-cross-account</a>      </p>\n\n<p>Or you can take a look at my whole working code here <a href=\"https://github.com/ttulka/aws-samples/tree/master/cross-account-pipeline\" rel=\"noreferrer\">https://github.com/ttulka/aws-samples/tree/master/cross-account-pipeline</a></p>\n",
                    "OwnerUserId": "2190498",
                    "LastActivityDate": "2018-04-12T10:46:31.930",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "49859869",
                "ParentRepo": "https://github.com/hvolschenk/nightwatch-docker",
                "StackOverflow_Post": {
                    "Id": "49859869",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "49975716",
                    "CreationDate": "2018-04-16T14:32:17.710",
                    "Score": "1",
                    "ViewCount": "855",
                    "Body": "<p>I am trying to launch Nightwatch inside a Docker container.</p>\n\n<p>I am getting an error from <code>selenium-server</code> which basically states that <code>chromedriver</code> could not be found. I can manually verify that the file that (I think) it's looking for does exist.</p>\n\n<p>I have created a sample repository to demonstrate the issue: <a href=\"https://github.com/hvolschenk/nightwatch-docker\" rel=\"nofollow noreferrer\">https://github.com/hvolschenk/nightwatch-docker</a></p>\n",
                    "OwnerUserId": "5918634",
                    "LastEditorUserId": "5918634",
                    "LastEditDate": "2018-04-16T15:21:30.597",
                    "LastActivityDate": "2018-07-12T10:19:59.167",
                    "Title": "Nightwatch in Docker - selenium-server can't find chromedriver",
                    "Tags": "<docker><selenium-chromedriver><nightwatch.js><selenium-server>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "49994277",
                "ParentRepo": "https://github.com/kallaspriit/typescript-nightwatch-example",
                "StackOverflow_Post": {
                    "Id": "49994277",
                    "PostTypeId": "1",
                    "CreationDate": "2018-04-24T05:50:06.543",
                    "Score": "0",
                    "ViewCount": "882",
                    "Body": "<p>During execution, unable to link locator using <strong>@</strong> symbol from elements. </p>\n\n<blockquote>\n  <p>ERROR: Unable to locate element: \"@queryInput\" using: xpath</p>\n</blockquote>\n\n<p><strong>Code:</strong></p>\n\n<pre><code>import * as config from 'config';\nimport { NightWatchClient, PageObject } from 'nightwatch';\n\nconst pageConfig = config.get&lt;IPageConfig&gt;('pages.google');\n\nconst page: PageObject = {\n  url: pageConfig.url,\n  elements: {\n    queryInput: { \n      selector: '//input[@name=\"q\"]',\n      locateStrategy: 'xpath'\n     }\n  },\n  commands: [\n    {\n      enterQuery: (client: NightWatchClient, query: string) =&gt; {\n        return client\n          .waitForElementVisible('//input[@name=\"q\"]', 5000)\n          //.setValue('//input[@name=\"q\"]', [query, client.Keys.ENTER])\n          .setValue('@queryInput', [query, client.Keys.ENTER])\n          .waitForElementVisible('//*[@id=\"res\"]', 5000);\n      },\n    },\n  ]  \n};\n\nexport = page;\n</code></pre>\n\n<p>Complete <a href=\"https://github.com/kallaspriit/typescript-nightwatch-example\" rel=\"nofollow noreferrer\">code</a></p>\n\n<p><a href=\"https://github.com/kallaspriit/typescript-nightwatch-example/blob/master/src/pages/google.ts\" rel=\"nofollow noreferrer\">Link</a></p>\n",
                    "OwnerUserId": "2372672",
                    "LastEditorUserId": "2372672",
                    "LastEditDate": "2018-04-24T07:43:56.617",
                    "LastActivityDate": "2019-02-18T13:21:24.200",
                    "Title": "Nightwatch(PageObject) + TypeScript unable to locate elements using @ symbol",
                    "Tags": "<javascript><typescript><automated-tests><nightwatch.js><pageobjects>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "52158995",
                "ParentRepo": "https://github.com/snaptest-io/nightwatch-harness",
                "StackOverflow_Post": {
                    "Id": "52158995",
                    "PostTypeId": "2",
                    "ParentId": "52114147",
                    "CreationDate": "2018-09-04T04:51:29.557",
                    "Score": "0",
                    "Body": "<p>I tried with this and it worked - <a href=\"https://github.com/snaptest-io/nightwatch-harness\" rel=\"nofollow noreferrer\">https://github.com/snaptest-io/nightwatch-harness</a></p>\n\n<p>You can add the NightwatchJS code generated in Snaptest.io in the above code .</p>\n",
                    "OwnerUserId": "9188188",
                    "LastActivityDate": "2018-09-04T04:51:29.557",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "52507174",
                "ParentRepo": "https://github.com/dibyenduroy/ringcentral_callqueue_monitoring_app",
                "StackOverflow_Post": {
                    "Id": "52507174",
                    "PostTypeId": "2",
                    "ParentId": "45821247",
                    "CreationDate": "2018-09-25T21:53:04.367",
                    "Score": "0",
                    "Body": "<p>We recently launched a new event stream called CSN (Call Session Notification). This event stream emits events for all stages of the call from Proceeding State to Answered to Disconnected and you can use that to calculate the time difference.</p>\n\n<p>The Documentation is at:</p>\n\n<p><a href=\"https://ringcentral-api-docs.readthedocs.io/en/latest/active_call_control_overview/\" rel=\"nofollow noreferrer\">https://ringcentral-api-docs.readthedocs.io/en/latest/active_call_control_overview/</a></p>\n\n<p>These are Advanced APIs and you would need an additional permission \"Telephony Sessions\" , to add that permissions to your app please email to devsupport@ringcentral.com with your Org and App details and they will add the permission. Once Added you can add the event filter <code>/restapi/v1.0/account/~/telephony/sessions</code> (Account level) or even at an extension level. </p>\n\n<p>I have a sample a sample App where I have used the CSN to get , calculate the number of calls on Hold and display it : <a href=\"https://github.com/dibyenduroy/ringcentral_callqueue_monitoring_app\" rel=\"nofollow noreferrer\">https://github.com/dibyenduroy/ringcentral_callqueue_monitoring_app</a></p>\n\n<p>Hope this helps.</p>\n",
                    "OwnerUserId": "9091222",
                    "LastEditorUserId": "1908967",
                    "LastEditDate": "2018-09-25T22:24:44.880",
                    "LastActivityDate": "2018-09-25T22:24:44.880",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "52539852",
                "ParentRepo": "https://github.com/vimeo/mill/issues/195",
                "StackOverflow_Post": {
                    "Id": "52539852",
                    "PostTypeId": "2",
                    "ParentId": "52526879",
                    "CreationDate": "2018-09-27T14:57:12.067",
                    "Score": "0",
                    "Body": "<p>The <a href=\"https://developer.vimeo.com/api/reference/channels#PUT/channels/%7Bchannel_id%7D/privacy/users\" rel=\"nofollow noreferrer\">documentation</a> on that endpoint is a bit lacking - Vimeo will <a href=\"https://github.com/vimeo/mill/issues/195\" rel=\"nofollow noreferrer\">fix that soon</a>.</p>\n\n<p>To add multiple users, you'll need to send an array of objects:</p>\n\n<pre><code>curl -X PUT \n  https://api.vimeo.com/channels/*channel_id*/privacy/users \n  -H 'Accept: application/vnd.vimeo.*+json;version=3.4' \n  -H 'Authorization: bearer *token*' \n  -H 'Content-Type: application/json' \n  -d '[\n        {\"uri\":\"/users/*userid1*\"},{\"uri\":\"/users/*userid2*\"}\n    ]\n\n'\n</code></pre>\n",
                    "OwnerUserId": "3704546",
                    "LastActivityDate": "2018-09-27T14:57:12.067",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "52634270",
                "ParentRepo": "https://github.com/umple/umple/issues/1384",
                "StackOverflow_Post": {
                    "Id": "52634270",
                    "PostTypeId": "2",
                    "ParentId": "52390821",
                    "CreationDate": "2018-10-03T19:20:27.283",
                    "Score": "0",
                    "Body": "<p>Umple doesn't currently have a builtin Javascript generator. Tools such as those listed at <a href=\"https://www.quora.com/What-is-the-best-way-to-automatically-convert-Java-to-JavaScript\" rel=\"nofollow noreferrer\">https://www.quora.com/What-is-the-best-way-to-automatically-convert-Java-to-JavaScript</a> look as though they might do a good job of allowing Umple to indirectly generate Javascript.</p>\n\n<p>Umple issue 1384 <a href=\"https://github.com/umple/umple/issues/1384\" rel=\"nofollow noreferrer\">https://github.com/umple/umple/issues/1384</a> is outstanding on this matter.</p>\n",
                    "OwnerUserId": "2529845",
                    "LastActivityDate": "2018-10-03T19:20:27.283",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "53412336",
                "ParentRepo": "https://github.com/aliyun/fc-docker/blob/master/php7.2/run/Dockerfile",
                "StackOverflow_Post": {
                    "Id": "53412336",
                    "PostTypeId": "2",
                    "ParentId": "53381983",
                    "CreationDate": "2018-11-21T12:45:29.103",
                    "Score": "0",
                    "Body": "<p>@legionth: I apologize that I didn't use the comment feature here, but my answer is too long. :-)\nThanks a lot for your comments - the usage of <code>RequestBodyParserMiddleware</code> is a great solution if you can control the server code. But in the context of Alibaba Cloud Function Compute service this seems not possible. I tried to find out more information about the invocation process - here are my results: </p>\n\n<ul>\n<li><p>Function Compute makes use of the Docker image defined in <a href=\"https://github.com/aliyun/fc-docker/blob/master/php7.2/run/Dockerfile\" rel=\"nofollow noreferrer\">https://github.com/aliyun/fc-docker/blob/master/php7.2/run/Dockerfile</a> .</p></li>\n<li><p>In the build process they download a PHP runtime environment from <a href=\"https://my-fc-testt.oss-cn-shanghai.aliyuncs.com/php7.2.tgz\" rel=\"nofollow noreferrer\">https://my-fc-testt.oss-cn-shanghai.aliyuncs.com/php7.2.tgz</a> . (I didn't find this on GitHub, but the code is public downloadable.)</p></li>\n<li><p>A shell script <code>start_server.sh</code> starts a PHP-CGI binary and runs a PHP script <code>server.php</code>.</p></li>\n</ul>\n\n<p>In <code>server.php</code> a <code>React\\Http\\Server</code> is started by: </p>\n\n<pre><code>$server = new Server(function (ServerRequestInterface $request) {\n\n[...]\n\n});\n\n[...]\n\n$socket = new \\React\\Socket\\Server(sprintf('0.0.0.0:%s', $port), $loop);\n$server-&gt;listen($socket);\n\n$loop-&gt;run();\n</code></pre>\n\n<p>As seen in the Function Compute <a href=\"https://www.alibabacloud.com/help/doc-detail/89029.htm?spm=a2c63.p38356.b99.23.23dd670eTBhltR#HTTP-trigger-interface\" rel=\"nofollow noreferrer\">documentation</a> (&amp; example of FC console), I can only use two functions:</p>\n\n<pre><code>/*\nif you open the initializer feature, please implement the initializer function, as below:\n*/\n\nfunction initializer($context) {\n\n}\n</code></pre>\n\n<p>and the <code>handler</code> function you can find in my first post. </p>\n\n<p>Maybe Alibaba will extend the PHP runtime in future to make it possible to use a custom middleware, but currently I didn't find a way to do this. </p>\n\n<p>Thanks again &amp; kind regards,</p>\n\n<p>Ralf</p>\n",
                    "OwnerUserId": "6398247",
                    "LastActivityDate": "2018-11-21T12:45:29.103",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "53462429",
                "ParentRepo": "https://github.com/danielrussellLA/restart-linksys-EA2700-router",
                "StackOverflow_Post": {
                    "Id": "53462429",
                    "PostTypeId": "2",
                    "ParentId": "146741",
                    "CreationDate": "2018-11-24T21:14:07.823",
                    "Score": "0",
                    "Body": "<p><a href=\"https://github.com/danielrussellLA/restart-linksys-EA2700-router\" rel=\"nofollow noreferrer\">https://github.com/danielrussellLA/restart-linksys-EA2700-router</a> you can try using a nightwatch bot similar to this one to programatically restart your router through its browser ui. This works well if your router does not have a command line interface that you can access (through telnet, ssh etc). It's pretty hacky, but it gets the job done.</p>\n",
                    "OwnerUserId": "6332271",
                    "LastEditorUserId": "6332271",
                    "LastEditDate": "2018-11-24T22:14:48.220",
                    "LastActivityDate": "2018-11-24T22:14:48.220",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "53620095",
                "ParentRepo": "https://github.com/polonel/trudesk/blob/master/src/settings/defaults.js",
                "StackOverflow_Post": {
                    "Id": "53620095",
                    "PostTypeId": "2",
                    "ParentId": "53445511",
                    "CreationDate": "2018-12-04T19:26:30.130",
                    "Score": "0",
                    "Body": "<p>I ran into this issue a while ago when I was messing around with the database. I got around it by validating the object that's referenced in src\\settings\\defaults.js at line 109 (according to the error above and <a href=\"https://github.com/polonel/trudesk/blob/master/src/settings/defaults.js\" rel=\"nofollow noreferrer\">the github repo at this time</a>).</p>\n\n<p>You can see the issue in code, where type._id is referenced. You need to confirm that type is an object and that _id is a string. Starting at line 107:</p>\n\n<pre><code>            var defaultTicketType = new SettingsSchema({\n                name: 'ticket:type:default',\n                value: type._id\n            });\n</code></pre>\n\n<p>Change that so validation of the object happens before the object's keys are referenced:</p>\n\n<pre><code>            if (typeof type !== 'object' ||  typeof type._id !== 'string' ) return;\n            var defaultTicketType = new SettingsSchema({\n                name: 'ticket:type:default',\n                value: type._id\n            });\n</code></pre>\n",
                    "OwnerUserId": "1316122",
                    "LastActivityDate": "2018-12-04T19:26:30.130",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "53691611",
                "ParentRepo": "https://github.com/kengz/spacy-nlp/blob/master/README.md",
                "StackOverflow_Post": {
                    "Id": "53691611",
                    "PostTypeId": "2",
                    "ParentId": "53691435",
                    "CreationDate": "2018-12-09T11:00:33.417",
                    "Score": "2",
                    "Body": "<p>I believe that <a href=\"https://github.com/explosion/spaCy\" rel=\"nofollow noreferrer\">spaCy</a> library may be the the right tool for your needs. Check out the description on GitHub to figure it out.</p>\n\n<p>It can be exposed to Node JS using <a href=\"https://github.com/kengz/spacy-nlp/blob/master/README.md\" rel=\"nofollow noreferrer\">spacy-nlp</a> package.</p>\n",
                    "OwnerUserId": "5314397",
                    "LastEditorUserId": "5314397",
                    "LastEditDate": "2018-12-09T11:10:32.740",
                    "LastActivityDate": "2018-12-09T11:10:32.740",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "54098001",
                "ParentRepo": "https://github.com/pubnub/chat-engine-gravatar/blob/master/example.html",
                "StackOverflow_Post": {
                    "Id": "54098001",
                    "PostTypeId": "2",
                    "ParentId": "54089485",
                    "CreationDate": "2019-01-08T18:56:29.720",
                    "Score": "1",
                    "Body": "<p>With PubNub and ChatEngine, you need to use separate channels for every chat room. You cannot have a private and a public chat that use the same channel. Every user can subscribe to many chats on many channels simultaneously. When you use the ChatEngine method to create a private chat, only the users who are involved can see the chat. The <a href=\"https://www.pubnub.com/docs/chat-engine/reference/chat#invite\" rel=\"nofollow noreferrer\">ChatEngine \"invite\" for private chat documentation</a> is here.</p>\n\n<p><strong>Private Chat</strong></p>\n\n<p>Some client's code\n</p>\n\n<pre><code>// one non-admin user running ChatEngine\nlet secretChat = new ChatEngine.Chat('unique-secret-channel');\nsecretChat.invite(adminUserObject);\n</code></pre>\n\n<p>The admin's client code\n</p>\n\n<pre><code>// This code goes in the admin client\nme.direct.on('$.invite', (payload) =&gt; {\n    let privChat = new ChatEngine.Chat(payload.data.channel, true);\n});\n</code></pre>\n\n<p><strong>Gravatar</strong></p>\n\n<p>This works when user's connect with email as part of their state object. Then you must initialize the gravatar plugin.  There is a <a href=\"https://github.com/pubnub/chat-engine-gravatar/blob/master/example.html\" rel=\"nofollow noreferrer\">ChatEngine Gravatar Example here</a>.</p>\n\n\n\n<pre><code>// include the gravatar plugin script above    \nChatEngine.connect(uuid, { email: email@email.com });\n\n// ...\n\nfor (let user of ChatEngine.users) {\n    user.plugin(ChatEngine.plugin.gravatar());\n    let div = document.createElement(\"div\");\n    div.innerHTML = '&lt;img src=\"' + user.state().gravatar + '\" height=\"40\" width=\"40\"/&gt;';\n    // add html to the web page\n}\n</code></pre>\n",
                    "OwnerUserId": "6193736",
                    "LastActivityDate": "2019-01-08T18:56:29.720",
                    "CommentCount": "12",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "54299914",
                "ParentRepo": "https://github.com/Team-Hycon/hycon-core/blob/master/src/common/blockGenesis.ts",
                "StackOverflow_Post": {
                    "Id": "54299914",
                    "PostTypeId": "2",
                    "ParentId": "54294040",
                    "CreationDate": "2019-01-22T01:12:44.220",
                    "Score": "1",
                    "Body": "<p>The genesis block doesn't actually require mining. You can create it as whatever you want as long as it follows the serialisation of your protocol. Genesis blocks tend to follow slightly different rules to normal blocks and so often do not pass validation under normal circumstances. \n<a href=\"https://github.com/Team-Hycon/hycon-core/blob/master/src/common/blockGenesis.ts\" rel=\"nofollow noreferrer\">Here</a> is how we handle the genesis block in our code-base. It has slightly different rules to how we handle <a href=\"https://github.com/Team-Hycon/hycon-core/blob/master/src/common/block.ts\" rel=\"nofollow noreferrer\">other blocks</a>. \nAll a block needs is a block to point backwards to. So as long as you have some previous hash new blocks should be able to be formed on top of your genesis block.</p>\n",
                    "OwnerUserId": "10827651",
                    "LastActivityDate": "2019-01-22T01:12:44.220",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "55485222",
                "ParentRepo": "https://github.com/pulumi/pulumi-awsx",
                "StackOverflow_Post": {
                    "Id": "55485222",
                    "PostTypeId": "2",
                    "ParentId": "55477419",
                    "CreationDate": "2019-04-03T00:09:21.797",
                    "Score": "0",
                    "Body": "<p>Figured I'd take a look at the actual code (go figure, right?) and found that <code>apigateway.x.API</code> is now under <code>awsx.apigateway.API</code>. Was wondering if <code>awsx</code> was related. Feel better now.</p>\n\n<p><a href=\"https://github.com/pulumi/pulumi-aws/pull/508\" rel=\"nofollow noreferrer\">https://github.com/pulumi/pulumi-aws/pull/508</a></p>\n\n<blockquote>\n  <p>The deprecated api aws.apigateway.x.API has been removed. Its replacement is in the @pulumi/awsx package with the name awsx.apigateway.API.</p>\n</blockquote>\n\n<p><code>pulumi-awsx</code> is described as \"AWS infrastructure best practices in component form.</p>\n\n<p><a href=\"https://github.com/pulumi/pulumi-awsx\" rel=\"nofollow noreferrer\">https://github.com/pulumi/pulumi-awsx</a></p>\n",
                    "OwnerUserId": "124563",
                    "LastActivityDate": "2019-04-03T00:09:21.797",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "55566008",
                "ParentRepo": "https://github.com/dkundel/twilio-roulette",
                "StackOverflow_Post": {
                    "Id": "55566008",
                    "PostTypeId": "2",
                    "ParentId": "55564293",
                    "CreationDate": "2019-04-08T03:52:22.973",
                    "Score": "2",
                    "Body": "<p>Twilio developer evangelist here.</p>\n\n<p>I can answer that Twilio would be a good approach for you to do this within your own application. I'd recommend using <a href=\"http://twilio.com/video\" rel=\"nofollow noreferrer\">Twilio Video</a> to build this as it allows cross platform communication via audio or video (in your case, you may not need the video, but this will give you the best audio quality).</p>\n\n<p>As an example, my colleague Dominik built a <a href=\"https://github.com/dkundel/twilio-roulette\" rel=\"nofollow noreferrer\">video roulette application</a>. It is the case that the interface was built in JavaScript for the web, but the idea would be the same for a native app. The <a href=\"https://github.com/dkundel/twilio-roulette/blob/master/index.js\" rel=\"nofollow noreferrer\">code for the server side</a> part of the application should give some insight into how to connect random pairings.</p>\n\n<p>It's also possible to integrate Twilio Video with CallKit and Connection Services so that you can make outbound calls to other devices that ring like a real incoming call.</p>\n",
                    "OwnerUserId": "28376",
                    "LastActivityDate": "2019-04-08T03:52:22.973",
                    "CommentCount": "7",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "55867581",
                "ParentRepo": "https://github.com/Fernal73/LearnNodeJS/blob/master/emitter/emitter.js",
                "StackOverflow_Post": {
                    "Id": "55867581",
                    "PostTypeId": "1",
                    "CreationDate": "2019-04-26T12:23:14.693",
                    "Score": "0",
                    "ViewCount": "549",
                    "Body": "<blockquote>\n<p>jshint emitter                                  emitter/emitter.js: line 15, col 61, Octal literals are not allowed in strict mode.</p>\n<p>1 error</p>\n</blockquote>\n<p>I receive the above message while running the linter jshint on my source code.</p>\n<p>The offending line in the program is:</p>\n<pre><code>let pattern = new RegExp(&quot;^-(?=[gim]{1,3}$)(?!.*(.).*\\1).*$&quot;);\n</code></pre>\n<p>jshint flags the error at \\1 in the regular expression.</p>\n<p>Is there any way to be rid of this message from jshint?</p>\n<p>You can view the source  <a href=\"https://github.com/Fernal73/LearnNodeJS/blob/master/emitter/emitter.js\" rel=\"nofollow noreferrer\">here</a></p>\n",
                    "OwnerUserId": "3924108",
                    "LastEditorUserId": "-1",
                    "LastEditDate": "2020-06-20T09:12:55.060",
                    "LastActivityDate": "2019-04-26T13:04:07.923",
                    "Title": "Octal literals flagged in regular expression back reference",
                    "Tags": "<javascript><node.js><regex><jshint>",
                    "AnswerCount": "1",
                    "CommentCount": "2",
                    "ClosedDate": "2019-04-26T12:33:33.717",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "55926595",
                "ParentRepo": "https://github.com/expo/detox-expo-helpers/pull/12",
                "StackOverflow_Post": {
                    "Id": "55926595",
                    "PostTypeId": "2",
                    "ParentId": "55868537",
                    "CreationDate": "2019-04-30T18:12:08.487",
                    "Score": "4",
                    "Body": "<h2>Summary</h2>\n\n<p>There is an <a href=\"https://github.com/expo/detox-expo-helpers/pull/12\" rel=\"nofollow noreferrer\">open pull-request</a> for this issue. I quote <a href=\"https://github.com/yaron1m\" rel=\"nofollow noreferrer\"><code>Yaron Malim</code></a></p>\n\n<pre><code>ReferenceError: device is not defined\n\n  at Object.reloadApp (../node_modules/detox-expo-helpers/index.js:68:3)\n</code></pre>\n\n<blockquote>\n  <p>When I added the following require:</p>\n</blockquote>\n\n<pre><code>const { device } = require('detox');\n</code></pre>\n\n<blockquote>\n  <p>The issue was solved.\n  In order to do so, I had to add detox as a dependency. This is the package.json</p>\n</blockquote>\n\n<pre><code>{\n  \"name\": \"detox-expo-helpers\",\n  \"version\": \"0.6.0\",\n  \"main\": \"index.js\",\n  \"license\": \"MIT\",\n  \"devDependencies\": {},\n  \"dependencies\": {\n    \"child-process-promise\": \"^2.2.1\",\n    \"detox\": \"^12.2.0\",\n    \"semver\": \"^5.6.0\",\n    \"xdl\": \"^51.5.0\"\n  }\n}\n</code></pre>\n\n<p>Details of the <a href=\"https://github.com/expo/detox-expo-helpers/pull/12/files/57122590bbe5abf00a826daf3fe13621fffb5313\" rel=\"nofollow noreferrer\">committed files in the pull request</a></p>\n\n<h2>Installing the Necessaries Dependencies</h2>\n\n<p>The <a href=\"https://github.com/expo/detox-expo-helpers\" rel=\"nofollow noreferrer\"><code>detox-expo-helpers</code> github repo</a> includes <a href=\"https://github.com/expo/with-detox-tests\" rel=\"nofollow noreferrer\">an example app</a>. Add <a href=\"https://github.com/expo/with-detox-tests/blob/master/package.json#L19\" rel=\"nofollow noreferrer\"><code>expo-detox-hook</code> to your <code>package.json</code></a> and run <code>npm install</code></p>\n\n<pre><code>{\n  \"devDependencies\": {\n    \"detox\": \"^9.0.6\",\n    \"detox-expo-helpers\": \"^0.6.0\",\n    \"expo-detox-hook\": \"^1.0.10\",\n    \"mocha\": \"^3.5.0\"\n  },\n  \"detox\": {\n    \"configurations\": {\n      \"ios.sim\": {\n        \"binaryPath\": \"bin/Exponent.app\",\n        \"type\": \"ios.simulator\",\n        \"name\": \"iPhone 7\"\n      }\n    }\n  }\n}\n</code></pre>\n\n<p>As explained on the <a href=\"https://github.com/expo/detox-expo-helpers#set-up-detox-on-your-project\" rel=\"nofollow noreferrer\">official <code>detox-expo-helpers</code> page</a> you should follow every step <a href=\"https://github.com/wix/detox/blob/master/docs/Introduction.GettingStarted.md\" rel=\"nofollow noreferrer\">to set up your <code>detox</code> project</a>, except for <a href=\"https://github.com/wix/detox/blob/master/docs/Introduction.GettingStarted.md#3-add-detox-config-to-packagejson\" rel=\"nofollow noreferrer\">the <code>package.json</code> configurations included in this step</a>, which are different in <code>expo</code>.</p>\n\n<p>The <code>detox-expo-helpers</code> includes the official configuration for your emulator <a href=\"https://github.com/expo/detox-expo-helpers#download-the-expo-app-to-some-directory-in-your-project-and-configure-in-packagejson\" rel=\"nofollow noreferrer\">at the step <strong>Download the Expo app to some directory in your project and configure in <code>package.json</code></strong></a>.</p>\n\n<p>It also includes an <a href=\"https://github.com/expo/with-detox-tests/blob/033020b165452d641f512a9b1a8a291632ce8e8f/package.json#L21-L29\" rel=\"nofollow noreferrer\"><strong>example</strong> of the <code>Detox</code> settings for your <code>package.json</code></a></p>\n\n<p>Your second test fails because <code>Detox</code> does not find the element on the page.\nYou need to pass a <code>testID</code> prop to the component with value <code>'hello_button'</code>.</p>\n\n<pre><code>it('should show hello screen after tap', async () =&gt; {\n    await element(by.id('hello_button')).tap();\n    await expect(element(by.text('Hello!!!'))).toBeVisible();\n});\n</code></pre>\n\n<p><a href=\"https://github.com/wix/Detox/blob/master/docs/APIRef.Matchers.md#byidid\" rel=\"nofollow noreferrer\">documentation on <code>by.id</code> matcher</a></p>\n\n<blockquote>\n  <p><code>by.id</code> will match an id that is given to the view via <code>testID</code> prop.</p>\n</blockquote>\n\n<p>Your component should look like</p>\n\n<pre><code>&lt;TouchableOpacity testID={'hello_button'}&gt;\n</code></pre>\n",
                    "OwnerUserId": "7295772",
                    "LastEditorUserId": "7295772",
                    "LastEditDate": "2019-05-07T14:01:45.287",
                    "LastActivityDate": "2019-05-07T14:01:45.287",
                    "CommentCount": "6",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "56312734",
                "ParentRepo": "https://github.com/UtkarshGpta/realtime-arduino-sensor-data",
                "StackOverflow_Post": {
                    "Id": "56312734",
                    "PostTypeId": "2",
                    "ParentId": "20953284",
                    "CreationDate": "2019-05-26T10:33:38.390",
                    "Score": "0",
                    "Body": "<p>I did the same thing that you're trying to do a year ago. Apart from viewing the data at the client's side, I also displayed an almost real-time graph where the graph would be updated after a specific interval of time set by you (I set it as 1 second). The real-time data transmission thing was handled by PubNub framework. You can go through my implementation on GitHub below.</p>\n\n<p><a href=\"https://github.com/UtkarshGpta/realtime-arduino-sensor-data\" rel=\"nofollow noreferrer\">RealTime Arduino Sensor Data Visualization</a></p>\n",
                    "OwnerUserId": "5600195",
                    "LastActivityDate": "2019-05-26T10:33:38.390",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "56831026",
                "ParentRepo": "https://github.com/SISheogorath/readme-to-dockerhub",
                "StackOverflow_Post": {
                    "Id": "56831026",
                    "PostTypeId": "2",
                    "ParentId": "34710513",
                    "CreationDate": "2019-07-01T06:42:19.650",
                    "Score": "1",
                    "Body": "<p>you can use a docker container in your pipeline using this</p>\n\n<p><a href=\"https://hub.docker.com/r/sheogorath/readme-to-dockerhub\" rel=\"nofollow noreferrer\">https://hub.docker.com/r/sheogorath/readme-to-dockerhub</a></p>\n\n<p>Project code</p>\n\n<p><a href=\"https://github.com/SISheogorath/readme-to-dockerhub\" rel=\"nofollow noreferrer\">https://github.com/SISheogorath/readme-to-dockerhub</a></p>\n\n<p>Gitlab CI Pipeline config looks like this</p>\n\n<pre><code>update-readme:\n  stage: docs\n  image:\n    name: docker:stable\n  services:\n    - docker:dind\n  script:\n    - docker run --rm -v $(pwd)/README.md:/data/README.md -e DOCKERHUB_USERNAME=$CI_REGISTRY_USER -e DOCKERHUB_PASSWORD=$CI_REGISTRY_PASSWORD -e DOCKERHUB_REPO_PREFIX=$CI_REGISTRY_IMAGE -e DOCKERHUB_REPO_NAME=$CONTAINER_NAME sheogorath/readme-to-dockerhub\n</code></pre>\n\n<p>Also I've got got a smaller command you can use as well, if you run this in the docker repo it will read <code>README.md</code> by default </p>\n\n<pre><code>  docker run --rm -v $(pwd):/data/ aemdesign/dockerhub-description \"$DOCKER_USERNAME\" \"$DOCKER_PASSWORD\" aemdesign/dispatcher\n</code></pre>\n\n<p>If you want to specify manually run </p>\n\n<pre><code>  docker run --rm -v $(pwd):/data/ aemdesign/dockerhub-description \"$DOCKER_USERNAME\" \"$DOCKER_PASSWORD\" aemdesign/dispatcher ./README.md\n</code></pre>\n\n<p>code: <a href=\"https://github.com/aem-design/docker-dockerhub-description\" rel=\"nofollow noreferrer\">https://github.com/aem-design/docker-dockerhub-description</a></p>\n",
                    "OwnerUserId": "2332337",
                    "LastEditorUserId": "2332337",
                    "LastEditDate": "2019-10-15T13:41:24.897",
                    "LastActivityDate": "2019-10-15T13:41:24.897",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "56954779",
                "ParentRepo": "https://github.com/nightwatchjs/nightwatch-website-tests",
                "StackOverflow_Post": {
                    "Id": "56954779",
                    "PostTypeId": "1",
                    "CreationDate": "2019-07-09T14:25:08.560",
                    "Score": "1",
                    "ViewCount": "352",
                    "Body": "<p>I am a new user to Nightwatch and am trying to convert a large number of tests to use the latest version of Nightwatch 1.1.12. My requirements are to use the following set up:</p>\n\n<pre><code>Nightwatch 1.12.1\nFirefox 60.8.0esr and Chrome 74\nGecko driver 1.7.1  (equates to gecko driver 0.17.1) \nsee https://github.com/vladikoff/node-geckodriver#readme\n</code></pre>\n\n<p>I have a sample setup and tests cloned from the Nightwatch website repo, <a href=\"https://github.com/nightwatchjs/nightwatch-website-tests\" rel=\"nofollow noreferrer\">https://github.com/nightwatchjs/nightwatch-website-tests</a>,\nat my repo:</p>\n\n<p><a href=\"https://github.com/kblodget/nightwatch-website-tests-config\" rel=\"nofollow noreferrer\">https://github.com/kblodget/nightwatch-website-tests-config</a></p>\n\n<p>I have modified the homepage-test.js test to move to the GitHub button , click it, then verify the GitHub page is opened.</p>\n\n<p>This test works in chrome, but fails when I run the same test using FireFox and the required gecko driver.\nThe Firefox error is </p>\n\n<pre><code>TimeoutError: An error occurred while running .moveToElement() command on &lt;Section [name=indexContainer],Section [name=download],Element [name=@gitHubButton]&gt;:\n   {\"status\":-1,\"value\":{\"error\":\"unknown command\",\"message\":\"POST /session/28e06a8d-7e6c-436a-81b7-149230ff226b/moveto did not match a known command\",\"stacktrace\":\"stack backtrace:\\n   0:           0x57af6d - backtrace::backtrace::trace::h59229d13f6a8837d\\n   1:           0x57b0c2 - backtrace::capture::Backtrace::new::h23089c033eded8f0\\n   2:           0x4472fc - webdriver::error::WebDriverError::new::h0b226f62ff19e120\\n   3:           0x439986 - &lt;webdriver::server::HttpHandler&lt;U&gt; as hyper::server::Handler&gt;::handle::h8a591087754286a9\\n   4:           0x42d1cf - hyper::server::listener::spawn_with::{{closure}}::h82d502303a553f20\\n   5:           0x4092d7 - std::panicking::try::do_call::h89ac8aec5c3b6b89\\n   6:           0x5de23a - panic_unwind::__rust_maybe_catch_panic\\n                        at /checkout/src/libpanic_unwind/lib.rs:98\\n   7:           0x41bd6e - &lt;F as alloc::boxed::FnBox&lt;A&gt;&gt;::call_box::h2822c178036f43e7\\n   8:           0x5d68d4 - alloc::boxed::{{impl}}::call_once&lt;(),()&gt;\\n                        at /checkout/src/liballoc/boxed.rs:650\\n                         - std::sys_common::thread::start_thread\\n                        at /checkout/src/libstd/sys_common/thread.rs:21\\n                         - std::sys::imp::thread::{{impl}}::new::thread_start\\n                        at /checkout/src/libstd/sys/unix/thread.rs:84\"},\"errorStatus\":\"\",\"error\":\"POST /session/28e06a8d-7e6c-436a-81b7-149230ff226b/moveto did not match a known command\",\"httpStatusCode\":404}\n       at &lt;anonymous&gt;\n       at process._tickCallback (internal/process/next_tick.js:188:7)\n</code></pre>\n\n<p>I've researched this through past issues and believe the issue is related to this </p>\n\n<pre><code>https://github.com/nightwatchjs/nightwatch/issues/1664\n</code></pre>\n\n<p>From this source the gecko driver does not support the moveTo command command and has been replaced  with  the Actions API implementation.</p>\n\n<p>Interesting though I have the same error when I update the nightwatch.conf.js file to use Firefox version 60 and the gecko driver to 1.16.2 (gecko driver v0.24.0)</p>\n\n<p>So how can I run these test in Firefox 60 browser? If I need to create a custom command to use the API actions, how is that done?</p>\n\n<p><strong>Update 1:</strong></p>\n\n<p>I realize this is an issue with geckodriver not fully implementing the WebDriver standard or complete compatibility with Selenium but I need a way to  fix these tests.</p>\n",
                    "OwnerUserId": "8845410",
                    "LastEditorUserId": "8845410",
                    "LastEditDate": "2019-07-16T12:37:40.567",
                    "LastActivityDate": "2019-07-16T12:37:40.567",
                    "Title": "Nightwatch FireFox60 and geckodriver MoveTo fails with unknown command",
                    "Tags": "<firefox><geckodriver><nightwatch>",
                    "AnswerCount": "0",
                    "CommentCount": "0",
                    "FavoriteCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "57138618",
                "ParentRepo": "https://github.com/infitio/flutter_socket_io",
                "StackOverflow_Post": {
                    "Id": "57138618",
                    "PostTypeId": "1",
                    "CreationDate": "2019-07-22T02:50:54.723",
                    "Score": "0",
                    "ViewCount": "1367",
                    "Body": "<p>I have to connect to a socket serve in my Flutter App. I tried used some plugins like ADHARA_SOCKET_IO, but unsuccessful.\nMy back is built on nodeJS.</p>\n\n<p>I tried run the serve disponibilized by the author of the ADHARA pluggin, to test my app, because on my API its dont work... but even the example APP run.\nthat is the error:</p>\n\n<p>I/flutter (16986): io.socket.engineio.client.EngineIOException: websocket error</p>\n\n<p>(when I run the Author's serve+app)</p>\n\n<p>p.s: I did check the path: '127.0.0.1:7000' / 0.0.0.0:7000.</p>\n\n<p>So, in my app, I did write a function to call the socket's initialization in a button.</p>\n\n<p>below is the code function. this is the error when call the function:</p>\n\n<p>E/Adhara:SocketIOPlugin(15905): java.lang.ClassCastException: java.lang.Integer cannot be cast to java.lang.Long\nI/flutter (15905): io.socket.engineio.client.EngineIOException: websocket error</p>\n\n<pre><code>\n    connectarSocket() async {\n\n      SocketIO socket = await SocketIOManager().createInstance(\n      SocketOptions('http://127.0.0.1:7000')); \n      socket.onConnect((data) {\n        print(\"connected...\");\n        print(data);\n        socket.emit(\"message\", [\"Hello world!\"]);\n      });\n      socket.on(\"news\", (data) {\n        //sample event\n        print(\"news\");\n        print(data);\n      });\n      socket.connect();\n\n    }\n\n</code></pre>\n\n<p>actually when I use the same code as the example app (author) I get this:\n    <strong>I/flutter (16986): io.socket.engineio.client.EngineIOException: websocket error</strong></p>\n\n<p>when I use the function, I get this:\n     <strong>E/Adhara:SocketIOPlugin(15905): java.lang.ClassCastException: java.lang.Integer cannot be cast to java.lang.Long\nI/flutter (15905): io.socket.engineio.client.EngineIOException: websocket error</strong></p>\n\n<p>here is the pluggin repo:\n<a href=\"https://github.com/infitio/flutter_socket_io\" rel=\"nofollow noreferrer\">https://github.com/infitio/flutter_socket_io</a></p>\n",
                    "OwnerUserId": "10799613",
                    "LastActivityDate": "2019-12-26T19:48:55.133",
                    "Title": "Flutter: Connection to a socket serve unsuccessful",
                    "Tags": "<flutter><socket.io>",
                    "AnswerCount": "1",
                    "CommentCount": "7",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "57264986",
                "ParentRepo": "https://github.com/msimpsonnz/gitbackup",
                "StackOverflow_Post": {
                    "Id": "57264986",
                    "PostTypeId": "2",
                    "ParentId": "54148868",
                    "CreationDate": "2019-07-30T05:42:56.920",
                    "Score": "-1",
                    "Body": "<p>I was able to do with IAM Role and Lambda using Lambda Layer with the AWS CLI installed\n<a href=\"https://github.com/aws-samples/aws-lambda-layer-awscli\" rel=\"nofollow noreferrer\">https://github.com/aws-samples/aws-lambda-layer-awscli</a></p>\n\n<p>I have the full solution here with a SAM template\n<a href=\"https://github.com/msimpsonnz/gitbackup\" rel=\"nofollow noreferrer\">https://github.com/msimpsonnz/gitbackup</a></p>\n",
                    "OwnerUserId": "11855638",
                    "LastActivityDate": "2019-07-30T05:42:56.920",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "57347292",
                "ParentRepo": "https://github.com/sebsto/stackoverflow-samples/tree/81b94f779f0344f9d7fd10ea3a26b2c25845f946/Amplify%20Federated",
                "StackOverflow_Post": {
                    "Id": "57347292",
                    "PostTypeId": "2",
                    "ParentId": "57344835",
                    "CreationDate": "2019-08-04T14:15:28.880",
                    "Score": "3",
                    "Body": "<p>Unfortunately, the <code>federatedSignIn()</code> method name is a bit misleading.  It only works with Cognito Identity Pool at the moment as mentioned in <a href=\"https://aws-amplify.github.io/docs/ios/authentication#federated-identities-social-sign-in/\" rel=\"nofollow noreferrer\">the doc</a> :</p>\n\n<blockquote>\n  <p>Currently, the federation feature in the AWSMobileClient supports\n  Cognito Identity Pools only.</p>\n</blockquote>\n\n<p>I can reproduce the behaviour you're experiencing.  Check source code <a href=\"https://github.com/sebsto/stackoverflow-samples/tree/81b94f779f0344f9d7fd10ea3a26b2c25845f946/Amplify%20Federated\" rel=\"nofollow noreferrer\">on this commit</a>. </p>\n\n<p><a href=\"https://github.com/aws-amplify/aws-sdk-ios/blob/master/AWSAuthSDK/Sources/AWSMobileClient/AWSMobileClientExtensions.swift#L628\" rel=\"nofollow noreferrer\">When looking at the Amplify source code</a>, this method is only keeping track of state and registers the token.  It returns no error even when you pass an invalid token (I tried with 000)</p>\n\n<p>There is no possibility to get a JWT token neither, this is tracked as a feature request : <a href=\"https://github.com/aws-amplify/aws-sdk-ios/issues/1128\" rel=\"nofollow noreferrer\">https://github.com/aws-amplify/aws-sdk-ios/issues/1128</a></p>\n\n<p>I can think about three workarounds :</p>\n\n<ul>\n<li>use <code>AWSCognitoAuth</code> class instead.</li>\n<li><del>use the Amplify-provided UI</del> (Cognito User Pool auth only, no federation option)</li>\n<li>use Cognito hosted UI (see <a href=\"https://github.com/sebsto/stackoverflow-samples/blob/5c5776117933a58090cffe5a3d664ec6f3a928d1/Amplify%20Federated/Test%20Amplify%20Federation/FirstViewController.swift\" rel=\"nofollow noreferrer\">working code here</a>)</li>\n</ul>\n\n<p>The Cognito hosted UI allows to do either a federated SignIn  or a Cognito SignIn. The link above is a full working project as example. </p>\n",
                    "OwnerUserId": "663360",
                    "LastEditorUserId": "663360",
                    "LastEditDate": "2019-08-05T14:13:15.477",
                    "LastActivityDate": "2019-08-05T14:13:15.477",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "57359331",
                "ParentRepo": "https://github.com/microsoft/react-native-code-push/blob/master/docs/multi-deployment-testing-ios.md",
                "StackOverflow_Post": {
                    "Id": "57359331",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "57397826",
                    "CreationDate": "2019-08-05T13:11:24.153",
                    "Score": "5",
                    "ViewCount": "9337",
                    "Body": "<p>I'm trying to implement AppCenter CodePush to update Javascript code without having to go through the App Store review process. </p>\n\n<p>I've followed both the iOS and Android steps mentioned here to setup multi deployment environments:\n<a href=\"https://github.com/microsoft/react-native-code-push/blob/master/docs/multi-deployment-testing-ios.md\" rel=\"nofollow noreferrer\">https://github.com/microsoft/react-native-code-push/blob/master/docs/multi-deployment-testing-ios.md</a>\n<a href=\"https://github.com/microsoft/react-native-code-push/blob/master/docs/multi-deployment-testing-android.md\" rel=\"nofollow noreferrer\">https://github.com/microsoft/react-native-code-push/blob/master/docs/multi-deployment-testing-android.md</a></p>\n\n<p><strong>Versions</strong></p>\n\n<p><code>\"react-native\": \"0.59.10\"</code></p>\n\n<p><code>\"react-native-code-push\": \"^5.6.1\"</code></p>\n\n<p>I tried on Android with <code>react-native run-android --variant release</code> and on iOS I changed my RUN and Archive scheme to STAGING. But in both cases they seem to fetch my bundle like so <code>[CodePush] Loading JS bundle from \"assets://index.android.bundle\"</code> and not from the CodePush repo. This is the only output I see (CodePush related).</p>\n\n<p>I made a codePush release like so: <code>appcenter codepush release-react -a name/appName-1 -d Staging</code> . This command succeeded, I see it on the iOS and Android staging environment with the correct version.</p>\n\n<p><strong>componentDidMount</strong></p>\n\n<pre><code>componentDidMount() {\n    codePush.notifyApplicationReady();\n    ...\n    codePush.sync({\n      updateDialog: true,\n      installMode: codePush.InstallMode.IMMEDIATE\n    });\n  }\n</code></pre>\n\n<p><strong>Export App</strong></p>\n\n<pre><code>App = codePush({\n  checkFrequency: codePush.CheckFrequency.ON_APP_RESUME\n})(App);\n\nAppRegistry.registerComponent(\"myApp\", () =&gt; App);\n</code></pre>\n\n<p><strong>Info.plist</strong></p>\n\n<p><code>CodePushDeploymentKey: $(CODEPUSH_KEY)</code></p>\n\n<p><strong>android/app/build.gradle</strong></p>\n\n<pre><code>buildTypes {\n        debug {\n            buildConfigField \"String\", \"CODEPUSH_KEY\", '\"\"'\n        }\n\n        releaseStaging {\n            buildConfigField \"String\", \"CODEPUSH_KEY\", '\"my_code\"'\n            matchingFallbacks = ['release']\n        }\n        release {\n            minifyEnabled enableProguardInReleaseBuilds\n            proguardFiles getDefaultProguardFile(\"proguard-android.txt\"), \"proguard-rules.pro\"\n            signingConfig signingConfigs.release\n            buildConfigField \"String\", \"CODEPUSH_KEY\", '\"my_code\"'\n        }\n    }\n</code></pre>\n\n<p>My build-settings contain the codePush Release and staging code's.</p>\n\n<p><a href=\"https://i.stack.imgur.com/Sa7Wn.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/Sa7Wn.png\" alt=\"enter image description here\"></a></p>\n\n<p>I also tried upgrading the CodePush Staging releases to production, but that did not solve my problem.</p>\n\n<p><code>appcenter codepush deployment list -a Name/MyApp</code> always returns 0 (1 pending).\n<a href=\"https://i.stack.imgur.com/ER7nQ.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/ER7nQ.png\" alt=\"enter image description here\"></a></p>\n\n<p><strong>UPDATE</strong>\nIt asks to update the app, after approving it successfully updates the app. But when I restart the app, it rollbacked to the previous version.</p>\n\n<p><strong>UPDATE 2</strong>\nAppDelgate.m changes:</p>\n\n<pre><code>#import &lt;CodePush/CodePush.h&gt;\n\n#if DEBUG\n  return [[RCTBundleURLProvider sharedSettings] jsBundleURLForBundleRoot:@\"index\" fallbackResource:nil];\n#else\n  return [CodePush bundleURL];\n#endif\n</code></pre>\n\n<p>MainApplication.java changes:</p>\n\n<pre><code>import com.microsoft.codepush.react.CodePush;\n@Override\nprotected String getJSBundleFile() {\n  return CodePush.getJSBundleFile();\n}\n\n@Override\nprotected List&lt;ReactPackage&gt; getPackages() {\n  return Arrays.&lt;ReactPackage&gt;asList(\n    .. \n    new CodePush(BuildConfig.CODEPUSH_KEY, MainApplication.this, BuildConfig.DEBUG),\n</code></pre>\n\n<p>build.gradle changes:</p>\n\n<pre><code>buildTypes {\n  debug {\n    buildConfigField \"String\", \"CODEPUSH_KEY\", '\"\"'\n  }\n\n  releaseStaging {\n    buildConfigField \"String\", \"CODEPUSH_KEY\", '\"&lt;staging_key&gt;\"'\n    matchingFallbacks = ['release']\n  }\n\n  release {\n    ..\n    buildConfigField \"String\", \"CODEPUSH_KEY\", '\"&lt;prod_key&gt;\"'\n  }\n}\n</code></pre>\n",
                    "OwnerUserId": "6018313",
                    "LastEditorUserId": "6018313",
                    "LastEditDate": "2019-08-07T16:35:46.227",
                    "LastActivityDate": "2021-11-05T08:05:49.360",
                    "Title": "React Native codePush rollback after restart",
                    "Tags": "<react-native><react-navigation><code-push><react-native-code-push>",
                    "AnswerCount": "3",
                    "CommentCount": "4",
                    "FavoriteCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "57804720",
                "ParentRepo": "https://github.com/momopig/yarn-offline-deploy-demo",
                "StackOverflow_Post": {
                    "Id": "57804720",
                    "PostTypeId": "2",
                    "ParentId": "57752923",
                    "CreationDate": "2019-09-05T11:41:56.057",
                    "Score": "1",
                    "Body": "<h1>How to install node modules in local network?</h1>\n\n<h2>1. Solution: yarn offline and 'Offline Mirro'</h2>\n\n<p>One of the main advantages of Yarn is that it can install node_modules from files located in file system. We call it \u201cOffline Mirror\u201d because it mirrors the files downloaded from registry during the first build and stores them locally for future builds.</p>\n\n<h2>2. New problem: How to use yarn in local network?</h2>\n\n<p>Download <a href=\"https://github.com/yarnpkg/yarn/releases\" rel=\"nofollow noreferrer\">yarn.tar.gz</a> into the local repository, and install it in local node_modules directory.</p>\n\n<pre><code>npm install yarn.tar.gz --no-save\n</code></pre>\n\n<h2>3. Usage</h2>\n\n<p># run <code>yarn install</code>, and download the node modules (.tar.gz) into the offline mirror directory '$REPOSITORY/yarn/yarn-offline-mirror'.</p>\n\n<pre><code>npm run online-install\n</code></pre>\n\n<p># with yarn.lock file, install node_modules from offline mirror directory '$REPOSITORY/yarn/yarn-offline-mirror'</p>\n\n<pre><code>npm run offline-install\n</code></pre>\n\n<h2>4. Problems</h2>\n\n<h3>4.1. problem 1</h3>\n\n4.1.1. description\n\n<p>error can`t make a request in offline mode(\"http://....\")</p>\n\n4.1.2. reason\n\n<p>the indirect dependencies could not be downloaded into offline mirror directory</p>\n\n4.1.3. resolution\n\n<pre><code>yarn config set yarn-offline-mirror-pruning false\n</code></pre>\n\n<h2>5. Github demo</h2>\n\n<p><a href=\"https://github.com/momopig/yarn-offline-deploy-demo\" rel=\"nofollow noreferrer\">yarn-offline-deploy-demo</a></p>\n\n<h2>6. Reference</h2>\n\n<p><a href=\"https://yarnpkg.com/blog/2016/11/24/offline-mirror/\" rel=\"nofollow noreferrer\">1. Running Yarn offline</a></p>\n",
                    "OwnerUserId": "6609197",
                    "LastActivityDate": "2019-09-05T11:41:56.057",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "57878011",
                "ParentRepo": "https://github.com/sportradar/aws-azure-login",
                "StackOverflow_Post": {
                    "Id": "57878011",
                    "PostTypeId": "1",
                    "CreationDate": "2019-09-10T20:44:45.193",
                    "Score": "2",
                    "ViewCount": "724",
                    "Body": "<p>I want to write a script that:</p>\n\n<ol>\n<li>Logs a user into Azure AD with the <a href=\"https://github.com/AzureAD/azure-activedirectory-library-for-python/wiki/Device-Code\" rel=\"nofollow noreferrer\">device code mechanism</a></li>\n<li>Constructs a <a href=\"https://learn.microsoft.com/en-us/azure/active-directory/develop/single-sign-on-saml-protocol\" rel=\"nofollow noreferrer\">SAML SSO request URL</a></li>\n<li>Makes the SAML request using the auth from step 1</li>\n<li>Gets the SAML response back, and does something with it (not just open it in a browser)</li>\n</ol>\n\n<p>Is there a way to do that with the Azure AD libraries?</p>\n\n<p>I feel like this should be possible and I\u2019m just missing something. Any ideas?\nI've tried a bunch of stuff and experimented with code in the Python library, but to no avail. </p>\n\n<p>I would prefer Python, but I can run it in a Docker image so language isn\u2019t so important.</p>\n\n<hr>\n\n<h3>Context</h3>\n\n<p>At work, we use Azure AD for authentication, and we can log into the AWS Console using Azure AD and SSO SAML.</p>\n\n<p>If I construct an appropriate SAML request URL and open it in my browser, I go through the in-browser auth flow. When I\u2019m logged in, Azure AD returns a SAML response, and eventually my browser redirects me to the AWS console. It\u2019s a URL of the form:</p>\n\n<pre><code>https://login.microsoftonline.com/11111111-1111-1111-11111111111/saml2?SAMLRequest=&lt;base64 encoded string&gt;\n</code></pre>\n\n<p></p></p>\n\n<p>Now I want to do a similar flow for AWS credentials \u2013 make a SAML request to log in, read the SAML response, create credentials using <a href=\"https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sts.html?highlight=saml#STS.Client.assume_role_with_saml\" rel=\"nofollow noreferrer\">assume_role_with_saml</a>, then write those to <code>~/.aws/credentials</code>. I think that means I have to access the SAML response directly \u2013 the browser just drops me at the end of the redirect chain.</p>\n\n<p>Any ideas?</p>\n\n<hr>\n\n<h3>Other ideas</h3>\n\n<ul>\n<li><p>I\u2019m aware of the <a href=\"https://github.com/sportradar/aws-azure-login\" rel=\"nofollow noreferrer\">aws-azure-login npm package</a> which does this by spinning up a headless browser \u2013 but it\u2019s unmaintained and I\u2019ve found it to be a flaky.</p></li>\n<li><p>Right now I have a Python script that opens the SAML request in Chrome (where I log in), then uses the <a href=\"https://pypi.org/project/browsercookie/\" rel=\"nofollow noreferrer\">browsercookie library</a> to raid Chrome\u2019s cookie jar and use those for its HTTP requests. That works, but it feels weird to be copying cookies this way. Also, it doesn\u2019t work if I\u2019m ssh'd into a remote server.</p></li>\n<li><p>I found an answer from <a href=\"https://stackoverflow.com/a/48467635/1558022\">a year and a half ago</a> that says \u201cADAL.JS does not support SAML2 tokens\u201d. Wondering if that might have changed, or am I still stuck?</p></li>\n</ul>\n",
                    "OwnerUserId": "1558022",
                    "LastActivityDate": "2019-09-12T00:56:57.050",
                    "Title": "Can I use the Azure Active Directory libraries (ADAL) to get a SAML response from Azure AD?",
                    "Tags": "<azure><saml><adal>",
                    "AnswerCount": "2",
                    "CommentCount": "2",
                    "FavoriteCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "58058348",
                "ParentRepo": "https://github.com/luminati-io/luminati-proxy",
                "StackOverflow_Post": {
                    "Id": "58058348",
                    "PostTypeId": "2",
                    "ParentId": "58032604",
                    "CreationDate": "2019-09-23T08:22:40.303",
                    "Score": "1",
                    "Body": "<p>Using proxy authentication with selenium can be tricky because you need to use the right versions of webdriver, selenium and browser to all support using a proxy. My recommendation is to use one of these alternatives to setting the proxy directly in your code using selenium.</p>\n\n<ol>\n<li>Set the proxy with credentials on the host machine - just be careful to turn the proxy off when you don't need it or to set it up in a virtual machine that you only use with the proxy. that is how they recommend doing it on the selenium website: <a href=\"https://www.seleniumhq.org/docs/04_webdriver_advanced.jsp#using-a-proxy\" rel=\"nofollow noreferrer\">https://www.seleniumhq.org/docs/04_webdriver_advanced.jsp#using-a-proxy</a></li>\n<li>Use Luminati Proxy manager (<a href=\"https://github.com/luminati-io/luminati-proxy\" rel=\"nofollow noreferrer\">https://github.com/luminati-io/luminati-proxy</a>) to set up a proxy port that does not require authentication and passes the traffic on with your proxy credentials.</li>\n<li>Use puppeteer to handle headless chrome (<a href=\"https://pypi.org/project/pyppeteer/\" rel=\"nofollow noreferrer\">https://pypi.org/project/pyppeteer/</a>) as the puppeteer library comes with the right version of chromium and is much easier to get started with.</li>\n</ol>\n",
                    "OwnerUserId": "12105782",
                    "LastActivityDate": "2019-09-23T08:22:40.303",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "58177298",
                "ParentRepo": "https://github.com/CyberSource/cybersource-flex-samples-node",
                "StackOverflow_Post": {
                    "Id": "58177298",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "58185371",
                    "CreationDate": "2019-10-01T02:17:07.397",
                    "Score": "3",
                    "ViewCount": "1048",
                    "Body": "<p>The CyberSource Token Management Service (described <a href=\"https://developer.cybersource.com/api/developer-guides/dita-tms/intro.html\" rel=\"nofollow noreferrer\">here</a> and <a href=\"https://developer.cybersource.com/api-reference-assets/index.html#token_management\" rel=\"nofollow noreferrer\">here</a>) allows you to create \"instruments\" which are tokenized cards that can be stored with a user's account and used for later purchases/transactions with your service.</p>\n\n<p>I would like to use the Flex API (described <a href=\"https://developer.cybersource.com/api/developer-guides/dita-flex/SAFlexibleToken/FlexAPI.html\" rel=\"nofollow noreferrer\">here</a>, <a href=\"https://developer.cybersource.com/api-reference-assets/index.html#flex#generate-key\" rel=\"nofollow noreferrer\">here</a> and <a href=\"https://github.com/CyberSource/cybersource-flex-samples-node\" rel=\"nofollow noreferrer\">here</a>) to perform an initial tokenization of the card.  Can I then use a Flex token to perform TMS calls?</p>\n\n<p>Obviously both mechanisms are tokenization, but there are advantages to both:</p>\n\n<ol>\n<li>TMS seems intended for long-term storage and supports auto-superseding PANs.</li>\n<li>Flex has the capability to switch to micro-form iframes.</li>\n</ol>\n\n<p>So it would be useful to do the initial tokenization with Flex for PCI-DSS reasons, and then use that to create TMS tokens for long-term storage.</p>\n",
                    "OwnerUserId": "700471",
                    "LastActivityDate": "2022-08-18T11:26:01.863",
                    "Title": "Can the CyberSource TMS API be used with a Flex API Token?",
                    "Tags": "<cybersource>",
                    "AnswerCount": "2",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "58632531",
                "ParentRepo": "https://github.com/kazzkiq/svero",
                "StackOverflow_Post": {
                    "Id": "58632531",
                    "PostTypeId": "1",
                    "CreationDate": "2019-10-30T19:36:35.417",
                    "Score": "1",
                    "ViewCount": "327",
                    "Body": "<p>I am using <a href=\"https://github.com/kazzkiq/svero\" rel=\"nofollow noreferrer\">Svero</a> to do routing in Svelte. I have the following set up per the <a href=\"https://github.com/kazzkiq/svero\" rel=\"nofollow noreferrer\">Svero docs</a>: </p>\n\n<pre class=\"lang-html prettyprint-override\"><code>&lt;Router&gt;\n  &lt;Route path=\"/\" component={FrontPage} /&gt;\n  &lt;Route path=\"/pricing\" component={Pricing} /&gt;\n  &lt;Route path=\"/about\" component={About} /&gt;\n  &lt;Route path=\"/*\" component={ErrorPage}&gt;\n&lt;/Router&gt;\n</code></pre>\n\n<p>Note I do <em>not</em> wish to have / be the same route as errors (as shown in the docs)</p>\n\n<p>This has the following side effects:</p>\n\n<ul>\n<li>Visits to / show the <code>FrontPage</code> content</li>\n<li>Visits to /pricing <strong>show the <code>FrontPage</code> content</strong> followed by the <code>Pricing</code> content</li>\n<li>Visits to /about <strong>show the <code>FrontPage</code> content</strong> followed by the <code>About</code> content</li>\n<li>Visits to / do not show anything</li>\n</ul>\n\n<p><strong>How can I make a route specifically for / with content that does not show up on other routes</strong>? How can I have a working fallback route? </p>\n\n<p>Note I have tried <code>path=\"/$\"</code> in case Svero supports RegExs, and it didn't work. </p>\n",
                    "OwnerUserId": "123671",
                    "LastActivityDate": "2019-10-30T19:55:47.633",
                    "Title": "How can I have a specific route for / using Svelte and Svero?",
                    "Tags": "<routing><svelte>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "58750024",
                "ParentRepo": "https://github.com/microsoft/code-push",
                "StackOverflow_Post": {
                    "Id": "58750024",
                    "PostTypeId": "2",
                    "ParentId": "58728432",
                    "CreationDate": "2019-11-07T13:41:34.623",
                    "Score": "0",
                    "Body": "<blockquote>\n  <p>For Ionic you can use <a href=\"https://ionicframework.com/docs/native/code-push\" rel=\"nofollow noreferrer\">Codepush</a>  \"A cloud service that enables\n  Cordova and React Native developers to deploy mobile app updates\n  directly to their users\u2019 devices.\"\n  <a href=\"https://github.com/microsoft/code-push\" rel=\"nofollow noreferrer\">https://github.com/microsoft/code-push</a></p>\n</blockquote>\n",
                    "OwnerUserId": "5330655",
                    "LastActivityDate": "2019-11-07T13:41:34.623",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "59192428",
                "ParentRepo": "https://github.com/imyoungyang/cdk-in-lambda",
                "StackOverflow_Post": {
                    "Id": "59192428",
                    "PostTypeId": "1",
                    "CreationDate": "2019-12-05T09:55:21.060",
                    "Score": "1",
                    "ViewCount": "364",
                    "Body": "<p>I need to dynamically create git branch testing resources on AWS. So, I need to \nwebhook -> api gateway -> lambda -> provision resources.</p>\n\n<p>I wrote an example to let AWS CDK can be executed in AWS Lambda environment.</p>\n\n<p><a href=\"https://github.com/imyoungyang/cdk-in-lambda\" rel=\"nofollow noreferrer\">https://github.com/imyoungyang/cdk-in-lambda</a></p>\n",
                    "OwnerUserId": "6299638",
                    "LastEditorUserId": "373542",
                    "LastEditDate": "2022-04-10T16:30:00.280",
                    "LastActivityDate": "2022-04-10T16:30:00.280",
                    "Title": "Execute AWS CDK in Lambda environment",
                    "Tags": "<aws-lambda><aws-cdk>",
                    "AnswerCount": "1",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "59244444",
                "ParentRepo": "https://github.com/Liorba/jupyterlab-spark-ui-tab",
                "StackOverflow_Post": {
                    "Id": "59244444",
                    "PostTypeId": "1",
                    "CreationDate": "2019-12-09T07:41:32.040",
                    "Score": "3",
                    "ViewCount": "2974",
                    "Body": "<p>I am trying to install <strong>jupyter labextenstion</strong> using instruction given in <a href=\"https://github.com/Liorba/jupyterlab-spark-ui-tab\" rel=\"nofollow noreferrer\">https://github.com/Liorba/jupyterlab-spark-ui-tab</a></p>\n\n<pre><code>An error occured.\nValueError: This extension does not yet support the current version of JupyterLab.\n\n\nConflicting Dependencies:\nJupyterLab              Extension              Package\n&gt;=2.0.0-alpha.3 &lt;2.1.0  &gt;=0.19.1 &lt;0.20.0       @jupyterlab/application\n&gt;=2.0.0-alpha.3 &lt;2.1.0  &gt;=0.19.1 &lt;0.20.0       @jupyterlab/apputils\n</code></pre>\n\n<p>I have tried with a different version of <strong>jupyterlab</strong> still facing this issue.</p>\n\n<p>If anyone solved same kind of problem please suggest a solution.</p>\n",
                    "OwnerUserId": "8444578",
                    "LastEditorUserId": "1021819",
                    "LastEditDate": "2020-04-03T10:59:24.867",
                    "LastActivityDate": "2020-04-03T10:59:24.867",
                    "Title": "How to install jupyter labextension?",
                    "Tags": "<python><apache-spark><jupyter-notebook><jupyter-lab>",
                    "AnswerCount": "0",
                    "CommentCount": "2",
                    "FavoriteCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "59621214",
                "ParentRepo": "https://github.com/awslabs/realworld-serverless-application",
                "StackOverflow_Post": {
                    "Id": "59621214",
                    "PostTypeId": "2",
                    "ParentId": "57450146",
                    "CreationDate": "2020-01-07T01:51:11.577",
                    "Score": "1",
                    "Body": "<p>What constitutes \u2018native\u2019 serverless is probably up for debate and constitutes a bit of a spectrum. There are ways to take advantage of managed services such that lambda function usage is minimized, but there are plenty of use-cases that require custom logic e.g. integrating with third-party services.</p>\n\n<p>I\u2019d start by asking yourself what your existing application does, and how large your time investment is going to be in order to refactor to be as \u2018serverless\u2019 as possible. If this is a project that you are using for purely learning purposes, you may want to do a full conversion to maximize your learning. If this is a revenue generating application for a business, this may be an inappropriate use of resources for the payoff.</p>\n\n<p>That said, the main differences between current best-practice serverless and usage of serverless-express will be:</p>\n\n<ul>\n<li>Presence of additional dependencies. This will take some additional time to resolve at runtime [1], will need to be managed correctly at deployment time (packaging), and will require additional effort to update/patch/audit (security).</li>\n<li>Permission granularity - as all route management is delegated to express, you will not be able to set permissions granularly for each route at the infrastructure level.</li>\n<li>You will not be able to set resource limits on a per route basis</li>\n</ul>\n\n<p>On the other hand:</p>\n\n<ul>\n<li>You will avoid large cloud formation templates</li>\n<li>Take advantage of your existing tooling and knowledge of express</li>\n</ul>\n\n<p>Although it does depend on what the application is/does, it is unlikely that you will notice much of a cold-start penalty over single-purpose lambda functions, and would probably be a case of premature optimization. Part of the serverless mindset is about focusing on value - so if it were me doing this, I'd do as little as possible to get the application running in lambda - start instrumenting routes with X-Ray and CloudWatch [2], and then optimize the routes that require it.</p>\n\n<p>From a learning perspective, if you do choose to use serverless-express, you will likely miss out on the opportunity to learn more about service-integrations, VTL transformations, request/response mapping etc that you would be exposed to if you took the more segmented approach. You can build some pretty cool things with just API Gateway and DynamoDB - without even having to touch a lambda function.</p>\n\n<p>That\u2019s not to say that using express in this way is a bad thing - AWS themselves note that this is a valid way to build a serverless application and new features like the HTTP API feature for API Gateway [3] help with this. In fact, the [real world serverless application [4] example that was published by AWS follows the single function principle, albeit for Java rather than an express application.</p>\n\n<p>[1] <a href=\"https://www.freecodecamp.org/news/just-how-expensive-is-the-full-aws-sdk-3713fed4fe70/\" rel=\"nofollow noreferrer\">https://www.freecodecamp.org/news/just-how-expensive-is-the-full-aws-sdk-3713fed4fe70/</a></p>\n\n<p>[2] <a href=\"https://theburningmonk.com/2019/11/check-list-for-going-live-with-api-gateway-and-lambda/\" rel=\"nofollow noreferrer\">https://theburningmonk.com/2019/11/check-list-for-going-live-with-api-gateway-and-lambda/</a></p>\n\n<p>[3] <a href=\"https://aws.amazon.com/blogs/compute/announcing-http-apis-for-amazon-api-gateway/\" rel=\"nofollow noreferrer\">https://aws.amazon.com/blogs/compute/announcing-http-apis-for-amazon-api-gateway/</a></p>\n\n<p>[4] <a href=\"https://github.com/awslabs/realworld-serverless-application\" rel=\"nofollow noreferrer\">https://github.com/awslabs/realworld-serverless-application</a></p>\n",
                    "OwnerUserId": "2377016",
                    "LastActivityDate": "2020-01-07T01:51:11.577",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "59832090",
                "ParentRepo": "https://github.com/caseycling/portfolio",
                "StackOverflow_Post": {
                    "Id": "59832090",
                    "PostTypeId": "1",
                    "CreationDate": "2020-01-20T23:10:20.273",
                    "Score": "0",
                    "ViewCount": "140",
                    "Body": "<p>I am currently building a portfolio website with React and need to set up a back-end to process requests for an email API I'm using for my contact page. I've installed express as one of my node modules and created a server.js file at the root with the following code:</p>\n\n<p><div class=\"snippet\" data-lang=\"js\" data-hide=\"false\" data-console=\"true\" data-babel=\"false\">\r\n<div class=\"snippet-code\">\r\n<pre class=\"snippet-code-js lang-js prettyprint-override\"><code>const express = require('express')\r\nconst app = express()\r\nconst port = 8080\r\n\r\napp.get('/hello', (req, res) =&gt; res.send('Hello World!'))\r\n\r\napp.listen(port, () =&gt; console.log(`Example app listening on port ${port}!`))</code></pre>\r\n</div>\r\n</div>\r\n</p>\n\n<p>Very basic start. However when I start my react application, I do not see the \"Example app listening on port 8080\" logged into my node terminal. I'm not sure what I've done wrong exactly as this is all I've needed in the past to start the server I've built with express although this time I built my react app first and then tried to implement this server so perhaps I missed something. \nFull code is here: <a href=\"https://github.com/caseycling/portfolio\" rel=\"nofollow noreferrer\">https://github.com/caseycling/portfolio</a></p>\n",
                    "OwnerUserId": "10818030",
                    "LastEditorUserId": "1087119",
                    "LastEditDate": "2020-01-20T23:24:37.883",
                    "LastActivityDate": "2020-01-20T23:24:37.883",
                    "Title": "Why can't I start up my express server in my React app?",
                    "Tags": "<node.js><express>",
                    "AnswerCount": "0",
                    "CommentCount": "3",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "60232614",
                "ParentRepo": "https://github.com/mycargus/nightwatch-docker-grid",
                "StackOverflow_Post": {
                    "Id": "60232614",
                    "PostTypeId": "2",
                    "ParentId": "60230096",
                    "CreationDate": "2020-02-14T19:46:54.313",
                    "Score": "1",
                    "Body": "<p>I haven't tried this myself but have found the below discussion and docs useful.</p>\n\n<p><a href=\"https://github.com/nightwatchjs/nightwatch/issues/1270\" rel=\"nofollow noreferrer\">https://github.com/nightwatchjs/nightwatch/issues/1270</a></p>\n\n<p><a href=\"https://medium.com/@kenfehling/ui-testing-with-nightwatch-js-headless-chrome-and-docker-part-1-f0ce2e8a23a1\" rel=\"nofollow noreferrer\">https://medium.com/@kenfehling/ui-testing-with-nightwatch-js-headless-chrome-and-docker-part-1-f0ce2e8a23a1</a></p>\n\n<p>If you consider using selenium grid,</p>\n\n<p><a href=\"https://github.com/mycargus/nightwatch-docker-grid\" rel=\"nofollow noreferrer\">https://github.com/mycargus/nightwatch-docker-grid</a></p>\n\n<p>Cheers!</p>\n",
                    "OwnerUserId": "3879644",
                    "LastActivityDate": "2020-02-14T19:46:54.313",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "60747265",
                "ParentRepo": "https://github.com/john-shaskin/polly-notes-reader",
                "StackOverflow_Post": {
                    "Id": "60747265",
                    "PostTypeId": "2",
                    "ParentId": "53797428",
                    "CreationDate": "2020-03-18T20:46:41.680",
                    "Score": "2",
                    "Body": "<p>The connection is closed after writing a few bytes,\ntarget <a href=\"https://github.com/john-shaskin/polly-notes-reader\" rel=\"nofollow noreferrer\">https://github.com/john-shaskin/polly-notes-reader</a>\nTry the following:</p>\n\n<p>run git bash(Do not use openssh, use git bash only) for windows, and enter the following commands</p>\n\n<pre><code>git config --global http.postBuffer 524288000\ngit config --global ssh.postBuffer 524288000\n</code></pre>\n\n<p>use simple settings for git push</p>\n\n<pre><code>git config --global push.default simple\n</code></pre>\n\n<p>change folder to repository you want to commit</p>\n\n<pre><code>cd /{driveletter}/{rootdir}/{repo}/{src}\n\ncd /d/projects/repo/src &lt;---- change accordingly.\n</code></pre>\n\n<p>now try </p>\n\n<pre><code>git push \n</code></pre>\n\n<p>If you still get the error, you need to enable GIT_TRACE_PACKET=true and GIT_TRACE=2, post the error log here again, I'll help you through it.</p>\n",
                    "OwnerUserId": "7384147",
                    "LastActivityDate": "2020-03-18T20:46:41.680",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "60882342",
                "ParentRepo": "https://github.com/coding-with-dom/intro-to-nightwatchjs/commit/a2e0e05351c9e1c9e108bdf1083ae2a03e0296d1",
                "StackOverflow_Post": {
                    "Id": "60882342",
                    "PostTypeId": "2",
                    "ParentId": "60882226",
                    "CreationDate": "2020-03-27T08:29:14.687",
                    "Score": "7",
                    "Body": "<p>Finally, I got a solution when I show his git account of the tutorial also post the solution too.</p>\n\n<p><a href=\"https://github.com/coding-with-dom/intro-to-nightwatchjs/commit/a2e0e05351c9e1c9e108bdf1083ae2a03e0296d1\" rel=\"noreferrer\">https://github.com/coding-with-dom/intro-to-nightwatchjs/commit/a2e0e05351c9e1c9e108bdf1083ae2a03e0296d1</a></p>\n\n<p><a href=\"https://i.stack.imgur.com/Zmg6I.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/Zmg6I.png\" alt=\"enter image description here\"></a></p>\n\n<p>I just need to change my file nightwatch.conf.js</p>\n\n<pre><code>module.exports = {\n  \"src_folders\" : [\"tests\"],\n\n  \"webdriver\" : {\n    \"start_process\": true,\n    \"server_path\": require('chromedriver').path,\n    \"port\": 9515\n  },\n\n  \"test_settings\" : {\n    \"default\" : {\n      \"desiredCapabilities\": {\n        \"browserName\": \"chrome\"\n      }\n    }\n  }\n}\n</code></pre>\n",
                    "OwnerUserId": "8694377",
                    "LastActivityDate": "2020-03-27T08:29:14.687",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "61397521",
                "ParentRepo": "https://github.com/sanderaernouts/vsts-git-tasks/blob/master/createpullrequest/createPullRequest.ts",
                "StackOverflow_Post": {
                    "Id": "61397521",
                    "PostTypeId": "2",
                    "ParentId": "61396789",
                    "CreationDate": "2020-04-23T21:44:11.293",
                    "Score": "0",
                    "Body": "<p>My colleague Sander has <a href=\"https://marketplace.visualstudio.com/items?itemName=sander-aernouts.git-buildtasks\" rel=\"nofollow noreferrer\">created an extension which does all the hard work of creating the PR</a>.</p>\n\n<p>If you want to see how it's done, <a href=\"https://github.com/sanderaernouts/vsts-git-tasks/blob/master/createpullrequest/createPullRequest.ts\" rel=\"nofollow noreferrer\">check out the source to the extension</a>.</p>\n\n<p>Another option s to use the <a href=\"https://learn.microsoft.com/en-us/cli/azure/ext/azure-devops/repos/pr?view=azure-cli-latest#ext-azure-devops-az-repos-pr-create\" rel=\"nofollow noreferrer\"><code>az repos pr create</code> command in the Azure CLI with the DevOps extension</a>. You'll need to enable script access to the pipeline's OAuth token to authenticate I presume.</p>\n",
                    "OwnerUserId": "736079",
                    "LastActivityDate": "2020-04-23T21:44:11.293",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "61397521",
                "ParentRepo": "https://github.com/sanderaernouts/vsts-git-tasks/blob/master/createpullrequest/createPullRequest.ts",
                "StackOverflow_Post": {
                    "Id": "61397521",
                    "PostTypeId": "2",
                    "ParentId": "61396789",
                    "CreationDate": "2020-04-23T21:44:11.293",
                    "Score": "0",
                    "Body": "<p>My colleague Sander has <a href=\"https://marketplace.visualstudio.com/items?itemName=sander-aernouts.git-buildtasks\" rel=\"nofollow noreferrer\">created an extension which does all the hard work of creating the PR</a>.</p>\n\n<p>If you want to see how it's done, <a href=\"https://github.com/sanderaernouts/vsts-git-tasks/blob/master/createpullrequest/createPullRequest.ts\" rel=\"nofollow noreferrer\">check out the source to the extension</a>.</p>\n\n<p>Another option s to use the <a href=\"https://learn.microsoft.com/en-us/cli/azure/ext/azure-devops/repos/pr?view=azure-cli-latest#ext-azure-devops-az-repos-pr-create\" rel=\"nofollow noreferrer\"><code>az repos pr create</code> command in the Azure CLI with the DevOps extension</a>. You'll need to enable script access to the pipeline's OAuth token to authenticate I presume.</p>\n",
                    "OwnerUserId": "736079",
                    "LastActivityDate": "2020-04-23T21:44:11.293",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "62215558",
                "ParentRepo": "https://github.com/Louisrobertson20/bluebrew",
                "StackOverflow_Post": {
                    "Id": "62215558",
                    "PostTypeId": "1",
                    "CreationDate": "2020-06-05T12:38:41.433",
                    "Score": "-1",
                    "ViewCount": "42",
                    "Body": "<p>Upon deploying website on Heroku, error code H12 (timeout) is encountered when clicking on 'blog' page link (all other links are fine), and 'internal server error' appears when submitting forms. No issues experienced when testing on local host. </p>\n\n<p>Github code: <a href=\"https://github.com/Louisrobertson20/bluebrew\" rel=\"nofollow noreferrer\">https://github.com/Louisrobertson20/bluebrew</a></p>\n",
                    "OwnerUserId": "13687378",
                    "LastActivityDate": "2020-06-05T19:08:46.667",
                    "Title": "Why are Heroku errors messages H12 timeout and 'internal server error' appearing upon deployment, when no issues experienced on local host?",
                    "Tags": "<heroku><timeout><internal-server-error>",
                    "AnswerCount": "2",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "62382750",
                "ParentRepo": "https://github.com/pulumi/pulumi-eks",
                "StackOverflow_Post": {
                    "Id": "62382750",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "62383158",
                    "CreationDate": "2020-06-15T06:44:24.527",
                    "Score": "0",
                    "ViewCount": "123",
                    "Body": "<p>There are Kubernetes RBAC in Amazon EKS with Pulumi instructions for TypeScript.</p>\n<pre class=\"lang-js prettyprint-override\"><code>const vpc = new awsx.ec2.Vpc(&quot;vpc&quot;, {});\nconst cluster = new eks.Cluster(&quot;eks-cluster&quot;, {\n  vpcId             : vpc.id,\n  subnetIds         : vpc.publicSubnetIds,\n  instanceType      : &quot;t2.medium&quot;,\n  nodeRootVolumeSize: 200,\n  desiredCapacity   : 1,\n  maxSize           : 2,\n  minSize           : 1,\n  deployDashboard   : false,\n  vpcCniOptions     : {\n    warmIpTarget    : 4,\n  },\n  roleMappings      : [\n    // Provides full administrator cluster access to the k8s cluster\n    {\n      groups    : [&quot;system:masters&quot;],\n      roleArn   : clusterAdminRole.arn,\n      username  : &quot;pulumi:admin-usr&quot;,\n    },\n    // Map IAM role arn &quot;AutomationRoleArn&quot; to the k8s user with name &quot;automation-usr&quot;, e.g. gitlab CI\n    {\n      groups    : [&quot;pulumi:automation-grp&quot;],\n      roleArn   : AutomationRole.arn,\n      username  : &quot;pulumi:automation-usr&quot;,\n    },\n    // Map IAM role arn &quot;EnvProdRoleArn&quot; to the k8s user with name &quot;prod-usr&quot;\n    {\n      groups    : [&quot;pulumi:prod-grp&quot;],\n      roleArn   : EnvProdRole.arn,\n      username  : &quot;pulumi:prod-usr&quot;,\n    },\n  ],\n});\n</code></pre>\n<blockquote>\n<p>Kubernetes RBAC in AWS EKS with open source Pulumi packages | Pulumi <a href=\"https://www.pulumi.com/blog/simplify-kubernetes-rbac-in-amazon-eks-with-open-source-pulumi-packages/\" rel=\"nofollow noreferrer\">https://www.pulumi.com/blog/simplify-kubernetes-rbac-in-amazon-eks-with-open-source-pulumi-packages/</a></p>\n</blockquote>\n<p>I'm looking for how to achieve this with .NET C#?\nIt looks like eks roleMappings extensions is only available for TypeScript, so that C# may be require to construct configmap manifest with Pulumi.Kubernetes?</p>\n<blockquote>\n<p><a href=\"https://github.com/pulumi/pulumi-aws/blob/c672e225a765b11b07ea23e7b1b411483d7f38da/sdk/dotnet/Eks/Cluster.cs\" rel=\"nofollow noreferrer\">https://github.com/pulumi/pulumi-aws/blob/c672e225a765b11b07ea23e7b1b411483d7f38da/sdk/dotnet/Eks/Cluster.cs</a></p>\n<p><a href=\"https://github.com/pulumi/pulumi-eks\" rel=\"nofollow noreferrer\">https://github.com/pulumi/pulumi-eks</a></p>\n</blockquote>\n",
                    "OwnerUserId": "10127260",
                    "LastEditorUserId": "-1",
                    "LastEditDate": "2020-06-20T09:12:55.060",
                    "LastActivityDate": "2020-06-15T07:16:10.473",
                    "Title": "How can I achieve Pulumi EKS RoleMappings with C#",
                    "Tags": "<c#><amazon-web-services><kubernetes><pulumi>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "62482350",
                "ParentRepo": "https://github.com/SalvadorSTM/My-Website",
                "StackOverflow_Post": {
                    "Id": "62482350",
                    "PostTypeId": "1",
                    "CreationDate": "2020-06-20T06:17:16.620",
                    "Score": "0",
                    "ViewCount": "55",
                    "Body": "<p>I'm building my first website. <a href=\"https://github.com/SalvadorSTM/My-Website\" rel=\"nofollow noreferrer\">Full source code available here.</a> </p>\n\n<p>When I access my website from its local ip in my home network it loads almost instantly, but when I access it through the domain name imsalvador.com (google domain) it sometimes stalls for around 10 seconds.</p>\n\n<p><a href=\"https://i.stack.imgur.com/wL2Ns.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/wL2Ns.png\" alt=\"\"></a></p>\n\n<p>I am running my NodeJs Express website with pm2 on a raspberry pi 3b+, from my really good gigabit fiber internet. </p>\n\n<p>I don't think it's chrome's 6 connection limit thats causing the long wait, as this has happened on many different devices ive tested from.</p>\n\n<p>This is the only thing im running on my pi, so resources should not be an issue. </p>\n\n<p><strong>Important Details</strong></p>\n\n<ol>\n<li>This is a NodeJs Express website</li>\n<li>Using certificate from Lets Encrypt to run with SSL</li>\n<li>Domain is from google domains, forwarding all http traffic to <strong>https</strong>://www.imsalvador.com/</li>\n<li>Using google Dynamic DNS API to provide my ip to google</li>\n<li>Iptables forwarding traffic from port <code>443 (https)</code> to <code>3001</code> (chosen listening port in app.js).</li>\n<li>Simple sendFile when <code>\"/\"</code> is requested <code>res.sendFile(__dirname + \"/index.html\");</code></li>\n<li>Top reporting healthy resources</li>\n<li>Rasp Pi 3b+ CPU has 4 cores, so I have pm2 running with 3 cores, and load balancing between them.</li>\n<li>Same behavior happens with docker node image, pm2, and node app.js</li>\n<li>Running express debug shows that the content is being delivered very fast after the get request is received. </li>\n<li>Running latest raspbian (pi os)</li>\n<li>Using eth0 interface</li>\n</ol>\n",
                    "OwnerUserId": "9351561",
                    "LastActivityDate": "2020-06-20T06:17:16.620",
                    "Title": "Why is my raspberry pi self-hosted website stalling for over 10 seconds inconsistently?",
                    "Tags": "<node.js><performance><express><raspberry-pi><google-chrome-devtools>",
                    "AnswerCount": "0",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "62504109",
                "ParentRepo": "https://github.com/microsoft/appcenter-cli/blob/2c7fab9a3dc617c1d6b9b0dd1561d4baf0f50a7c/src/util/profile/environments.ts",
                "StackOverflow_Post": {
                    "Id": "62504109",
                    "PostTypeId": "1",
                    "CreationDate": "2020-06-21T20:35:31.743",
                    "Score": "2",
                    "ViewCount": "368",
                    "Body": "<p>How to I send environment variables for AppCenter builds using the CLI.</p>\n<p>I want to send an environment variable such as &quot;TENANT=customer1&quot;.</p>\n<p>I am using a command similar to:</p>\n<pre><code>appcenter build queue -b master\n</code></pre>\n<p>I looked into the &quot;--env&quot; parameter but that seems to deal with the environment of things like API endpoints: <a href=\"https://github.com/microsoft/appcenter-cli/blob/2c7fab9a3dc617c1d6b9b0dd1561d4baf0f50a7c/src/util/profile/environments.ts\" rel=\"nofollow noreferrer\">https://github.com/microsoft/appcenter-cli/blob/2c7fab9a3dc617c1d6b9b0dd1561d4baf0f50a7c/src/util/profile/environments.ts</a></p>\n",
                    "OwnerUserId": "3006737",
                    "LastEditorUserId": "3006737",
                    "LastEditDate": "2020-06-21T20:52:52.013",
                    "LastActivityDate": "2022-08-23T16:16:51.767",
                    "Title": "Send environment variables to Visual Studio app center using the CLI",
                    "Tags": "<visual-studio-app-center>",
                    "AnswerCount": "1",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "62739918",
                "ParentRepo": "https://github.com/sureshmangs/Node.js-Stuff/tree/master/sendMailUsingNodemailer",
                "StackOverflow_Post": {
                    "Id": "62739918",
                    "PostTypeId": "2",
                    "ParentId": "62738857",
                    "CreationDate": "2020-07-05T11:14:44.643",
                    "Score": "1",
                    "Body": "<p>You can do the following</p>\n<p>app.js</p>\n<pre><code>var nodemailer = require('nodemailer');\nvar tech = require('./external.js');\n\nvar transporter = nodemailer.createTransport({\n service: 'Gmail',\n auth: {\n        user: tech.senderUsername,\n        pass: tech.senderPassword\n    }\n});\n\nconst mailOptions = {\n  from: tech.senderUsername, // sender address\n  to: tech.reciverUsername, // list of receivers\n  subject: 'Subject of your email', // Subject line\n  html: '&lt;p&gt;Enter your message here.&lt;/p&gt;'// plain text body\n};\n\ntransporter.sendMail(mailOptions, function (err, info) {\n   if(err)\n     console.log(err)\n   else\n     console.log(info);\n});\n</code></pre>\n<p><strong>Note :</strong></p>\n<p>You may also need to follow these steps while using google account</p>\n<p>Enable the settings to allow less secure apps for the Gmail account that you are using.\nHere is the link: <a href=\"https://accounts.google.com/ServiceLogin/signinchooser?service=accountsettings&amp;passive=1209600&amp;osid=1&amp;continue=https%3A%2F%2Fmyaccount.google.com%2Flesssecureapps&amp;followup=https%3A%2F%2Fmyaccount.google.com%2Flesssecureapps&amp;emr=1&amp;mrp=security&amp;flowName=GlifWebSignIn&amp;flowEntry=ServiceLogin\" rel=\"nofollow noreferrer\">Google Less Secure Apps</a></p>\n<p>Allow access for &quot;Display Unlock captcha option&quot; (Allow access to your Google account)\nHere is the link: <a href=\"https://accounts.google.com/ServiceLogin/signinchooser?passive=1209600&amp;continue=https%3A%2F%2Faccounts.google.com%2FDisplayUnlockCaptcha&amp;followup=https%3A%2F%2Faccounts.google.com%2FDisplayUnlockCaptcha&amp;flowName=GlifWebSignIn&amp;flowEntry=ServiceLogin\" rel=\"nofollow noreferrer\">Google Unlock Captcha</a></p>\n<p>For more info, you can go through <a href=\"https://github.com/sureshmangs/Node.js-Stuff/tree/master/sendMailUsingNodemailer\" rel=\"nofollow noreferrer\">sendMailUsingNodemailer</a></p>\n",
                    "OwnerUserId": "11398996",
                    "LastActivityDate": "2020-07-05T11:14:44.643",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "62866252",
                "ParentRepo": "https://github.com/jhuckaby/Cronicle",
                "StackOverflow_Post": {
                    "Id": "62866252",
                    "PostTypeId": "2",
                    "ParentId": "62854358",
                    "CreationDate": "2020-07-12T20:39:56.677",
                    "Score": "0",
                    "Body": "<p>I ended up setting an installation of <a href=\"https://github.com/jhuckaby/Cronicle\" rel=\"nofollow noreferrer\">Cronicle</a> from jhuckaby.</p>\n<p>Essentially a cron manager, but what's most important for my case is the live log-viewer. This enables me to run the script using a cron job at the intervals I defined, and watch as it executes via the log-viewer, while being able to leave and come back at any point to view the currently running task (or any of the previous tasks that ran while I was away).</p>\n<p><a href=\"https://i.stack.imgur.com/k0LGV.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/k0LGV.png\" alt=\"enter image description here\" /></a></p>\n",
                    "OwnerUserId": "4853607",
                    "LastActivityDate": "2020-07-12T20:39:56.677",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "63420084",
                "ParentRepo": "https://github.com/JavascriptLearner815/speedo-bot",
                "StackOverflow_Post": {
                    "Id": "63420084",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "63420212",
                    "CreationDate": "2020-08-14T21:12:34.700",
                    "Score": "1",
                    "ViewCount": "1124",
                    "Body": "<p>I am trying to make a <strong>has-permission</strong> command for my Discord bot, which takes two arguments: the user to check, and the permission to check for. You can see the code in the <a href=\"https://github.com/JavascriptLearner815/speedo-bot\" rel=\"nofollow noreferrer\">bot's GitHub repository</a> (the <code>config.json</code> file is hidden due to it containing private information about my bot application).</p>\n<p>Discord Screenshot:\n<img src=\"https://i.stack.imgur.com/PAMGo.png\" alt=\"Discord Screenshot\" /></p>\n<p>The bot just replies <code>there was an error trying to execute that command!</code>.</p>\n<p>Console Screenshot:\n<img src=\"https://i.stack.imgur.com/GfD8i.png\" alt=\"Console Screenshot\" /></p>\n<p>The console just says <code>TypeError: member.hasPermission is not a function</code>.</p>\n<p>Is there any way around this? It seems like this is the only problem I am having making this command.</p>\n",
                    "OwnerUserId": "13900902",
                    "LastEditorUserId": "13900902",
                    "LastEditDate": "2020-08-16T21:18:36.670",
                    "LastActivityDate": "2020-08-16T21:18:36.670",
                    "Title": "`TypeError: member.hasPermission() is not a function` when checking permissions in discord.js",
                    "Tags": "<javascript><node.js><discord><discord.js>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "63483778",
                "ParentRepo": "https://github.com/golkhandani/pm2_docker/tree/master",
                "StackOverflow_Post": {
                    "Id": "63483778",
                    "PostTypeId": "2",
                    "ParentId": "63473887",
                    "CreationDate": "2020-08-19T09:17:19.813",
                    "Score": "1",
                    "Body": "<p>The best approach would be using <code>ecosystem.config.js</code>.\nPut this file in your project's root dir:</p>\n<pre><code>\nmodule.exports = {\n  apps: [{\n    name: 'app',\n    script: 'src/index.js', // Your entry point\n    instances: 1,\n    autorestart: true, // THIS is the important part, this will tell PM2 to restart your app if it falls over\n    max_memory_restart: '1G'\n  }]\n}\n</code></pre>\n<p>then install pm2 as npm module in your project and add this script to your <code>package.json</code></p>\n<pre><code>...\nscripts: {\n...\n  &quot;start:pm2&quot;:&quot;pm2 start ecosystem.config.js --no-daemon&quot;\n}\n</code></pre>\n<p>and finally use this CMD in your dockerfile</p>\n<pre><code>CMD [ &quot;npm&quot;, &quot;run&quot;, &quot;start:pm2&quot; ]\n</code></pre>\n<p><strong>EDIT 1</strong></p>\n<p>you can find a sample project here with original dockerfile:</p>\n<p><a href=\"https://github.com/golkhandani/pm2_docker/tree/master\" rel=\"nofollow noreferrer\">https://github.com/golkhandani/pm2_docker/tree/master</a></p>\n<p><a href=\"https://i.stack.imgur.com/viLyk.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/viLyk.png\" alt=\"enter image description here\" /></a></p>\n<p><strong>EDIT 2</strong></p>\n<p>I have just tested the repo with another <code>Manjaro</code> linux and\nhere is commands</p>\n<pre><code>git clone https://github.com/golkhandani/pm2_docker.git\n\ndocker build pm2_docker/ --tag pm2docker:test\n\ndocker run -p 3000:3000 -t pm2docker:test\n</code></pre>\n<p>the <code>-p 3000:3000</code> arg should be added to access locally to your server.</p>\n<p>these are additional screenshots that show command and results:</p>\n<p><a href=\"https://i.stack.imgur.com/1Viz8.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/1Viz8.png\" alt=\"enter image description here\" /></a></p>\n<p><a href=\"https://i.stack.imgur.com/ajdhX.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/ajdhX.png\" alt=\"enter image description here\" /></a></p>\n<p><a href=\"https://i.stack.imgur.com/NhJvR.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/NhJvR.png\" alt=\"enter image description here\" /></a></p>\n<p><a href=\"https://i.stack.imgur.com/qTnW9.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/qTnW9.png\" alt=\"enter image description here\" /></a></p>\n",
                    "OwnerUserId": "9758562",
                    "LastEditorUserId": "9758562",
                    "LastEditDate": "2020-08-19T19:30:48.857",
                    "LastActivityDate": "2020-08-19T19:30:48.857",
                    "CommentCount": "10",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "64288550",
                "ParentRepo": "https://github.com/II-alex-II/leader-line-new",
                "StackOverflow_Post": {
                    "Id": "64288550",
                    "PostTypeId": "2",
                    "ParentId": "62932910",
                    "CreationDate": "2020-10-09T23:37:35.743",
                    "Score": "9",
                    "Body": "<p><a href=\"https://github.com/anseki/leader-line/\" rel=\"noreferrer\">Leader Line</a> package cannot be imported as discussed in this <a href=\"https://github.com/anseki/leader-line/issues/8#issuecomment-370147614\" rel=\"noreferrer\">GitHub issue</a>.</p>\n<p>An updated package is available here: <a href=\"https://github.com/II-alex-II/leader-line-new\" rel=\"noreferrer\">Leader Line New</a>. This package is just the <strong>anseki</strong> version with imports and types.</p>\n<p>The javascript in your case looks like this:</p>\n<pre class=\"lang-js prettyprint-override\"><code>import LeaderLine from 'leader-line-new';\nconst myLine = new LeaderLine(\n     document.getElementById('start'),\n     document.getElementById('end')\n);\n</code></pre>\n",
                    "OwnerUserId": "8176040",
                    "LastActivityDate": "2020-10-09T23:37:35.743",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "64622172",
                "ParentRepo": "https://github.com/cyrilis/epub-gen/blob/master/lib/index.js",
                "StackOverflow_Post": {
                    "Id": "64622172",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "64622515",
                    "CreationDate": "2020-10-31T13:26:51.337",
                    "Score": "0",
                    "ViewCount": "321",
                    "Body": "<p>I use <strong>epub-gen</strong> in <code>reactjs</code>.</p>\n<blockquote>\n<p>Unhandled Rejection (TypeError): fs.existsSync is not a function</p>\n</blockquote>\n<p>I tested <code>import * as fs from &quot;fs&quot; </code>  instead of <code> var fs = require(&quot;fs&quot;)</code>.</p>\n<p>epub-gen/lib/index.js <a href=\"https://github.com/cyrilis/epub-gen/blob/master/lib/index.js\" rel=\"nofollow noreferrer\">here</a>.</p>\n<pre><code>// Generated by CoffeeScript 2.3.2\n(function() {\n  var fs = require(&quot;fs&quot;);\n...\n  EPub = class EPub {\n..\n      if (!fs.existsSync(this.options.tempDir)) {\n        fs.mkdirSync(this.options.tempDir);\n      }\n    ..\n</code></pre>\n",
                    "OwnerUserId": "12053014",
                    "LastEditorUserId": "11788715",
                    "LastEditDate": "2021-07-27T19:47:55.413",
                    "LastActivityDate": "2021-07-27T19:47:55.413",
                    "Title": "Unhandled Rejection (TypeError): fs.existsSync is not a function",
                    "Tags": "<javascript><node.js><reactjs><typescript>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "64733606",
                "ParentRepo": "https://github.com/tamino-martinius/cdk-lambda-layers--node-jwt",
                "StackOverflow_Post": {
                    "Id": "64733606",
                    "PostTypeId": "2",
                    "ParentId": "64731376",
                    "CreationDate": "2020-11-07T23:57:58.927",
                    "Score": "1",
                    "Body": "<p>Couldn't the implementation be distributed via npm alongside the CDK module? Provided the CDK construct can resolve the asset relative to itself (e.g. via <code>__dirname</code>) then it should just work, shouldn't it?</p>\n<p>There's <a href=\"https://github.com/tamino-martinius/cdk-lambda-layers--node-jwt\" rel=\"nofollow noreferrer\">an example here</a> where the author creates a redistributable lambda layer using the same approach.</p>\n<pre class=\"lang-js prettyprint-override\"><code>export class NodeJwtLayer extends LayerVersion {\n  constructor(scope: Construct, id: string = &quot;NodeJwtLayer&quot;) {\n    super(scope, id, {\n      code: new AssetCode(__dirname + &quot;/nodejs.zip&quot;)\n</code></pre>\n",
                    "OwnerUserId": "56151",
                    "LastActivityDate": "2020-11-07T23:57:58.927",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "65040921",
                "ParentRepo": "https://github.com/smileynanda99/collegefellow",
                "StackOverflow_Post": {
                    "Id": "65040921",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "65041060",
                    "CreationDate": "2020-11-27T16:45:36.543",
                    "Score": "1",
                    "ViewCount": "48",
                    "Body": "<p><strong>This is my app link</strong>\n<a href=\"https://collegefellow.azurewebsites.net/users/login\" rel=\"nofollow noreferrer\">collegefellow.social/users/login</a></p>\n<p><strong>My code repo</strong><a href=\"https://github.com/smileynanda99/collegefellow\" rel=\"nofollow noreferrer\"> github</a> ( login page=&gt; /views/login.ejs )</p>\n<p><strong>Layout issue</strong>\n<a href=\"https://i.stack.imgur.com/BePPg.jpg\" rel=\"nofollow noreferrer\">Image here</a></p>\n",
                    "OwnerUserId": "14544576",
                    "LastActivityDate": "2020-11-27T16:57:18.800",
                    "Title": "how to fix mobile layout issue",
                    "Tags": "<html><css><forms><layout>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "65259160",
                "ParentRepo": "https://github.com/LebryantJohnson/ultimatebot/blob/1a5eb172ed26d589fee0be8e468afa54c91dc7ff/censor/punishment.js#L31",
                "StackOverflow_Post": {
                    "Id": "65259160",
                    "PostTypeId": "2",
                    "ParentId": "65259080",
                    "CreationDate": "2020-12-11T21:57:09.780",
                    "Score": "1",
                    "Body": "<p>You can use the <code>toLowerCase()</code> method of strings to achieve this. Simply call it on both the message being checked for swearing, and/or on the banned word it is being checked for. Here's an example:</p>\n<pre><code>checkProfanity: function(message, bannedWords) {\n    var words = message.split(' ');\n    for (var word of words) {\n      if (bannedWords.indexOf(word.toLowerCase()) &gt; -1) return true;\n    }\n    return false;\n}\n</code></pre>\n<p>This is the modification necessary in your <a href=\"https://github.com/LebryantJohnson/ultimatebot/blob/1a5eb172ed26d589fee0be8e468afa54c91dc7ff/censor/punishment.js#L31\" rel=\"nofollow noreferrer\">punishment.js</a> file to make your filter case insensitive. Since all of the banned words in your <code>bannedwords.txt</code> file are lowercase, we can simply convert each individual word of the message to lowercase to make the comparison between the word and banned word possible.</p>\n",
                    "OwnerUserId": "6901876",
                    "LastEditorUserId": "6901876",
                    "LastEditDate": "2020-12-11T22:09:56.683",
                    "LastActivityDate": "2020-12-11T22:09:56.683",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "65987186",
                "ParentRepo": "https://github.com/Shaxadhere/MernCRUD",
                "StackOverflow_Post": {
                    "Id": "65987186",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "65992720",
                    "CreationDate": "2021-02-01T04:32:43.293",
                    "Score": "0",
                    "ViewCount": "88",
                    "Body": "<p>I wrote two node js applications, they are fetching data properly but they are not taking post values 1st applications is this <a href=\"https://github.com/Shaxadhere/tinder-clone/tree/master/tinder-backend\" rel=\"nofollow noreferrer\">TinderClone</a> this is just an api with no frontend i am posting data from postman and it is returning auto generated id but not the data i am posting,</p>\n<p>Other application i cloned from github, it has proper frontend with working CRUD, but when i tried to post values from postman it wont take any values it will just add record in database with null values, so is there anything wrong im doing on postman? cause it is still working if i post data with the form on its frontend the application url is <a href=\"https://github.com/Shaxadhere/MernCRUD\" rel=\"nofollow noreferrer\">MernCRUD</a></p>\n<p>Postman Screenshots:\n<a href=\"https://i.stack.imgur.com/PMqoW.png\" rel=\"nofollow noreferrer\">posting data</a>,\n<a href=\"https://i.stack.imgur.com/7IVaj.png\" rel=\"nofollow noreferrer\">fetching data</a></p>\n<p>Code:</p>\n<pre><code>//Cards Schema (Cards.js)\nimport mongoose from 'mongoose'\n\nconst cardSchema = mongoose.Schema({\n    name: String,\n    imgUrl: String\n})\n\nexport default mongoose.model('cards', cardSchema)\n\n//Posting Data (Server.js)\napp.post('/tinder/cards', (req, res) =&gt; {\nconst dbCard = req.body;\n\n   Cards.create(dbCard, (err, data) =&gt; {\n       if(err){\n          res.status(500).send(err)\n       }\n       else{\n          res.status(201).send(data)\n       }\n   })\n})\n\n//Fetching Data\napp.get('/tinder/cards', (req, res) =&gt; {\n   Cards.find((err, data) =&gt; {\n       if(err){\n          res.status(500).send(error);\n       }\n       else{\n          res.status(200).send(data);\n       }\n   });\n});\n</code></pre>\n",
                    "OwnerUserId": "11806745",
                    "LastEditorUserId": "11806745",
                    "LastEditDate": "2021-02-01T11:39:06.600",
                    "LastActivityDate": "2021-02-01T12:26:22.073",
                    "Title": "Node JS Application not taking Values from postman",
                    "Tags": "<node.js><api><express><postman><mern>",
                    "AnswerCount": "1",
                    "CommentCount": "4",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "66110717",
                "ParentRepo": "https://github.com/vicatcu/monorepo-example-error",
                "StackOverflow_Post": {
                    "Id": "66110717",
                    "PostTypeId": "1",
                    "CreationDate": "2021-02-08T23:11:27.557",
                    "Score": "2",
                    "ViewCount": "138",
                    "Body": "<p>I've seen other posts like this one on Stack Overflow but I don't think this is a duplicate.</p>\n<p>I have built up an Angular 11 monorepo with three private libraries and an application. Everything seems to build without significant complaints in the terminal, and the application even launches to its home page without complaint.</p>\n<p>One of my libraries has a combination of components and pages, and both the components and the pages are included in the library module exports (and entryComponents for good measure). But VSCode is telling me components declared in the library module are not visible to pages in the <em>same</em> module. It's not just a VSCode issue either because when my page loads, sure enough, the component that VSCode  flags doesn't appear in the page.</p>\n<p>Then when I navigate to my login page (also in that same library module) it renders the page but the devTools console indicates that: <code>Can't bind to 'ngIf' since it isn't a known property of 'div'</code>. I've checked similar posts on Stack Overflow and they all come down to making sure CommonModule is imported everywhere, and it sure looks to me like I've done that, but I'm still getting this error.</p>\n<p>I'm going to go try and create a minimal reproducible example, but in the meantime, can anyone think of what bone-headed thing I might be doing wrong here?</p>\n<p><strong>UPDATE #1</strong></p>\n<p>I've created a &quot;minimal&quot; reproducible example (which is still fairly complex, but as basic as I could conceive of it). You can clone it here: <a href=\"https://github.com/vicatcu/monorepo-example-error\" rel=\"nofollow noreferrer\">https://github.com/vicatcu/monorepo-example-error</a>. You should be able to do:</p>\n<pre><code>npm install\nnpm run application\n</code></pre>\n<p>Then in your browser you will see a blank page with the text &quot;Nav Links are Below this&quot; displayed. However, the intent is that you <em>should</em> see that, plus below that the text &quot;Navigate Using This Component&quot; courtesy of the NavLinks component, and below that randomly you should see &quot;Some Random text&quot;. The LoginComponent is the default route.</p>\n<p>What's going wrong here?</p>\n<p><strong>UPDATE #2</strong></p>\n<p>I've updated the minimal reproducible example to not include any dependencies on ionic nor any requirements for rsync in the npm run application script, on this branch: <a href=\"https://github.com/vicatcu/monorepo-example-error/tree/remove-ionic-deps\" rel=\"nofollow noreferrer\">https://github.com/vicatcu/monorepo-example-error/tree/remove-ionic-deps</a></p>\n<p>Same problem.</p>\n",
                    "OwnerUserId": "212215",
                    "LastEditorUserId": "212215",
                    "LastEditDate": "2021-02-09T18:40:53.513",
                    "LastActivityDate": "2021-02-09T18:40:53.513",
                    "Title": "With an Angular Monorepo Can't bind to 'ngIf' since it isn't a known property of 'div' and 'my-selector' is not a known element",
                    "Tags": "<angular><ionic-framework><monorepo>",
                    "AnswerCount": "1",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "66194792",
                "ParentRepo": "https://github.com/France-Alliance/Bot-Discord",
                "StackOverflow_Post": {
                    "Id": "66194792",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "73262760",
                    "CreationDate": "2021-02-14T11:10:37.523",
                    "Score": "0",
                    "ViewCount": "99",
                    "Body": "<p><strong>CONTEXT</strong> For the few month, I've been writing a Discord Bot and everything was perfect but I have two problem: I have a command that take a long time to execute, any user that will request another command kill the current one and more and more user are using the bot, it's starting to be a bit difficult to run commands.</p>\n<p><strong>GOAL:</strong> Users should be able to execute any command at any time without having effect on the same/a different command summon by the same/a different user. To explain in a different way, bot shouldn't execute the last command received but more in a parallel way, like if every command executed was in a different instance.</p>\n<p><code>For exemple, if two user in different server execute the same command at the same time, the bot must execute both in parallel so it can respond without delaying one of them or without cancelling one of them (current situation) </code></p>\n<p><strong>HOW:</strong> That's where I need you. I've heard of command handling but as far as I understand, it's not the answer</p>\n<p><strong>MOOD OF THE QUESTIONS</strong>*: <a href=\"https://www.reddit.com/r/discordapp/comments/70rykl/how_to_handle_multiple_bot_requests_at_the_same/\" rel=\"nofollow noreferrer\">Reddit</a>\n| <a href=\"https://stackoverflow.com/questions/57550170/how-does-a-discord-bot-handle-events-from-multiple-servers/57558006#57558006\">Stack Overflow</a>\n<br>*They didn't answered my question but their question were not far from mine</p>\n<p><a href=\"https://github.com/France-Alliance/Bot-Discord\" rel=\"nofollow noreferrer\"><strong>CODE</strong></a></p>\n<br>\nThank you for reading and have a nice day (or night) !\n<br>\n<p><em>If I can improve this question by any way, let me know</em></p>\n",
                    "OwnerUserId": "12700252",
                    "LastEditorUserId": "12700252",
                    "LastEditDate": "2021-02-17T21:32:56.300",
                    "LastActivityDate": "2022-08-06T19:34:49.110",
                    "Title": "Parallel execution of commands",
                    "Tags": "<node.js><discord.js>",
                    "AnswerCount": "1",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "66309813",
                "ParentRepo": "https://github.com/ruhansh/shadow-example",
                "StackOverflow_Post": {
                    "Id": "66309813",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "66312547",
                    "CreationDate": "2021-02-22T03:50:43.523",
                    "Score": "2",
                    "ViewCount": "900",
                    "Body": "<p>I am getting this error when trying to build a Clojurescript project with shadow-cljs. I've tried looking for syntax errors as described <a href=\"https://stackoverflow.com/questions/61556845/the-required-js-dependency-readable-stream-writable-js-is-not-available\">here</a> but I can get the same the error with a single line and a single import although not all imports cause the same error.</p>\n<p>This compiles:</p>\n<pre><code>(ns campfire.core)\n\n(defn init [] (println &quot;ok&quot;))\n</code></pre>\n<p>This doesn't:</p>\n<pre><code>(ns campfire.core\n  (:require [&quot;bugout&quot; :as b]))\n\n(defn init [] (println &quot;ok&quot;))\n</code></pre>\n<p>The output from the above example is:</p>\n<pre><code>shadow-cljs - config: /home/ru/Projects/campfire/shadow-cljs.edn\nshadow-cljs - HTTP server available at http://localhost:3000\nshadow-cljs - server version: 2.11.18 running at http://localhost:9630\nshadow-cljs - nREPL server started on port 8777\nshadow-cljs - watching build :frontend\n[:frontend] Configuring build.\n[:frontend] Compiling ...\n[:frontend] Build failure:\nThe required JS dependency &quot;readable-stream/writable.js&quot; is not available, it was required by &quot;node_modules/stream-browserify/index.js&quot;.\n\nDependency Trace:\n        campfire/core.cljs\n        node_modules/bugout/index.js\n        node_modules/bs58check/index.js\n        node_modules/create-hash/browser.js\n        node_modules/cipher-base/index.js\n        node_modules/stream-browserify/index.js\n\nSearched for npm packages in:\n        /home/ru/Projects/campfire/node_modules\n\nSee: https://shadow-cljs.github.io/docs/UsersGuide.html#npm-install\n</code></pre>\n<p>package.json</p>\n<pre><code>{\n  &quot;name&quot;: &quot;campfire&quot;,\n  &quot;version&quot;: &quot;0.0.1&quot;,\n  &quot;private&quot;: true,\n  &quot;scripts&quot;: {\n    &quot;build&quot;: &quot;shadow-cljs release frontend&quot;\n  },\n  &quot;devDependencies&quot;: {\n    &quot;shadow-cljs&quot;: &quot;2.11.18&quot;\n  },\n  &quot;dependencies&quot;: {\n    &quot;bugout&quot;: &quot;^0.0.10&quot;,\n    &quot;webtorrent&quot;: &quot;^0.114.1&quot;\n  }\n}\n</code></pre>\n<p>shadow-cljs.edn</p>\n<pre><code>{:source-paths\n [&quot;src/dev&quot;\n  &quot;src/main&quot;\n  &quot;src/test&quot;]\n\n :dependencies\n []\n\n :dev-http {3000 &quot;public&quot;}\n :nrepl {:port 8777}\n :builds\n {:frontend\n  {:target  :browser\n   :modules {:main {:init-fn campfire.core/init}}}}}\n</code></pre>\n<p>I've seen similar build errors that were fixed by clearing .shadow-cljs etc and rebuilding but nothing like that seems to be helping. I'm new to shadow so apologies if this is something obvious. Does anyone have any idea what's going on here?</p>\n<h1>Update</h1>\n<p>So it looks like what's happening is that <code>stream-browserify 2.0.2</code> requires <code>readable stream ^2.0.2</code> which npm installs in the nested node_modules folder. Elsewhere <code>readable-stream 3.6.0</code> is being installed in top level node_modules. Shadow is trying to resolve <code>writer.js</code> against the 3.6.0 version of readable stream instead of the 2.0.2 version.</p>\n<p>Confusingly though, stream-browserify isn't a dependency of cipher-base as given in the dependency trace but of node-libs-browser which is itself a dependency of shadow-cljs.</p>\n<p>Is it possible that this is a bug in shadow or is it expected behaviour?</p>\n<h1>Update 2</h1>\n<p>I've created an example repo that replicates what I'm seeing as simply as I can <a href=\"https://github.com/ruhansh/shadow-example\" rel=\"nofollow noreferrer\">here</a>.</p>\n",
                    "OwnerUserId": "15256753",
                    "LastEditorUserId": "15256753",
                    "LastEditDate": "2021-02-23T01:20:29.810",
                    "LastActivityDate": "2021-02-23T01:20:29.810",
                    "Title": "The required JS dependency \"readable-stream/writable.js\" is not available, it was required by \"node_modules/stream-browserify/index.js\"",
                    "Tags": "<clojurescript><shadow-cljs>",
                    "AnswerCount": "2",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "66344844",
                "ParentRepo": "https://github.com/ruhansh/shadow-example2",
                "StackOverflow_Post": {
                    "Id": "66344844",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "66347539",
                    "CreationDate": "2021-02-24T04:44:23.523",
                    "Score": "1",
                    "ViewCount": "579",
                    "Body": "<p>I'm getting this error while trying to build a Clojurescript project with shadow-cljs. The error is happening with the optimization level set to simple.</p>\n<p>The full output in the browser console looks like this:</p>\n<pre><code>js.js:74 shadow-cljs - failed to load 34\nshadow.js.jsRequire @ js.js:74\nshadow$provide.&lt;computed&gt; @ index.js:5\nshadow.js.jsRequire @ js.js:66\nshadow$provide.&lt;computed&gt; @ index.js:8\nshadow.js.jsRequire @ js.js:66\nshadow$provide.&lt;computed&gt; @ index.js:6\nshadow.js.jsRequire @ js.js:66\nshadow.js.require @ js.js:113\n(anonymous) @ index.js:2\n(anonymous) @ append.js:2\njs.js:74 shadow-cljs - failed to load 49\nshadow.js.jsRequire @ js.js:74\nshadow$provide.&lt;computed&gt; @ index.js:8\nshadow.js.jsRequire @ js.js:66\nshadow$provide.&lt;computed&gt; @ index.js:6\nshadow.js.jsRequire @ js.js:66\nshadow.js.require @ js.js:113\n(anonymous) @ index.js:2\n(anonymous) @ append.js:2\njs.js:74 shadow-cljs - failed to load 124\nshadow.js.jsRequire @ js.js:74\nshadow$provide.&lt;computed&gt; @ index.js:6\nshadow.js.jsRequire @ js.js:66\nshadow.js.require @ js.js:113\n(anonymous) @ index.js:2\n(anonymous) @ append.js:2\njs.js:74 shadow-cljs - failed to load 148\nshadow.js.jsRequire @ js.js:74\nshadow.js.require @ js.js:113\n(anonymous) @ index.js:2\n(anonymous) @ append.js:2\nindex.js:5 Uncaught TypeError: $jscomp.inherits is not a function\n    at Object.shadow$provide.&lt;computed&gt; (index.js:5)\n    at shadow.js.jsRequire (js.js:66)\n    at Object.shadow$provide.&lt;computed&gt; (index.js:5)\n    at shadow.js.jsRequire (js.js:66)\n    at Object.shadow$provide.&lt;computed&gt; (index.js:8)\n    at shadow.js.jsRequire (js.js:66)\n    at Object.shadow$provide.&lt;computed&gt; (index.js:6)\n    at Object.shadow.js.jsRequire (js.js:66)\n    at Object.shadow.js.require (js.js:113)\n    at index.js:2\nshadow$provide.&lt;computed&gt; @ index.js:5\nshadow.js.jsRequire @ js.js:66\nshadow$provide.&lt;computed&gt; @ index.js:5\nshadow.js.jsRequire @ js.js:66\nshadow$provide.&lt;computed&gt; @ index.js:8\nshadow.js.jsRequire @ js.js:66\nshadow$provide.&lt;computed&gt; @ index.js:6\nshadow.js.jsRequire @ js.js:66\nshadow.js.require @ js.js:113\n(anonymous) @ index.js:2\n(anonymous) @ append.js:2\nfavicon.ico:1 GET http://localhost:8000/favicon.ico 404 (File not found)\n</code></pre>\n<p>I've created an example repo that replicates what I'm seeing as simply as I can <a href=\"https://github.com/ruhansh/shadow-example2\" rel=\"nofollow noreferrer\">here</a>.</p>\n<p>I've tried clearing caches and whatnot as described <a href=\"https://stackoverflow.com/questions/64169633/clojurescript-typeerror-jscomp-inherits-is-not-a-function\">here</a>.</p>\n<p>With optimizations set to advanced I don't get this problem but I get other bugs more randomly with harder to read stack traces. Since it seems likely that it's the same problem appearing in different ways and since this is easier to replicate I'm attempting to making things work in simple mode first. The errors I get in the full app with advanced compilation look like this:</p>\n<pre><code>core.cljs:2564 Uncaught TypeError: pe is not a function\n    at Ib (core.cljs:2564)\n    at Function.wn.b (set.cljs:56)\n    at Nn.g._update_watching (ratom.cljs:408)\n    at yn (ratom.cljs:62)\n    at Qn (ratom.cljs:539)\n    at c.render (component.cljs:271)\n    at kg (react-dom.production.min.js:188)\n    at qi (react-dom.production.min.js:187)\n    at ak (react-dom.production.min.js:270)\n    at Ni (react-dom.production.min.js:251)\nIb @ core.cljs:2564\nwn.b @ set.cljs:56\ng._update_watching @ ratom.cljs:408\nyn @ ratom.cljs:62\nQn @ ratom.cljs:539\n(anonymous) @ component.cljs:271\nkg @ react-dom.production.min.js:188\nqi @ react-dom.production.min.js:187\nak @ react-dom.production.min.js:270\nNi @ react-dom.production.min.js:251\nme @ react-dom.production.min.js:251\nAg @ react-dom.production.min.js:244\n(anonymous) @ react-dom.production.min.js:124\ne.unstable_runWithPriority @ scheduler.production.min.js:19\ncd @ react-dom.production.min.js:123\nOh @ react-dom.production.min.js:124\nuc @ react-dom.production.min.js:123\nVc @ react-dom.production.min.js:238\nenqueueForceUpdate @ react-dom.production.min.js:135\nr.forceUpdate @ react.production.min.js:13\ng.flush_render @ batching.cljs:39\ng.flush_queues @ batching.cljs:98\ng.run_queues @ batching.cljs:78\na @ batching.cljs:59\nrequestAnimationFrame (async)\ng.schedule @ batching.cljs:59\nmn @ batching.cljs:52\ng.queue_render @ batching.cljs:64\npn @ batching.cljs:112\nQn.d.ob.d.Ja @ ratom.cljs:544\ng._handle_change @ ratom.cljs:402\nHc @ ratom.cljs:345\nCn @ ratom.cljs:104\ng.ua @ ratom.cljs:146\nQc @ core.cljs:864\nqf @ core.cljs:4493\n(anonymous) @ lobby.cljs:53\nfa @ react-dom.production.min.js:53\nma @ react-dom.production.min.js:53\nwa @ react-dom.production.min.js:54\nnh @ react-dom.production.min.js:101\nih @ react-dom.production.min.js:102\n(anonymous) @ react-dom.production.min.js:114\n$g @ react-dom.production.min.js:293\neb @ react-dom.production.min.js:51\neh @ react-dom.production.min.js:106\nyb @ react-dom.production.min.js:76\nub @ react-dom.production.min.js:75\ne.unstable_runWithPriority @ scheduler.production.min.js:19\ncd @ react-dom.production.min.js:123\nrb @ react-dom.production.min.js:293\nFb @ react-dom.production.min.js:74\n</code></pre>\n<p>Interestingly these particular errors go away when I turn on pseudo-names.</p>\n<p>Does anyone have any idea what's going on here?</p>\n",
                    "OwnerUserId": "15256753",
                    "LastActivityDate": "2021-02-24T08:54:58.520",
                    "Title": "Uncaught TypeError: $jscomp.inherits is not a function",
                    "Tags": "<clojurescript><shadow-cljs>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "66366711",
                "ParentRepo": "https://github.com/cvsudheer108/CloudLabs/tree/main/RazorPayPaymentSample",
                "StackOverflow_Post": {
                    "Id": "66366711",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "66368650",
                    "CreationDate": "2021-02-25T10:25:12.237",
                    "Score": "0",
                    "ViewCount": "1305",
                    "Body": "<p>I have a test account with Razorpay and have been testing payments successfully.\nToday I started getting this error.\nI tried changing the test API Key and testing again and still the same issue.\nThe issue can be replicated with the following code in the repo.\n<a href=\"https://github.com/cvsudheer108/CloudLabs/tree/main/RazorPayPaymentSample\" rel=\"nofollow noreferrer\">https://github.com/cvsudheer108/CloudLabs/tree/main/RazorPayPaymentSample</a></p>\n<p>In the sample, the Step2 is giving the error: This payment has failed due to an issue with the merchant.</p>\n<p>Please let me know if you need more details.</p>\n<p>Thanks in advance!!</p>\n",
                    "OwnerUserId": "80108",
                    "LastActivityDate": "2021-02-25T12:39:01.227",
                    "Title": "Razorpay Payment error : This payment has failed due to an issue with the merchant",
                    "Tags": "<razorpay>",
                    "AnswerCount": "1",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "66802352",
                "ParentRepo": "https://github.com/tusharshahrs/pulumi-homelab/tree/master/gcp-postgres-py",
                "StackOverflow_Post": {
                    "Id": "66802352",
                    "PostTypeId": "2",
                    "ParentId": "66678471",
                    "CreationDate": "2021-03-25T15:10:01.373",
                    "Score": "1",
                    "Body": "<p>Here is <a href=\"https://github.com/tusharshahrs/pulumi-homelab/tree/master/gcp-postgres-py\" rel=\"nofollow noreferrer\">sample code</a> with an explanation on how we set everything up including create/delete table with Pulumi.</p>\n<p>The code will look like this:</p>\n<pre><code># Postgres https://www.pulumi.com/docs/reference/pkg/postgresql/\n# provider: https://www.pulumi.com/docs/reference/pkg/postgresql/provider/\npostgres_provider = postgres.Provider(&quot;postgres-provider&quot;,\n  host=myinstance.public_ip_address,\n  username=users.name,\n  password=users.password,\n  port=5432,\n  superuser=True)\n\n# creates a database on the instance in google cloud with the provider we created\nmydatabase = postgres.Database(&quot;pulumi-votes-database&quot;,\n   encoding=&quot;UTF8&quot;,\n   opts=pulumi.ResourceOptions(provider=postgres_provider)\n)\n\n# Table creation/deletion is via pg8000 https://github.com/tlocke/pg8000\ndef tablecreation(mytable_name):\n    print(&quot;tablecreation with:&quot;, mytable_name)\n    create_first_part = &quot;CREATE TABLE IF NOT EXISTS&quot;\n    create_sql_querty = &quot;(id serial PRIMARY KEY, email VARCHAR ( 255 ) UNIQUE NOT NULL, api_key VARCHAR ( 255 ) NOT NULL)&quot;\n    create_combined = f'{create_first_part} {mytable_name}{create_sql_querty}'\n    print(&quot;tablecreation create_combined_sql:&quot;, create_combined)\n    myconnection=pg8000.native.Connection(\n        host=postgres_sql_instance_public_ip_address,\n        port=5432,\n        user=postgres_sql_user_username,\n        password=postgres_sql_user_password,\n        database=postgres_sql_database_name\n    )\n\n    print(&quot;tablecreation starting&quot;)\n    cursor=myconnection.run(create_combined)\n    print(&quot;Table Created:&quot;, mytable_name)\n    selectversion = 'SELECT version();'\n    cursor2=myconnection.run(selectversion)\n    print(&quot;SELECT Version:&quot;, cursor2)\n\ndef droptable(table_to_drop):\n    first_part_of_drop= &quot;DROP TABLE IF EXISTS &quot;\n    last_part_of_drop= ' CASCADE'\n    combinedstring = f'{first_part_of_drop} {table_to_drop} {last_part_of_drop}'\n    conn=pg8000.native.Connection(\n        host=postgres_sql_instance_public_ip_address,\n        port=5432,\n        user=postgres_sql_user_username,\n        password=postgres_sql_user_password,\n        database=postgres_sql_database_name\n        )\n    print(&quot;droptable delete_combined_sql &quot;, combinedstring)\n    cursor=conn.run(combinedstring)\n    print(&quot;droptable completed &quot;, cursor)\n</code></pre>\n<p>After the 1st time of bringing the infrastructure up via <code>pulumi up -y</code>, you can uncomment the following code block in <code>__main__.py</code> and then add the configs for the postgressql server via cli and then run <code>pulumi up -y</code></p>\n<pre><code>create_table1 = &quot;votertable&quot;\ncreating_table = tablecreation(create_table1)\nprint(&quot;&quot;)\ncreate_table2 = &quot;regionals&quot;\ncreating_table = tablecreation(create_table2)\nprint(&quot;&quot;)\ndrop_table = &quot;table2&quot;\ndeleting_table = droptable(drop_table)\n</code></pre>\n<p>The settings for the table are in the <code>Pulumi.dev.yaml</code> file and are set via <a href=\"https://www.pulumi.com/docs/reference/cli/pulumi_config_set/\" rel=\"nofollow noreferrer\">pulumi config set</a></p>\n",
                    "OwnerUserId": "14874157",
                    "LastEditorUserId": "14874157",
                    "LastEditDate": "2021-03-25T19:57:05.210",
                    "LastActivityDate": "2021-03-25T19:57:05.210",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "67212674",
                "ParentRepo": "https://github.com/shiney1884/giraffe-website",
                "StackOverflow_Post": {
                    "Id": "67212674",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "67213104",
                    "CreationDate": "2021-04-22T11:48:21.740",
                    "Score": "0",
                    "ViewCount": "46",
                    "Body": "<p>I am building an e-commerce site with node.js and using EJS also, and i'm trying to get it so that the amount in the basket shows on each page. I have this function below that works as it shows the amount on one of the pages but not other pages.</p>\n<pre><code>function getBasketItems(req, res, callback) {\n    db.query('SELECT * FROM basketitems WHERE customerID = ?', [req.session.username], (err, res) =&gt; {\n        if (err) {\n            callback(err, null);\n        } else {\n            var amount = res.length;\n            callback(null, amount);\n        }\n    })\n}\n</code></pre>\n<p>The function works here:</p>\n<pre><code>router.get('/pens', (req, res) =&gt; {\n    let title = 'Pens | Giraffe Website';\n    let header = 'Pens';\n    let sql = 'SELECT * FROM products';\n    let basketAmount = 0;\n    getBasketItems(req, res, (err, data) =&gt; {\n        if (err) {\n            console.log(err)\n        } else {\n            basketAmount = data;\n        }\n    });\n\n    db.query(sql, (err, result) =&gt; {\n        if (err) throw err;\n\n        res.render('products', {\n            title: title,\n            header: header,\n            data: result,\n            username: req.session.username,\n            loggedin: req.session.loggedin,\n            basketAmount: basketAmount\n        });\n    })\n});\n</code></pre>\n<p>But not here:</p>\n<pre><code>router.get('/', (req, res) =&gt; {\n    let title = 'Home | Giraffe Website';\n    let basketAmount = 0;\n    getBasketItems(req, res, (err, data) =&gt; {\n        if (err) {\n            console.log(err)\n        } else {\n            basketAmount = data;\n        }\n    });\n\n    res.render('index', {\n        title: title,\n        username: req.session.username,\n        loggedin: req.session.loggedin,\n        basketAmount: basketAmount\n    });\n})\n</code></pre>\n<p>Here is the GitHub Repo - <a href=\"https://github.com/shiney1884/giraffe-website\" rel=\"nofollow noreferrer\">https://github.com/shiney1884/giraffe-website</a>\nAny help would be greatly appreciated, thanks!</p>\n",
                    "OwnerUserId": "13280620",
                    "LastEditorUserId": "5389997",
                    "LastEditDate": "2021-04-22T11:57:54.807",
                    "LastActivityDate": "2021-04-22T12:13:52.910",
                    "Title": "I am trying to get my site to show the amount of items in the basket at the basket icon on each page",
                    "Tags": "<javascript><node.js><ejs><e-commerce>",
                    "AnswerCount": "2",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "67305827",
                "ParentRepo": "https://github.com/gupta-piyush19/Blogic/blob/main/client/src/components/Pages/Home.js",
                "StackOverflow_Post": {
                    "Id": "67305827",
                    "PostTypeId": "1",
                    "CreationDate": "2021-04-28T18:20:27.283",
                    "Score": "0",
                    "ViewCount": "98",
                    "Body": "<p>I am creating a blog website using MERN stack and used context API for state management, in which I'm showing all the blogs on the home page but as soon as any blog gets deleted or added, the blog page redirects to the home page and deleted blog still appears and also newly created blogs doesn't appear there(because of fetching blogs from API before it gets deleted or added), any workaround other than reloading the home page?\nUsing fetchBlog() inside useEffect() on mounting of homepage component.</p>\n<pre><code>const { blogs, getAllBlogs, loading } = useContext(BlogContext);\nuseEffect(() =&gt; {\n    getAllBlogs();\n  }, []);\n</code></pre>\n<p>from <a href=\"https://github.com/gupta-piyush19/Blogic/blob/main/client/src/components/Pages/Home.js\" rel=\"nofollow noreferrer\">https://github.com/gupta-piyush19/Blogic/blob/main/client/src/components/Pages/Home.js</a></p>\n<p>and</p>\n<pre><code>const saveHandler = () =&gt; {\n    if (title === &quot;&quot; || image === &quot;&quot;) {\n      setAlert(&quot;Please fill all the fields&quot;, &quot;warning&quot;);\n    } else {\n      const contentState = editorState.getCurrentContent();\n      createBlog({\n        title,\n        image,\n        body: JSON.stringify(convertToRaw(contentState)),\n      });\n      history.push({\n        pathname: &quot;/&quot;,\n      });\n    }\n  };\n</code></pre>\n<p>from <a href=\"https://github.com/gupta-piyush19/Blogic/blob/main/client/src/components/Editor/DraftEditor.js\" rel=\"nofollow noreferrer\">https://github.com/gupta-piyush19/Blogic/blob/main/client/src/components/Editor/DraftEditor.js</a>\non creating a new blog, the website will redirect to the home page but the newly created blog may not be there.\nIf its not very clear then please try to create a new blog on this app and you will understand the problem.\n<a href=\"https://blogic-app.herokuapp.com/\" rel=\"nofollow noreferrer\">https://blogic-app.herokuapp.com/</a></p>\n",
                    "OwnerUserId": "15314153",
                    "LastEditorUserId": "15314153",
                    "LastEditDate": "2021-05-04T14:07:15.220",
                    "LastActivityDate": "2021-05-04T14:07:15.220",
                    "Title": "Deleted item still appearing on home page after deleting from database in MERN",
                    "Tags": "<javascript><reactjs><axios><react-hooks><mern>",
                    "AnswerCount": "0",
                    "CommentCount": "7",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "67379480",
                "ParentRepo": "https://github.com/alapanme/NightwatchJS",
                "StackOverflow_Post": {
                    "Id": "67379480",
                    "PostTypeId": "2",
                    "ParentId": "67374828",
                    "CreationDate": "2021-05-04T05:54:22.260",
                    "Score": "1",
                    "Body": "<p>What I will suggest is to create a create a new file for <code>Nightwatch.conf.js</code> and then start adding rest of the configuration from there. Below is an example which works for me:</p>\n<pre><code>module.exports = {\n    src_folders: [&quot;tests&quot;],\n    skip_testcases_on_fail: false,\n    page_objects_path: &quot;pageObjects&quot;,\n    custom_commands_path: &quot;./commands&quot;,\n    screenshots: {\n        enabled: true,\n        path: &quot;./screenshots&quot;,\n        on_failure: true,\n        on_error: true\n    },\n    test_settings: {\n        default: {\n            desiredCapabilities: {\n                browserName: 'chrome',\n                chromeOptions: {\n                    prefs: {\n                        download: {\n                            default_directory: require('path').resolve(__dirname + '/download')\n                        }\n                    }\n                },\n            },\n            webdriver: {\n                start_process: true,\n                port: 4444,\n                server_path: require('chromedriver').path,\n            }\n        },\n\n        test_workers: {\n            enabled: true,\n            workers: 'auto'\n        },\n\n        safari: {\n            desiredCapabilities: {\n                browserName: 'safari',\n                alwaysMatch: {\n                    acceptInsecureCerts: false\n                }\n            },\n            webdriver: {\n                port: 4445,\n                start_process: true,\n                server_path: '/usr/bin/safaridriver'\n            }\n        },\n\n        firefox: {\n            desiredCapabilities: {\n                browserName: 'firefox'\n            },\n            webdriver: {\n                start_process: true,\n                port: 4446,\n                server_path: require('geckodriver').path\n            }\n        }\n    }\n}\n</code></pre>\n<p>The Nightwatch JS, chromedriver, geckodriver are installed using the npm commands. Since I am using a mac I just needed to enable the safari webdriver.</p>\n<pre><code>npm install nightwatch --save-dev\nnpm install geckodriver --save-dev\nnpm install chromedriver --save-dev\nsafaridriver --enable\n</code></pre>\n<ol>\n<li>This is the full repo if you want to have a look: <a href=\"https://github.com/alapanme/NightwatchJS\" rel=\"nofollow noreferrer\">https://github.com/alapanme/NightwatchJS</a></li>\n<li>Also if you need the detailed steps how I setup Nightwatch on my machine you can refer: <a href=\"https://testersdock.com/nightwatch-js-installation/\" rel=\"nofollow noreferrer\">https://testersdock.com/nightwatch-js-installation/</a></li>\n</ol>\n",
                    "OwnerUserId": "4571271",
                    "LastActivityDate": "2021-05-04T05:54:22.260",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "67820534",
                "ParentRepo": "https://github.com/ChristopherPHolder/Deep-Blue",
                "StackOverflow_Post": {
                    "Id": "67820534",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "68194169",
                    "CreationDate": "2021-06-03T11:21:36.207",
                    "Score": "1",
                    "ViewCount": "220",
                    "Body": "<p>I am trying to use a lambda function to sent contact form submissions to an email.\nThe site is built on React, the lambda was built following the guide they suggest <a href=\"https://dev.to/adnanrahic/building-a-serverless-contact-form-with-aws-lambda-and-aws-ses-4jm0\" rel=\"nofollow noreferrer\">Building a serverless contact form with AWS Lambda and AWS SES</a></p>\n<p>However, the issue is that in the guide he uses vanilla JS instead of something more suitable for React and I can't figure out where to place the JS code or if I need to do something else to make it work.</p>\n<p>The lambda function work and I can send emails using a curl command such as</p>\n<pre><code>curl --header &quot;Content-Type: application/json&quot; \\\n  --request POST \\\n  --data '{&quot;email&quot;:&quot;john.doe@email.com&quot;,&quot;name&quot;:&quot;John Doe&quot;,&quot;content&quot;:&quot;Hey!&quot;}' \\\n  https://{id}.execute-api.{region}.amazonaws.com/{stage}/email/send\n</code></pre>\n<p>But it does not function on the form directly because the function is expecting a <code>header &quot;Content-Type: application/json&quot;</code> so I need to add this snippet of JS code, but I don't know where and the site is failing because of that.</p>\n<p><div class=\"snippet\" data-lang=\"js\" data-hide=\"false\" data-console=\"true\" data-babel=\"false\">\r\n<div class=\"snippet-code\">\r\n<pre class=\"snippet-code-js lang-js prettyprint-override\"><code>const form = document.getElementById('contactForm')\nconst url = 'https://{id}.execute-api.{region}.amazonaws.com/{stage}/email/send'\nconst toast = document.getElementById('toast')\nconst submit = document.getElementById('submit')\n\nfunction post(url, body, callback) {\n  var req = new XMLHttpRequest();\n  req.open(\"POST\", url, true);\n  req.setRequestHeader(\"Content-Type\", \"application/json\");\n  req.addEventListener(\"load\", function () {\n    if (req.status &lt; 400) {\n      callback(null, JSON.parse(req.responseText));\n    } else {\n      callback(new Error(\"Request failed: \" + req.statusText));\n    }\n  });\n  req.send(JSON.stringify(body));\n}\nfunction success () {\n  toast.innerHTML = 'Thanks for sending me a message! I\\'ll get in touch with you ASAP. :)'\n  submit.disabled = false\n  submit.blur()\n  form.name.focus()\n  form.name.value = ''\n  form.email.value = ''\n  form.content.value = ''\n}\nfunction error (err) {\n  toast.innerHTML = 'There was an error with sending your message, hold up until I fix it. Thanks for waiting.'\n  submit.disabled = false\n  console.log(err)\n}\n\nform.addEventListener('submit', function (e) {\n  e.preventDefault()\n  toast.innerHTML = 'Sending'\n  submit.disabled = true\n\n  const payload = {\n    name: form.name.value,\n    email: form.email.value,\n    content: form.content.value\n  }\n  post(url, payload, function (err, res) {\n    if (err) { return error(err) }\n    success()\n  })\n})</code></pre>\r\n<pre class=\"snippet-code-html lang-html prettyprint-override\"><code>&lt;form id=\"contactForm\"&gt;\n  &lt;input type=\"text\" name=\"name\" required placeholder=\"Your name\" /&gt;\n  &lt;input type=\"email\" name=\"email\" required placeholder=\"Your email address\" /&gt;\n  &lt;input type=\"text\" name=\"phone_number\" required placeholder=\"Your phone number\" /&gt;\n  &lt;textarea name=\"message\" required placeholder=\"Write your message...\" &gt;\n  &lt;/textarea&gt;\n  &lt;button id=\"submit\" type=\"submit\"&gt;Send\n    &lt;i className=\"flaticon-tick\"&gt;&lt;/i&gt; \n  &lt;/button&gt;\n&lt;/form&gt;</code></pre>\r\n</div>\r\n</div>\r\n</p>\n<p>And the form is located inside a react functional component:</p>\n<pre><code>const ContactForm = () =&gt; {\n    return (\n        &lt;form&gt;\n            &lt;!-- Above form is here --&gt;\n        &lt;/form&gt;\n    )\n}\nexport default ContactForm\n</code></pre>\n<p>I am trying to imbed it directly into the component but it seems like that is not working. Where should this JS code be within my React project?</p>\n<p>I am not sure if I need to use something like a hook in React. (I am pretty now to react and don't really understand how all that works yet)</p>\n<p>This is the repository:<a href=\"https://github.com/ChristopherPHolder/Deep-Blue\" rel=\"nofollow noreferrer\">Deep-Blue</a></p>\n<p>and the site is located at <a href=\"https://deep-blue.io\" rel=\"nofollow noreferrer\">deep-blue.io</a></p>\n<p>I also asked the Gatsby community and did not get an answer, I have been looking at many different tutorials like, <a href=\"https://seifi.org/reactjs/build-a-contact-form-in-gatsby-part-2-react-hook-form.html\" rel=\"nofollow noreferrer\">this one</a> but they all either use different technologies or fall short of explaining how to handle form submissions in ReactJS with GastbyJS</p>\n",
                    "OwnerUserId": "12263245",
                    "LastEditorUserId": "12263245",
                    "LastEditDate": "2021-06-26T12:11:40.210",
                    "LastActivityDate": "2021-06-30T12:57:40.960",
                    "Title": "Where to place form related JS function in React for my lambda contact form?",
                    "Tags": "<javascript><reactjs><forms><aws-lambda>",
                    "AnswerCount": "2",
                    "CommentCount": "4",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "68724223",
                "ParentRepo": "https://github.com/sts-ryan-holton/puppeteer-demo",
                "StackOverflow_Post": {
                    "Id": "68724223",
                    "PostTypeId": "1",
                    "CreationDate": "2021-08-10T09:26:10.987",
                    "Score": "0",
                    "ViewCount": "190",
                    "Body": "<p>I'm using Puppeteer in my Node JS app to get the URLs in a redirect chain, e.g: going from one URL to the next. Up until this point I've been creating ngrok URLs which use simple PHP header functions to redirect a user with 301 and 302 requests, and my starting URL is a page that redirects to one of the ngrok URL's after a few seconds.</p>\n<p>However, it appears that <code>Network.requestWillBeSent</code> exits if it comes across a page that uses a Javascript redirection, and I need it to somehow wait and pick up these ones as well.</p>\n<p>Example journey of URLs:</p>\n<ol>\n<li>START -&gt; <a href=\"https://example.com/\" rel=\"nofollow noreferrer\">https://example.com/</a> &lt;-- <code>setTimeout</code> and redirects to an ngrok</li>\n<li>ngrok url uses PHP to redirect with a 301</li>\n<li>some other ngrok that uses a JS <code>setTimeout</code> to redirect to, for example, another <a href=\"https://example.com/\" rel=\"nofollow noreferrer\">https://example.com/</a></li>\n<li>FINISH -&gt; <a href=\"https://example.com/\" rel=\"nofollow noreferrer\">https://example.com/</a></li>\n</ol>\n<p>In this situation, <code>Network.requestWillBeSent</code> picks up 1 and 2, but finishes on 3 and thus doesn't get to 4.</p>\n<p>So rather than it console logging all four URLs, I only get two.</p>\n<p>It's difficult to create a reproduction since I can't set up all ngrok urls etc, but here's a <a href=\"https://codesandbox.io/s/dark-fire-qmp0w\" rel=\"nofollow noreferrer\">Codesandbox link</a> and a <a href=\"https://github.com/sts-ryan-holton/puppeteer-demo\" rel=\"nofollow noreferrer\">Github</a> link, attached below is my code:</p>\n<pre class=\"lang-js prettyprint-override\"><code>const dayjs = require('dayjs');\nconst AdvancedFormat = require('dayjs/plugin/advancedFormat');\ndayjs.extend(AdvancedFormat);\n\nconst puppeteer = require('puppeteer');\n\nasync function runEmulation () {\n\n  const goToUrl = 'https://example.com/';\n\n  // vars\n  const journey = [];\n  let hopDataToReturn;\n\n  // initiate a Puppeteer instance with options and launch\n  const browser = await puppeteer.launch({\n    headless: false\n  });\n\n  // launch a new page\n  const page = await browser.newPage();\n\n  // initiate a new CDP session\n  const client = await page.target().createCDPSession();\n  await client.send('Network.enable');\n  await client.on('Network.requestWillBeSent', async (e) =&gt; {\n\n    // if not a document, skip\n    if (e.type !== 'Document') return;\n\n    console.log(`adding URL to journey: ${e.documentURL}`)\n\n    // the journey\n    journey.push({\n      url: e.documentURL,\n      type: e.redirectResponse ? e.redirectResponse.status : 'JS Redirection',\n      duration_in_ms: 0,\n      duration_in_sec: 0,\n      loaded_at: dayjs().valueOf()\n    });\n  });\n\n  await page.goto(goToUrl);\n  await page.waitForNavigation();\n  await browser.close();\n\n  console.log('=== JOURNEY ===')\n  console.log(journey)\n}\n\n// init\nrunEmulation()\n</code></pre>\n<p>What am I missing inside <code>Network.requestWillBeSent</code> or what do I need to add in order to pick up websites in the middle that use JS to redirect to another site after a few seconds.</p>\n",
                    "OwnerUserId": "9982090",
                    "LastActivityDate": "2021-08-10T10:19:50.423",
                    "Title": "Network.requestWillBeSent doesn't account for Javascript setTimeout redirections",
                    "Tags": "<javascript><node.js><puppeteer>",
                    "AnswerCount": "1",
                    "CommentCount": "3",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "69414684",
                "ParentRepo": "https://github.com/mailgun/mailgun-js-boland/issues/89",
                "StackOverflow_Post": {
                    "Id": "69414684",
                    "PostTypeId": "2",
                    "ParentId": "69359664",
                    "CreationDate": "2021-10-02T06:55:50.773",
                    "Score": "1",
                    "Body": "<blockquote>\n<p>As we can see, the <code>to</code> attribute is filled with all email addresses, which is not what I am expecting.</p>\n</blockquote>\n<p>It is not properly supported with SMTP by Mailgun.</p>\n<p>However, relying on the (unintuitive) implementation of BCC in Mailgun, there is a workaround:</p>\n<pre class=\"lang-py prettyprint-override\"><code>mail = EmailMultiAlternatives(\n    subject=&quot;Hey - %recipient.name%&quot;,\n    body=&quot;Hey %recipient.name%,\\n\\nThis is just a batch email test!!!&quot;,\n    from_email=&quot;JPG &lt;me@somehost.com&gt;&quot;,\n    # to=to_emails,  # Replace this\n    bcc=to_emails,   # with this\n)\nrecipient_variables = {\n    address: {&quot;name&quot;: address} for address in to_emails\n}\nmail.extra_headers[&quot;To&quot;] = &quot;%recipient%&quot;  # Add this\nmail.extra_headers[&quot;X-Mailgun-Recipient-Variables&quot;] = json.dumps(recipient_variables)\n</code></pre>\n<p>Reference: <a href=\"https://stackoverflow.com/q/37948729/8601760\">https://stackoverflow.com/questions/37948729/mailgun-smtp-batch-sending-with-recipient-variables-shows-all-recipients-in-to-field</a></p>\n<hr />\n<ol>\n<li>Why does <code>to=[&quot;%recipient%&quot;]</code> not work with SMTP?</li>\n</ol>\n<p>It's the standard in the protocol.</p>\n<p>From <a href=\"https://documentation.mailgun.com/_/downloads/en/latest/pdf/\" rel=\"nofollow noreferrer\">https://documentation.mailgun.com/_/downloads/en/latest/pdf/</a>:</p>\n<blockquote>\n<p>SMTP send will error with \u201ccannot parse to address\u201d or \u201ccannot parse from address\u201d if the provided email address fails syntax checks in accordance with RFC5321, RFC5322, RFC6854.</p>\n</blockquote>\n<ol start=\"2\">\n<li>What to do for proper support of Batch Sending with Mailgun?</li>\n</ol>\n<p>Use the API.</p>\n<p>From <a href=\"https://stackoverflow.com/q/30787399/8601760\">https://stackoverflow.com/questions/30787399/laravel-5-sending-group-emails</a> (multiposted to <a href=\"https://laracasts.com/discuss/channels/laravel/sending-email-to-1000s-of-reciepents\" rel=\"nofollow noreferrer\">https://laracasts.com/discuss/channels/laravel/sending-email-to-1000s-of-reciepents</a>):</p>\n<blockquote>\n<p>So far, I have created an array of recipient email addresses, sent the email to a webmaster type address, and included the end recipients in BCC</p>\n<p>While this works, it's not ideal.</p>\n</blockquote>\n<blockquote>\n<p>Rather than using Laravel's built in <code>Mail</code>, I elected to use Mailgun's API (specifically batch sending) directly</p>\n<p>This also allows me to access unique recipient variables within my email template</p>\n</blockquote>\n<p>(It's not specific to Laravel/PHP, but to SMTP via Mailgun.)</p>\n<ol start=\"3\">\n<li>What do you mean by &quot;unintuitive&quot; implementation of BCC in Mailgun?</li>\n</ol>\n<p>Mailgun effectively personalises the email for each BCC recipient using recipient-variables.</p>\n<p>From <a href=\"https://github.com/mailgun/mailgun-js-boland/issues/89\" rel=\"nofollow noreferrer\">https://github.com/mailgun/mailgun-js-boland/issues/89</a>:</p>\n<blockquote>\n<p>the bcc person is receiving the email as it was addressed to them instead of being part of the bcc</p>\n</blockquote>\n<p>This causes a separate issue when you actually want BCC recipients to get the same content.</p>\n<p>From <a href=\"https://stackoverflow.com/q/48887866/8601760\">https://stackoverflow.com/questions/48887866/bcc-in-mailgun-batch-send-does-not-include-substitutions</a>:</p>\n<blockquote>\n<p>In the copy sent to the bcc address, the recip_vars substitution has not been made.</p>\n</blockquote>\n<blockquote>\n<p>According to the good people at Mailgun, this is not possible, at least in the current release of the service.</p>\n</blockquote>\n",
                    "OwnerUserId": "8601760",
                    "LastEditorUserId": "8601760",
                    "LastEditDate": "2021-10-02T07:02:02.190",
                    "LastActivityDate": "2021-10-02T07:02:02.190",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "69991507",
                "ParentRepo": "https://github.com/jonashackt/tekton-argocd-eks",
                "StackOverflow_Post": {
                    "Id": "69991507",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "69991508",
                    "CreationDate": "2021-11-16T15:03:32.077",
                    "Score": "1",
                    "ViewCount": "1775",
                    "Body": "<p>We have a AWS EKS running (setup using Pulumi), where we installed Tekton as described in the <a href=\"https://buildpacks.io/docs/tools/tekton/\" rel=\"nofollow noreferrer\">Cloud Native Buildpacks Tekton docs</a>. The <a href=\"https://github.com/jonashackt/tekton-argocd-eks\" rel=\"nofollow noreferrer\">example project is available</a>.</p>\n<p><a href=\"https://github.com/jonashackt/tekton-argocd-eks/blob/main/pipelines/pipeline.yml\" rel=\"nofollow noreferrer\">Our Tekton pipeline</a> is configured like this (which is derived <a href=\"https://buildpacks.io/docs/tools/tekton/#43-pipeline\" rel=\"nofollow noreferrer\">from the Cloud Native Buildpacks Tekton docs</a> also):</p>\n<pre><code>apiVersion: tekton.dev/v1beta1\nkind: Pipeline\nmetadata:\n  name: buildpacks-test-pipeline\nspec:\n  params:\n    - name: IMAGE\n      type: string\n      description: image URL to push\n    - name: SOURCE_URL\n      type: string\n      description: A git repo url where the source code resides.\n    - name: SOURCE_REVISION\n      description: The branch, tag or SHA to checkout.\n      default: &quot;&quot;\n  workspaces:\n    - name: source-workspace # Directory where application source is located. (REQUIRED)\n    - name: cache-workspace # Directory where cache is stored (OPTIONAL)\n  tasks:\n    - name: fetch-repository # This task fetches a repository from github, using the `git-clone` task you installed\n      taskRef:\n        name: git-clone\n      workspaces:\n        - name: output\n          workspace: source-workspace\n      params:\n        - name: url\n          value: &quot;$(params.SOURCE_URL)&quot;\n        - name: revision\n          value: &quot;$(params.SOURCE_REVISION)&quot;\n        - name: subdirectory\n          value: &quot;&quot;\n        - name: deleteExisting\n          value: &quot;true&quot;\n    - name: buildpacks # This task uses the `buildpacks` task to build the application\n      taskRef:\n        name: buildpacks\n      runAfter:\n        - fetch-repository\n      workspaces:\n        - name: source\n          workspace: source-workspace\n        - name: cache\n          workspace: cache-workspace\n      params:\n        - name: APP_IMAGE\n          value: &quot;$(params.IMAGE)&quot;\n        - name: BUILDER_IMAGE\n          value: paketobuildpacks/builder:base # This is the builder we want the task to use (REQUIRED)\n</code></pre>\n<p>We added <code>SOURCE_URL</code> and <code>SOURCE_REVISION</code> as parameters already.</p>\n<p>The question is: <strong>How can we trigger a Tekton <code>PipelineRun</code> from GitLab CI</strong> (inside our <code>.gitlab-ci.yml</code>) adhering to the following requirements:</p>\n<ul>\n<li>simplest possible approach</li>\n<li>Do not use the extra complexity introduced by <a href=\"https://github.com/tektoncd/triggers\" rel=\"nofollow noreferrer\">Tekton Triggers</a> (incl. <a href=\"https://github.com/tektoncd/experimental/tree/main/commit-status-tracker\" rel=\"nofollow noreferrer\">commit-status-tracker</a>) but still keep GitLab as the source of truth (e.g. see green/red pipeline runs on commits etc.)</li>\n<li>report successfully run Tekton Pipelines as green GitLab CI Pipelines &amp; failed Tekton Pipelines as red GitLab CI Pipelines</li>\n<li>preserve/stream the Tekton Pipeline logs into GitLab CI Pipeline logs - both in case of errors or success inside the Tekton Pipelines</li>\n<li>use <a href=\"https://docs.gitlab.com/ee/ci/variables/predefined_variables.html\" rel=\"nofollow noreferrer\">GitLab CI Predefined Variables</a> for a generic approach</li>\n</ul>\n",
                    "OwnerUserId": "4964553",
                    "LastEditorUserId": "4964553",
                    "LastEditDate": "2022-02-24T11:35:30.207",
                    "LastActivityDate": "2022-02-24T11:35:30.207",
                    "Title": "How to trigger Tekton Pipeline from GitLab CI directly with predefined GitLab CI variables & Tekton logs streamed into GitLab Pipeline logs",
                    "Tags": "<kubernetes><gitlab><gitlab-ci><amazon-eks><tekton>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "FavoriteCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "69991508",
                "ParentRepo": "https://github.com/jonashackt/pulumi-eks-tekton/blob/trigger-build-from-gitlab/tekton-ci-config/pipeline.yml",
                "StackOverflow_Post": {
                    "Id": "69991508",
                    "PostTypeId": "2",
                    "ParentId": "69991507",
                    "CreationDate": "2021-11-16T15:03:32.077",
                    "Score": "5",
                    "Body": "<p><strong>TLDR;</strong></p>\n<p>I created a fully comprehensible example project showing all necessary steps and running pipelines here: <a href=\"https://gitlab.com/jonashackt/microservice-api-spring-boot/\" rel=\"noreferrer\">https://gitlab.com/jonashackt/microservice-api-spring-boot/</a> with the full <code>.gitlab-ci.yml</code> to directly trigger a Tekton Pipeline:</p>\n<pre><code>image: registry.gitlab.com/jonashackt/aws-kubectl-tkn:0.21.0\n\nvariables:\n  AWS_DEFAULT_REGION: 'eu-central-1'\n\nbefore_script:\n  - mkdir ~/.kube\n  - echo &quot;$EKSKUBECONFIG&quot; &gt; ~/.kube/config\n  - echo &quot;--- Testdrive connection to cluster&quot;\n  - kubectl get nodes\n\nstages:\n  - build\n\nbuild-image:\n  stage: build\n  script:\n    - echo &quot;--- Create parameterized Tekton PipelineRun yaml&quot;\n    - tkn pipeline start buildpacks-test-pipeline\n      --serviceaccount buildpacks-service-account-gitlab\n      --workspace name=source-workspace,subPath=source,claimName=buildpacks-source-pvc\n      --workspace name=cache-workspace,subPath=cache,claimName=buildpacks-source-pvc\n      --param IMAGE=$CI_REGISTRY_IMAGE\n      --param SOURCE_URL=$CI_PROJECT_URL\n      --param SOURCE_REVISION=$CI_COMMIT_REF_SLUG\n      --dry-run\n      --output yaml &gt; pipelinerun.yml\n\n    - echo &quot;--- Trigger PipelineRun in Tekton / K8s&quot;\n    - PIPELINE_RUN_NAME=$(kubectl create -f pipelinerun.yml --output=jsonpath='{.metadata.name}')\n\n    - echo &quot;--- Show Tekton PipelineRun logs&quot;\n    - tkn pipelinerun logs $PIPELINE_RUN_NAME --follow\n\n    - echo &quot;--- Check if Tekton PipelineRun Failed &amp; exit GitLab Pipeline accordingly&quot;\n    - kubectl get pipelineruns $PIPELINE_RUN_NAME --output=jsonpath='{.status.conditions[*].reason}' | grep Failed &amp;&amp; exit 1 || exit 0\n</code></pre>\n<p>Here are the brief steps you need to do:</p>\n<p><strong>1. Choose a base image for your <code>.gitlab-ci.yml</code> providing <code>aws</code> CLI, <code>kubectl</code> and Tekton CLI (<code>tkn</code>)</strong></p>\n<p>This is entirely up to you. I created an example project <a href=\"https://gitlab.com/jonashackt/aws-kubectl-tkn\" rel=\"noreferrer\">https://gitlab.com/jonashackt/aws-kubectl-tkn</a> which provides an image, which is based on the official <a href=\"https://hub.docker.com/r/amazon/aws-cli\" rel=\"noreferrer\">https://hub.docker.com/r/amazon/aws-cli</a> image and is accessible via <code>registry.gitlab.com/jonashackt/aws-kubectl-tkn:0.21.0</code>.</p>\n<p><strong>2. CI/CD Variables for aws CLI &amp; Kubernetes cluster access</strong></p>\n<p>Inside your GitLab CI project (or better: inside the group, where your GitLab CI project resides in) you need to create <code>AWS_ACCESS_KEY_ID</code>, <code>AWS_SECRET_ACCESS_KEY</code> as CI/CD Variables holding the the aws cli credentials (beware to <code>mask</code> them while creating them in order to prevent them beeing printed into the GitLab CI logs). Depending on your EKS clusters (or other K8s clusters) config, you need to provide a <code>kubeconfig</code> to access your cluster. One way is to create a GitLab CI/CD variable like <code>EKSKUBECONFIG</code> providing the necessary file (e.g. in the example project this is provided by Pulumi with <code>pulumi stack output kubeconfig &gt; kubeconfig</code>). In this setup using Pulumi there are no secret credentials inside the <code>kubeconfig</code> so the variable doesn't need to be masked. But be aware of possible credentials here and protect them accordingly if needed.</p>\n<p><a href=\"https://i.stack.imgur.com/YF4CO.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/YF4CO.png\" alt=\"enter image description here\" /></a></p>\n<p>Also define <code>AWS_DEFAULT_REGION</code> containing your EKS cluster's region:</p>\n<pre><code># As we need kubectl, aws &amp; tkn CLI we use https://gitlab.com/jonashackt/aws-kubectl-tkn\nimage: registry.gitlab.com/jonashackt/aws-kubectl-tkn:0.21.0\n\nvariables:\n  AWS_DEFAULT_REGION: 'eu-central-1'\n</code></pre>\n<p><strong>3. Use <code>kubeconfig</code> and testdrive cluster connection in <code>before_script</code> section</strong></p>\n<p>Preparing things we need later inside other steps could be done inside the <code>before_script</code> section. So let's create the directory <code>~/.kube</code> there and create the file <code>~/.kube/config</code> from the contents of the variable <code>EKSKUBECONFIG</code>. Finally fire a <code>kubectl get nodes</code> to check if the cluster connection is working. Our <code>before_script</code> section now looks like this:</p>\n<pre><code>before_script:\n  - mkdir ~/.kube\n  - echo &quot;$EKSKUBECONFIG&quot; &gt; ~/.kube/config\n  - echo &quot;--- Testdrive connection to cluster&quot;\n  - kubectl get nodes\n</code></pre>\n<p><strong>4. Pass parameters to Tekton PipelineRun</strong></p>\n<p>Passing parameters via <code>kubectl</code> isn't trivial - or even needs to be done using a templating engine like Helm. But luckily the Tekton CLI has something for us: <a href=\"https://stackoverflow.com/questions/67405826/tekton-running-pipeline-via-passing-parameter\"><code>tkn pipeline start</code> accepts parameters</a>. So we can transform the <a href=\"https://buildpacks.io/docs/tools/tekton/#5-create--apply-pipelinerun\" rel=\"noreferrer\">Cloud Native Buildpacks Tekton PipelineRun Yaml file</a> into a <code>tkn</code> CLI command like this:</p>\n<pre><code>tkn pipeline start buildpacks-test-pipeline \\\n    --serviceaccount buildpacks-service-account-gitlab \\\n    --workspace name=source-workspace,subPath=source,claimName=buildpacks-source-pvc \\\n    --workspace name=cache-workspace,subPath=cache,claimName=buildpacks-source-pvc \\\n    --param IMAGE=registry.gitlab.com/jonashackt/microservice-api-spring-boot \\\n    --param SOURCE_URL=https://gitlab.com/jonashackt/microservice-api-spring-boot \\\n    --param SOURCE_REVISION=main \\\n    --timeout 240s \\\n    --showlog\n</code></pre>\n<p>Now here are some points to consider. First the name <code>buildpacks-test-pipeline</code> right after the <code>tkn pipeline start</code> works as an equivalent to the yaml files <code>spec: pipelineRef: name: buildpacks-test-pipeline</code> definition.</p>\n<p>It will also work as a reference to the <code>Pipeline</code> object defined inside the file <a href=\"https://github.com/jonashackt/pulumi-eks-tekton/blob/trigger-build-from-gitlab/tekton-ci-config/pipeline.yml\" rel=\"noreferrer\">pipeline.yml</a> which starts with <code>metadata: name: buildpacks-test-pipeline</code> like:</p>\n<p>apiVersion: tekton.dev/v1beta1\nkind: Pipeline\nmetadata:\nname: buildpacks-test-pipeline\n...</p>\n<p>Second to define workspaces isn't trivial. Luckily <a href=\"https://issueexplorer.com/issue/tektoncd/cli/1368\" rel=\"noreferrer\">there's help</a>. We can define a workspace in <code>tkn</code> CLI like this: <code>--workspace name=source-workspace,subPath=source,claimName=buildpacks-source-pvc</code>.</p>\n<p>Third using the parameters as intended now becomes easy. Simply use <code>--param</code> accordingly. We also use <code>--showlog</code> to directly stream the Tekton logs into the commandline (or GitLab CI!) together with <code>--timeout</code>.</p>\n<p>Finally using <a href=\"https://docs.gitlab.com/ee/ci/variables/predefined_variables.html\" rel=\"noreferrer\">GitLab CI Predefined variables</a> our <code>.gitlab-ci.yml</code>'s build stage looks like this:</p>\n<pre><code>build-image:\n  stage: build\n  script:\n    - echo &quot;--- Run Tekton Pipeline&quot;\n    - tkn pipeline start buildpacks-test-pipeline\n      --serviceaccount buildpacks-service-account-gitlab\n      --workspace name=source-workspace,subPath=source,claimName=buildpacks-source-pvc\n      --workspace name=cache-workspace,subPath=cache,claimName=buildpacks-source-pvc\n      --param IMAGE=$CI_REGISTRY_IMAGE\n      --param SOURCE_URL=$CI_PROJECT_URL\n      --param SOURCE_REVISION=$CI_COMMIT_REF_SLUG\n      --timeout 240s\n      --showlog\n</code></pre>\n<p><strong>5. Solve the every GitLab CI Pipeline is green problem</strong></p>\n<p>This could have been everything we need to do. But: right now every GitLab CI Pipeline is green, regardless of the Tekton Pipeline's status.</p>\n<p>Therefore we remove <code>--showlog</code> and <code>--timeout</code> again, but add a <code>--dry-run</code> together with the <code>--output yaml</code> flags. Without the <code>--dry-run</code> the <code>tkn pipeline start</code> command would create a <code>PipelineRun</code> object definition already, which we can't create then using <code>kubectl</code> anymore:</p>\n<pre><code>build-image:\n  stage: build\n  script:\n    - echo &quot;--- Create parameterized Tekton PipelineRun yaml&quot;\n    - tkn pipeline start buildpacks-test-pipeline\n      --serviceaccount buildpacks-service-account-gitlab\n      --workspace name=source-workspace,subPath=source,claimName=buildpacks-source-pvc\n      --workspace name=cache-workspace,subPath=cache,claimName=buildpacks-source-pvc\n      --param IMAGE=$CI_REGISTRY_IMAGE\n      --param SOURCE_URL=$CI_PROJECT_URL\n      --param SOURCE_REVISION=$CI_COMMIT_REF_SLUG\n      --dry-run\n      --output yaml &gt; pipelinerun.yml\n</code></pre>\n<p>Now that we removed <code>--showlog</code> and don't start an actual Tekton pipeline using <code>tkn</code> CLI, we need to create the pipeline run using:</p>\n<pre><code>- PIPELINE_RUN_NAME=$(kubectl create -f pipelinerun.yml --output=jsonpath='{.metadata.name}')\n</code></pre>\n<p>Having the temporary variable <code>PIPELINE_RUN_NAME</code> available containing the exact pipeline run id, we can stream the Tekton pipeline logs into our GitLab CI log again:</p>\n<pre><code>- tkn pipelinerun logs $PIPELINE_RUN_NAME --follow\n</code></pre>\n<p>Finally we need to check for Tekton pipeline run's status and exit our GitLab CI pipeline accordingly in order to prevent red Tekton pipelines resulting in green GitLab CI pipelines. Therefore let's check the status of the Tekton pipeline run first. This can be achieved <a href=\"https://stackoverflow.com/a/55077916/4964553\">using <code>--output=jsonpath='{.status.conditions[*].reason}'</code></a> together with a <code>kubectl get pipelineruns</code>:</p>\n<pre><code>kubectl get pipelineruns $PIPELINE_RUN_NAME --output=jsonpath='{.status.conditions[*].reason}'\n</code></pre>\n<p>Then we pipe the result into <a href=\"https://stackoverflow.com/a/11612379/4964553\">a <code>grep</code> which checks, if <code>Failed</code> is inside</a> the <code>status.condiditons.reason</code> field.</p>\n<p>Finally we use a bash onliner (which is <code>&lt;expression to check true or false&gt; &amp;&amp; command when true || command when false</code>) to issue the suitable <code>exit</code> command (see <a href=\"https://askubuntu.com/a/892605\">https://askubuntu.com/a/892605</a>):</p>\n<pre><code>- kubectl get pipelineruns $PIPELINE_RUN_NAME --output=jsonpath='{.status.conditions[*].reason}' | grep Failed &amp;&amp; exit 1 || exit 0\n</code></pre>\n<p>Now every GitLab CI Pipeline becomes green, when the Tekton Pipeline succeeded - and gets red when the Tekton Pipeline failed. <a href=\"https://gitlab.com/jonashackt/microservice-api-spring-boot/-/pipelines\" rel=\"noreferrer\">The example project has some logs</a> if you're interested. It's pretty cool to see the Tekton logs inside the GitLab CI logs:</p>\n<p><a href=\"https://i.stack.imgur.com/XJnP7.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/XJnP7.png\" alt=\"enter image description here\" /></a></p>\n",
                    "OwnerUserId": "4964553",
                    "LastEditorUserId": "4964553",
                    "LastEditDate": "2021-11-16T15:31:45.920",
                    "LastActivityDate": "2021-11-16T15:31:45.920",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "71025381",
                "ParentRepo": "https://github.com/charleszipp/azure-pipelines-tasks-terraform",
                "StackOverflow_Post": {
                    "Id": "71025381",
                    "PostTypeId": "1",
                    "CreationDate": "2022-02-07T21:04:14.537",
                    "Score": "2",
                    "ViewCount": "875",
                    "Body": "<p>I'm <a href=\"https://learn.microsoft.com/en-us/azure/developer/terraform/create-k8s-cluster-with-tf-and-aks\" rel=\"nofollow noreferrer\">following the official docs to create Azure Kubernetes clusters</a>. The docs state that I need to create a service principal first, manually, and provide the client_id and client_secret.</p>\n<p>Doing it manually is not an option.</p>\n<p>Here is the code for my service principal. It's decorated with links to the most recent Terraform docs for reference.</p>\n<pre><code>data &quot;azurerm_subscription&quot; &quot;current&quot; {}\ndata &quot;azuread_client_config&quot; &quot;current&quot; {}\n\nresource &quot;random_id&quot; &quot;current&quot; {\n  byte_length = 8\n  prefix      = &quot;ExternalDnsTf&quot;\n}\n\n# Create Azure AD App.\n# https://registry.terraform.io/providers/hashicorp/azuread/latest/docs/resources/application\nresource &quot;azuread_application&quot; &quot;current&quot; {\n  display_name = random_id.current.hex\n  owners       = [data.azuread_client_config.current.object_id]\n\n}\n\n# Create Service Principal associated with the Azure AD App\n# https://registry.terraform.io/providers/hashicorp/azuread/latest/docs/resources/service_principal\nresource &quot;azuread_service_principal&quot; &quot;current&quot; {\n  application_id               = azuread_application.current.application_id\n  app_role_assignment_required = false\n  owners                       = [data.azuread_client_config.current.object_id]\n}\n\n# Create Service Principal password\n# https://registry.terraform.io/providers/hashicorp/azuread/latest/docs/resources/application_password\nresource &quot;azuread_application_password&quot; &quot;current&quot; {\n  application_object_id = azuread_application.current.object_id\n}\n\n# Create role assignment for service principal\n# https://registry.terraform.io/providers/hashicorp/azurerm/latest/docs/resources/role_assignment\nresource &quot;azurerm_role_assignment&quot; &quot;current&quot; {\n  scope                = data.azurerm_subscription.current.id\n  role_definition_name = &quot;Contributor&quot;\n\n # When assigning to a SP, use the object_id, not the appId\n # see: https://learn.microsoft.com/en-us/azure/role-based-access-control/role-assignments-cli\n  principal_id = azuread_service_principal.current.object_id\n}\n</code></pre>\n<p>I keep getting the following error in my pipeline: (note, I am the owner of my subscription)</p>\n<pre><code>ApplicationsClient.BaseClient.Post(): unexpected status 403 with OData\n\u2502 error: Authorization_RequestDenied: Insufficient privileges to complete the\n\u2502 operation.\n\n</code></pre>\n<p>What I'm trying to do is to eliminate the manual steps to setup supporting services. Take ExternalDNS for example. <a href=\"https://github.com/kubernetes-sigs/external-dns/blob/master/docs/tutorials/azure.md\" rel=\"nofollow noreferrer\">The Azure docs</a> state that I need to use <code>az ad sp create-for-rbac -n ExternalDnsServicePrincipal; az role assignment create --role &quot;Reader&quot; --assignee &lt;appId GUID&gt; --scope &lt;resource group resource id&gt;; az role assignment create --role &quot;Contributor&quot; --assignee &lt;appId GUID&gt; --scope &lt;dns zone resource id&gt;</code></p>\n<p><strong>Ultimately, I'm trying to create the terraform version of the azure cli commands.</strong></p>\n<p>Support for <code>create-for-rbac</code> <a href=\"https://github.com/hashicorp/terraform-provider-azuread/issues/40#issuecomment-477076926\" rel=\"nofollow noreferrer\">was a feature request on github</a>. That used to work great, but so much has changed, it's not applicable to current API versions. Also, with AAD Graph being deprecated in favor Microsoft Graph API, I wonder if I'm getting snagged on that.</p>\n<p>The ExternalDNS docs also suggested Managed Service Identities (MSI). Service principals, MSI, MSGraph API integration, honestly, I don't care which one is used. Whatever is current best-practices is fine <strong>so long as I do not have to log into the portal to manually create or give permissions, or manually run <code>az cli</code> commands.</strong></p>\n<p><strong>EDIT: Permissions clarification</strong></p>\n<p>I'm using Terraform, of course, to provision resources. If I do all of this without terraform (manually or with a bash script), I use <code>azure cli</code> I start setting permissions by doing the following:</p>\n<ul>\n<li><code>az login</code></li>\n<li><code>az account set -s &lt;my-subscription-id&gt;</code></li>\n</ul>\n<p>I am the owner of my subscription. I can run all commands, create SPs, MSIs, assign roles, etc, with no problem.</p>\n<p>In the pipelines, <a href=\"https://github.com/charleszipp/azure-pipelines-tasks-terraform\" rel=\"nofollow noreferrer\">I am using the charleszipp az pipelines terraform</a> plugin. In the logs, I see:</p>\n<ul>\n<li><code>az login --service-principal -t &lt;my-tenant-id&gt; -u *** -p ***</code></li>\n<li><code>az account set -s &lt;my-subscription-id&gt;</code></li>\n</ul>\n<p>I'm not sure if that makes a difference. I interpret that as ultimately, commands are executed after signing in and setting the account subscription, like I do manually.</p>\n<p>Technically, I'm not using a service connection in several of these tasks. However, where one is required, I have created a Service connection and defined its Scope to the subscription level. It's of type Azure Resource Manager.</p>\n<p>However, if I click &quot;manage service principal, it takes me to the portal where there are no permissions defined.</p>\n<p>While I am the owner of my subscription, I am not the root management group. I'm owned / provisioned by someone else. Ultimately, they have control of Active Directory. I cannot add or edit permissions. If I try to add any under permissions API and select Microsoft Graph, it says that authorization is required. <code>Grant Admin Consent for &lt;parent organization</code> is greyed out.</p>\n<p>But why would that be important if I'm the owner of my subscription? If I can do whatever I want via the az cli command line, what's preventing me from doing the same in the pipeline?</p>\n",
                    "OwnerUserId": "658182",
                    "LastEditorUserId": "658182",
                    "LastEditDate": "2022-02-08T16:03:16.760",
                    "LastActivityDate": "2022-02-08T16:03:16.760",
                    "Title": "How do I automatically create service principals or MSIs with Terraform for use in Azure Pipelines to manage AKS resources?",
                    "Tags": "<azure-devops><azure-active-directory><terraform><azure-aks><terraform-provider-azure>",
                    "AnswerCount": "1",
                    "CommentCount": "3",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "71088679",
                "ParentRepo": "https://github.com/sanjidtk/sbot",
                "StackOverflow_Post": {
                    "Id": "71088679",
                    "PostTypeId": "1",
                    "CreationDate": "2022-02-12T03:10:22.137",
                    "Score": "-1",
                    "ViewCount": "125",
                    "Body": "<p>Hi I have been using this termux instagram bot for a very long time and it is very effective too. But suddenly a month ago this bot wouldn't open so can any one please fix this?\ngit clone <a href=\"https://github.com/sanjidtk/sbot\" rel=\"nofollow noreferrer\">https://github.com/sanjidtk/sbot</a>\n<a href=\"https://i.stack.imgur.com/nqGmH.jpg\" rel=\"nofollow noreferrer\">enter image description here</a></p>\n<p><a href=\"https://i.stack.imgur.com/6qlnM.jpg\" rel=\"nofollow noreferrer\">enter image description here</a></p>\n<p><a href=\"https://i.stack.imgur.com/cis24.jpg\" rel=\"nofollow noreferrer\">enter image description here</a></p>\n",
                    "OwnerUserId": "18185936",
                    "LastActivityDate": "2022-02-13T04:08:12.700",
                    "Title": "can someone please fix this this termux module",
                    "Tags": "<python><node.js><instagram><instagram-api><termux>",
                    "AnswerCount": "1",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "71094472",
                "ParentRepo": "https://github.com/Emabliss/joblisting",
                "StackOverflow_Post": {
                    "Id": "71094472",
                    "PostTypeId": "1",
                    "CreationDate": "2022-02-12T17:58:55.700",
                    "Score": "1",
                    "ViewCount": "129",
                    "Body": "<p>I have this mern app i've been trying to deploy on heroku, it builds and gets deployed successfully with  no errors in my terminal but when I open app I instead see Application error. When I do <code>heroku logs --tail</code> in my terminal, I get this &quot;npm ERR! Missing script: &quot;start&quot;&quot;. Here is my api/package.json file:</p>\n<pre><code>  &quot;name&quot;: &quot;api&quot;,\n  &quot;version&quot;: &quot;1.0.0&quot;,\n  &quot;engines&quot;: {\n    &quot;node&quot;: &quot;14.17.5&quot;\n  },\n  &quot;description&quot;: &quot;&quot;,\n  &quot;main&quot;: &quot;index.js&quot;,\n  &quot;author&quot;: &quot;Emanuel&quot;,\n  &quot;license&quot;: &quot;ISC&quot;,\n  &quot;dependencies&quot;: {\n    &quot;bcrypt&quot;: &quot;^5.0.1&quot;,\n    &quot;cors&quot;: &quot;^2.8.5&quot;,\n    &quot;dotenv&quot;: &quot;^10.0.0&quot;,\n    &quot;express&quot;: &quot;^4.17.2&quot;,\n    &quot;helmet&quot;: &quot;^5.0.1&quot;,\n    &quot;marked&quot;: &quot;^4.0.8&quot;,\n    &quot;mongoose&quot;: &quot;^6.1.4&quot;,\n    &quot;morgan&quot;: &quot;^1.10.0&quot;,\n    &quot;multer&quot;: &quot;^1.4.4&quot;,\n    &quot;nodemon&quot;: &quot;^2.0.15&quot;,\n    &quot;path&quot;: &quot;^0.12.7&quot;\n  },\n  &quot;scripts&quot;: {\n    &quot;start&quot;: &quot;node index.js&quot;,\n    &quot;heroku-postbuild&quot;: &quot;cd client &amp;&amp; npm install &amp;&amp; npm run build&quot;\n  }\n}\n</code></pre>\n<p>and my client/package.json:</p>\n<pre><code>  &quot;name&quot;: &quot;test-tailwind&quot;,\n  &quot;version&quot;: &quot;0.1.0&quot;,\n  &quot;private&quot;: true,\n  &quot;dependencies&quot;: {\n    &quot;@material-ui/core&quot;: &quot;^4.12.3&quot;,\n    &quot;@material-ui/icons&quot;: &quot;^4.11.2&quot;,\n    &quot;@tailwindcss/line-clamp&quot;: &quot;^0.3.0&quot;,\n    &quot;@tailwindcss/typography&quot;: &quot;^0.5.0&quot;,\n    &quot;@testing-library/jest-dom&quot;: &quot;^5.16.1&quot;,\n    &quot;@testing-library/react&quot;: &quot;^12.1.2&quot;,\n    &quot;@testing-library/user-event&quot;: &quot;^13.5.0&quot;,\n    &quot;axios&quot;: &quot;^0.24.0&quot;,\n    &quot;react&quot;: &quot;^17.0.2&quot;,\n    &quot;react-dom&quot;: &quot;^17.0.2&quot;,\n    &quot;react-markdown&quot;: &quot;^7.1.2&quot;,\n    &quot;react-paginate&quot;: &quot;^8.1.0&quot;,\n    &quot;react-router-dom&quot;: &quot;^5.2.0&quot;,\n    &quot;react-scripts&quot;: &quot;5.0.0&quot;,\n    &quot;tailwind-scrollbar-hide&quot;: &quot;^1.1.7&quot;,\n    &quot;web-vitals&quot;: &quot;^2.1.2&quot;\n  },\n  &quot;scripts&quot;: {\n    &quot;start&quot;: &quot;react-scripts start&quot;,\n    &quot;build&quot;: &quot;react-scripts build&quot;,\n    &quot;test&quot;: &quot;react-scripts test&quot;,\n    &quot;eject&quot;: &quot;react-scripts eject&quot;\n  },\n  &quot;eslintConfig&quot;: {\n    &quot;extends&quot;: [\n      &quot;react-app&quot;,\n      &quot;react-app/jest&quot;\n    ]\n  },\n  &quot;browserslist&quot;: {\n    &quot;production&quot;: [\n      &quot;&gt;0.2%&quot;,\n      &quot;not dead&quot;,\n      &quot;not op_mini all&quot;\n    ],\n    &quot;development&quot;: [\n      &quot;last 1 chrome version&quot;,\n      &quot;last 1 firefox version&quot;,\n      &quot;last 1 safari version&quot;\n    ]\n  }\n  \n}\n</code></pre>\n<p>Please I really need deploy this app because building it has caused me sleepless nights and I can't just quit now. Link to github repo: <a href=\"https://github.com/Emabliss/joblisting\" rel=\"nofollow noreferrer\">https://github.com/Emabliss/joblisting</a>. Thanks in advance.</p>\n",
                    "OwnerUserId": "18190708",
                    "LastActivityDate": "2022-02-12T17:58:55.700",
                    "Title": "MERN app running on local server but fails during deployment on Heroku",
                    "Tags": "<node.js><reactjs><mongodb><express><heroku>",
                    "AnswerCount": "0",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "71362978",
                "ParentRepo": "https://github.com/JonathanDPotter/friendbook-back",
                "StackOverflow_Post": {
                    "Id": "71362978",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "71386809",
                    "CreationDate": "2022-03-05T14:24:20.773",
                    "Score": "0",
                    "ViewCount": "46",
                    "Body": "<p>When I send post requests to my API where the body is a single string, the API is receiving an empty string instead.</p>\n<p>function call (client):</p>\n<pre><code> const response = await api.uploadImg(&quot;image&quot;);\n</code></pre>\n<p>axios request (client):</p>\n<pre><code>const uploadImg = async (image: string) =&gt; {\n  const response = await axios.post(`${apiBaseURL}/api/image`, image);\n  return response.data;\n};\n</code></pre>\n<p>router (server):</p>\n<pre><code>import { Router } from &quot;express&quot;;\nimport controller from &quot;../controllers/image&quot;;\n\nconst router = Router();\n\nrouter.post(&quot;/&quot;, controller.upload);\n\nexport default router;\n</code></pre>\n<p>controller (server):</p>\n<pre><code>import { Request, Response } from &quot;express&quot;;\n\nconst upload = async (req: Request, res: Response) =&gt; {\n  res.json(req.body)\n};\n\nexport default { upload };\n</code></pre>\n<p>The response I get after sending the string &quot;image&quot; is:</p>\n<pre><code>{image: ''}\n</code></pre>\n<p>It is confounding, because I have another route that successfully receives request body data without destroying it, but this route (and another test route that I made) always receives an empty string instead of the string sent.  The route originally was supposed to receive a base64 image string and upload it to cloudinary, but when it looked like it was just receiving an empty string, I changed the controller to simply return the request body for testing purposes.</p>\n<p>full express server:</p>\n<pre><code>import express from &quot;express&quot;;\nimport morgan from &quot;morgan&quot;;\nimport cors from &quot;cors&quot;;\n// util\nimport config from &quot;./config&quot;;\nimport connectMongo from &quot;./config/mongo&quot;;\nimport connectCloudinary from &quot;./config/cloudinary&quot;;\n// routes\nimport indexRoutes from &quot;./routes&quot;;\nimport userRoutes from &quot;./routes/user&quot;;\nimport postRoutes from &quot;./routes/post&quot;;\nimport imageRoutes from &quot;./routes/image&quot;;\n\nconst server = express();\n\nserver.listen(config.server.port, () =&gt; {\n  console.log(&quot;Server running on port:&quot;, config.server.port);\n\n  // logging when in developement\n  if (config.server.env === &quot;developement&quot;) server.use(morgan(&quot;dev&quot;));\n\n  // parse requests\n  server.use(express.urlencoded({ extended: true, limit: &quot;50mb&quot; }));\n  server.use(express.json({ limit: &quot;50mb&quot; }));\n\n  // connect the database\n  connectMongo();\n\n  // connect cloudinary for image uploads\n  connectCloudinary();\n\n  // cross-origin-routing\n  server.use(\n    cors({\n      origin: config.client.url,\n    })\n  );\n\n  // routing\n  server.use(&quot;/&quot;, indexRoutes);\n  server.use(&quot;/api/users&quot;, userRoutes);\n  server.use(&quot;/api/posts&quot;, postRoutes);\n  server.use(&quot;/api/image&quot;, imageRoutes);\n});\n</code></pre>\n<p>link to github repo for back-end <a href=\"https://github.com/JonathanDPotter/friendbook-back\" rel=\"nofollow noreferrer\">here</a>.</p>\n",
                    "OwnerUserId": "15163097",
                    "LastActivityDate": "2022-03-07T20:19:17.277",
                    "Title": "Express API controller is receiving empty strings",
                    "Tags": "<typescript><api><express><axios>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "71623999",
                "ParentRepo": "https://github.com/RetireJS/retire.js",
                "StackOverflow_Post": {
                    "Id": "71623999",
                    "PostTypeId": "1",
                    "CreationDate": "2022-03-25T23:07:18.513",
                    "Score": "0",
                    "ViewCount": "54",
                    "Body": "<p>As I understood from documentation setting up <a href=\"https://gruntjs.com/getting-started\" rel=\"nofollow noreferrer\">Grunt</a> requires access to the webpack, which from my understanding is hidden when project is using create-react-app and we do not eject out of it. Is it possible to set up Grunt library for such project somehow?</p>\n<p>In case if it matters, I think I need Grunt in order to set up a plugin for <a href=\"https://github.com/RetireJS/retire.js\" rel=\"nofollow noreferrer\">Retire.js</a> library in order to check libraries for known vulnerabilities and I would like this process to be as automated as it is possible.</p>\n",
                    "OwnerUserId": "11816224",
                    "LastActivityDate": "2022-03-25T23:07:18.513",
                    "Title": "Is it possible to set up Grunt.js for Create React App project?",
                    "Tags": "<javascript><reactjs><webpack><gruntjs><create-react-app>",
                    "AnswerCount": "0",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "71966751",
                "ParentRepo": "https://github.com/ashwanigarg/benchmark-nodejs-mongodb",
                "StackOverflow_Post": {
                    "Id": "71966751",
                    "PostTypeId": "1",
                    "CreationDate": "2022-04-22T09:48:55.987",
                    "Score": "4",
                    "ViewCount": "429",
                    "Body": "<p>I am testing the performance of Node.js (ExpressJS/Fastify), Python (Flask) and Java (Spring Boot with webflux) with MongoDB. I hosted all these sample applications on the same server one after another so all services have the same environment. I used two different tools Load-test and Apache Benchmark cli for measuring the performance.</p>\n<p>All the code for the Node sample is present in this repository:\n<a href=\"https://github.com/ashwanigarg/benchmark-nodejs-mongodb\" rel=\"nofollow noreferrer\">benchmark-nodejs-mongodb</a></p>\n<p>I have executed multiple tests with various combinations of the number of requests and concurrent requests with both the tools</p>\n<p><strong>Apache Benchmark</strong> Total 1K requests and 100 concurrent</p>\n<blockquote>\n<p>ab -k -n 1000 -c 100 http://{{server}}:7102/api/case1/1000</p>\n</blockquote>\n<p><strong>Load-Test</strong> Total 100 requests and 10 concurrent</p>\n<blockquote>\n<p>loadtest http://{{server}}:7102/api/case1/1000 -n 100 -c 10</p>\n</blockquote>\n<p>The results are also attached to the Github repository and are shocking for NodeJS as compared to other technologies, either the requests are breaking in between the test or the completion of the test is taking too much time.</p>\n<p><strong>Server Configuration:</strong> Not dedicated but</p>\n<p>CPU: Core i7 8th Gen 12 Core\nRAM: 32GB\nStorage: 2TB HDD\nNetwork Bandwidth: 30Mbps</p>\n<p><strong>Mongo Server</strong> Different nodes on different networks connected through the Internet</p>\n<p>Please help me in understanding this issue in detail. I do understand how the Event loop works in nodejs but this problem is not identifiable.</p>\n<h2>Reproduced</h2>\n<p>Setup:</p>\n<ul>\n<li>Mongodb Atlas M30</li>\n<li>AWS c4xlarge in the same region</li>\n</ul>\n<p>Results:</p>\n<p>No failures</p>\n<pre><code>Document Path:          /api/case1/1000\nDocument Length:        37 bytes\n\nConcurrency Level:      100\nTime taken for tests:   33.915 seconds\nComplete requests:      1000\nFailed requests:        0\nKeep-Alive requests:    1000\nTotal transferred:      265000 bytes\nHTML transferred:       37000 bytes\nRequests per second:    29.49 [#/sec] (mean)\nTime per request:       3391.491 [ms] (mean)\nTime per request:       33.915 [ms] (mean, across all concurrent requests)\nTransfer rate:          7.63 [Kbytes/sec] received\n\nConnection Times (ms)\n              min  mean[+/-sd] median   max\nConnect:        0    1   3.1      0      12\nProcessing:   194 3299 1263.1   3019    8976\nWaiting:      190 3299 1263.1   3019    8976\nTotal:        195 3300 1264.0   3019    8976\n</code></pre>\n<p>Length failures on havier load:</p>\n<pre><code>Document Path:          /api/case1/5000\nDocument Length:        37 bytes\n\nConcurrency Level:      100\nTime taken for tests:   176.851 seconds\nComplete requests:      1000\nFailed requests:        22\n   (Connect: 0, Receive: 0, Length: 22, Exceptions: 0)\nKeep-Alive requests:    978\nTotal transferred:      259170 bytes\nHTML transferred:       36186 bytes\nRequests per second:    5.65 [#/sec] (mean)\nTime per request:       17685.149 [ms] (mean)\nTime per request:       176.851 [ms] (mean, across all concurrent requests)\nTransfer rate:          1.43 [Kbytes/sec] received\n\nConnection Times (ms)\n              min  mean[+/-sd] median   max\nConnect:        0    0   0.9      0       4\nProcessing:   654 17081 5544.0  16660   37911\nWaiting:      650 17323 5290.9  16925   37911\nTotal:        654 17081 5544.1  16660   37911\n</code></pre>\n",
                    "OwnerUserId": "4918924",
                    "LastEditorUserId": "1110423",
                    "LastEditDate": "2022-05-09T22:00:03.477",
                    "LastActivityDate": "2022-05-17T08:16:56.993",
                    "Title": "Node+Express+MongoDB Native Client Performance issue",
                    "Tags": "<node.js><mongodb><performance><benchmarking>",
                    "AnswerCount": "2",
                    "CommentCount": "6",
                    "FavoriteCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "72245027",
                "ParentRepo": "https://github.com/blackcatbot/blackcat",
                "StackOverflow_Post": {
                    "Id": "72245027",
                    "PostTypeId": "1",
                    "CreationDate": "2022-05-15T01:48:55.810",
                    "Score": "0",
                    "ViewCount": "36",
                    "Body": "<p>I have a Discord bot written in Nodejs (JavaScript), but I run into a memory leak issue recently.</p>\n<p>My code is using ~10GB memory, and it keep increasing. I run <code>process.memUsage()</code> and it returned something like this:</p>\n<pre><code>rss: ~10GB\nheapTotal: ~300MB\nheapUsed: ~250MB\nexternal: ~500MB\narrayBuffer: ~500MB\n</code></pre>\n<p>I can't figure out which piece of code is leaking, there is alot tool that will diagnose memory leak in Node.js, but almost all tools is watching <code>heap</code> instead <code>rss</code>.</p>\n<blockquote>\n<p>Note: I did not use any <code>var</code> keyword, I hate it.</p>\n</blockquote>\n<p>Code repository: <a href=\"https://github.com/blackcatbot/blackcat\" rel=\"nofollow noreferrer\">https://github.com/blackcatbot/blackcat</a></p>\n",
                    "OwnerUserId": "15071148",
                    "LastActivityDate": "2022-05-15T01:48:55.810",
                    "Title": "My JavaScript code is memory leaking, but I don't know how to fix",
                    "Tags": "<javascript><node.js><performance><memory-leaks>",
                    "AnswerCount": "0",
                    "CommentCount": "5",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "72600171",
                "ParentRepo": "https://github.com/basir/mern-amazona/commit/12e565bf6e1859b963729eaba46a5352962fe9e1",
                "StackOverflow_Post": {
                    "Id": "72600171",
                    "PostTypeId": "1",
                    "CreationDate": "2022-06-13T08:57:42.850",
                    "Score": "0",
                    "ViewCount": "80",
                    "Body": "<p>working on a cart app in a udemy course  - the problem is when the quantity gets bought it supposed to make the button disabled but its not working, only showing the add to cart button without disabling it when quantity are zero\ndata.countInStock seems not to be updating</p>\n<pre><code>import { Button } from 'react-bootstrap';\nimport { Card } from 'react-bootstrap';\nimport { Link } from 'react-router-dom';\nimport React, { useContext } from 'react';\nimport Rating from './Rating';\nimport axios from 'axios';\nimport { Store } from '../Store';\n\nfunction Product(props){\n const {product} = props;\n\nconst {state , dispatch:ctxDispatch} = useContext(Store);\nconst {cart: {cartItems}} = state\n\nconst addToCartHandler = async (item )=&gt;{\n  const existItem = cartItems.find((x)=&gt; x._id === product._id);\n   const quantity = existItem ? existItem.quantity+1:1 ; \n\n  const {data} = await axios.get(`/api/products/${item._id}`);\n  if(data.countInStock &lt; quantity){\n      window.alert('sorry product is out of stock')\n      return;\n  }\n   ctxDispatch({\n       type:'CART_ADD_ITEM' \n       , payload:{...item , quantity},\n   });\n  };\n  \n\nreturn(\n\n    &lt;Card&gt;\n\n\n    &lt;Link to={`/product/${product.slug}`}&gt; \n      &lt;img src={product.image} className=&quot;card-img-top&quot; alt={product.name} /&gt;\n    &lt;/Link&gt;\n    &lt;Card.Body&gt;\n    &lt;Link to={`/product/${product.slug}`}&gt;\n        &lt;Card.Title&gt;{product.name}&lt;/Card.Title&gt;\n    &lt;/Link&gt;\n    &lt;Rating rating={product.rating} numReviews={product.numReviews} /&gt;\n    &lt;Card.Text&gt;${product.price}&lt;/Card.Text&gt;\n\n    {  product.countInStock === 0 ? (\n\n      \n      &lt;Button  color=&quot;light&quot; disabled={true} &gt;  Out of stock&lt;/Button&gt;\n      \n    ):(\n      \n      &lt;Button onClick={() =&gt; addToCartHandler(product)}&gt;Add to cart&lt;/Button&gt;\n    )}\n  &lt;/Card.Body&gt;\n&lt;/Card&gt;\n)}\n</code></pre>\n<p>it's not showing the button out of stock when quantity gets used, What's wrong with the code?\nfull code: <a href=\"https://github.com/basir/mern-amazona/commit/12e565bf6e1859b963729eaba46a5352962fe9e1\" rel=\"nofollow noreferrer\">https://github.com/basir/mern-amazona/commit/12e565bf6e1859b963729eaba46a5352962fe9e1</a></p>\n<p>full code with backend : <a href=\"https://github.com/basir/mern-amazona/tree/12e565bf6e1859b963729eaba46a5352962fe9e1\" rel=\"nofollow noreferrer\">https://github.com/basir/mern-amazona/tree/12e565bf6e1859b963729eaba46a5352962fe9e1</a></p>\n",
                    "OwnerUserId": "1560145",
                    "LastActivityDate": "2022-06-13T09:13:55.247",
                    "Title": "react button conditional rendering not working properly",
                    "Tags": "<javascript><reactjs>",
                    "AnswerCount": "1",
                    "CommentCount": "6",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "72600316",
                "ParentRepo": "https://github.com/repetitioestmaterstudiorum/ts-boiler",
                "StackOverflow_Post": {
                    "Id": "72600316",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "72622089",
                    "CreationDate": "2022-06-13T09:08:21.367",
                    "Score": "5",
                    "ViewCount": "1143",
                    "Body": "<p>I stumbled upon a problem with absolute imports. The repository is publicly available here: <a href=\"https://github.com/repetitioestmaterstudiorum/ts-boiler\" rel=\"noreferrer\">https://github.com/repetitioestmaterstudiorum/ts-boiler</a></p>\n<p>When I'm trying to import a file with absolute path (relative to the project directory) and then execute <code>npm run dev</code> or <code>npm run ts-node src/index.ts</code> I am getting the following error:</p>\n<pre><code>Error: Cannot find module '/src/constants'\nRequire stack:\n- /Users/&lt;my-username&gt;/&lt;some-path&gt;/ts-boiler/src/index.ts\n    at Function.Module._resolveFilename (node:internal/modules/cjs/loader:933:15)\n    at Function.Module._resolveFilename.sharedData.moduleResolveFilenameHook.installedValue [as _resolveFilename] (/Users/&lt;my-username&gt;/&lt;some-path&gt;/ts-boiler/node_modules/@cspotcode/source-map-support/source-map-support.js:811:30)\n    at Function.Module._load (node:internal/modules/cjs/loader:778:27)\n    at Module.require (node:internal/modules/cjs/loader:1005:19)\n    at require (node:internal/modules/cjs/helpers:102:18)\n    at Object.&lt;anonymous&gt; (/Users/&lt;my-username&gt;/&lt;some-path&gt;/ts-boiler/src/index.ts:1:1)\n    at Module._compile (node:internal/modules/cjs/loader:1105:14)\n    at Module.m._compile (/Users/&lt;my-username&gt;/&lt;some-path&gt;/ts-boiler/node_modules/ts-node/src/index.ts:1597:23)\n    at Module._extensions..js (node:internal/modules/cjs/loader:1159:10)\n    at Object.require.extensions.&lt;computed&gt; [as .ts] (/Users/&lt;my-username&gt;/&lt;some-path&gt;/ts-boiler/node_modules/ts-node/src/index.ts:1600:12) {\n  code: 'MODULE_NOT_FOUND',\n  requireStack: [ '/Users/&lt;my-username&gt;/&lt;some-path&gt;/ts-boiler/src/index.ts' ]\n}\n</code></pre>\n<p>(my username and folder structure is obfuscated for privacy reasons)</p>\n<p>Relative imports, such as <code>import { C } from './constants'</code> inside the file <code>src/index.ts</code> work fine. When changing that to <code>import { C } from '/src/constants'</code> or <code>import { C } from 'src/constants'</code> with the corresponding <code>tsconfig.json</code> settings, I'm getting the error.\n(the same error also occurs when I append <code>.js</code> or <code>.ts</code> to the import)</p>\n<p><code>tsconfig.json</code> settings for absolute imports with leading dash enabled:</p>\n<pre><code>&quot;baseUrl&quot;: &quot;.&quot;,\n&quot;paths&quot;: {\n    /* Support absolute imports with a leading '/' */\n    &quot;/*&quot;: [&quot;*&quot;]\n},\n</code></pre>\n<p>I usually work with MeteorJS and recently followed the tutorial for Remix (to get to know the framework). Both of these frameworks encourage absolute imports and I copied both of their <code>tsconfig.json</code> files into my project (adding <code>~</code> in the case of Remix's settings) to try and see if their configuration would work for me - without success!</p>\n<p>I also looked at this on how to enable absolute imports: <a href=\"https://javascript.plainenglish.io/why-and-how-to-use-absolute-imports-in-react-d5b52f24d53c\" rel=\"noreferrer\">https://javascript.plainenglish.io/why-and-how-to-use-absolute-imports-in-react-d5b52f24d53c</a> which resulted in the same error.</p>\n<p>What's more confusing for me is that VSCode with ESLint configured does not complain about the absolute imports with the right settings in the <code>tsconfig.json</code> file.</p>\n<p>And weirdly, there is one import that uses an absolute path that works well inside the project with the same settings: <code>import type { Constants } from '/types/t.constants'</code>. It also works without &quot;type&quot;, e.g. <code>import { Constants } from '/types/t.constants'</code>. It could be because the imported file is not in &quot;src/&quot; but in &quot;types/&quot;?</p>\n<p>Maybe someone solved a similar problem once?</p>\n",
                    "OwnerUserId": "11751547",
                    "LastEditorUserId": "11751547",
                    "LastEditDate": "2022-06-13T11:24:00.200",
                    "LastActivityDate": "2022-06-14T20:16:21.517",
                    "Title": "ts-node 'MODULE_NOT_FOUND' when using absolute imports in TypeScript",
                    "Tags": "<typescript><importerror><tsconfig><absolute-path>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "72609313",
                "ParentRepo": "https://github.com/ojc011/ecommercebiz",
                "StackOverflow_Post": {
                    "Id": "72609313",
                    "PostTypeId": "1",
                    "CreationDate": "2022-06-13T21:35:34.113",
                    "Score": "0",
                    "ViewCount": "83",
                    "Body": "<p><a href=\"https://i.stack.imgur.com/hUJaO.png\" rel=\"nofollow noreferrer\">Google map &quot;loading&quot; and error message</a></p>\n<p><a href=\"https://i.stack.imgur.com/IeBrO.png\" rel=\"nofollow noreferrer\">MapScreen file in react app.</a></p>\n<p><a href=\"https://github.com/ojc011/ecommercebiz\" rel=\"nofollow noreferrer\">Repository</a></p>\n<pre><code>const libs = ['places'];\n</code></pre>\n<pre><code> return (\n    &lt;div className=&quot;full-box&quot;&gt;\n      &lt;LoadScript libraries={libs} googleMapsApiKey={googleApiKey}&gt;\n        &lt;GoogleMap\n          id=&quot;smaple-map&quot;\n          mapContainerStyle={{ height: '100%', width: '100%' }}\n          center={center}\n          zoom={15}\n          onLoad={onLoad}\n          onIdle={onIdle}\n        &gt;\n          &lt;StandaloneSearchBox\n            onLoad={onLoadPlaces}\n            onPlacesChanged={onPlacesChanged}\n          &gt;\n            &lt;div className=&quot;map-input-box&quot;&gt;\n              &lt;input type=&quot;text&quot; placeholder=&quot;Enter your address&quot;&gt;&lt;/input&gt;\n              &lt;Button type=&quot;button&quot; onClick={onConfirm}&gt;\n                Confirm\n              &lt;/Button&gt;\n            &lt;/div&gt;\n          &lt;/StandaloneSearchBox&gt;\n          &lt;Marker position={location} onLoad={onMarkerLoad}&gt;&lt;/Marker&gt;\n        &lt;/GoogleMap&gt;\n      &lt;/LoadScript&gt;\n    &lt;/div&gt;\n  );\n</code></pre>\n<p>I am getting this error when trying to implement google maps api into my ecommerce application. I have read other threads saying I can only have one , however, I do only have one loadscript tag on this entire application so that did not solve the issue for me. Hopefully I am not glossing over something silly but I've been stuck on this error for a few days now trying to find a solution.</p>\n",
                    "OwnerUserId": "7207835",
                    "LastEditorUserId": "7207835",
                    "LastEditDate": "2022-06-13T21:55:37.650",
                    "LastActivityDate": "2022-08-17T20:06:35.670",
                    "Title": "\"google api is already presented\"",
                    "Tags": "<node.js><reactjs><mongodb><express>",
                    "AnswerCount": "1",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "72753859",
                "ParentRepo": "https://github.com/Hritvik-Mohan/Auction-Project",
                "StackOverflow_Post": {
                    "Id": "72753859",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "72754062",
                    "CreationDate": "2022-06-25T12:27:01.713",
                    "Score": "0",
                    "ViewCount": "123",
                    "Body": "<pre><code>MongoDB connected...\nDevelopment server live on http://localhost:3000\nnode:internal/errors:465\n    ErrorCaptureStackTrace(err);\n    ^\n\nError: querySrv ECONNREFUSED _mongodb._tcp.auctiondbcluster.s6rzg.mongodb.net\n    at QueryReqWrap.onresolve [as oncomplete] (node:dns:213:19) {\n  errno: undefined,\n  code: 'ECONNREFUSED',\n  syscall: 'querySrv',\n  hostname: '_mongodb._tcp.auctiondbcluster.s6rzg.mongodb.net'\n}\n</code></pre>\n<p>Everything works smooth when I am connected to my wifi but when I am offline and starting the server it gives this error. And by the way no I am not trying to connect to MongoDB online cluster, I am trying to connect to local host (mongodb://localhost:27017/auctionDB).</p>\n<p>Here the function I am using in <code>app.js</code></p>\n<pre><code>const runServer = async () =&gt;{\n  if(process.env.NODE_ENV !== &quot;production&quot;){\n    await connectDb(process.env.MONGODB_LOCAL_CONNECTION);\n    app.listen(PORT, ()=&gt;{\n      console.log(`Development server live on http://localhost:${PORT}`);\n    })\n  } else {\n    await connectDb(process.env.MONGODB_CONNECTION_STRING);\n    app.listen(PORT, ()=&gt;{\n      console.log(`Production server live on port ${PORT}`);\n    })\n  }\n}\n\nrunServer();\n</code></pre>\n<p>In my <code>.env</code> file <code>NODE_ENV</code> is set to development.\nHere is the <code>connectDb.js</code> function I am using to connect to the database</p>\n<pre><code>const mongoose = require(&quot;mongoose&quot;);\n\n/**\n * @description: Connect to the database by providing the connection string.\n * @param {String} uri | MongoDB URI\n * @default: mongodb://localhost:27017/auctionDB\n *\n * @returns {undefined}\n */\nconst connectDb = (url = process.env.MONGODB_LOCAL_CONNECTION) =&gt; {\n    try {\n      const con = mongoose.connect(url, {\n        useNewUrlParser: true,\n        useUnifiedTopology: true\n      });\n      if(con) console.log(&quot;MongoDB connected...&quot;)\n    } catch(e){\n      console.log(`Error: ${e}`);\n    }\n};  \n\nmodule.exports = connectDb;\n</code></pre>\n<p><a href=\"https://github.com/Hritvik-Mohan/Auction-Project\" rel=\"nofollow noreferrer\">Here</a> is the entire project on github</p>\n",
                    "OwnerUserId": "14900981",
                    "LastEditorUserId": "14900981",
                    "LastEditDate": "2022-06-25T12:29:35.110",
                    "LastActivityDate": "2022-06-25T13:01:02.140",
                    "Title": "Getting Error: querySrv ECONNREFUSED _mongodb._tcp.auctiondbcluster.s6rzg.mongodb.net. When trying to connect to localhost when I am offline",
                    "Tags": "<javascript><node.js><mongodb>",
                    "AnswerCount": "2",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "73035719",
                "ParentRepo": "https://github.com/MayorMonty/Snoostorm/issues/23",
                "StackOverflow_Post": {
                    "Id": "73035719",
                    "PostTypeId": "1",
                    "CreationDate": "2022-07-19T11:01:59.143",
                    "Score": "0",
                    "ViewCount": "66",
                    "Body": "<p>I'm working on a Reddit bot running on NodeJS and based on snoostorm and snoowrap but I'm having trouble handling errors.</p>\n<p>I would like to catch any error occured when trying to access the <code>comment</code> object (I.E. to reply to it). Such errors would be both networking ones (401, 503) and Reddit ones (THREAD_LOCKED, RATELIMIT, SOMETHING_IS_BROKEN).</p>\n<p>I have tried using the following try/catch, both inside and outside the <code>stream.on()</code> callback but nothing seems to change. Here's the code.</p>\n<pre><code>const r = new Snoowrap({\n    clientId: process.env.CLIENT_ID,\n    clientSecret: process.env.CLIENT_SECRET,\n    username: process.env.REDDIT_USER,\n    password: process.env.REDDIT_PASS\n});\n\nconst stream = new CommentStream(r, {\n    subreddit: 'testingground4bots',\n    results: 1\n});\n\n\nstream.on('item', comment =&gt; {\n    try {\n        comment.reply('This is a test')\n    } catch (e) {\n        console.log('An error occurred', e)\n    }\n})\n</code></pre>\n<p>No suppose the receiver of that message blocked my bot. What I would get is a <code>SOMETHING_IS_BROKEN</code> error. I'm interested in handling such an error to be able to react accordingly.</p>\n<p>The developer of snoostorm <a href=\"https://github.com/MayorMonty/Snoostorm/issues/23\" rel=\"nofollow noreferrer\">says the following</a>, regarding error handling:</p>\n<blockquote>\n<p>Events should bubble up through the call stack, and as such <code>try/catch</code> or promise <code>.catch()</code> is going to be your best bet. Currently I'm not exposing the raw requests on the <code>Poll</code> parent class, but I imagine that could be a feature in the future.</p>\n</blockquote>\n<p>Yet I had no luck with try/catch and I get TypeErrors when I try to <code>comment.catch()</code>, possibly because the promise has already been fulfilled when it reaches my code. I've tried reaching out to the developer via an issue on GitHub but I haven't received an answer after more than a month since I opened it.</p>\n<p>Here's how the error's call stack looks like in the console:</p>\n<pre><code>Unhandled rejection Error: SOMETHING_IS_BROKEN,Something is broken, please try again later.,parent\n    at [...]\\node_modules\\snoowrap\\dist\\helpers.js:84:11\n    at PassThroughHandlerContext.finallyHandler ([...]\\node_modules\\bluebird\\js\\release\\finally.js:57:23)\n    at PassThroughHandlerContext.tryCatcher ([...]\\node_modules\\bluebird\\js\\release\\util.js:16:23)\n    at Promise._settlePromiseFromHandler ([...]\\node_modules\\bluebird\\js\\release\\promise.js:547:31)\n    at Promise._settlePromise ([...]\\node_modules\\bluebird\\js\\release\\promise.js:604:18)\n    at Promise._settlePromise0 ([...]\\node_modules\\bluebird\\js\\release\\promise.js:649:10)\n    at Promise._settlePromises ([...]\\node_modules\\bluebird\\js\\release\\promise.js:729:18)\n    at _drainQueueStep ([...]\\node_modules\\bluebird\\js\\release\\async.js:93:12)\n    at _drainQueue ([...]\\node_modules\\bluebird\\js\\release\\async.js:86:9)\n    at Async._drainQueues ([...]\\node_modules\\bluebird\\js\\release\\async.js:102:5)\n    at Async.drainQueues [as _onImmediate] ([...]\\node_modules\\bluebird\\js\\release\\async.js:15:14)\n    at process.processImmediate (node:internal/timers:471:21)\n</code></pre>\n<h1>EDIT: August 2022</h1>\n<p>The Snoostorm developer <a href=\"https://github.com/MayorMonty/Snoostorm/issues/58\" rel=\"nofollow noreferrer\">commented</a>:</p>\n<blockquote>\n<p>currently there is no way for you to handle exceptions encountered, but it wouldn't be too difficult to add. I will add it to my todo list :-)</p>\n</blockquote>\n<p>Though I wouldn't raise my hopes too high. That repository isn't very active and I quite frankly don't expect this to ever get fixed. For the time being it's nothing tragic for my bot, even in case of errors it doesn't crash and that's good enough for me.<br />\nSorry for anyone else dealing with this issue, I'm afraid this is all I can do to help you.</p>\n",
                    "OwnerUserId": "12273353",
                    "LastEditorUserId": "12273353",
                    "LastEditDate": "2022-09-10T21:07:51.377",
                    "LastActivityDate": "2022-09-10T21:07:51.377",
                    "Title": "Error handling on snoostorm / snoowrap (nodejs)",
                    "Tags": "<javascript><node.js><error-handling><bots><reddit>",
                    "AnswerCount": "0",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "73191647",
                "ParentRepo": "https://github.com/Gaurav200247/E-Book-Store-Mern-Project",
                "StackOverflow_Post": {
                    "Id": "73191647",
                    "PostTypeId": "1",
                    "CreationDate": "2022-08-01T09:29:58.267",
                    "Score": "4",
                    "ViewCount": "1883",
                    "Body": "<p>I don't know what's going on I am making a frontend using vite + react for my mern project and suddenly starts encountering this error.</p>\n<pre><code>Error: Module &quot;events&quot; has been externalized for browser compatibility. Cannot access &quot;events.EventEmitter&quot; in client code.\n</code></pre>\n<p>git repo link : <a href=\"https://github.com/Gaurav200247/E-Book-Store-Mern-Project\" rel=\"nofollow noreferrer\">https://github.com/Gaurav200247/E-Book-Store-Mern-Project</a></p>\n",
                    "OwnerUserId": "19293666",
                    "LastEditorUserId": "123671",
                    "LastEditDate": "2022-08-22T12:16:52.363",
                    "LastActivityDate": "2022-09-28T23:06:55.030",
                    "Title": "Uncaught Error: Module \"events\" has been externalized for browser compatibility. Cannot access \"events.EventEmitter\" in client code",
                    "Tags": "<reactjs><npm><package.json><vite>",
                    "AnswerCount": "2",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "73452283",
                "ParentRepo": "https://github.com/rebeccapeltz/notebooks/blob/main/iris.ipynb",
                "StackOverflow_Post": {
                    "Id": "73452283",
                    "PostTypeId": "1",
                    "CreationDate": "2022-08-23T00:41:30.603",
                    "Score": "0",
                    "ViewCount": "34",
                    "Body": "<p>I'm using a node notebook extension with the nnb file extension.  It renders wonderfully in VS Code, but the markdown and visuals aren't available on GitHub like the ipynb files <a href=\"https://github.com/rebeccapeltz/notebooks/blob/main/iris.ipynb\" rel=\"nofollow noreferrer\">https://github.com/rebeccapeltz/notebooks/blob/main/iris.ipynb</a>.</p>\n<p>Is there any way to get the serialized data(<a href=\"https://github.com/rebeccapeltz/cascadiajs-notebooks/blob/main/cld-deliver.nnb\" rel=\"nofollow noreferrer\">https://github.com/rebeccapeltz/cascadiajs-notebooks/blob/main/cld-deliver.nnb</a>) from my node.js notebook to render as markdown on GitHub?</p>\n",
                    "OwnerUserId": "1079785",
                    "LastActivityDate": "2022-08-23T00:41:30.603",
                    "Title": "Visual Studio Code Notebooks - what would it take to make a node notebook render in github like the python notebooks",
                    "Tags": "<node.js><jupyter-notebook>",
                    "AnswerCount": "0",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "73452283",
                "ParentRepo": "https://github.com/rebeccapeltz/cascadiajs-notebooks/blob/main/cld-deliver.nnb",
                "StackOverflow_Post": {
                    "Id": "73452283",
                    "PostTypeId": "1",
                    "CreationDate": "2022-08-23T00:41:30.603",
                    "Score": "0",
                    "ViewCount": "34",
                    "Body": "<p>I'm using a node notebook extension with the nnb file extension.  It renders wonderfully in VS Code, but the markdown and visuals aren't available on GitHub like the ipynb files <a href=\"https://github.com/rebeccapeltz/notebooks/blob/main/iris.ipynb\" rel=\"nofollow noreferrer\">https://github.com/rebeccapeltz/notebooks/blob/main/iris.ipynb</a>.</p>\n<p>Is there any way to get the serialized data(<a href=\"https://github.com/rebeccapeltz/cascadiajs-notebooks/blob/main/cld-deliver.nnb\" rel=\"nofollow noreferrer\">https://github.com/rebeccapeltz/cascadiajs-notebooks/blob/main/cld-deliver.nnb</a>) from my node.js notebook to render as markdown on GitHub?</p>\n",
                    "OwnerUserId": "1079785",
                    "LastActivityDate": "2022-08-23T00:41:30.603",
                    "Title": "Visual Studio Code Notebooks - what would it take to make a node notebook render in github like the python notebooks",
                    "Tags": "<node.js><jupyter-notebook>",
                    "AnswerCount": "0",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "73629012",
                "ParentRepo": "https://github.com/amazon-archives/realworld-serverless-application/blob/master/backend/src/main/java/software/amazon/serverless/apprepo/api/impl/pagination/EncryptedTokenSerializer.java#L51",
                "StackOverflow_Post": {
                    "Id": "73629012",
                    "PostTypeId": "2",
                    "ParentId": "73628705",
                    "CreationDate": "2022-09-07T00:49:25.050",
                    "Score": "0",
                    "Body": "<p>Actually Base64 encrypting solves the problem:</p>\n<p><a href=\"https://github.com/amazon-archives/realworld-serverless-application/blob/master/backend/src/main/java/software/amazon/serverless/apprepo/api/impl/pagination/EncryptedTokenSerializer.java#L51\" rel=\"nofollow noreferrer\">https://github.com/amazon-archives/realworld-serverless-application/blob/master/backend/src/main/java/software/amazon/serverless/apprepo/api/impl/pagination/EncryptedTokenSerializer.java#L51</a></p>\n",
                    "OwnerUserId": "4697708",
                    "LastActivityDate": "2022-09-07T00:49:25.050",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "73891313",
                "ParentRepo": "https://github.com/bogdal/aws-cdk-website",
                "StackOverflow_Post": {
                    "Id": "73891313",
                    "PostTypeId": "1",
                    "CreationDate": "2022-09-29T06:44:53.530",
                    "Score": "0",
                    "ViewCount": "21",
                    "Body": "<p>I have a basic angular site served from S3 through Cloudfront.\nRecently I enabled rendertron using the Lambda@Edge functions as here</p>\n<ol>\n<li><a href=\"https://blog.mirumee.com/deployment-of-spa-pwa-applications-in-the-real-world-60ea9e6b24dc\" rel=\"nofollow noreferrer\">https://blog.mirumee.com/deployment-of-spa-pwa-applications-in-the-real-world-60ea9e6b24dc</a>\nand</li>\n<li><a href=\"https://github.com/bogdal/aws-cdk-website\" rel=\"nofollow noreferrer\">https://github.com/bogdal/aws-cdk-website</a></li>\n</ol>\n<p>Now, I get randomly 503 error. After a few minutes, site works fine again.\nSeems like something is timing out or cache issue.\n<a href=\"https://i.stack.imgur.com/7xNIU.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/7xNIU.png\" alt=\"CF Error page\" /></a></p>\n<p>Since it works sometimes, I doubt if this is permissions issue.\nAnyone faced this before?</p>\n",
                    "OwnerUserId": "2583495",
                    "LastEditorUserId": "18346482",
                    "LastEditDate": "2022-09-29T07:19:02.570",
                    "LastActivityDate": "2022-09-29T07:19:02.570",
                    "Title": "Cloudfront 503 Error after enabling rendortron impementation",
                    "Tags": "<angular><amazon-cloudfront><aws-lambda-edge><rendertron>",
                    "AnswerCount": "0",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "73965236",
                "ParentRepo": "https://github.com/js313/clothio/blob/master/index.js",
                "StackOverflow_Post": {
                    "Id": "73965236",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "73965268",
                    "CreationDate": "2022-10-05T19:07:59.570",
                    "Score": "0",
                    "ViewCount": "96",
                    "Body": "<p>I am trying to count the number of documents in a table that satisfy a condition.</p>\n<p>My code in node:-</p>\n<pre><code>const [washingCount, washedCount, dirtyCount] = await Promise.all([\n        pool.query(&quot;SELECT COUNT(*) FROM clothes WHERE status = 'washing'&quot;),\n        pool.query(&quot;SELECT COUNT(*) FROM clothes WHERE status = 'washed'&quot;),\n        pool.query(&quot;SELECT COUNT(*) FROM clothes WHERE status = 'dirty'&quot;)\n    ])\n</code></pre>\n<p>But I am getting the error saying:</p>\n<blockquote>\n<p>error: column &quot;count&quot; does not exist</p>\n</blockquote>\n<p>And when I copy the same query over to PostgreSQL CLI, those output the desired results.</p>\n<p><a href=\"https://i.stack.imgur.com/WZtEx.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/WZtEx.png\" alt=\"enter image description here\" /></a></p>\n<p>For full code refer:- <a href=\"https://github.com/js313/clothio/blob/master/index.js\" rel=\"nofollow noreferrer\">https://github.com/js313/clothio/blob/master/index.js</a></p>\n<p>Error stack trace:-\n<a href=\"https://i.stack.imgur.com/yXOkT.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/yXOkT.png\" alt=\"enter image description here\" /></a></p>\n<p>What am I missing here?</p>\n<p>Thank you.</p>\n",
                    "OwnerUserId": "13103518",
                    "LastEditorUserId": "13103518",
                    "LastEditDate": "2022-10-06T17:38:19.407",
                    "LastActivityDate": "2022-10-06T17:38:19.407",
                    "Title": "node-postgres not parsing queries correctly",
                    "Tags": "<express><pg><node-postgres>",
                    "AnswerCount": "1",
                    "CommentCount": "4",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "74128545",
                "ParentRepo": "https://github.com/AnkitaMalik22/hsfd-system/blob/main/backend/controllers/foodControllers.js#L135",
                "StackOverflow_Post": {
                    "Id": "74128545",
                    "PostTypeId": "1",
                    "CreationDate": "2022-10-19T16:07:18.120",
                    "Score": "0",
                    "ViewCount": "23",
                    "Body": "<p>Updated Data Not Saving In MongoDB</p>\n<h4>GET Food Details</h4>\n<ul>\n<li>router.route(&quot;/food/:id&quot;).get(getfoodDetails)</li>\n<li>here the request status is false by default.</li>\n<li>&quot;status&quot;: false,\n<strong>PostMan Response</strong></li>\n</ul>\n<pre class=\"lang-bash prettyprint-override\"><code>{\n    &quot;success&quot;: true,\n    &quot;food&quot;: {\n        &quot;_id&quot;: &quot;6310c11a25659a73a9323135&quot;,\n        &quot;name&quot;: &quot;chowmin&quot;,\n        &quot;description&quot;: &quot;this is desc..&quot;,\n        &quot;ratings&quot;: 0,\n        &quot;category&quot;: &quot;chineese&quot;,\n        &quot;Quantity&quot;: 1,\n        &quot;owner&quot;: &quot;hotel belmuri&quot;,\n        &quot;image&quot;: [],\n        &quot;requests&quot;: [\n            {\n                &quot;user&quot;: &quot;63105a8dfca318c1972bcc29&quot;,\n                &quot;name&quot;: &quot;Vollunteer&quot;,\n                &quot;comment&quot;: &quot;want this for poor people&quot;,\n                &quot;status&quot;: false,\n                &quot;_id&quot;: &quot;6310c527bed4bba6a608b29f&quot;\n            },\n            {\n                &quot;user&quot;: &quot;632884611816c85c14edcd2f&quot;,\n                &quot;name&quot;: &quot;Ankita&quot;,\n                &quot;comment&quot;: &quot;want this for poor people&quot;,\n                &quot;status&quot;: false,\n                &quot;_id&quot;: &quot;6329cec0b2b6e6c02927d3e6&quot;\n            }\n        ],\n        &quot;createdAt&quot;: &quot;2022-09-01T14:26:34.396Z&quot;,\n        &quot;__v&quot;: 2,\n        &quot;numOfRequests&quot;: 2\n    }\n}\n\n</code></pre>\n<h4>PUT  | Accept Food request</h4>\n<ul>\n<li><p>router.route(&quot;/request/accept/:id&quot;).put(isAuthenticatedUser,authorizeRoles(&quot;hotel&quot;),acceptFoodRequest)</p>\n</li>\n<li><p><a href=\"https://github.com/AnkitaMalik22/hsfd-system/blob/main/backend/controllers/foodControllers.js#L135\" rel=\"nofollow noreferrer\">https://github.com/AnkitaMalik22/hsfd-system/blob/main/backend/controllers/foodControllers.js#L135</a></p>\n</li>\n<li><p>here i am trying to change the request status from false to true.</p>\n</li>\n<li><p>&quot;status&quot;: true,</p>\n</li>\n</ul>\n<p><strong>PostMan Response</strong></p>\n<pre class=\"lang-bash prettyprint-override\"><code>{\n    &quot;success&quot;: true,\n    &quot;food&quot;: {\n        &quot;_id&quot;: &quot;6310c11a25659a73a9323135&quot;,\n        &quot;name&quot;: &quot;chowmin&quot;,\n        &quot;description&quot;: &quot;this is desc..&quot;,\n        &quot;ratings&quot;: 0,\n        &quot;category&quot;: &quot;chineese&quot;,\n        &quot;Quantity&quot;: 1,\n        &quot;owner&quot;: &quot;hotel belmuri&quot;,\n        &quot;image&quot;: [],\n        &quot;requests&quot;: [\n            {\n                &quot;user&quot;: &quot;63105a8dfca318c1972bcc29&quot;,\n                &quot;name&quot;: &quot;Vollunteer&quot;,\n                &quot;comment&quot;: &quot;want this for poor people&quot;,\n                &quot;status&quot;: true,\n                &quot;_id&quot;: &quot;6310c527bed4bba6a608b29f&quot;\n            },\n            {\n                &quot;user&quot;: &quot;632884611816c85c14edcd2f&quot;,\n                &quot;name&quot;: &quot;Ankita&quot;,\n                &quot;comment&quot;: &quot;want this for poor people&quot;,\n                &quot;status&quot;: false,\n                &quot;_id&quot;: &quot;6329cec0b2b6e6c02927d3e6&quot;\n            }\n        ],\n        &quot;createdAt&quot;: &quot;2022-09-01T14:26:34.396Z&quot;,\n        &quot;__v&quot;: 2,\n        &quot;numOfRequests&quot;: 2\n    }\n}\n</code></pre>\n<p>It's Changed to  <strong>&quot;status&quot;: true</strong> ! But the problem is it's not saving in MongoDb .</p>\n<p>When i'm requesting  get food details again it's showing <strong>&quot;status&quot;: false</strong></p>\n",
                    "OwnerUserId": "19085252",
                    "LastEditorUserId": "272109",
                    "LastEditDate": "2022-10-19T16:11:41.877",
                    "LastActivityDate": "2022-10-19T16:11:41.877",
                    "Title": "Updated Data Not Saving In MongoDB",
                    "Tags": "<node.js><mongodb>",
                    "AnswerCount": "0",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "74332952",
                "ParentRepo": "https://github.com/googlearchive/friendlypix-web",
                "StackOverflow_Post": {
                    "Id": "74332952",
                    "PostTypeId": "1",
                    "CreationDate": "2022-11-06T02:44:10.320",
                    "Score": "1",
                    "ViewCount": "57",
                    "Body": "<p>How to Bundle all the files inside \u201csrc\u201d folder and replace the existing bundled files inside \u201cPublic\u201d folder  in any Node.js web app?</p>\n<p>My project structure is similar to this: <a href=\"https://github.com/googlearchive/friendlypix-web\" rel=\"nofollow noreferrer\">https://github.com/googlearchive/friendlypix-web</a></p>\n",
                    "OwnerUserId": "10284549",
                    "LastEditorUserId": "10284549",
                    "LastEditDate": "2022-11-11T16:12:02.013",
                    "LastActivityDate": "2022-11-11T16:12:02.013",
                    "Title": "Bundling files in \"src\" folder into \"public\" folder using webpack",
                    "Tags": "<node.js><typescript><firebase><google-cloud-platform><webpack>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            }
        ],
        "Type": 2
    },
    "https://github.com/cloudera/hue": {
        "CVE Description": [
            "Cloudera Hue 4.6.0 allows XSS."
        ],
        "Edges": [
            {
                "SID": "8441799",
                "StackOverflow_Post": {
                    "Id": "8441799",
                    "PostTypeId": "2",
                    "ParentId": "8441707",
                    "CreationDate": "2011-12-09T06:19:58.797",
                    "Score": "4",
                    "Body": "<p>You may check to see this project: <a href=\"http://www.cloudera.com/blog/2010/07/whats-new-in-cdh3b2-hue/\" rel=\"nofollow\">Hue</a></p>\n\n<p>Code can be downloaded from <a href=\"https://github.com/cloudera/hue\" rel=\"nofollow\">github Hue</a>.</p>\n",
                    "OwnerUserId": "261483",
                    "LastActivityDate": "2011-12-09T06:19:58.797",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            }
        ],
        "Type": 0
    },
    "https://github.com/cortexproject/cortex": {
        "CVE Description": [
            "The Alertmanager in CNCF Cortex before 1.8.1 has a local file disclosure vulnerability when -experimental.alertmanager.enable-api is used. The HTTP basic auth password_file can be used as an attack vector to send any file content via a webhook. The alertmanager templates can be used as an attack vector to send any file content because the alertmanager can load any text file specified in the templates list."
        ],
        "Edges": [
            {
                "SID": "58964433",
                "StackOverflow_Post": {
                    "Id": "58964433",
                    "PostTypeId": "2",
                    "ParentId": "58948167",
                    "CreationDate": "2019-11-20T22:33:37.010",
                    "Score": "6",
                    "Body": "<p>You are asking about hot/warm architecture high availability for Prometheus.</p>\n<p>There are two aspects to your question:</p>\n<ol>\n<li>The storage of data: Prometheus has the ability of using <a href=\"https://prometheus.io/docs/prometheus/latest/storage/\" rel=\"nofollow noreferrer\">remote storage</a> that can be used to provide HA for your data</li>\n<li>The scraping of targets: there is no builtin mechanism to scrape in cluster.</li>\n</ol>\n<ul>\n<li>Either both Prometheus scrape at the same time (but then you have hot/hot)</li>\n<li>or you find a way to detect a Prometheus is down (prometheus scrape each other) and trigger an action (quite easy to do with a webhook) - by example enabling config and triggering the reload</li>\n</ul>\n<p>If HA is really important for you, you'd rather:</p>\n<ul>\n<li>use a hot/hot setup with some proxy like <a href=\"https://github.com/Comcast/trickster\" rel=\"nofollow noreferrer\">Trikster</a> or clustering like <a href=\"https://github.com/thanos-io/thanos\" rel=\"nofollow noreferrer\">Thanos</a></li>\n<li>switch to <a href=\"https://github.com/cortexproject/cortex\" rel=\"nofollow noreferrer\">Cortex</a> which is like a de-structured Prometheus to provide scalability and HA</li>\n</ul>\n<p>If you can afford some small downtime of Prometheus, you can also just let the scheduler re-schedule Prometheus and persist the data (maybe with remote read/write).</p>\n",
                    "OwnerUserId": "3480808",
                    "LastEditorUserId": "3480808",
                    "LastEditDate": "2020-08-20T14:32:17.183",
                    "LastActivityDate": "2020-08-20T14:32:17.183",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "74329564",
                "ParentRepo": "https://github.com/grafana/cortex-tools",
                "StackOverflow_Post": {
                    "Id": "74329564",
                    "PostTypeId": "1",
                    "CreationDate": "2022-11-05T16:37:10.103",
                    "Score": "0",
                    "ViewCount": "50",
                    "Body": "<p>I am trying to configure Recording rule and according to documentation, it is not clear, how to set it up.</p>\n<p>I configured <strong>rules.yml</strong> file in <code>/loki/rules</code> directory. According the doc <a href=\"https://grafana.com/docs/loki/latest/rules/#recording-rules\" rel=\"nofollow noreferrer\">Recording rules</a>, I implement my own rule:</p>\n<pre><code>name: MyRules\ninterval: 1m\nrules:\n  - record: generator:requests:rate2m\n    expr: |\n      sum(\n        rate({service=&quot;generator_generator&quot;}[2m])\n      )\n    labels:\n      cluster: &quot;something&quot;\n</code></pre>\n<p>At first, this does not make anything, no logs in Loki about wrong format, no metrics in Prometheus (remote write). After that, I copy this file also to directory <code>rules-temp</code> and also to the <code>/loki/rules/fake/</code> directory, based on doc <a href=\"https://grafana.com/docs/loki/latest/rules/#ruler-storage\" rel=\"nofollow noreferrer\">Ruler storage</a>. From the doc, I am not sure, where this file should be located so I copied it everywhere. The result was the same - no logs in Loki, nothing in Prometheus.</p>\n<p>After day off, I started Loki and find out log:</p>\n<pre><code>2022-11-03T08:24:24.062210590Z level=error ts=2022-11-03T08:24:24.061854756Z caller=ruler.go:497 msg=&quot;unable to list rules&quot; err=&quot;failed to list rule groups for user fake: failed to list rule group for user fake and namespace rules.yml: error parsing /loki/rules/fake/rules.yml: /loki/rules/fake/rules.yml: yaml: unmarshal errors:\\n  line 1: field name not found in type rulefmt.RuleGroups\\n  line 2: field interval not found in type rulefmt.RuleGroups\\n  line 3: field rules not found in type rulefmt.RuleGroups&quot;\n</code></pre>\n<p>This log was not there before, even when I restart Loki, it is not there, do not understand why. But I assume, Loki cannot parse my rules file. I found out <a href=\"https://github.com/grafana/cortex-tools\" rel=\"nofollow noreferrer\">corterx-tool</a> for validating Loki rules. After few run, I ended up with new <strong>rules.yml</strong> file:</p>\n<pre><code>namespace: rules\ngroups:\n    - name: MyRules\n      interval: 1m\n      rules:\n        - record: generator:requests:rate1m\n          expr: |-\n            sum(rate({service=&quot;generator_generator&quot;}[2m]))\n          labels:\n            cluster: something\n</code></pre>\n<p>It is quiet different from the one in docs, but It looks like its ok:</p>\n<pre><code>$ cortextool rules lint --backend=loki rules.yml\nINFO[0000] SUCCESS: 1 rules found, 0 linted expressions\n</code></pre>\n<p>After this small success I run Loki again but no result in Loki logs or Prometheus. I tried even set wrong prometheus remote write addres but Loki does not log anything about this error.</p>\n<p>My current configuration of Loki ruler:</p>\n<pre><code>ruler:\n  alertmanager_url: http://localhost:9093\n  remote_write:\n    enabled: true\n    client:\n      url: http://prometheus:9090/api/v1/write\n</code></pre>\n<p>Prometheus runs in default configuration.</p>\n<p>Versions:\nLoki: <strong>2.6.1</strong>\nPrometheus: <strong>v2.39.1</strong></p>\n<p><strong>Questions:</strong></p>\n<ol>\n<li>Where should be rule file located and whats the difference between <code>/rules</code>, <code>/rules-temp</code> and <code>/rules/&lt;tenant-id&gt;</code>?</li>\n<li>What is the format of rules and rule files? Can there be multiple files?</li>\n<li>Why the log about rules does not occur in Loki logs (wrong Prometheus url, wrong rules.yml format)?</li>\n<li>How to properly configure rules (both Recording and Alerting) in Loki? Documentation looks very unclear.</li>\n<li>How to debug this configuration and setup? Basically, I do not know where to check, if something is wrong with no logs or any information about it.</li>\n</ol>\n<p>Thanks for any tips.</p>\n",
                    "OwnerUserId": "5686623",
                    "LastActivityDate": "2022-11-05T16:37:10.103",
                    "Title": "How configure Recording and Alerting rules with Loki",
                    "Tags": "<grafana><grafana-loki>",
                    "AnswerCount": "0",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            }
        ],
        "Type": 2
    },
    "https://github.com/salesagility/SuiteCRM": {
        "CVE Description": [
            "XSS in the client account page in SuiteCRM before 7.11.19 allows an attacker to inject JavaScript via the name field",
            "Persistent cross-site scripting (XSS) in the web interface of SuiteCRM before 7.11.19 allows a remote attacker to introduce arbitrary JavaScript via a Content-Type Filter bypass to upload malicious files. This occurs because text/html is blocked, but other types that allow JavaScript execution (such as text/xml) are not blocked.",
            "Persistent cross-site scripting (XSS) in the web interface of SuiteCRM before 7.11.19 allows a remote attacker to introduce arbitrary JavaScript via malicious SVG files. This occurs because the clean_file_output protection mechanism can be bypassed.",
            "SuiteCRM before 7.10.33 and 7.11.22 allows information disclosure via Directory Traversal. An attacker can partially include arbitrary files via the file_name parameter of the Step3 import functionality.",
            "SuiteCRM before 7.10.33 and 7.11.22 allows information disclosure via Directory Traversal. An attacker can partially include arbitrary files via the importFile parameter of the RefreshMapping import functionality.",
            "SuiteCRM through 7.11.21 is vulnerable to CSRF, with resultant remote code execution, via the UpgradeWizard functionality, if a PHP file is included in a ZIP archive.",
            "SuiteCRM 7.10.x before 7.10.33 and 7.11.x before 7.11.22 is vulnerable to privilege escalation."
        ],
        "Edges": [
            {
                "SID": "22865190",
                "StackOverflow_Post": {
                    "Id": "22865190",
                    "PostTypeId": "5",
                    "CreationDate": "2014-04-04T14:11:40.347",
                    "Score": "0",
                    "Body": "<p>SuiteCRM is a CRM application written in PHP and is a fork of the popular SugarCRM Community Edition project. It adds various plugins onto SugarCRM CE including support for Quotes and Products, Reports, Workflow, Events, Teams and Case portal integration.</p>\n\n<h3>Useful links</h3>\n\n<ul>\n<li><a href=\"https://suitecrm.com\" rel=\"nofollow noreferrer\">Official website</a></li>\n<li><a href=\"https://github.com/salesagility/SuiteCRM\" rel=\"nofollow noreferrer\">Github repository</a></li>\n<li><a href=\"https://suitecrm.com/community\" rel=\"nofollow noreferrer\">Community</a></li>\n</ul>\n",
                    "OwnerUserId": "505722",
                    "LastEditorUserId": "3704489",
                    "LastEditDate": "2017-11-24T08:52:43.473",
                    "LastActivityDate": "2017-11-24T08:52:43.473",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            }
        ],
        "Type":0
    },
    "https://github.com/jchristn/WatsonWebserver": {
        "CVE Description": [
            "An Input Validation Vulnerability exists in Joel Christner .NET C# packages WatsonWebserver, IpMatcher 1.0.4.1 and below (IpMatcher) and 4.1.3 and below (WatsonWebserver) due to insufficient validation of input IP addresses and netmasks against the internal Matcher list of IP addresses and subnets."
        ],
        "Edges": [
            {
                "SID": "42681193",
                "StackOverflow_Post": {
                    "Id": "42681193",
                    "PostTypeId": "2",
                    "ParentId": "11167183",
                    "CreationDate": "2017-03-08T20:21:08.897",
                    "Score": "1",
                    "Body": "<p>I know I'm tremendously late to the party on this, but I published a library (source here <a href=\"https://github.com/jchristn/WatsonWebserver\" rel=\"nofollow noreferrer\">https://github.com/jchristn/WatsonWebserver</a>) on NuGet which encapsulates an async webserver.</p>\n",
                    "OwnerUserId": "1026363",
                    "LastActivityDate": "2017-03-08T20:21:08.897",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            }
        ],
        "Type": 0
    },
    "https://github.com/jchristn/IpMatcher": {
        "CVE Description": [
            "An Input Validation Vulnerability exists in Joel Christner .NET C# packages WatsonWebserver, IpMatcher 1.0.4.1 and below (IpMatcher) and 4.1.3 and below (WatsonWebserver) due to insufficient validation of input IP addresses and netmasks against the internal Matcher list of IP addresses and subnets."
        ],
        "Edges": [
            {
                "SID": "49203320",
                "StackOverflow_Post": {
                    "Id": "49203320",
                    "PostTypeId": "2",
                    "ParentId": "1499269",
                    "CreationDate": "2018-03-09T22:47:40.473",
                    "Score": "2",
                    "Body": "<p>I'm late to the party here, but had a similar need, and put together a quick package to do exactly this.</p>\n\n<p><a href=\"https://www.nuget.org/packages/IpMatcher/\" rel=\"nofollow noreferrer\">https://www.nuget.org/packages/IpMatcher/</a></p>\n\n<p>and source:</p>\n\n<p><a href=\"https://github.com/jchristn/IpMatcher\" rel=\"nofollow noreferrer\">https://github.com/jchristn/IpMatcher</a></p>\n\n<p>Simple use:</p>\n\n<pre><code>using IpMatcher;\n\nMatcher matcher = new Matcher();\nmatcher.Add(\"192.168.1.0\", \"255.255.255.0\");\nmatcher.Add(\"192.168.2.0\", \"255.255.255.0\");\nmatcher.Remove(\"192.168.2.0\");\nmatcher.Exists(\"192.168.1.0\", \"255.255.255.0\");  // true\nmatcher.Match(\"192.168.1.34\"); // true\nmatcher.Match(\"10.10.10.10\");  // false\n</code></pre>\n",
                    "OwnerUserId": "1026363",
                    "LastActivityDate": "2018-03-09T22:47:40.473",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            }
        ],
        "Type": 0
    },
    "https://github.com/an-tao/drogon": {
        "CVE Description": [
            "A path traversal vulnerability in the static router for Drogon from 1.0.0-beta14 to 1.6.0 could allow an unauthenticated, remote attacker to arbitrarily read files. The vulnerability is due to lack of proper input validation for requested path. An attacker could exploit this vulnerability by sending crafted HTTP request with specific path to read. Successful exploitation could allow the attacker to read files that should be restricted."
        ],
        "Edges": [
            {
                "SID": "50732285",
                "StackOverflow_Post": {
                    "Id": "50732285",
                    "PostTypeId": "2",
                    "ParentId": "9148667",
                    "CreationDate": "2018-06-07T02:51:12.430",
                    "Score": "1",
                    "Body": "<p>The project drogon on github \uff08<a href=\"https://github.com/an-tao/drogon\" rel=\"nofollow noreferrer\">project Drogon,a c++11 web framework</a>\uff09may be helpful to you. In this framework, you can register your handler method like this:</p>\n\n<pre><code>drogon::HttpAppFramework::registerHttpApiMethod(\"/api/v1/handle/{1}/{2}\",yourMethod...);\n</code></pre>\n\n<p><code>yourMethod</code> maybe any callable object.</p>\n\n<p>The <code>HttpApiController</code> class is a simple wrapper class that allows you to register functions with macros. There are examples in the project that demonstrate the use of these functions.</p>\n\n<p>Hope it helps you..</p>\n",
                    "OwnerUserId": "9906422",
                    "LastEditorUserId": "3841734",
                    "LastEditDate": "2019-07-26T15:18:16.383",
                    "LastActivityDate": "2019-07-26T15:18:16.383",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            }
        ],
        "Type": 0
    },
    "https://github.com/filebrowser/filebrowser": {
        "CVE Description": [
            "A stored cross-site scripting (XSS) vulnerability exists in FileBrowser < v2.16.0 that allows an authenticated user authorized to upload a malicious .svg file which acts as a stored XSS payload. If this stored XSS payload is triggered by an administrator it will trigger malicious OS commands on the server running the FileBrowser instance."
        ],
        "Edges": [
            {
                "SID": "56182210",
                "StackOverflow_Post": {
                    "Id": "56182210",
                    "PostTypeId": "1",
                    "CreationDate": "2019-05-17T08:07:36.010",
                    "Score": "0",
                    "ViewCount": "39",
                    "Body": "<p>GitHub:<a href=\"https://github.com/filebrowser/filebrowser\" rel=\"nofollow noreferrer\">https://github.com/filebrowser/filebrowser</a></p>\n\n<p>When I read the source code of this project, I found that main.go relied on the cmd package. I found that the path in the import statement contains v2, but I have no v2 in the file path after I cloned the project from github? why is this happening?</p>\n\n<pre class=\"lang-golang prettyprint-override\"><code>package main\n\nimport (\n    \"runtime\"\n\n    \"github.com/filebrowser/filebrowser/v2/cmd\"\n)\n\nfunc main() {\n    runtime.GOMAXPROCS(runtime.NumCPU())\n    cmd.Execute()\n}\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/tOic2.png\" rel=\"nofollow noreferrer\">The structure of this project</a></p>\n",
                    "OwnerUserId": "6837851",
                    "LastActivityDate": "2019-08-02T18:21:19.420",
                    "Title": "Why are some packages in the code prefixed with v2, but the file path I cloned has no v2?",
                    "Tags": "<go><go-modules>",
                    "AnswerCount": "1",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            }
        ],
        "Type": 0
    },
    "https://github.com/RaspAP/raspap-webgui": {
        "CVE Description": [
            "includes/configure_client.php in RaspAP 2.6.6 allows attackers to execute commands via command injection.",
            "raspap-webgui in RaspAP 2.6.6 allows attackers to execute commands as root because of the insecure sudoers permissions. The www-data account can execute /etc/raspap/hostapd/enablelog.sh as root with no password; however, the www-data account can also overwrite /etc/raspap/hostapd/enablelog.sh with any executable content."
        ],
        "Edges": [
            {
                "SID": "67546273",
                "StackOverflow_Post": {
                    "Id": "67546273",
                    "PostTypeId": "1",
                    "CreationDate": "2021-05-15T11:33:31.737",
                    "Score": "1",
                    "ViewCount": "179",
                    "Body": "<p>I currently serve audio/video from a raspberry pi using the <a href=\"https://github.com/iizukanao/picam\" rel=\"nofollow noreferrer\">picam project</a> along with <code>nginx</code> to stream it as an HLS (Http Live Streaming) stream (as detailed in the project page). Thus, in <code>/etc/nginx/sites-available/default</code> I add:</p>\n<pre><code>location /hls/ {\n        root /run/shm;\n    }\n</code></pre>\n<p>Then, I can access my stream (for example with VLC player) at <code>http://mypi.local/hls/index.m3u8</code>.</p>\n<p>However, I no longer wish to rely on my internet box to stream. Indeed, I would like my client(s) to directly connect to the pi. Thus, I have recently tried <a href=\"https://github.com/RaspAP/raspap-webgui\" rel=\"nofollow noreferrer\">Raspap</a> to transform my raspberry pi to a hotspot.</p>\n<p>However, as raspap seems to use <code>lighttpd</code> as its webserver, I am wondering how I can still stream my audio/video stream as it is currently done with <code>picam</code> and <code>nginx</code>.</p>\n",
                    "OwnerUserId": "5688175",
                    "LastActivityDate": "2021-05-27T23:17:52.303",
                    "Title": "Serve HLS with raspap/lighttpd rather than nginx",
                    "Tags": "<nginx><lighttpd><hostapd><picamera>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            }
        ],
        "Type": 0
    },
    "https://github.com/openbmc/openbmc": {
        "CVE Description": [
            "In OpenBMC 2.9, crafted IPMI messages allow an attacker to cause a denial of service to the BMC via the netipmid (IPMI lan+) interface.",
            "In OpenBMC 2.9, crafted IPMI messages allow an attacker to bypass authentication and gain full control of the system."
        ],
        "Edges": [
            {
                "SID": "52520725",
                "StackOverflow_Post": {
                    "Id": "52520725",
                    "PostTypeId": "5",
                    "CreationDate": "2018-09-26T14:57:14.670",
                    "Score": "0",
                    "Body": "<p>OpenPOWER is an open system based on IBM OpenPOWER P8/P9 (and future) chips, and it is open from HW design to SW firmware.</p>\n\n<p>There is <a href=\"https://openpowerfoundation.org/\" rel=\"nofollow noreferrer\">OpenPOWER Foundation</a> who is an open technical community based on the POWER architecture, enabling collaborative development and opportunity for member differentiation and industry growth.</p>\n\n<p>And there is <a href=\"https://www-355.ibm.com/systems/power/openpower/\" rel=\"nofollow noreferrer\">OpenPOWER Portal</a> which contains system reference designs, firmware, tool, etc.</p>\n\n<p>Usually, an OpenPOWER system's firmware consists of:</p>\n\n<ul>\n<li>Open sourced BMC: <a href=\"https://github.com/openbmc/openbmc\" rel=\"nofollow noreferrer\">OpenBMC</a></li>\n<li>Open sourced host firmware: <a href=\"https://github.com/open-power/hostboot\" rel=\"nofollow noreferrer\">Hostboot</a>, <a href=\"https://github.com/open-power/skiboot\" rel=\"nofollow noreferrer\">Skiboot</a>, <a href=\"https://github.com/open-power/petitboot\" rel=\"nofollow noreferrer\">Petitboot</a></li>\n</ul>\n\n<p>And usually it runs Ubuntu, CentOS (or RHEL), OpenSUSE (or SLES).</p>\n",
                    "OwnerUserId": "1030870",
                    "LastEditorUserId": "1030870",
                    "LastEditDate": "2018-10-01T04:07:39.693",
                    "LastActivityDate": "2018-10-01T04:07:39.693",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            }
        ],
        "Type": 0
    },
    "https://github.com/beego/beego": {
        "CVE Description": [
            "Cross Site Scripting (XSS) vulnerability exists in the admin panel in Beego v2.0.1 via the URI path in an HTTP request, which is activated by administrators viewing the \"Request Statistics\" page."
        ],
        "Edges": [
            {
                "ParentSID": "35731806",
                "ParentRepo": "https://github.com/dionyself/golang-cms/blob/master/models/form.go",
                "StackOverflow_Post": {
                    "Id": "35731806",
                    "PostTypeId": "1",
                    "CreationDate": "2016-03-01T19:33:11.307",
                    "Score": "0",
                    "ViewCount": "1046",
                    "Body": "<p>I am trying to validate some forms using Beego validation, but it is not working at all: invalid data passes without errors.</p>\n\n<p>This the relevant code, I don't know what is wrong. Can you point me at the mistake?</p>\n\n<p><a href=\"https://github.com/dionyself/golang-cms/blob/master/models/form.go\" rel=\"nofollow\">https://github.com/dionyself/golang-cms/blob/master/models/form.go</a></p>\n\n<pre><code>package models\n\nimport (\n    \"github.com/astaxie/beego\"\n    \"github.com/astaxie/beego/validation\"\n)\n\ntype BaseForm struct {\n    Errors map[string]string\n}\n\nfunc (form *BaseForm) Validate() bool {\n    valid := validation.Validation{}\n    b, err := valid.Valid(form)\n    if err != nil {\n        beego.Error(err)\n    }\n    if !b {\n        for _, err := range valid.Errors {\n            form.Errors[err.Key] = err.Message\n            beego.Debug(err.Key, err.Message)\n        }\n    }\n    return b\n}\n\ntype RegisterForm struct {\n    BaseForm\n    Username   string `form:\"username\" valid:\"Required; AlphaNumeric; MinSize(4); MaxSize(300)\"`\n    Password   string `form:\"password\" valid:\"Required; MinSize(4); MaxSize(30)\"`\n    PasswordRe string `form:\"passwordre\" valid:\"Required; MinSize(4); MaxSize(30)\"`\n}\n\nfunc (form *RegisterForm) Valid(v *validation.Validation) {\n    // Check if passwords of two times are same.\n    if form.Password != form.PasswordRe {\n        v.SetError(\"PasswordRe\", \"Passwords did not match\")\n        return\n    }\n}\n\ntype ArticleForm struct {\n    BaseForm\n    Id            int    `form:\"-\"`\n    Title         string `form:\"title\" valid:\"Required;MinSize(4);MaxSize(300)\"`\n    Category      int    `form:\"category\"`\n    Content       string `form:\"content\" valid:\"Required; MinSize(50); MaxSize(2000)\"`\n    TopicTags     string `form:\"topic-tags\" valid:\"MinSize(4); MaxSize(300)\"`\n    TaggedUsers   string `form:\"tagged-users\" valid:\"MinSize(4); MaxSize(300)\"`\n    AllowReviews  bool   `form:\"allow-reviews\" valid:\"Required\"`\n    AllowComments bool   `form:\"allow-comments\" valid:\"Required\"`\n    Errors        map[string]string\n}\n\nfunc (form *ArticleForm) Valid(v *validation.Validation) {\n    if form.Category &gt;= 0 {\n        v.SetError(\"Category\", \"Invalid category\")\n        return\n    }\n}\n</code></pre>\n\n<p>Some documentation:\n<a href=\"http://beego.me/docs/mvc/controller/validation.md\" rel=\"nofollow\">http://beego.me/docs/mvc/controller/validation.md</a></p>\n\n<p>This is the code that parses the form:</p>\n\n<pre><code>func (this *ArticleController) Post() {\n    form := models.ArticleForm{}\n    Art := new(models.Article)\n    if err := this.ParseForm(&amp;form); err != nil {\n        this.Abort(\"401\")\n    } else {\n        db := this.GetDB()\n        if !form.Validate() {\n            this.Data[\"form\"] = form\n            var cats []*models.Category\n            db.QueryTable(\"category\").All(&amp;cats)\n            this.Data[\"Categories\"] = cats\n            this.ConfigPage(\"article-editor.html\")\n            for key, msg := range form.Errors {\n                fmt.Println(key, msg)\n            }\n        } else {\n            db.Insert(Art)\n            this.Data[\"Article\"] = Art\n            this.ConfigPage(\"article.html\")\n        }\n    }\n}\n</code></pre>\n\n<p>Note: FormData is always accepted (even an empty form), form.Validate() is always returning 'true'... 0 errors on logs. </p>\n",
                    "OwnerUserId": "2127399",
                    "LastEditorUserId": "2127399",
                    "LastEditDate": "2016-03-01T21:04:06.280",
                    "LastActivityDate": "2016-07-28T09:12:57.573",
                    "Title": "Beego validation accepts invalid data",
                    "Tags": "<validation><go><beego>",
                    "AnswerCount": "1",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "38141561",
                "ParentRepo": "https://github.com/beego/bee/blob/master/bee.json",
                "StackOverflow_Post": {
                    "Id": "38141561",
                    "PostTypeId": "2",
                    "ParentId": "36078560",
                    "CreationDate": "2016-07-01T09:14:58.800",
                    "Score": "1",
                    "Body": "<p>You run the application with command <code>bee run</code> and it supports config file like <a href=\"https://github.com/beego/bee/blob/master/bee.json\" rel=\"nofollow\">this</a>.\n<code>bee</code> command watch file change default by file extension. You can see from the source code <a href=\"https://github.com/beego/bee/blob/master/watch.go#L241\" rel=\"nofollow\"><code>\nvar watchExts = []string{\".go\"}</code></a>. It means <code>bee</code> will watch the file with extension <code>.go</code>, so if <code>.go</code> file change it will auto restarting.</p>\n\n<p>If you want <code>bee</code> command to watch the <code>conf/app.conf</code> file, you need to make a file <code>bee.json</code> at your app directory and the content should like this:</p>\n\n<pre><code>{\n    \"version\": 0,\n    \"gopm\": {\n        \"enable\": false,\n        \"install\": false\n    },\n    \"go_install\": false,\n    \"watch_ext\": [.conf],\n    \"dir_structure\": {\n        \"watch_all\": false,\n        \"controllers\": \"\",\n        \"models\": \"\",\n        \"others\": []\n    },\n    \"cmd_args\": [],\n    \"envs\": [],\n    \"database\": {\n        \"driver\": \"mysql\"\n    }\n}\n</code></pre>\n",
                    "OwnerUserId": "1924657",
                    "LastActivityDate": "2016-07-01T09:14:58.800",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "60409703",
                "ParentRepo": "https://github.com/the-benchmarker/web-frameworks",
                "StackOverflow_Post": {
                    "Id": "60409703",
                    "PostTypeId": "2",
                    "ParentId": "3989438",
                    "CreationDate": "2020-02-26T08:33:18.250",
                    "Score": "3",
                    "Body": "<p>This question is still relevant until today. And with rails' features are increasing over the time, I want to add a new answer.</p>\n\n<p>There are so many gems right now, so what you can achieve in Rails, most likely you can achieve it too in Sinatra. If we want to compare between Rails and Sinatra (or any other frameworks), we just need to compare the performance and the ease of use.</p>\n\n<p>One of <a href=\"https://rubyonrails.org/doctrine/\" rel=\"nofollow noreferrer\">Rails doctrine</a> is convention over configuration. When you create a project in Rails, automatically you get many gems included in your <code>Gemfile</code>. Not only gems, when you look at <code>config</code> directory, you'll see many things included. This doctrine is the reason why the magic can happen in the first place. Once you break the convention, you have to modify -or even create- your configuration.</p>\n\n<p>When we want to have more flexibility but still not reinvent the wheel, we can use framework like Sinatra, where only not so many features is enabled when we first create the project. Even so, I've created mini rails from Sinatra: I just adopting rails' way, with libs/gems that I really need. Because I need to develop my own configuration, the development time was longer than using rails.</p>\n\n<p>If you see this <a href=\"https://github.com/the-benchmarker/web-frameworks\" rel=\"nofollow noreferrer\">web frameworks benchmark</a>, you'll see that Rails is so slow while other ruby framework, like Sinatra, can be found much higher than Rails.</p>\n\n<p>So, when the best to use Rails?</p>\n\n<ul>\n<li>You need fast development time. Just follow the convention;</li>\n<li>The future features of your apps are still unknown.</li>\n</ul>\n\n<p>When the best to use Sinatra?</p>\n\n<ul>\n<li>You don't need fast development time;</li>\n<li>Sinatra can be fast if you only work in mini project;</li>\n<li>You know that you won't add many features in the future.</li>\n</ul>\n\n<p>What do you gain from Rails? Development speed.</p>\n\n<p>What do you gain from Sinatra? Flexibility.</p>\n",
                    "OwnerUserId": "10055107",
                    "LastActivityDate": "2020-02-26T08:33:18.250",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "62630337",
                "ParentRepo": "https://github.com/kongyuebin1/dongfeng-pay/tree/master/service",
                "StackOverflow_Post": {
                    "Id": "62630337",
                    "PostTypeId": "1",
                    "CreationDate": "2020-06-29T02:26:53.923",
                    "Score": "-1",
                    "ViewCount": "50",
                    "Body": "<p>There is an <a href=\"https://github.com/kongyuebin1/dongfeng-pay/tree/master/service\" rel=\"nofollow noreferrer\">open-source project</a>:</p>\n<p><a href=\"https://i.stack.imgur.com/psUC6.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/psUC6.png\" alt=\"enter image description here\" /></a></p>\n<p>in the application I do not find the httpport config, when I build and run it, there use the <code>8080</code>. I want to change it.  but how?</p>\n",
                    "OwnerUserId": "7693832",
                    "LastActivityDate": "2020-06-29T03:20:04.253",
                    "Title": "How to set the project httpport in the non-appconf beego project?",
                    "Tags": "<go><beego>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "72414456",
                "ParentRepo": "https://github.com/casdoor/casdoor",
                "StackOverflow_Post": {
                    "Id": "72414456",
                    "PostTypeId": "2",
                    "ParentId": "72412558",
                    "CreationDate": "2022-05-28T09:25:57.133",
                    "Score": "0",
                    "Body": "<p>You might need to use an Oauth2 provider like:</p>\n<ul>\n<li><p><a href=\"https://github.com/dexidp/dex\" rel=\"nofollow noreferrer\"><code>dexidp/dex</code></a>, an identity service that uses OpenID Connect to drive authentication for other apps.<br />\nDex acts as a portal to other identity providers through &quot;<a href=\"https://github.com/dexidp/dex#connectors\" rel=\"nofollow noreferrer\">connectors</a>&quot;, which do support your targets</p>\n</li>\n<li><p>or <a href=\"https://github.com/casdoor/casdoor\" rel=\"nofollow noreferrer\"><code>casdoor</code></a>, an Identity and Access Management (IAM) / Single-Sign-On (SSO) platform with web UI supporting OAuth 2.0, including some of your targets.</p>\n</li>\n</ul>\n<p>Oauth2 is not the only option, as <a href=\"https://smartgit.userecho.com/en/communities/1/topics/368-azure-devops-integration-like-github-bitbucket#comment-3473\" rel=\"nofollow noreferrer\">illustrated by SmartGit</a></p>\n<blockquote>\n<p>After some reflection I realized that I actually haven\u2019t had authentication problems with SmartGit and Azure DevOps for quite a while, so I spent some time experimenting to figure out just how SmartGit is authenticating to my repos in Azure DevOps.</p>\n<p>I ultimately determined that it uses Personal Access Tokens via the Git Credential Manager.<br />\nSo explicit support of PATs by SmartGit probably isn\u2019t a critical feature after all. When you install Git (on Windows at least), you have the option to install the Git Credential Manager as well.<br />\nAs long as you do that you should have smooth sailing.</p>\n</blockquote>\n",
                    "OwnerUserId": "6309",
                    "LastActivityDate": "2022-05-28T09:25:57.133",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            }
        ],
        "Type": 0
    },
    "https://github.com/bolt/core": {
        "CVE Description": [
            "Bolt CMS <= 4.2 is vulnerable to Remote Code Execution. Unsafe theme rendering allows an authenticated attacker to edit theme to inject server-side template injection that leads to remote code execution."
        ],
        "Edges": [
            {
                "ParentSID": "65758979",
                "ParentRepo": "https://github.com/bolt/users",
                "StackOverflow_Post": {
                    "Id": "65758979",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "65769656",
                    "CreationDate": "2021-01-17T09:19:04.527",
                    "Score": "0",
                    "ViewCount": "125",
                    "Body": "<p>I moved to Bolt 4 (from Bolt 3.7) and would like to implement front-end user to give them access to private contents of the website. Previously, I used the extension <a href=\"https://market.bolt.cm/view/boltauth/auth\" rel=\"nofollow noreferrer\">BoltAuth/Auth</a>, which worked like a charm.</p>\n<p>Now in Bolt 4, there is no easy way like in Bolt 3.x to install an extension from the back-end page. I <a href=\"https://docs.bolt.cm/4.0/extensions/introduction\" rel=\"nofollow noreferrer\">found out</a> I could use <code>composer</code> to do so, but I run in the following problem:</p>\n<pre><code>&gt; composer require &quot;boltauth/auth:3.0.1&quot;\n\n[InvalidArgumentException]\nCould not find a matching version of package boltauth/auth. Check the package \nspelling, your version constraint and that the package is available in a stability \nwhich matches your minimum-stability (stable).\n</code></pre>\n<p>Either I do something wrong, or the extension is not compatible with Bolt 4.1.</p>\n<p>Could someone tell me if there is a way to make this extension work? Or alternatives for front-end user management?</p>\n<p>EDIT: I'm now using the <code>bolt/users</code> <a href=\"https://github.com/bolt/users\" rel=\"nofollow noreferrer\">extension</a> as it can be used to add a <code>ROLE_MEMBERS</code> and let users login for the frontend.</p>\n",
                    "OwnerUserId": "6059658",
                    "LastEditorUserId": "6059658",
                    "LastEditDate": "2021-01-31T07:36:06.993",
                    "LastActivityDate": "2021-01-31T07:36:06.993",
                    "Title": "Frontend users with Bolt 4",
                    "Tags": "<frontend><content-management-system><bolt-cms><bolt>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "67837258",
                "ParentRepo": "https://github.com/bobdenotter/conimex/blob/master/src/Import.php",
                "StackOverflow_Post": {
                    "Id": "67837258",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "67856780",
                    "CreationDate": "2021-06-04T12:28:56.427",
                    "Score": "0",
                    "ViewCount": "66",
                    "Body": "<p>Want to add content to <strong>bolt 4 programmatically</strong> however can only really see 1 example for Bolt 3.</p>\n<p>Would like this to run via <strong>cron</strong> in long run however this functionality looks on the backburner for Bolt 4 too but sure I can botch a way to run.</p>\n<p>Within <strong>Bolt 3</strong> the below was suggested:</p>\n<pre><code>$values = file('myfile.csv');\n\n// now create an associative array to use below\n\n$record = $this-&gt;app['storage']-&gt;getEmptyContent($contenttypeslug);\n$record-&gt;setValues($values);\n\n$id = $this-&gt;app['storage']-&gt;saveContent($record);\n</code></pre>\n<p>This however does not seem to work as i'm guessing a lot has changed in this update. I intend to get my data via api and then run similar to above if anyone in the know can suggest how to go about this?</p>\n<p>I have started by looking at using <code>Bolt\\Repository\\ContentRepository;</code> and <code>Bolt\\Controller\\Backend\\ContentEditController</code> by trying to pick apart similar functionality here:</p>\n<p><a href=\"https://github.com/bobdenotter/conimex/blob/master/src/Import.php\" rel=\"nofollow noreferrer\">https://github.com/bobdenotter/conimex/blob/master/src/Import.php</a></p>\n<p>However this seems overly complicated for me to quite pick apart and just want a simpler example maybe with image / image galleries.</p>\n<p>So far I have started with a command line function then can use system cron to run it at desired frequency. The below code is not working for many reasons firstly <code>getFieldToUpdate</code> seems to throw a private function error and can't seem to get passed that.</p>\n<pre><code>public function import(): void\n{\n    $user = $this-&gt;getUser();\n    /** @var Content $content */\n    $slug = 'test-property';\n\n    $contentTypeSlug = 'properties';\n    $contentType = $this-&gt;config-&gt;getContentType($contentTypeSlug);\n    $content = $this-&gt;contentRepository-&gt;findOneBySlug($slug, $contentType);\n\n    if (! $content) {\n        $content = new Content($contentType);\n        $content-&gt;setStatus('published');\n        $content-&gt;setAuthor($user);\n    }\n    $content-&gt;setFieldValue(&quot;bedrooms&quot;, 2);\n    //$field = $this-&gt;contentEditController-&gt;getFieldToUpdate($content, 'bedrooms');\n    //$this-&gt;contentEditController-&gt;updateField($field, $item, null);\n    //$content-&gt;setFieldValue($key, $item);\n    \n    $this-&gt;em-&gt;persist($content);\n    $this-&gt;em-&gt;flush();\n    \n}\n\nprivate function getUser()\n{\n    $user = null;\n\n    // Fall back to the first user we can find. \u200d\n    if (! $user) {\n        $user = $this-&gt;userRepository-&gt;findOneBy([]);\n    }\n\n    return $user;\n}\n</code></pre>\n",
                    "OwnerUserId": "2135854",
                    "LastEditorUserId": "2135854",
                    "LastEditDate": "2021-06-04T15:51:13.093",
                    "LastActivityDate": "2021-06-06T07:34:20.683",
                    "Title": "Bolt 4 Add Records Programmatically via Cron",
                    "Tags": "<bolt-cms>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "67856780",
                "ParentRepo": "https://github.com/bobdenotter/phpnews_2019/blob/master/src/RssFetcherExtension.php#L93-L191",
                "StackOverflow_Post": {
                    "Id": "67856780",
                    "PostTypeId": "2",
                    "ParentId": "67837258",
                    "CreationDate": "2021-06-06T07:34:20.683",
                    "Score": "1",
                    "Body": "<p>There's a working example here:</p>\n<p><a href=\"https://github.com/bobdenotter/phpnews_2019/blob/master/src/RssFetcherExtension.php#L93-L191\" rel=\"nofollow noreferrer\">https://github.com/bobdenotter/phpnews_2019/blob/master/src/RssFetcherExtension.php#L93-L191</a></p>\n",
                    "OwnerUserId": "21285",
                    "LastActivityDate": "2021-06-06T07:34:20.683",
                    "CommentCount": "3",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            }
        ],
        "Type": 0
    },
    "https://github.com/aws/aws-iot-device-sdk-js-v2": {
        "CVE Description": [
            "Connections initialized by the AWS IoT Device SDK v2 for Java (versions prior to 1.3.3), Python (versions prior to 1.5.18), C++ (versions prior to 1.12.7) and Node.js (versions prior to 1.5.1) did not verify server certificate hostname during TLS handshake when overriding Certificate Authorities (CA) in their trust stores on Windows. This issue has been addressed in aws-c-io submodule versions 0.9.13 onward. This issue affects: Amazon Web Services AWS IoT Device SDK v2 for Java versions prior to 1.3.3 on Microsoft Windows. Amazon Web Services AWS IoT Device SDK v2 for Python versions prior to 1.5.18 on Microsoft Windows. Amazon Web Services AWS IoT Device SDK v2 for C++ versions prior to 1.12.7 on Microsoft Windows. Amazon Web Services AWS IoT Device SDK v2 for Node.js versions prior to 1.5.3 on Microsoft Windows.",
            "Connections initialized by the AWS IoT Device SDK v2 for Java (versions prior to 1.4.2), Python (versions prior to 1.6.1), C++ (versions prior to 1.12.7) and Node.js (versions prior to 1.5.3) did not verify server certificate hostname during TLS handshake when overriding Certificate Authorities (CA) in their trust stores on MacOS. This issue has been addressed in aws-c-io submodule versions 0.10.5 onward. This issue affects: Amazon Web Services AWS IoT Device SDK v2 for Java versions prior to 1.4.2 on macOS. Amazon Web Services AWS IoT Device SDK v2 for Python versions prior to 1.6.1 on macOS. Amazon Web Services AWS IoT Device SDK v2 for C++ versions prior to 1.12.7 on macOS. Amazon Web Services AWS IoT Device SDK v2 for Node.js versions prior to 1.5.3 on macOS. Amazon Web Services AWS-C-IO 0.10.4 on macOS.",
            "The AWS IoT Device SDK v2 for Java, Python, C++ and Node.js appends a user supplied Certificate Authority (CA) to the root CAs instead of overriding it on Unix systems. TLS handshakes will thus succeed if the peer can be verified either from the user-supplied CA or the system\u2019s default trust-store. Attackers with access to a host\u2019s trust stores or are able to compromise a certificate authority already in the host's trust store (note: the attacker must also be able to spoof DNS in this case) may be able to use this issue to bypass CA pinning. An attacker could then spoof the MQTT broker, and either drop traffic and/or respond with the attacker's data, but they would not be able to forward this data on to the MQTT broker because the attacker would still need the user's private keys to authenticate against the MQTT broker. The 'aws_tls_ctx_options_override_default_trust_store_*' function within the aws-c-io submodule has been updated to override the default trust store. This corrects this issue. This issue affects: Amazon Web Services AWS IoT Device SDK v2 for Java versions prior to 1.5.0 on Linux/Unix. Amazon Web Services AWS IoT Device SDK v2 for Python versions prior to 1.6.1 on Linux/Unix. Amazon Web Services AWS IoT Device SDK v2 for C++ versions prior to 1.12.7 on Linux/Unix. Amazon Web Services AWS IoT Device SDK v2 for Node.js versions prior to 1.5.3 on Linux/Unix. Amazon Web Services AWS-C-IO 0.10.4 on Linux/Unix.",
            "The AWS IoT Device SDK v2 for Java, Python, C++ and Node.js appends a user supplied Certificate Authority (CA) to the root CAs instead of overriding it on macOS systems. Additionally, SNI validation is also not enabled when the CA has been \u201coverridden\u201d. TLS handshakes will thus succeed if the peer can be verified either from the user-supplied CA or the system\u2019s default trust-store. Attackers with access to a host\u2019s trust stores or are able to compromise a certificate authority already in the host's trust store (note: the attacker must also be able to spoof DNS in this case) may be able to use this issue to bypass CA pinning. An attacker could then spoof the MQTT broker, and either drop traffic and/or respond with the attacker's data, but they would not be able to forward this data on to the MQTT broker because the attacker would still need the user's private keys to authenticate against the MQTT broker. The 'aws_tls_ctx_options_override_default_trust_store_*' function within the aws-c-io submodule has been updated to address this behavior. This issue affects: Amazon Web Services AWS IoT Device SDK v2 for Java versions prior to 1.5.0 on macOS. Amazon Web Services AWS IoT Device SDK v2 for Python versions prior to 1.7.0 on macOS. Amazon Web Services AWS IoT Device SDK v2 for C++ versions prior to 1.14.0 on macOS. Amazon Web Services AWS IoT Device SDK v2 for Node.js versions prior to 1.6.0 on macOS. Amazon Web Services AWS-C-IO 0.10.7 on macOS."
        ],
        "Edges": [
            {
                "SID": "66437166",
                "StackOverflow_Post": {
                    "Id": "66437166",
                    "PostTypeId": "1",
                    "CreationDate": "2021-03-02T10:01:13.230",
                    "Score": "0",
                    "ViewCount": "703",
                    "Body": "<p>I am using MQTT node module (<a href=\"https://www.npmjs.com/package/mqtt\" rel=\"nofollow noreferrer\">https://www.npmjs.com/package/mqtt</a>), with mqtts type of connection with key, certificate and CA. The connection happens and the connected event is triggered. However, always while subscribing to a topic the connection closes.</p>\n<p>Code for connection:</p>\n<pre><code>const mqtt = require(&quot;mqtt&quot;);  //also tried async version and same problem\n\nthis._client = mqtt.connect(\n  'mqtts://' + this._iotUrl,\n   {\n    cert: fs.readFileSync(this._certPath),\n    ca: fs.readFileSync(this._caPath),\n    key: fs.readFileSync(this._keyPath),\n    region: 'eu-west-1',\n    clientId: clientId,\n    clean: true,\n    rejectUnauthorized: true,\n    resubscribe: true\n  });\n</code></pre>\n<p>Code for subscription:</p>\n<pre><code>this._client.on('connect', () =&gt; {\n    console.log(&quot;client connected!! %s&quot;, clientId);\n    this._client.subscribe('&quot;test/topic&quot;', { qos: 1 }, (err, granted) =&gt; {\n        if (err) {\n            console.error(&quot;topic subscription: granted &quot;, granted, err,);\n         } else {\n             console.log(&quot;granted: &quot;, granted);\n          }\n      });\n });\n</code></pre>\n<p>Result of execution:</p>\n<pre><code>======== Starting MQTT Client ==========\n\nclient connection request\nstarting run function \nclient connected!! mqttjs_bw5yymezc\ntopic subscription: granted  [ { topic: '&quot;test/topic&quot;', qos: 1 } ] Error: Connection closed\n    at /Users/&lt;user&gt;/&lt;project&gt;/src/shared/node_modules/mqtt/lib/client.js:124:29\n    at Array.forEach (&lt;anonymous&gt;)\n    at flushVolatile (/Users/&lt;user&gt;&lt;project&gt;/src/shared/node_modules/mqtt/lib/client.js:122:24)\n    at TLSSocket.&lt;anonymous&gt; (/Users/&lt;user&gt;/&lt;project&gt;/src/shared/node_modules/mqtt/lib/client.js:358:5)\n    at TLSSocket.emit (events.js:327:22)\n    at TLSSocket.EventEmitter.emit (domain.js:467:12)\n    at net.js:673:12\n    at TCP.done (_tls_wrap.js:563:7)\nclient connected!! mqttjs_bw5yymezc\ngranted:  []\n</code></pre>\n<p>According to my options defined in mqtt connection, it continues trying to connect again, and the same happens every time. There is no helpful message or feedback in the error to try to pinpoint the issue. Also tried to use mqtt debug and see exactly the same.</p>\n<p><strong>EXTRA INFORMATION</strong></p>\n<p>To be able to subscribe to the topics using the certificate, a policy was set up and attached to the certificate.\nThis &quot;should be&quot; correct because last week until Friday I was able to connect/subscribe/publish without problems.</p>\n<p>To try to identify the issue, I even try many things with the policy. The policy current state:</p>\n<pre><code>{\n    Version: '2012-10-17',\n    Statement: [\n        {\n            Effect: 'Allow',\n            Action: [&quot;iot:Connect&quot;],\n            Resource: [\n                &quot;arn:aws:iot:eu-west-1:&lt;AWS_client&gt;:client/mqttjs_*&quot;,\n            ]\n\n        },\n        {\n            Effect: 'Allow',\n            Action: [&quot;iot:Subscribe&quot;],\n            Resource: [\n                &quot;arn:aws:iot:eu-west-1:&lt;AWS_client&gt;:topicfilter/application/topic/#/test&quot;,\n                //&quot;arn:aws:iot:eu-west-1:&lt;AWS_client&gt;:topic/test/topic&quot;,\n            ]\n\n        },\n        {\n            Effect: 'Allow',\n            Action: [&quot;iot:Publish&quot;],\n            Resource: [\n                &quot;arn:aws:iot:eu-west-1:&lt;AWS_client&gt;:topic/test/topic&quot;,\n            ]\n\n        },\n    ],\n}\n</code></pre>\n<p>Additionally, I even tried using aws-iot-device-sdk-js-v2 (<a href=\"https://github.com/aws/aws-iot-device-sdk-js-v2\" rel=\"nofollow noreferrer\">https://github.com/aws/aws-iot-device-sdk-js-v2</a>), a module that already facilitates all the MQTT functionality. I tested the pub/sub sample, just passing url, key, certificate and ca path (same used in the code above))in the command line (example bellow). I could connect and see the subscribe and publish last week. Now the connection also drops.</p>\n<p>Executing aws-iot-device-sdk-js-v2 with pub/sub sample:</p>\n<pre><code>node dist/index.js --endpoint &lt;aws_iot_endpoint&gt; --ca_file &quot;&lt;path&gt;/cert/AmazonRootCA1-dev.pem&quot; --cert &quot;&lt;path&gt;/cert/certificate_generated.pem.crt&quot; --key &quot;/&lt;path&gt;/cert/private_generated.pem.key&quot;\n</code></pre>\n<p>What can be causing this connection issue?\nSomeone experienced a similar issue?</p>\n",
                    "OwnerUserId": "3223806",
                    "LastEditorUserId": "504554",
                    "LastEditDate": "2021-03-02T10:43:50.167",
                    "LastActivityDate": "2021-03-02T10:43:50.167",
                    "Title": "nodejs - MQTT connection always drops while subscribing to a topic",
                    "Tags": "<node.js><mqtt><aws-iot><subscribe>",
                    "AnswerCount": "0",
                    "CommentCount": "4",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "66437166",
                "ParentRepo": "https://github.com/aws/aws-iot-device-sdk-js-v2",
                "StackOverflow_Post": {
                    "Id": "66437166",
                    "PostTypeId": "1",
                    "CreationDate": "2021-03-02T10:01:13.230",
                    "Score": "0",
                    "ViewCount": "703",
                    "Body": "<p>I am using MQTT node module (<a href=\"https://www.npmjs.com/package/mqtt\" rel=\"nofollow noreferrer\">https://www.npmjs.com/package/mqtt</a>), with mqtts type of connection with key, certificate and CA. The connection happens and the connected event is triggered. However, always while subscribing to a topic the connection closes.</p>\n<p>Code for connection:</p>\n<pre><code>const mqtt = require(&quot;mqtt&quot;);  //also tried async version and same problem\n\nthis._client = mqtt.connect(\n  'mqtts://' + this._iotUrl,\n   {\n    cert: fs.readFileSync(this._certPath),\n    ca: fs.readFileSync(this._caPath),\n    key: fs.readFileSync(this._keyPath),\n    region: 'eu-west-1',\n    clientId: clientId,\n    clean: true,\n    rejectUnauthorized: true,\n    resubscribe: true\n  });\n</code></pre>\n<p>Code for subscription:</p>\n<pre><code>this._client.on('connect', () =&gt; {\n    console.log(&quot;client connected!! %s&quot;, clientId);\n    this._client.subscribe('&quot;test/topic&quot;', { qos: 1 }, (err, granted) =&gt; {\n        if (err) {\n            console.error(&quot;topic subscription: granted &quot;, granted, err,);\n         } else {\n             console.log(&quot;granted: &quot;, granted);\n          }\n      });\n });\n</code></pre>\n<p>Result of execution:</p>\n<pre><code>======== Starting MQTT Client ==========\n\nclient connection request\nstarting run function \nclient connected!! mqttjs_bw5yymezc\ntopic subscription: granted  [ { topic: '&quot;test/topic&quot;', qos: 1 } ] Error: Connection closed\n    at /Users/&lt;user&gt;/&lt;project&gt;/src/shared/node_modules/mqtt/lib/client.js:124:29\n    at Array.forEach (&lt;anonymous&gt;)\n    at flushVolatile (/Users/&lt;user&gt;&lt;project&gt;/src/shared/node_modules/mqtt/lib/client.js:122:24)\n    at TLSSocket.&lt;anonymous&gt; (/Users/&lt;user&gt;/&lt;project&gt;/src/shared/node_modules/mqtt/lib/client.js:358:5)\n    at TLSSocket.emit (events.js:327:22)\n    at TLSSocket.EventEmitter.emit (domain.js:467:12)\n    at net.js:673:12\n    at TCP.done (_tls_wrap.js:563:7)\nclient connected!! mqttjs_bw5yymezc\ngranted:  []\n</code></pre>\n<p>According to my options defined in mqtt connection, it continues trying to connect again, and the same happens every time. There is no helpful message or feedback in the error to try to pinpoint the issue. Also tried to use mqtt debug and see exactly the same.</p>\n<p><strong>EXTRA INFORMATION</strong></p>\n<p>To be able to subscribe to the topics using the certificate, a policy was set up and attached to the certificate.\nThis &quot;should be&quot; correct because last week until Friday I was able to connect/subscribe/publish without problems.</p>\n<p>To try to identify the issue, I even try many things with the policy. The policy current state:</p>\n<pre><code>{\n    Version: '2012-10-17',\n    Statement: [\n        {\n            Effect: 'Allow',\n            Action: [&quot;iot:Connect&quot;],\n            Resource: [\n                &quot;arn:aws:iot:eu-west-1:&lt;AWS_client&gt;:client/mqttjs_*&quot;,\n            ]\n\n        },\n        {\n            Effect: 'Allow',\n            Action: [&quot;iot:Subscribe&quot;],\n            Resource: [\n                &quot;arn:aws:iot:eu-west-1:&lt;AWS_client&gt;:topicfilter/application/topic/#/test&quot;,\n                //&quot;arn:aws:iot:eu-west-1:&lt;AWS_client&gt;:topic/test/topic&quot;,\n            ]\n\n        },\n        {\n            Effect: 'Allow',\n            Action: [&quot;iot:Publish&quot;],\n            Resource: [\n                &quot;arn:aws:iot:eu-west-1:&lt;AWS_client&gt;:topic/test/topic&quot;,\n            ]\n\n        },\n    ],\n}\n</code></pre>\n<p>Additionally, I even tried using aws-iot-device-sdk-js-v2 (<a href=\"https://github.com/aws/aws-iot-device-sdk-js-v2\" rel=\"nofollow noreferrer\">https://github.com/aws/aws-iot-device-sdk-js-v2</a>), a module that already facilitates all the MQTT functionality. I tested the pub/sub sample, just passing url, key, certificate and ca path (same used in the code above))in the command line (example bellow). I could connect and see the subscribe and publish last week. Now the connection also drops.</p>\n<p>Executing aws-iot-device-sdk-js-v2 with pub/sub sample:</p>\n<pre><code>node dist/index.js --endpoint &lt;aws_iot_endpoint&gt; --ca_file &quot;&lt;path&gt;/cert/AmazonRootCA1-dev.pem&quot; --cert &quot;&lt;path&gt;/cert/certificate_generated.pem.crt&quot; --key &quot;/&lt;path&gt;/cert/private_generated.pem.key&quot;\n</code></pre>\n<p>What can be causing this connection issue?\nSomeone experienced a similar issue?</p>\n",
                    "OwnerUserId": "3223806",
                    "LastEditorUserId": "504554",
                    "LastEditDate": "2021-03-02T10:43:50.167",
                    "LastActivityDate": "2021-03-02T10:43:50.167",
                    "Title": "nodejs - MQTT connection always drops while subscribing to a topic",
                    "Tags": "<node.js><mqtt><aws-iot><subscribe>",
                    "AnswerCount": "0",
                    "CommentCount": "4",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "67401265",
                "ParentRepo": "https://github.com/zhex900/mir-kiosk-electron/blob/master/electron-kiosk/webpack.main.config.js",
                "StackOverflow_Post": {
                    "Id": "67401265",
                    "PostTypeId": "1",
                    "CreationDate": "2021-05-05T12:26:22.683",
                    "Score": "3",
                    "ViewCount": "511",
                    "Body": "<p>I am trying to run the packaged electron app on my local Mac. But get an error message saying <code>Error: Cannot find module ...</code> I think the <code>node_module</code> is not installed.</p>\n<p>I used <code>electron-forge package</code> to build the package.</p>\n<p>Is there something wrong with my webpack config?</p>\n<p><a href=\"https://github.com/zhex900/mir-kiosk-electron/blob/master/electron-kiosk/webpack.main.config.js\" rel=\"nofollow noreferrer\">https://github.com/zhex900/mir-kiosk-electron/blob/master/electron-kiosk/webpack.main.config.js</a></p>\n<pre><code>#package.json\n\n  &quot;dependencies&quot;: {\n    &quot;@aws-sdk/client-iot&quot;: &quot;^3.14.0&quot;,\n    &quot;@aws-sdk/client-s3&quot;: &quot;^3.14.0&quot;,\n    &quot;@aws-sdk/s3-request-presigner&quot;: &quot;^3.14.0&quot;,\n    &quot;aws-iot-device-sdk-v2&quot;: &quot;^1.4.5&quot;,\n    &quot;babel-runtime&quot;: &quot;^6.26.0&quot;,\n    &quot;electron-squirrel-startup&quot;: &quot;^1.0.0&quot;,\n    &quot;macaddress&quot;: &quot;^0.5.2&quot;,\n    &quot;react&quot;: &quot;^17.0.2&quot;,\n    &quot;react-dom&quot;: &quot;^17.0.2&quot;\n  }\n</code></pre>\n<p><a href=\"https://i.stack.imgur.com/CvfkQ.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/CvfkQ.png\" alt=\"enter image description here\" /></a></p>\n",
                    "OwnerUserId": "2564566",
                    "LastActivityDate": "2021-05-10T08:51:36.967",
                    "Title": "electron-forge package Error: Cannot find module",
                    "Tags": "<node.js><electron><electron-packager><electron-forge>",
                    "AnswerCount": "0",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            }
        ],
        "Type":2
    },
    "https://github.com/aws/aws-iot-device-sdk-python-v2": {
        "CVE Description": [
            "Connections initialized by the AWS IoT Device SDK v2 for Java (versions prior to 1.3.3), Python (versions prior to 1.5.18), C++ (versions prior to 1.12.7) and Node.js (versions prior to 1.5.1) did not verify server certificate hostname during TLS handshake when overriding Certificate Authorities (CA) in their trust stores on Windows. This issue has been addressed in aws-c-io submodule versions 0.9.13 onward. This issue affects: Amazon Web Services AWS IoT Device SDK v2 for Java versions prior to 1.3.3 on Microsoft Windows. Amazon Web Services AWS IoT Device SDK v2 for Python versions prior to 1.5.18 on Microsoft Windows. Amazon Web Services AWS IoT Device SDK v2 for C++ versions prior to 1.12.7 on Microsoft Windows. Amazon Web Services AWS IoT Device SDK v2 for Node.js versions prior to 1.5.3 on Microsoft Windows.",
            "Connections initialized by the AWS IoT Device SDK v2 for Java (versions prior to 1.4.2), Python (versions prior to 1.6.1), C++ (versions prior to 1.12.7) and Node.js (versions prior to 1.5.3) did not verify server certificate hostname during TLS handshake when overriding Certificate Authorities (CA) in their trust stores on MacOS. This issue has been addressed in aws-c-io submodule versions 0.10.5 onward. This issue affects: Amazon Web Services AWS IoT Device SDK v2 for Java versions prior to 1.4.2 on macOS. Amazon Web Services AWS IoT Device SDK v2 for Python versions prior to 1.6.1 on macOS. Amazon Web Services AWS IoT Device SDK v2 for C++ versions prior to 1.12.7 on macOS. Amazon Web Services AWS IoT Device SDK v2 for Node.js versions prior to 1.5.3 on macOS. Amazon Web Services AWS-C-IO 0.10.4 on macOS.",
            "The AWS IoT Device SDK v2 for Java, Python, C++ and Node.js appends a user supplied Certificate Authority (CA) to the root CAs instead of overriding it on Unix systems. TLS handshakes will thus succeed if the peer can be verified either from the user-supplied CA or the system\u2019s default trust-store. Attackers with access to a host\u2019s trust stores or are able to compromise a certificate authority already in the host's trust store (note: the attacker must also be able to spoof DNS in this case) may be able to use this issue to bypass CA pinning. An attacker could then spoof the MQTT broker, and either drop traffic and/or respond with the attacker's data, but they would not be able to forward this data on to the MQTT broker because the attacker would still need the user's private keys to authenticate against the MQTT broker. The 'aws_tls_ctx_options_override_default_trust_store_*' function within the aws-c-io submodule has been updated to override the default trust store. This corrects this issue. This issue affects: Amazon Web Services AWS IoT Device SDK v2 for Java versions prior to 1.5.0 on Linux/Unix. Amazon Web Services AWS IoT Device SDK v2 for Python versions prior to 1.6.1 on Linux/Unix. Amazon Web Services AWS IoT Device SDK v2 for C++ versions prior to 1.12.7 on Linux/Unix. Amazon Web Services AWS IoT Device SDK v2 for Node.js versions prior to 1.5.3 on Linux/Unix. Amazon Web Services AWS-C-IO 0.10.4 on Linux/Unix.",
            "The AWS IoT Device SDK v2 for Java, Python, C++ and Node.js appends a user supplied Certificate Authority (CA) to the root CAs instead of overriding it on macOS systems. Additionally, SNI validation is also not enabled when the CA has been \u201coverridden\u201d. TLS handshakes will thus succeed if the peer can be verified either from the user-supplied CA or the system\u2019s default trust-store. Attackers with access to a host\u2019s trust stores or are able to compromise a certificate authority already in the host's trust store (note: the attacker must also be able to spoof DNS in this case) may be able to use this issue to bypass CA pinning. An attacker could then spoof the MQTT broker, and either drop traffic and/or respond with the attacker's data, but they would not be able to forward this data on to the MQTT broker because the attacker would still need the user's private keys to authenticate against the MQTT broker. The 'aws_tls_ctx_options_override_default_trust_store_*' function within the aws-c-io submodule has been updated to address this behavior. This issue affects: Amazon Web Services AWS IoT Device SDK v2 for Java versions prior to 1.5.0 on macOS. Amazon Web Services AWS IoT Device SDK v2 for Python versions prior to 1.7.0 on macOS. Amazon Web Services AWS IoT Device SDK v2 for C++ versions prior to 1.14.0 on macOS. Amazon Web Services AWS IoT Device SDK v2 for Node.js versions prior to 1.6.0 on macOS. Amazon Web Services AWS-C-IO 0.10.7 on macOS."
        ],
        "Edges": [
            {
                "SID": "62116033",
                "StackOverflow_Post": {
                    "Id": "62116033",
                    "PostTypeId": "1",
                    "CreationDate": "2020-05-31T12:12:17.660",
                    "Score": "1",
                    "ViewCount": "382",
                    "Body": "<p>While experimenting with AWS IOT MQTT with Persistent Session I found that Broker returns 'session_present = True' in reply to connection request having 'clean_session = False'.\nWhich is expected as I reconnected within 60 mins as specified by AWS Documentation ( practically it was less than 5 mins )</p>\n\n<p>I am using <a href=\"https://github.com/aws/aws-iot-device-sdk-python-v2\" rel=\"nofollow noreferrer\">aws-iot-device-sdk-python-v2</a></p>\n\n<p>Issue :\n      As per the theory , if 'session_present = True' then the broker stores ass previous session's info hence no need to subscribe to topics again.\nBut if I skip the step of subscribing to the topic then no messages received.\nIs it the obvious behavior ? do I need to unsubscribe even though 'session_present = True' ?</p>\n",
                    "OwnerUserId": "11049988",
                    "LastActivityDate": "2022-01-28T06:29:14.730",
                    "Title": "AWS IOT MQTT with Persistent Session- subscribe failed",
                    "Tags": "<amazon-web-services><aws-iot>",
                    "AnswerCount": "1",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "65591581",
                "ParentRepo": "https://github.com/aws-samples/aws-iot-cqrs-example/blob/master/lib/querycommandcontainers.ts",
                "StackOverflow_Post": {
                    "Id": "65591581",
                    "PostTypeId": "2",
                    "ParentId": "60347716",
                    "CreationDate": "2021-01-06T07:10:26.730",
                    "Score": "7",
                    "Body": "<p>You can ref AWS sample code:\n<a href=\"https://github.com/aws-samples/aws-iot-cqrs-example/blob/master/lib/querycommandcontainers.ts\" rel=\"noreferrer\">https://github.com/aws-samples/aws-iot-cqrs-example/blob/master/lib/querycommandcontainers.ts</a></p>\n<pre><code>const getIoTEndpoint = new customResource.AwsCustomResource(this, 'IoTEndpoint', {\n            onCreate: {\n              service: 'Iot',\n              action: 'describeEndpoint',\n              physicalResourceId: customResource.PhysicalResourceId.fromResponse('endpointAddress'),\n              parameters: {\n                &quot;endpointType&quot;: &quot;iot:Data-ATS&quot;\n              }\n            },\n            policy: customResource.AwsCustomResourcePolicy.fromSdkCalls({resources: customResource.AwsCustomResourcePolicy.ANY_RESOURCE})\n          });\n\nconst IOT_ENDPOINT = getIoTEndpoint.getResponseField('endpointAddress')\n</code></pre>\n",
                    "OwnerUserId": "14949959",
                    "LastActivityDate": "2021-01-06T07:10:26.730",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "72299009",
                "ParentRepo": "https://github.com/aws-samples/amazon-lookout-for-vision/blob/main/Amazon%20Lookout%20for%20Vision%20Lab.ipynb",
                "StackOverflow_Post": {
                    "Id": "72299009",
                    "PostTypeId": "2",
                    "ParentId": "71881585",
                    "CreationDate": "2022-05-19T05:22:56.620",
                    "Score": "0",
                    "Body": "<p>Before using the <code>lookoutvision.detect_anomalies</code> api need to start the model using\n<code>start_model()</code> api.</p>\n<p>Also use <code>stop_model()</code> to stop the model after anomaly is detected beacuse running the model when is not used will increase the cost.</p>\n<p>Refer <a href=\"https://github.com/aws-samples/amazon-lookout-for-vision/blob/main/Amazon%20Lookout%20for%20Vision%20Lab.ipynb\" rel=\"nofollow noreferrer\">https://github.com/aws-samples/amazon-lookout-for-vision/blob/main/Amazon%20Lookout%20for%20Vision%20Lab.ipynb</a> for code sample</p>\n",
                    "OwnerUserId": "18553059",
                    "LastEditorUserId": "18553059",
                    "LastEditDate": "2022-05-19T09:22:14.933",
                    "LastActivityDate": "2022-05-19T09:22:14.933",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "74300573",
                "ParentRepo": "https://github.com/awslabs/aws-greengrass-labs-component-for-home-assistant/blob/main/tests/test_artifacts_secret.py",
                "StackOverflow_Post": {
                    "Id": "74300573",
                    "PostTypeId": "1",
                    "CreationDate": "2022-11-03T09:15:48.880",
                    "Score": "0",
                    "ViewCount": "15",
                    "Body": "<p>I want to mock ipc client to write some test cases in python but was to do so. Didn't find any leads on web too.<br />\nCheked out this link too: <a href=\"https://github.com/awslabs/aws-greengrass-labs-component-for-home-assistant/blob/main/tests/test_artifacts_secret.py\" rel=\"nofollow noreferrer\">https://github.com/awslabs/aws-greengrass-labs-component-for-home-assistant/blob/main/tests/test_artifacts_secret.py</a>\nBut I wasn't able to mock the IPC as its using some mocker as an argument and I wasn't able to find that mocker. Any Ideas?</p>\n",
                    "OwnerUserId": "19006871",
                    "LastActivityDate": "2022-11-03T09:15:48.880",
                    "Title": "Mocking the Greengrass IPC client",
                    "Tags": "<unit-testing><mocking><greengrass><aws-iot-greengrass>",
                    "AnswerCount": "0",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            }
        ],
        "Type": 2
    },
    "https://github.com/ladybirdweb/faveo-helpdesk": {
        "CVE Description": [
            "Cross-site scripting (XSS) vulnerability in dompdf/dompdf/www/demo.php infaveo-helpdesk v1.11.0 and below allow remote attackers to inject arbitrary web script or HTML via the $_SERVER[\"PHP_SELF\"] parameter."
        ],
        "Edges": [
            {
                "SID": "50522338",
                "StackOverflow_Post": {
                    "Id": "50522338",
                    "PostTypeId": "1",
                    "CreationDate": "2018-05-25T05:50:21.473",
                    "Score": "0",
                    "ViewCount": "47",
                    "Body": "<p>So I've been working on this open source application called <a href=\"https://github.com/ladybirdweb/faveo-helpdesk\" rel=\"nofollow noreferrer\">Faveo Helpdesk</a>, which is built in Laravel. It has installer which checks server environment for requirements of Laravel and other required PHP extensions. It also has a check to verify permission for storage and bootstrap directories as they should be writable by web server according to <a href=\"https://laravel.com/docs/5.6/installation#server-requirements\" rel=\"nofollow noreferrer\">Laravel Requirements</a>.</p>\n\n<p>The problem is the installer itself runs on Laravel and uses Laravel routes to show installation steps. And if the permissions are not correct on server it will not run and show installation steps as Laravel will not run in that case.</p>\n\n<p>As many users face the same issue with the application and each time we need to guide/help them for checking and updating the permissions manually. I want to catch the exception and handle it by redirecting user to a normal php file where I'll show them the message to correct their file permission. Currently it simply shows browser error page giving no idea about the problem to users.</p>\n\n<p>Is there a better way to handle this?</p>\n",
                    "OwnerUserId": "5663251",
                    "LastActivityDate": "2018-05-25T05:57:03.277",
                    "Title": "How to notify user that they can't run/install Laravel application because of file permission of storage/bootstrap directory?",
                    "Tags": "<php><laravel><permissions><requirements>",
                    "AnswerCount": "0",
                    "CommentCount": "5",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            }
        ],
        "Type": 0
    },
    "https://github.com/JamesHeinrich/getID3": {
        "CVE Description": [
            "Cross-site scripting (XSS) vulnerability in demos/demo.mysqli.php in getID3 1.X and v2.0.0-beta allows remote attackers to inject arbitrary web script or HTML via the showtagfiles parameter."
        ],
        "Edges": [
            {
                "SID": "16431103",
                "StackOverflow_Post": {
                    "Id": "16431103",
                    "PostTypeId": "2",
                    "ParentId": "16431015",
                    "CreationDate": "2013-05-08T01:14:10.070",
                    "Score": "1",
                    "Body": "<p>The ID3 package is long abandoned and no longer shipped with <strong>PHP 7 and up</strong>.<br />\nCheck out <a href=\"https://github.com/JamesHeinrich/getID3\" rel=\"nofollow noreferrer\">getID3</a> for an alternative.</p>\n<hr />\n<p><strong>PHP 5:</strong></p>\n<p>Easiest way would probably be <a href=\"http://www.php.net/manual/en/function.id3-get-tag.php\" rel=\"nofollow noreferrer\"><code>id3_get_tag($filename, $version)</code></a>.</p>\n<p>Just provide a string containing the file path and optionally a ID3 Tag version (leave out if you don't know):</p>\n<pre><code>$files = array('/folder/file1.mp3', '/folder/file2.mp3');\n$tags = array();\nforeach($files as $file) {\n    $tags[$file] = id3_get_tag($file);\n    // convert genre:\n    if(array_key_exists('genre', $tags[$file]) &amp;&amp; is_integer($tags[$file]['genre'])\n       &amp;&amp; $tags[$file]['genre'] &gt;= 0 &amp;&amp; $tags[$file]['genre'] &lt;= 147) {\n        $tags[$file]['genre'] = id3_get_genre_name($tags[$file]['genre']);\n    }\n}\n</code></pre>\n<p><code>$tags</code> will then be an array like this:</p>\n<pre><code>['/folder/file1.mp3'] = array('interpret' =&gt; 'John Doe', 'title' =&gt; 'PHP is cool', 'genre' =&gt; 'Techno')\n['/folder/file2.mp3'] = array('interpret' =&gt; 'Jane Doe', 'title' =&gt; 'ASP is low', 'genre' =&gt; 'House')\n</code></pre>\n<p>What keys you actually get from this, depends on the ID3 version of each .mp3 file and the actual content (whatever someone wrote into that file).</p>\n",
                    "OwnerUserId": "1693208",
                    "LastEditorUserId": "1693208",
                    "LastEditDate": "2022-07-19T00:16:03.047",
                    "LastActivityDate": "2022-07-19T00:16:03.047",
                    "CommentCount": "5",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "37010530",
                "ParentRepo": "https://github.com/infinity-next/infinity-next/blob/master/app/Http/Controllers/Content/ImageController.php#L250-L450",
                "StackOverflow_Post": {
                    "Id": "37010530",
                    "PostTypeId": "2",
                    "ParentId": "36778167",
                    "CreationDate": "2016-05-03T17:23:24.560",
                    "Score": "6",
                    "Body": "<p><code>X-Send-File</code>.</p>\n\n<p><code>X-Send-File</code> is an internal directive that has variants for Apache, nginx, and lighthttpd. It allows you to <em>completely skip</em> distributing a file through PHP and is an instruction that tells the webserver what to send as a response instead of the actual response from the FastCGI.</p>\n\n<p>I've dealt with this before on a personal project and if you want to see the sum of my work, you can access it here:<br>\n<a href=\"https://github.com/infinity-next/infinity-next/blob/master/app/Http/Controllers/Content/ImageController.php#L250-L450\" rel=\"noreferrer\">https://github.com/infinity-next/infinity-next/blob/master/app/Http/Controllers/Content/ImageController.php#L250-L450</a></p>\n\n<p>This deals not only with distributing files, but handling streaming media seeking. You are free to use that code.</p>\n\n<p>Here is the official nginx documentation on <code>X-Send-File</code>.<br>\n<a href=\"https://www.nginx.com/resources/wiki/start/topics/examples/xsendfile/\" rel=\"noreferrer\">https://www.nginx.com/resources/wiki/start/topics/examples/xsendfile/</a></p>\n\n<p>You <strong>do</strong> have to edit your webserver and mark specific directories as internal for nginx to comply with <code>X-Send-File</code> directives.</p>\n\n<p>I have example configuration for both Apache and nginx for my above code here.<br>\n<a href=\"https://github.com/infinity-next/infinity-next/wiki/Installation\" rel=\"noreferrer\">https://github.com/infinity-next/infinity-next/wiki/Installation</a></p>\n\n<p>This has been tested on high-traffic websites. Do <strong>not</strong> buffer media through a PHP Daemon unless your site has next to no traffic or you're bleeding resources.</p>\n",
                    "OwnerUserId": "4635062",
                    "LastActivityDate": "2016-05-03T17:23:24.560",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "43269976",
                "ParentRepo": "https://github.com/phanan/koel",
                "StackOverflow_Post": {
                    "Id": "43269976",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "43272213",
                    "CreationDate": "2017-04-07T04:59:27.277",
                    "Score": "1",
                    "ViewCount": "933",
                    "Body": "<p>I've got elements tied to @click  </p>\n\n<p><code>&lt;th @click=\"sort('dateadded')\"  class=\"created_at\"&gt;Date Added</code></p>\n\n<p>what i'd like to do is to call this on page load / or when the component renders in vuejs, in that way i'd be able to have a presorted table when it opens up. apparently, if i call it after rendering it still doesn't sort.</p>\n\n<p>here's a loop to display the items.</p>\n\n<pre><code>&lt;tr is=\"song-item\" v-for=\"item in displayedItems\"  :orderBy=\"dateadded\" :song=\"item\" ref=\"rows\"&gt;&lt;/tr&gt;\n</code></pre>\n\n<p>and in computed i've the following:</p>\n\n<pre><code>computed: {\n\n    displayedItems() {\n\n      return limitBy( filterBy(\n          this.mutatedItems,\n          this.q,\n          'dateadded', 'title', 'album.name', 'artist.name',  'id',\n        ),\n        this.numOfItems,\n      );\n    },\n\n     //displayedItems2(){return orderBy (limitBy (filterBy( this.mutatedItems, this.q, 'title', 'album.name', 'artist.name', 'dateadded'  ), this.numOfItems,  ), 'dateadded', -1);},\n  }\n</code></pre>\n\n<p>now the thing is if i return with orderby (displayedItems2) i'm unable to sort from the page itself. so how would i go on about sorting pre-render or simply call the sort('dateadded') externally? i.e., without clicking onto it.</p>\n\n<p>All i want to do is to be able to get access to sort('dateadded') </p>\n\n<p>i'm basically trying to sort this before rendering/displaying:\n<a href=\"http://demo.koel.phanan.net/#!/songs\" rel=\"nofollow noreferrer\">http://demo.koel.phanan.net/#!/songs</a> (after logging in the demo, use the link)\n<a href=\"https://github.com/phanan/koel\" rel=\"nofollow noreferrer\">https://github.com/phanan/koel</a></p>\n\n<p>it doesn't have date-added, but if we can reference sorting title. thank you.</p>\n",
                    "OwnerUserId": "7830599",
                    "LastActivityDate": "2017-04-07T07:31:00.437",
                    "Title": "Vuejs Sorting after rendering",
                    "Tags": "<javascript><vue.js><lodash><vuejs2>",
                    "AnswerCount": "1",
                    "CommentCount": "3",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "45816862",
                "ParentRepo": "https://github.com/DanielnetoDotCom/YouPHPTube",
                "StackOverflow_Post": {
                    "Id": "45816862",
                    "PostTypeId": "2",
                    "ParentId": "45013779",
                    "CreationDate": "2017-08-22T11:51:08.043",
                    "Score": "0",
                    "Body": "<p><a href=\"https://github.com/DanielnetoDotCom/YouPHPTube\" rel=\"nofollow noreferrer\">youPHPTube</a> is a good solution for those who are looking for a youtube clone.</p>\n\n<p>The app is running fine and the project seems <a href=\"https://github.com/DanielnetoDotCom/YouPHPTube/graphs/contributors?from=2017-04-02&amp;to=2017-08-09&amp;type=c\" rel=\"nofollow noreferrer\">currently active</a>.</p>\n",
                    "OwnerUserId": "1632809",
                    "LastActivityDate": "2017-08-22T11:51:08.043",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "51149062",
                "ParentRepo": "https://github.com/ILIAS-eLearning/ILIAS/tre",
                "StackOverflow_Post": {
                    "Id": "51149062",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "51178479",
                    "CreationDate": "2018-07-03T07:41:01.350",
                    "Score": "2",
                    "ViewCount": "930",
                    "Body": "<p>I am currently writing a logger writing to rather large log files in ILIAS for some plugin. I am using the neat new filesystem. Since the new log messages need to append to a file, I can not simply use put or update, since they seem to always truncate the logfile. Flysystem seems not to support an easy append command, so one way I found that is working is the following:</p>\n\n<pre><code>$old_data = \"\";\nif ($DIC-&gt;filesystem()-&gt;storage()-&gt;has($this-&gt;path)) {\n    $old_data = $DIC-&gt;filesystem()-&gt;storage()-&gt;read($this-&gt;path);\n}\n$DIC-&gt;filesystem()-&gt;storage()-&gt;put($this-&gt;path, $old_data.$string);\n</code></pre>\n\n<p>However, this seems like very expensive regarding IO if massive amounts of data are appended to the log. I guess, this is best done using streams. I the docs (<a href=\"https://github.com/ILIAS-eLearning/ILIAS/tree/release_5-3/src/Filesystem\" rel=\"nofollow noreferrer\">https://github.com/ILIAS-eLearning/ILIAS/tree/release_5-3/src/Filesystem</a>) I found the following:</p>\n\n<pre><code>$webDataRoot = $DIC-&gt;filesystem()-&gt;web();\n$fileStream = $webDataRoot-&gt;readStream('relative/path/to/file');\n\n//seek at the end of the stream\n$fileStream-&gt;seek($fileStream-&gt;getSize() - 1);\n//append something\n$fileStream-&gt;write(\"something\");\n</code></pre>\n\n<p>However, with this I am getting the <strong>Can not write to a non-writable stream</strong> exception. It seems, that I would need to open the stream like so:</p>\n\n<pre><code>$resource = fopen('myPath', 'rw');\n</code></pre>\n\n<p>However this is specifically discouraged in the docs. What is the best way to tackle this by making use of the filesystem in ILIAS?</p>\n",
                    "OwnerUserId": "3698695",
                    "LastActivityDate": "2021-04-06T09:13:13.620",
                    "Title": "Append to file using flysystem in ILIAS",
                    "Tags": "<php><flysystem><ilias>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "59853229",
                "ParentRepo": "https://github.com/wapmorgan/MediaFile",
                "StackOverflow_Post": {
                    "Id": "59853229",
                    "PostTypeId": "2",
                    "ParentId": "59846475",
                    "CreationDate": "2020-01-22T05:36:41.480",
                    "Score": "0",
                    "Body": "<p>[UPADATED] Using promises, we can preload videos metadata and store them in an array. What I did here is using local storage to store the timing array and use it's final Sum later.\nOtherwise we will get 0 because of Asynchronicity of metadata preloading that didn't finished yet !</p>\n\n<p>This way, you can separate all this from your Slider Code and just use <code>totalTime=(JSON.parse(localStorage.getItem('durations'))).reduce((a, b) =&gt; a + b, 0);</code><br>\n.</p>\n\n<pre><code>function Preload(){\n\nvar slides = document.querySelectorAll('video');    \n    return new Promise(function (resolve) {\n            var ready = 0;\n            var videosDura = [];\n            slides.forEach(function (v) {\n                v.addEventListener('loadedmetadata', function () {\n                    videosDura.push(Math.round(v.duration));\n                    ready++;\n                    localStorage.setItem(\"durations\", JSON.stringify(videosDura));\n                    if (ready === slides.length) {\n                        $('.preloader').fadeOut('slow');\n                        resolve();\n\n                    }\n                });\n            });\n        }).then(function () {\n        console.log((JSON.parse(localStorage.getItem('durations'))).reduce((a, b) =&gt; a + b, 0));\n\n        // Call any function dependant on this Variable\n\n    });\n}  \n\n\n$(document).ready(function () {\nPreload();\n});\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/ksLzQ.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/ksLzQ.png\" alt=\"enter image description here\"></a>\n<a href=\"https://i.stack.imgur.com/fOlil.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/fOlil.png\" alt=\"enter image description here\"></a></p>\n\n<p>There is another approach to check videos using <a href=\"https://www.w3schools.com/jsref/prop_video_readystate.asp\" rel=\"nofollow noreferrer\">videoObject.readyState</a> property.</p>\n\n<p>In <a href=\"https://jsfiddle.net/bilelh/xnzsfqyj/\" rel=\"nofollow noreferrer\">this Fiddle</a> you can test the expected result.</p>\n\n<p>For performance and optimization, thinking of bandwidth, page loading speed, compatibility and mobile devices... I suggest you read first this <a href=\"https://developers.google.com/web/fundamentals/media/fast-playback-with-video-preload\" rel=\"nofollow noreferrer\">article</a> while working on your actual project. </p>\n\n<p>The best approach to use video metadata is to use an API for ajax calls or pre-store it on the server side first. Some meta generator projects on Github:</p>\n\n<ul>\n<li>NodeJs : <a href=\"https://github.com/fcingolani/video-metadata-api\" rel=\"nofollow noreferrer\">Video Meta Data Api</a> / <a href=\"https://github.com/egg-/video-parser\" rel=\"nofollow noreferrer\">Video Parser</a></li>\n<li>pHp : <a href=\"https://github.com/wapmorgan/MediaFile\" rel=\"nofollow noreferrer\">MediaFile</a></li>\n<li>Go : <a href=\"https://github.com/jsimnz/viddio\" rel=\"nofollow noreferrer\">Viddio</a></li>\n</ul>\n",
                    "OwnerUserId": "4929742",
                    "LastEditorUserId": "4929742",
                    "LastEditDate": "2020-01-23T13:25:46.130",
                    "LastActivityDate": "2020-01-23T13:25:46.130",
                    "CommentCount": "6",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "61331074",
                "ParentRepo": "https://github.com/AzuraCast/AzuraCast/issues/1628#issuecomment-498906552",
                "StackOverflow_Post": {
                    "Id": "61331074",
                    "PostTypeId": "2",
                    "ParentId": "58592332",
                    "CreationDate": "2020-04-20T20:03:13.617",
                    "Score": "0",
                    "Body": "<blockquote>\n  <p>The listener count shown in the statistics is the average listener count across the entire day, as a sum total of each measurement point (15 seconds or less apart from each other) added together and averaged.</p>\n</blockquote>\n\n<p>(<a href=\"https://github.com/AzuraCast/AzuraCast/issues/1628#issuecomment-498906552\" rel=\"nofollow noreferrer\">From a GitHub issue</a>)</p>\n",
                    "OwnerUserId": "13365683",
                    "LastEditorUserId": "2648551",
                    "LastEditDate": "2020-04-21T01:10:05.237",
                    "LastActivityDate": "2020-04-21T01:10:05.237",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "63286563",
                "ParentRepo": "https://github.com/koel/koel",
                "StackOverflow_Post": {
                    "Id": "63286563",
                    "PostTypeId": "2",
                    "ParentId": "58791817",
                    "CreationDate": "2020-08-06T15:10:24.073",
                    "Score": "0",
                    "Body": "<p>apparently in the master branch of <a href=\"https://github.com/koel/koel\" rel=\"nofollow noreferrer\">koel</a> assets are in a separate repo.\nCloning the repo recursively should fix it.</p>\n<pre><code>git clone https://github.com/koel/koel.git --recursive\n</code></pre>\n<p>if not work try this after:</p>\n<pre><code>git submodule update --init --recursive\n</code></pre>\n",
                    "OwnerUserId": "5753091",
                    "LastEditorUserId": "5753091",
                    "LastEditDate": "2020-08-06T15:16:10.640",
                    "LastActivityDate": "2020-08-06T15:16:10.640",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "64141140",
                "ParentRepo": "https://github.com/WWBN/AVideo",
                "StackOverflow_Post": {
                    "Id": "64141140",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "64142051",
                    "CreationDate": "2020-09-30T15:43:03.227",
                    "Score": "0",
                    "ViewCount": "215",
                    "Body": "<p>I have a GitHub repository <a href=\"https://github.com/WWBN/AVideo\" rel=\"nofollow noreferrer\">WWBN/AVideo</a> and I want to change the text that appears on a button.</p>\n<p>I viewed the page source and the button is defined as <code>subscribeButton1</code>. Now I need to find out which file this variable is located so I can change the text associated with it. How can I do that?</p>\n<p>Here is what I want to find:</p>\n<p><img src=\"https://i.stack.imgur.com/nmkxI.png\" alt=\"enter image description here\" /></p>\n",
                    "OwnerUserId": "14283495",
                    "LastEditorUserId": "1549818",
                    "LastEditDate": "2020-09-30T17:12:50.790",
                    "LastActivityDate": "2020-09-30T17:12:50.790",
                    "Title": "How can I find where a variable is located in GitHub?",
                    "Tags": "<git><github>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "64601541",
                "ParentRepo": "https://github.com/collectiveaccess/providence",
                "StackOverflow_Post": {
                    "Id": "64601541",
                    "PostTypeId": "1",
                    "CreationDate": "2020-10-30T01:30:29.123",
                    "Score": "0",
                    "ViewCount": "42",
                    "Body": "<p>I am trying to set up a content management system called <a href=\"https://github.com/collectiveaccess/providence\" rel=\"nofollow noreferrer\">CollectiveAccess</a> Providence, but currently I am stuck at getting the php app authenticated on the database.  The initial install page indicates a problem authenticating to the database:</p>\n<pre><code>Fatal error: Uncaught DatabaseException: Access denied for user 'providenceuser'@'localhost' to database 'providencedb' in /var/www/html/providence/app/lib/Db/mysqli.php:144 Stack trace: #0 /var/www/html/providence/app/lib/Db.php(134): Db_mysqli-&gt;connect() #1 /var/www/html/providence/app/lib/Db.php(108): Db-&gt;connect() #2 /var/www/html/providence/app/lib/ConfigurationCheck.php(103): Db-&gt;__construct() #3 /var/www/html/providence/install/inc/page1.php(44): ConfigurationCheck::performInstall() #4 /var/www/html/providence/install/index.php(148): require_once('/var/www/html/p...') #5 {main} thrown in /var/www/html/providence/app/lib/Db/mysqli.php on line 144\n</code></pre>\n<p>For testing purposes, this question uses <a href=\"https://gist.github.com/chales/11359952\" rel=\"nofollow noreferrer\">db-connect-test.php</a>  which also had issues, but which I was able to get past.\nOn the first try of the test app, I got access denied.</p>\n<pre><code>dev-admin@devtest:~$ php -f php_db_test/db-connect-test.php\nPHP Warning:  mysqli_connect(): (HY000/1698): Access denied for user 'root'@'localhost' in /home/dev-admin/php_db_test/db-connect-test.php on line 10\n\n</code></pre>\n<p>When I ran the same command as superuser, I could connect because it correctly reported:</p>\n<pre><code>There are no tables&lt;br /&gt;\n</code></pre>\n<p>With the test app, if I changed the db user 'root' and left the password empty as '', it seems I am able to connect:</p>\n<p>However, the same thing did not work for Providence, still giving me an &quot;access denied&quot;.</p>\n<p>I thought maybe the type of connection was the problem, so I ran:</p>\n<pre><code>UPDATE mysql.user SET plugin = 'mysql_native_password' WHERE user = 'providenceuser' AND plugin IN ('unix_socket', 'auth_socket');\n\nFLUSH PRIVILEGES;\n</code></pre>\n<p>However that, did not help.\nI have also tried changing 'localhost' in the config files to <code>127.0.0.1</code> without success.</p>\n<p>What else can I try or where else can I look for clues?</p>\n",
                    "OwnerUserId": "4780574",
                    "LastEditorUserId": "1839439",
                    "LastEditDate": "2020-10-30T12:14:15.287",
                    "LastActivityDate": "2020-10-30T12:14:15.287",
                    "Title": "Php app refused access to database, but same credentials work from CLI",
                    "Tags": "<mysql><privileges>",
                    "AnswerCount": "1",
                    "CommentCount": "6",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "69186968",
                "ParentRepo": "https://github.com/ampache/ampache/blob/develop/public/templates/show_login_form.inc.php#L70",
                "StackOverflow_Post": {
                    "Id": "69186968",
                    "PostTypeId": "1",
                    "CreationDate": "2021-09-15T04:01:33.940",
                    "Score": "0",
                    "ViewCount": "105",
                    "Body": "<p>I'm setting up an <a href=\"https://ampache.org/\" rel=\"nofollow noreferrer\">ampache</a> server on my home network. I've got nginx, php, and ampache up and running, and everything seems fine except for access from outside my home network.</p>\n<p>For example, let's say my router's public IP address is <code>aaa.bbb.ccc.ddd</code>, and the server's LAN IP address is <code>192.168.xxx.yyy</code>. Outside my home network, if I do</p>\n<pre class=\"lang-sh prettyprint-override\"><code>curl -k https://aaa.bbb.ccc.ddd/login.php\n</code></pre>\n<p>all of the URLs in the resulting html reference <code>192.168.xxx.yyy</code>, which I obviously can't see from outside my home network. For example, look at <a href=\"https://github.com/ampache/ampache/blob/develop/public/templates/show_login_form.inc.php#L70\" rel=\"nofollow noreferrer\">this code</a>:</p>\n<pre class=\"lang-php prettyprint-override\"><code>&lt;form name=&quot;login&quot; method=&quot;post&quot; enctype=&quot;multipart/form-data&quot; action=&quot;&lt;?php echo $web_path; ?&gt;/login.php&quot;&gt;\n</code></pre>\n<p>When I run curl as shown above, this gets rendered to</p>\n<pre class=\"lang-html prettyprint-override\"><code>&lt;form name=&quot;login&quot; method=&quot;post&quot; enctype=&quot;multipart/form-data&quot; action=&quot;https://192.168.xxx.yyy/login.php&quot;&gt;\n</code></pre>\n<p>I don't know much about php, but it seems like the <code>$web_path</code> part is being replaced by <code>https://192.168.xxx.yyy</code>, even though the URL I requested was <code>https://aaa.bbb.ccc.ddd</code>.</p>\n<p>My nginx virtual server config looks like:</p>\n<pre><code>server {\n    listen 80;\n    server_name 192.168.xxx.yyy mydomain.no-ip.org;\n    return 301 https://$server_name$request_uri;\n}\n\n\nserver {\n   listen      443 ssl default_server;\n   server_name 192.168.xxx.yyy mydomain.no-ip.org;\n}\n</code></pre>\n<p>Note that I have a no-ip dynamic DNS set up in case the public IP changes, but it doesn't matter if I use the domain name or the IP address, the result is the same. Since <code>aaa.bbb.ccc.ddd</code> isn't explicitly listed, the default server catches it, but all URLs in the html that gets returned still reference <code>192.168.xxx.yyy</code>.</p>\n<p>In my ampache.cfg.php file, <code>http_host</code>, <code>http_port</code>, <code>web_path</code>, and <code>local_web_path</code> are all commented out. My understanding is that it should then use the host name that the client requested, which it isn't doing. If I set <code>http_host</code> and <code>http_port</code> explicitly, then it <em><strong>does</strong></em> use those to properly assemble URLs... however, for some reason, I am not allowed to access <code>aaa.bbb.ccc.ddd</code> from <em><strong>inside</strong></em> my network (I can't get any answers from my ISP about this). So, if I set those so that <code>http_host</code> is <code>aaa.bbb.ccc.ddd</code>, it will always return html like</p>\n<pre class=\"lang-html prettyprint-override\"><code>&lt;form name=&quot;login&quot; method=&quot;post&quot; enctype=&quot;multipart/form-data&quot; action=&quot;https://aaa.bbb.ccc.ddd/login.php&quot;&gt;\n</code></pre>\n<p>If I'm outside my network, that's fine. If I'm at home, though, it will fail because it can't find aaa.bbb.ccc.ddd. So, I can force it to work for <em><strong>either</strong></em> internal or external access, but not both.</p>\n<p>How should I resolve this? Is there a way to configure either ampache or nginx to build URLs based on the client's requested hostname?</p>\n",
                    "OwnerUserId": "3684433",
                    "LastActivityDate": "2021-09-18T03:06:54.890",
                    "Title": "How to get the web_path variable in php to use the same hostname as the request?",
                    "Tags": "<php><nginx><url><subnet>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "69870309",
                "ParentRepo": "https://github.com/owen-oj/laravel-getid3",
                "StackOverflow_Post": {
                    "Id": "69870309",
                    "PostTypeId": "1",
                    "CreationDate": "2021-11-07T06:42:00.897",
                    "Score": "0",
                    "ViewCount": "191",
                    "Body": "<p>I have a controller which handles the upload functionality of the music file. The controller uses this <a href=\"https://github.com/owen-oj/laravel-getid3\" rel=\"nofollow noreferrer\">Laravel getID3 package</a> to parse the metadata from the music file and store in the database.\nMy code looks like this</p>\n<pre><code>if($request-&gt;hasfile('songs')){\n            foreach ( $request-&gt;file('songs') as $key =&gt; $file){\n                $track = new getID3($file);\n                $tifo = $track-&gt;extractInfo();\n                $artistName = $track-&gt;getArtist();\n                $songName = $track-&gt;getTitle();\n                $albumName = $track-&gt;getAlbum();\n                $extension = $track-&gt;getFileFormat();\n                $thumbnail = $track-&gt;getArtwork(true);\n                $thumbnails = 'artwork-'.time().'.'.$thumbnail-&gt;getClientOriginalExtension();\n                $location = time() .uniqid().'.' . $extension;\n                $file-&gt;storeAs('public/songs',$location);\n                //$file-&gt;storeAs('public/sthumbs',$thumbnails);\n\n                $file = new MusicUpload();\n\n                $music_upload_file = new MusicUpload();\n                $music_upload_file-&gt;user_id = Auth::user()-&gt;id;\n                $music_upload_file-&gt;filename = $songName;\n                $music_upload_file-&gt;extension = $extension;\n                $music_upload_file-&gt;artistname = $artistName;\n                $music_upload_file-&gt;albumname = $albumName;\n                $music_upload_file-&gt;location = $location;\n                $music_upload_file-&gt;thumbnail = $thumbnails;\n                $music_upload_file-&gt;save();\n            }\n        }\n</code></pre>\n<p>What I want to do is to store both the music file as well as the thumbnail of the file in the database.</p>\n<p>Here the <code>$thumbnails</code> will store the image in the specified folder but the image is unreadable, i.e. it has the same file size as the music and doesn't contain the artwork which is to be stored and retrieved.\nIf I don't include the <code>$thumbnails</code> part, the package default stores to the temp folder which is inaccessible to the controller.</p>\n<p>So how do I write the code such that the thumbnail(artwork) of the music gets stored in the correct folder and it can display the output too.</p>\n",
                    "OwnerUserId": "14009092",
                    "LastActivityDate": "2021-11-07T07:49:36.747",
                    "Title": "Storing Image path using Laravel",
                    "Tags": "<php><mysql><laravel>",
                    "AnswerCount": "1",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "71119036",
                "ParentRepo": "https://github.com/statamic/cms/pull/5238",
                "StackOverflow_Post": {
                    "Id": "71119036",
                    "PostTypeId": "2",
                    "ParentId": "69163788",
                    "CreationDate": "2022-02-14T22:30:07.493",
                    "Score": "0",
                    "Body": "<p>For anyone seeing this in the future: Statamic 3.3 is being released in a few days which will introduce <a href=\"https://github.com/statamic/cms/pull/5238\" rel=\"nofollow noreferrer\">im</a><a href=\"https://github.com/statamic/cms/pull/5201\" rel=\"nofollow noreferrer\">pro</a><a href=\"https://github.com/statamic/cms/pull/5058\" rel=\"nofollow noreferrer\">vem</a><a href=\"https://github.com/statamic/cms/pull/5056\" rel=\"nofollow noreferrer\">ents</a> to Blade in Statamic and includes a <a href=\"https://github.com/statamic/cms/pull/4257\" rel=\"nofollow noreferrer\">complete rewrite of Antlers</a>.</p>\n",
                    "OwnerUserId": "3237188",
                    "LastActivityDate": "2022-02-14T22:30:07.493",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            }
        ],
        "Type": 2
    },
    "https://github.com/prasathmani/tinyfilemanager": {
        "CVE Description": [
            "A Path Traversal vulnerability exists in TinyFileManager all version up to and including 2.4.6 that allows attackers to upload a file (with Admin credentials or with the CSRF vulnerability) with the \"fullpath\" parameter containing path traversal strings (../ and ..\\) in order to escape the server's intended working directory and write malicious files onto any directory on the computer.",
            "A Cross-Site Request Forgery (CSRF) vulnerability exists in TinyFileManager all version up to and including 2.4.6 that allows attackers to upload files and run OS commands by inducing the Administrator user to browse a URL controlled by an attacker.",
            "A Stored XSS exists in TinyFileManager All version up to and including 2.4.6 in /tinyfilemanager.php when the server is given a file that contains HTML and javascript in its name. A malicious user can upload a file with a malicious filename containing javascript code and it will run on any user browser when they access the server."
        ],
        "Edges": [
            {
                "SID": "70143336",
                "StackOverflow_Post": {
                    "Id": "70143336",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "70154387",
                    "CreationDate": "2021-11-28T12:19:29.633",
                    "Score": "-1",
                    "ViewCount": "370",
                    "Body": "<p>I am trying to make a file manager with php , so when I open it in browser it would give a list of the current directory and the file would be clickable using the anchor tag in html (which I have done so far) , and when the file is clicked , it would open it in the text mode and shows whatever the source code inside the file is.</p>\n<p>I am facing two problems which I couldn't figure out</p>\n<p>Problem #1:</p>\n<p>The first problem is that I want my file manager to read any source code weather its an image or pdf , just like the tinyfilemanager that I found <a href=\"https://github.com/prasathmani/tinyfilemanager\" rel=\"nofollow noreferrer\">here</a> this master piece can read any file, even if you open an image with a notepad and insert some php code at the very end of the file it will read render that too, so here's my source code:</p>\n<pre><code>&lt;?php\nfunction list_all_files($directory){\n//opening the dir\n    if($handle=opendir($directory.'/')){\n        echo &quot;looking inside '$directory'&quot;.&quot;&lt;br&gt;&quot;;\n    }\n\n    while($file=readdir($handle)){\n        //listing all the directories without &quot;..&quot; (dots)\n        if($file!='.'&amp;&amp;$file!='..') {\n\n            echo '&lt;a href=&quot;Read.php?dir='.$directory.'&amp;read='.$directory.'/'.$file.'&quot;&gt;'.$file.'&lt;/a&gt;&lt;br&gt;';\n        } //if ends here\n    } //while loop endds here\n} //list_all_files ends here\n\n\nfunction read_file($file)\n{\n    $handle = fopen($file, &quot;r&quot;);\n    if ($handle) {\n        while (($line = fgets($handle)) !== false) {\n            echo($line);\n        }\n        fclose($handle);\n    } else {\n        echo &quot;error opening the file&quot;;\n    }\n}\n\n\n//main function\nif(!isset($_GET['dir'])) {\n    $dir='images';\n}else{\n    $dir=$_GET['dir'];\n}\n\nlist_all_files($dir);\n\nif(isset($_GET['read'])){\n    $file1 = $_GET['read'];\n    read_file($file1);\n}\n\n?&gt;\n</code></pre>\n<p>the above program I made can also read files code but when I click on any PHP file that contains an html code, it just displays it rather than giving its source code in text mode, image below:</p>\n<p><a href=\"https://i.stack.imgur.com/Qy0e6.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/Qy0e6.png\" alt=\"its Rendering and displaying html\" /></a></p>\n<p>and not only this, if I put some php code at the very end of the image file using a notepad it wouldn't display it. check this:</p>\n<p><a href=\"https://i.stack.imgur.com/PMcJZ.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/PMcJZ.png\" alt=\"php code in the image file\" /></a></p>\n<p><a href=\"https://i.stack.imgur.com/DTaD3.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/DTaD3.png\" alt=\"output of the php code\" /></a></p>\n<p>I did a lot of research on why my code isn't working while the tinyFilemanager is perfect with any of the above mention cases , and I found that the whenever I execute the page file via browser it by default uses this</p>\n<pre><code>header(&quot;Content-Type: text/html&quot;);\n</code></pre>\n<p>so If I wanted to do what I wanted , then I would have to use this:</p>\n<pre><code>header(&quot;Content-Type: text/x-php&quot;);\n</code></pre>\n<p>which covers both of the above cases, but leads to the 2nd problem.</p>\n<p>Problem #2:</p>\n<pre><code>&lt;?php\nfunction list_all_files($directory){\n//opening the dir\nif($handle=opendir($directory.'/')){\necho &quot;looking inside '$directory'&quot;.&quot;&lt;br&gt;&quot;;\n}\n\nwhile($file=readdir($handle)){\n    //listing all the directories without &quot;..&quot; (dots)\n    if($file!='.'&amp;&amp;$file!='..') {\n\n    echo '&lt;a href=&quot;Read.php?dir='.$directory.'&amp;read='.$directory.'/'.$file.'&quot;&gt;'.$file.'&lt;/a&gt;&lt;br&gt;';\n            } //if ends here\n        } //while loop endds here\n} //list_all_files ends here\n\n\nfunction read_file($file)\n{\n    $handle = fopen($file, &quot;r&quot;);\n    if ($handle) {\n        while (($line = fgets($handle)) !== false) {\n            echo($line);\n        }\n        fclose($handle);\n    } else {\n       echo &quot;error opening the file&quot;;\n    }\n}\n\n\n//main function\nif(!isset($_GET['dir'])) {\n    $dir=getcwd();\n}else{\n    $dir=$_GET['dir'];\n}\n\n//listing all the directories and files in text/html format so that our anchor tag would be available.\nob_start();\nheader('Content-Type: text/html; charset=UTF-8');\nlist_all_files($dir);\nob_end_flush();\n\n\n\nif(isset($_GET['read'])){\n//changing the header to text/php-x so that the php code in any jpg file can be viewed clearly\n    ob_clean();\n    header('Content-Type: text/x-php; charset=UTF-8');\n    ob_start();\n    $file1 = $_GET['read'];\n    read_file($file1);\n    ob_end_flush();\n}\n\n?&gt;\n</code></pre>\n<p>The above codes works perfectly fine, but there is this one problem. since its content-type is not text/html anymore, it wouldn't display the html content on the web page. which is good but bad at the same time because then I wouldn't get the list of directory in the anchor tag form, because I thought ob_start and ob_end_flush(). if I use these two, it would just solve the problem by creating a buffer for each of the function separately and executes it. so when it executes it the above function would be render with the content-type text/html and would show the directory listing with anchor tag, and the 2nd would just be in text/x-php which would solve the above two cases, but I was soooooo wrong.</p>\n",
                    "OwnerUserId": "8627152",
                    "LastEditorUserId": "4420967",
                    "LastEditDate": "2021-11-28T14:18:56.727",
                    "LastActivityDate": "2021-11-29T12:08:19.883",
                    "Title": "Problem in reading files with php fopen and in making file manager",
                    "Tags": "<php><file><fopen><file-manager>",
                    "AnswerCount": "1",
                    "CommentCount": "11",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            }
        ],
        "Type": 0
    },
    "https://github.com/mkdocs/mkdocs": {
        "CVE Description": [
            "** DISPUTED ** The mkdocs 1.2.2 built-in dev-server allows directory traversal using the port 8000, enabling remote exploitation to obtain :sensitive information. NOTE: the vendor has disputed this as described in https://github.com/mkdocs/mkdocs/issues/2601.] and https://github.com/nisdn/CVE-2021-40978/issues/1."
        ],
        "Edges": [
            {
                "ParentSID": "1236347",
                "ParentRepo": "https://github.com/pypa/warehouse",
                "StackOverflow_Post": {
                    "Id": "1236347",
                    "PostTypeId": "2",
                    "ParentId": "1235331",
                    "CreationDate": "2009-08-06T00:00:39.360",
                    "Score": "16",
                    "Body": "<p><strong>Update: PyPi is now powered by <a href=\"https://github.com/pypa/warehouse\" rel=\"nofollow noreferrer\">Warehouse</a>, which is the replacement for Cheese Shop.</strong></p>\n\n<p>The source to Cheese Shop can be downloaded from <a href=\"https://bitbucket.org/pypa/pypi/src\" rel=\"nofollow noreferrer\">https://bitbucket.org/pypa/pypi/src</a>. There is also an example, from the page you linked to, of using Apache as a \"dumb\" Python package repository:</p>\n\n<pre><code># Mount pypi repositories into URI space\nAlias /pypi   /var/pypi\n\n# /pypi/dev: Redirect for unknown packages (fallback to pypi)\nRewriteCond   /var/pypi/dev/$1 !-d\nRewriteCond   /var/pypi/dev/$1 !-f\nRewriteRule   ^/pypi/dev/([^/]+)/?$ http://pypi.python.org/pypi/$1/ [R,L]\n\nRewriteCond   /var/pypi/dev/$1/$2 !-f\nRewriteRule   ^/pypi/dev/([^/]+)/([^/]+)$ http://pypi.python.org/pypi/$1/$2 [R,L]\n\n# /pypi/stable: Redirect for unknown packages (fallback to pypi)\nRewriteCond   /var/pypi/stable/$1 !-d\nRewriteCond   /var/pypi/stable/$1 !-f\nRewriteRule   ^/pypi/stable/([^/]+)/?$ http://pypi.python.org/pypi/$1/ [R,L]\n\nRewriteCond   /var/pypi/stable/$1/$2 !-f\nRewriteRule   ^/pypi/stable/([^/]+)/([^/]+)$ http://pypi.python.org/pypi/$1/$2 [R,L]\n</code></pre>\n",
                    "OwnerUserId": "3560",
                    "LastEditorUserId": "1003288",
                    "LastEditDate": "2020-01-16T16:28:20.797",
                    "LastActivityDate": "2020-01-16T16:28:20.797",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "1475696",
                "ParentRepo": "https://github.com/pinax/pinax/blob/master/requirements/pinax.txt",
                "StackOverflow_Post": {
                    "Id": "1475696",
                    "PostTypeId": "2",
                    "ParentId": "1448292",
                    "CreationDate": "2009-09-25T06:17:47.203",
                    "Score": "5",
                    "Body": "<p>As the two other posts said, it comes with a lot of pre-packaged apps that take care of common tasks in modern websites. Here's a list of the external apps that come packaged: <a href=\"https://github.com/pinax/pinax/blob/master/requirements/pinax.txt\" rel=\"nofollow noreferrer\">https://github.com/pinax/pinax/blob/master/requirements/pinax.txt</a></p>\n\n<p>It also gives you project templates to start from, which you can see here: <a href=\"https://github.com/pinax/pinax/tree/master/pinax/projects/\" rel=\"nofollow noreferrer\">https://github.com/pinax/pinax/tree/master/pinax/projects/</a></p>\n\n<p>The projects have working default settings in place so that you can run syncdb then runserver to get going immediately, unlike default Django. Its design also encourages you to write your own apps in such a way that they are more reusable. As they put it, \"By integrating numerous reusable Django apps to take care of the things that many sites have in common, it lets you focus on what makes your site different.\"</p>\n\n<p>It does have a small learning curve of its own but I've personally been very happy with it and learned a lot more about Django (and git and virtualenv) by using Pinax.</p>\n",
                    "OwnerUserId": "151577",
                    "LastEditorUserId": "151577",
                    "LastEditDate": "2011-01-23T16:42:03.813",
                    "LastActivityDate": "2011-01-23T16:42:03.813",
                    "CommentCount": "3",
                    "ContentLicense": "CC BY-SA 2.5"
                }
            },
            {
                "ParentSID": "1499562",
                "ParentRepo": "https://github.com/vinta/awesome-python",
                "StackOverflow_Post": {
                    "Id": "1499562",
                    "PostTypeId": "2",
                    "ParentId": "1499543",
                    "CreationDate": "2009-09-30T17:29:49.247",
                    "Score": "98",
                    "Body": "<p>A great resource is <a href=\"http://www.djangopackages.com/\" rel=\"noreferrer\">www.djangopackages.com</a>, which lists a lot of the notable Django apps out there, including links to their respective repos, popularity ratings, etc..</p>\n\n<p>Another way to find popular projects is directly on GitHub: <a href=\"https://github.com/search?q=django\" rel=\"noreferrer\">https://github.com/search?q=django</a></p>\n\n<p>Finally:</p>\n\n<ol>\n<li>Awesome Django @ <a href=\"https://github.com/wsvincent/awesome-django\" rel=\"noreferrer\">https://github.com/wsvincent/awesome-django</a></li>\n<li>Awesome Python @ <a href=\"https://github.com/vinta/awesome-python\" rel=\"noreferrer\">https://github.com/vinta/awesome-python</a></li>\n</ol>\n",
                    "OwnerUserId": "128463",
                    "LastEditorUserId": "10865034",
                    "LastEditDate": "2019-01-04T09:06:58.563",
                    "LastActivityDate": "2019-01-04T09:06:58.563",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "1548393",
                "ParentRepo": "https://github.com/vlasovskikh/funcparserlib",
                "StackOverflow_Post": {
                    "Id": "1548393",
                    "PostTypeId": "2",
                    "ParentId": "1547782",
                    "CreationDate": "2009-10-10T16:29:48.147",
                    "Score": "22",
                    "Body": "<p>I would recommend <a href=\"https://github.com/vlasovskikh/funcparserlib\" rel=\"noreferrer\"><code>funcparserlib</code></a>. It was written especially for parsing little languages and DSLs and it is faster and smaller than <code>pyparsing</code> (see stats on its homepage). Minimalists and functional programmers should like <code>funcparserlib</code>.</p>\n\n<p>Edit: By the way, I'm the author of this library, so my opinion may be biased.</p>\n",
                    "OwnerUserId": "187103",
                    "LastEditorUserId": "65516",
                    "LastEditDate": "2017-06-29T12:03:56.523",
                    "LastActivityDate": "2017-06-29T12:03:56.523",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "4107648",
                "ParentRepo": "https://github.com/opencomparison/opencomparison",
                "StackOverflow_Post": {
                    "Id": "4107648",
                    "PostTypeId": "2",
                    "ParentId": "1499543",
                    "CreationDate": "2010-11-05T15:58:22.037",
                    "Score": "5",
                    "Body": "<p>I asked Malcolm Tredinnick a few weeks ago if there was a project he admired and he suggested Django Packages. <a href=\"https://github.com/opencomparison/opencomparison\" rel=\"nofollow\">They keep their source on Github</a> .</p>\n\n<p>I wouldn't say that it should be used as a Django tutorial but they have an admirable style of programming and I have picked up more than a few tips and tricks by reading their source. It is definitely a good example to learn from.</p>\n",
                    "OwnerUserId": "376655",
                    "LastEditorUserId": "29995",
                    "LastEditDate": "2012-12-17T02:31:27.453",
                    "LastActivityDate": "2012-12-17T02:31:27.453",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "4889847",
                "ParentRepo": "https://github.com/nlohmann/json",
                "StackOverflow_Post": {
                    "Id": "4889847",
                    "PostTypeId": "5",
                    "CreationDate": "2011-02-03T18:02:56.433",
                    "Score": "0",
                    "Body": "<p><a href=\"https://www.json.org/\" rel=\"nofollow noreferrer\">JSON</a> (<strong>J</strong>ava<strong>S</strong>cript <strong>O</strong>bject <strong>N</strong>otation) is a serializable data interchange format intended to be machine- and human-readable.</p>\n<p>JSON is defined by <a href=\"https://tools.ietf.org/html/rfc7159\" rel=\"nofollow noreferrer\">RFC 7159</a> which is completely language independent, but it uses conventions familiar to programmers of the C-family of languages, including <a href=\"/questions/tagged/c\" class=\"post-tag\" title=\"show questions tagged &#39;c&#39;\" rel=\"tag\" aria-labelledby=\"c-container\">c</a>, <a href=\"/questions/tagged/c%2b%2b\" class=\"post-tag\" title=\"show questions tagged &#39;c++&#39;\" rel=\"tag\" aria-labelledby=\"c++-container\">c++</a>, <a href=\"/questions/tagged/c%23\" class=\"post-tag\" title=\"show questions tagged &#39;c#&#39;\" rel=\"tag\" aria-labelledby=\"c#-container\">c#</a>, <a href=\"/questions/tagged/java\" class=\"post-tag\" title=\"show questions tagged &#39;java&#39;\" rel=\"tag\" aria-labelledby=\"java-container\">java</a>, <a href=\"/questions/tagged/javascript\" class=\"post-tag\" title=\"show questions tagged &#39;javascript&#39;\" rel=\"tag\" aria-labelledby=\"javascript-container\">javascript</a>, <a href=\"/questions/tagged/perl\" class=\"post-tag\" title=\"show questions tagged &#39;perl&#39;\" rel=\"tag\" aria-labelledby=\"perl-container\">perl</a>, <a href=\"/questions/tagged/python\" class=\"post-tag\" title=\"show questions tagged &#39;python&#39;\" rel=\"tag\" aria-labelledby=\"python-container\">python</a>, and <a href=\"https://en.wikipedia.org/wiki/List_of_C-family_programming_languages\" rel=\"nofollow noreferrer\">many others</a>. These properties make JSON an ideal data-interchange language to use with <a href=\"https://en.wikipedia.org/wiki/Representational_state_transfer\" rel=\"nofollow noreferrer\">RESTful</a> APIs or <a href=\"/questions/tagged/ajax\" class=\"post-tag\" title=\"show questions tagged &#39;ajax&#39;\" rel=\"tag\" aria-labelledby=\"ajax-container\">ajax</a>. It is often used instead of <a href=\"/questions/tagged/xml\" class=\"post-tag\" title=\"show questions tagged &#39;xml&#39;\" rel=\"tag\" aria-labelledby=\"xml-container\">xml</a> because of its lightweight and compact structure.</p>\n<p>Many programming languages provide methods for parsing a JSON-formatted text string into a native object and vice versa. For example, JavaScript in modern browsers and other environments includes the methods <a href=\"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/JSON/parse\" rel=\"nofollow noreferrer\">JSON.parse()</a> and <a href=\"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/JSON/stringify\" rel=\"nofollow noreferrer\">JSON.stringify()</a>.</p>\n<p>The JSON format is based on two types of structures:</p>\n<ul>\n<li><p>Collection of name/value pairs</p>\n<pre><code>{&quot;name1&quot;:&quot;value1&quot;, &quot;name2&quot;:&quot;value2&quot;}\n</code></pre>\n</li>\n<li><p>An ordered list of values (more commonly referred to as an array)</p>\n<pre><code>[&quot;value1&quot;, &quot;value2&quot;]\n</code></pre>\n</li>\n</ul>\n<p>JSON defines six types of values: <em>null</em>, <em>numbers</em>, <em>strings</em>, <em>booleans</em>, <em>arrays</em> and <em>objects</em>. With regard to objects, the order of members is not significant, and the behaviour of a JSON parser when duplicate member names are encountered is undefined.</p>\n<p>Note that <strong>JSON is <em>not</em> the same thing as JavaScript object literals</strong>. Instead, JSON is a standard format to serialize from and deserialize objects in most languages. For more information, see <a href=\"http://benalman.com/news/2010/03/theres-no-such-thing-as-a-json/\" rel=\"nofollow noreferrer\">There is no such thing as a JSON object in JavaScript</a>.</p>\n<p>Shortly after it was created, JSON validation was added following the description set out by Douglas Crockford of <em>json.org</em> in <a href=\"https://www.ietf.org/rfc/rfc4627.txt\" rel=\"nofollow noreferrer\">RFC 4627</a>. It has since been expanded to validate both current competing JSON standards <em>RFC 7159</em> and <em><a href=\"https://www.ecma-international.org/publications/standards/Ecma-404.htm\" rel=\"nofollow noreferrer\">ECMA-404</a></em>.</p>\n<hr>\n<h3>Advantages</h3>\n<ul>\n<li>JSON is a lightweight data-interchange format (no markup bloat)</li>\n<li>JSON is language independent.</li>\n<li>JSON is &quot;self-describing&quot; and easy to understand.</li>\n<li>JSON can be natively understood by JavaScript parsers, including node.js</li>\n</ul>\n<hr>\n<h3>JSON libraries</h3>\n<ul>\n<li>Java: <a href=\"https://jsonp.java.net/\" rel=\"nofollow noreferrer\">JSR 353 (JSONP)</a>, <a href=\"https://github.com/FasterXML/jackson\" rel=\"nofollow noreferrer\">FasterXML Jackson</a>, <a href=\"https://github.com/google/gson\" rel=\"nofollow noreferrer\">Google Gson</a>, <a href=\"https://github.com/douglascrockford/JSON-java\" rel=\"nofollow noreferrer\">JSON-Java</a>, or <a href=\"http://jsoniter.com/\" rel=\"nofollow noreferrer\">jsoniter</a></li>\n<li>JavaScript: <a href=\"https://github.com/douglascrockford/JSON-js\" rel=\"nofollow noreferrer\">json2.js</a> (only needed in old browsers without native JSON support)</li>\n<li>Ruby: <a href=\"https://github.com/flori/json\" rel=\"nofollow noreferrer\">JSON implementation for Ruby</a></li>\n<li>C#: <a href=\"https://github.com/JamesNK/Newtonsoft.Json\" rel=\"nofollow noreferrer\">JSON.Net</a></li>\n<li>Python 2: <a href=\"https://docs.python.org/2.7/library/json.html\" rel=\"nofollow noreferrer\">JSON encoder and decoder</a></li>\n<li>Python 3: <a href=\"https://docs.python.org/3.6/library/json.html\" rel=\"nofollow noreferrer\">JSON encoder and decoder</a></li>\n<li>PHP: <a href=\"https://php.net/manual/pt_BR/book.json.php\" rel=\"nofollow noreferrer\">JSON extension for PHP</a></li>\n<li>C:\n<ul>\n<li><a href=\"https://github.com/douglascrockford/JSON-java\" rel=\"nofollow noreferrer\">Jansson</a> \u2013 C library for encoding, decoding and manipulating JSON.</li>\n<li><a href=\"https://github.com/douglascrockford/JSON-js\" rel=\"nofollow noreferrer\">jsmn</a> \u2013 Minimalistic JSON parser.</li>\n<li><a href=\"https://github.com/flori/json\" rel=\"nofollow noreferrer\">json-c</a> \u2013 Library for working with JSON.</li>\n<li><a href=\"https://github.com/JamesNK/Newtonsoft.Json\" rel=\"nofollow noreferrer\">parson</a> \u2013 Lightweight JSON library written in C.</li>\n<li><a href=\"https://docs.python.org/2.7/library/json.html\" rel=\"nofollow noreferrer\">WJElement</a> \u2013 Advanced JSON manipulation library, with support for JSON Schema.</li>\n<li><a href=\"https://docs.python.org/3.6/library/json.html\" rel=\"nofollow noreferrer\">YAJL</a> \u2013 Fast C JSON streaming parser library.</li>\n<li><a href=\"https://github.com/DaveGamble/cJSON\" rel=\"nofollow noreferrer\">cJSON</a> \u2013 Ultralightweight JSON parser</li>\n</ul>\n</li>\n<li>C++:\n<ul>\n<li><a href=\"https://github.com/nlohmann/json\" rel=\"nofollow noreferrer\">nlohmann/json</a> \u2013 JSON for Modern C++</li>\n<li><a href=\"https://rapidjson.org/\" rel=\"nofollow noreferrer\">RapidJSON</a> \u2013 Fast JSON parser/generator with SAM/DOM API</li>\n<li><a href=\"https://github.com/taocpp/json\" rel=\"nofollow noreferrer\">taoJSON</a> \u2013 header-only JSON library</li>\n</ul>\n</li>\n<li>Scala: <a href=\"https://www.playframework.com/documentation/2.8.x/ScalaJson\" rel=\"nofollow noreferrer\">play-json</a>, <a href=\"https://json4s.org/\" rel=\"nofollow noreferrer\">json4s</a>, <a href=\"https://github.com/spray/spray-json\" rel=\"nofollow noreferrer\">spray-json</a>, and much more as elaborated at <a href=\"https://stackoverflow.com/q/8054018/2359227\">What JSON library to use in Scala?</a></li>\n</ul>\n<hr>\n<h3>Browser Addons</h3>\n<ul>\n<li><a href=\"https://chrome.google.com/webstore/detail/pretty-json/kililblhcfpodipkcbobnbgnbbhgbkji?hl=en\" rel=\"nofollow noreferrer\">Pretty JSON for Chrome</a></li>\n<li><a href=\"https://addons.mozilla.org/en-US/firefox/addon/10869\" rel=\"nofollow noreferrer\">JSONView for Firefox</a></li>\n<li><a href=\"https://chrome.google.com/webstore/detail/json-formatter/bcjindcccaagfpapjjmafapmmgkkhgoa?hl=en\" rel=\"nofollow noreferrer\">JSON Formatter for Chrome</a></li>\n</ul>\n<hr />\n<h3>Useful links</h3>\n<ul>\n<li><a href=\"https://en.wikipedia.org/wiki/JSON\" rel=\"nofollow noreferrer\">Wikipedia page</a></li>\n<li><a href=\"https://www.json.com\" rel=\"nofollow noreferrer\">JSON Example</a></li>\n<li><a href=\"https://www.copterlabs.com/json-what-it-is-how-it-works-how-to-use-it/\" rel=\"nofollow noreferrer\">JSON: What It Is, How It Works, &amp; How to Use It</a></li>\n<li><a href=\"https://developer.mozilla.org/en-US/docs/JSON\" rel=\"nofollow noreferrer\">JSON on Mozilla Developer Network</a></li>\n<li><a href=\"https://jsonlint.com/\" rel=\"nofollow noreferrer\">JSONLint</a></li>\n<li><a href=\"https://msdn.microsoft.com/en-us/library/bb299886.aspx\" rel=\"nofollow noreferrer\">JSON-Introduction By Microsoft</a></li>\n<li><a href=\"https://www.wired.com/2010/02/get_started_with_json/\" rel=\"nofollow noreferrer\">Get Started With JSON</a> (Introduction at Wired)</li>\n<li><a href=\"https://github.com/douglascrockford/JSON-js\" rel=\"nofollow noreferrer\">JSON library for old browsers</a> (IE8 and below)</li>\n<li><a href=\"https://stackoverflow.com/questions/tagged/json?sort=frequent&amp;pagesize=50\">FAQ</a> on Stack Overflow</li>\n<li><a href=\"https://stedolan.github.io/jq/\" rel=\"nofollow noreferrer\">jq</a> (Command line JSON processor)</li>\n<li><a href=\"https://jsonformatter.curiousconcept.com/\" rel=\"nofollow noreferrer\">JSON Formatter &amp; Validator</a></li>\n<li><a href=\"https://stackoverflow.com/questions/5615352/xml-and-json-advantages-and-disadvantages\">XML and JSON -- Advantages and Disadvantages?</a></li>\n</ul>\n<hr />\n<h3>Books</h3>\n<ul>\n<li><a href=\"https://www.apress.com/9781484202036\" rel=\"nofollow noreferrer\">Beginning JSON</a></li>\n<li><a href=\"http://shop.oreilly.com/product/0636920041597.do\" rel=\"nofollow noreferrer\">Introduction to JavaScript Object Notation A To-the-Point Guide to JSON</a></li>\n<li><a href=\"https://www.packtpub.com/application-development/javascript-json-cookbook\" rel=\"nofollow noreferrer\">JavaScript JSON Cookbook</a></li>\n<li><a href=\"https://www.packtpub.com/web-development/javascript-and-json-essentials\" rel=\"nofollow noreferrer\">JavaScript and JSON Essentials</a></li>\n</ul>\n<hr />\n<h3>See also</h3>\n<p><a href=\"/questions/tagged/jsonp\" class=\"post-tag\" title=\"show questions tagged &#39;jsonp&#39;\" rel=\"tag\" aria-labelledby=\"jsonp-container\">jsonp</a> <a href=\"/questions/tagged/xml\" class=\"post-tag\" title=\"show questions tagged &#39;xml&#39;\" rel=\"tag\" aria-labelledby=\"xml-container\">xml</a> <a href=\"/questions/tagged/s-expression\" class=\"post-tag\" title=\"show questions tagged &#39;s-expression&#39;\" rel=\"tag\" aria-labelledby=\"s-expression-container\">s-expression</a> <a href=\"/questions/tagged/javascript\" class=\"post-tag\" title=\"show questions tagged &#39;javascript&#39;\" rel=\"tag\" aria-labelledby=\"javascript-container\">javascript</a> <a href=\"/questions/tagged/rest\" class=\"post-tag\" title=\"show questions tagged &#39;rest&#39;\" rel=\"tag\" aria-labelledby=\"rest-container\">rest</a> <a href=\"/questions/tagged/jackson\" class=\"post-tag\" title=\"show questions tagged &#39;jackson&#39;\" rel=\"tag\" aria-labelledby=\"jackson-container\">jackson</a> <a href=\"/questions/tagged/gson\" class=\"post-tag\" title=\"show questions tagged &#39;gson&#39;\" rel=\"tag\" aria-labelledby=\"gson-container\">gson</a> <a href=\"/questions/tagged/markup\" class=\"post-tag\" title=\"show questions tagged &#39;markup&#39;\" rel=\"tag\" aria-labelledby=\"markup-container\">markup</a></p>\n",
                    "OwnerUserId": "218196",
                    "LastEditorUserId": "4595675",
                    "LastEditDate": "2022-09-02T12:13:49.190",
                    "LastActivityDate": "2022-09-02T12:13:49.190",
                    "CommentCount": "0",
                    "CommunityOwnedDate": "2012-06-14T02:51:12.357",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "5318688",
                "ParentRepo": "https://github.com/github/linguist",
                "StackOverflow_Post": {
                    "Id": "5318688",
                    "PostTypeId": "2",
                    "ParentId": "5318580",
                    "CreationDate": "2011-03-15T22:07:50.693",
                    "Score": "88",
                    "Body": "<p>Update April 2013, by <a href=\"https://stackoverflow.com/users/304339/nuclearsandwich\">nuclearsandwich</a> (GitHub support team or &quot;supportocat&quot;):</p>\n<ul>\n<li><p>the help page &quot;<a href=\"https://help.github.com/articles/my-repository-is-marked-as-the-wrong-language\" rel=\"noreferrer\">My repository is marked as the wrong language</a>&quot; mentions using now the <a href=\"https://github.com/github/linguist\" rel=\"noreferrer\"><strong>linguist library</strong></a> to determine file language for syntax highlighting and repo statistics. Linguist will exclude certain file names and paths from statistic, <a href=\"https://github.com/github/linguist/blob/master/lib/linguist/vendor.yml\" rel=\"noreferrer\">excluding certain vendor files and directories</a>.</p>\n</li>\n<li><p>the help page &quot;<a href=\"https://help.github.com/articles/why-isn-t-my-favorite-language-recognized\" rel=\"noreferrer\">Why isn't my favorite language recognized?</a>&quot; adds:</p>\n</li>\n</ul>\n<blockquote>\n<p>If your desired language is not receiving syntax highlighting you can contribute to the Linguist library to add it.</p>\n</blockquote>\n<hr />\n<p>(Original answer, Oct. 2012)</p>\n<p>This <a href=\"http://support.github.com/discussions/site/1969-wrong-language-tag\" rel=\"noreferrer\">thread on GitHub support</a> explains it:</p>\n<blockquote>\n<p>It just sums up file sizes for each extension. Largest one &quot;wins&quot;.</p>\n<p>We'd like to avoid opening files up and parsing their content, as both would slow down the process... but that might be the only method of resolving conflicts like this one.</p>\n</blockquote>\n<p>Since this is not 100% accurate, that had lead some to add:</p>\n<blockquote>\n<p>I, too, would vote for a simple manual-override switch for the cases where the guess is wrong.</p>\n</blockquote>\n<hr />\n<p>Note: as <a href=\"https://stackoverflow.com/users/126042/mark-rushakoff\">Mark Rushakoff</a> mentions in <a href=\"https://stackoverflow.com/a/10047563/6309\">his answer</a> (upvoted), the guessing got better since then with the <a href=\"https://github.com/github/linguist\" rel=\"noreferrer\">linguist project</a> (open-sourced from June 2011).<br />\nYou can see there are still issues though: <a href=\"https://github.com/github/linguist/issues\" rel=\"noreferrer\">GitHub Linguist Issues</a>.<br />\nSee <a href=\"http://digitizor.com/2011/07/01/github-linguist-open-source/\" rel=\"noreferrer\">here for more details</a>:</p>\n<blockquote>\n<p>Once the language has been detected, it is passed to <a href=\"https://github.com/github/albino\" rel=\"noreferrer\">Albino</a>, a <a href=\"http://pygments.org/\" rel=\"noreferrer\">Pygments</a> wrapper, which does the actual syntax highlighting.</p>\n</blockquote>\n<p>And you can <a href=\"https://stackoverflow.com/a/13599737/6309\"><strong>add linguist directives in a .gitattributes file</strong></a>.</p>\n",
                    "OwnerUserId": "6309",
                    "LastEditorUserId": "-1",
                    "LastEditDate": "2020-06-20T09:12:55.060",
                    "LastActivityDate": "2017-02-16T09:24:25.670",
                    "CommentCount": "4",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "5503999",
                "ParentRepo": "https://github.com/tomchristie/django-rest-framework/blob/master/rest_framework/serializers.py",
                "StackOverflow_Post": {
                    "Id": "5503999",
                    "PostTypeId": "2",
                    "ParentId": "5503925",
                    "CreationDate": "2011-03-31T17:41:01.647",
                    "Score": "86",
                    "Body": "<p>Use <code>**</code> for creating a new model. Loop through the dictionary and use <code>setattr()</code> in order to update an existing model.</p>\n\n<p>From Tom Christie's Django Rest Framework</p>\n\n<p><a href=\"https://github.com/tomchristie/django-rest-framework/blob/master/rest_framework/serializers.py\" rel=\"noreferrer\">https://github.com/tomchristie/django-rest-framework/blob/master/rest_framework/serializers.py</a></p>\n\n<pre><code>for attr, value in validated_data.items():\n    setattr(instance, attr, value)\ninstance.save()\n</code></pre>\n",
                    "OwnerUserId": "20862",
                    "LastEditorUserId": "1199464",
                    "LastEditDate": "2016-06-20T14:54:27.077",
                    "LastActivityDate": "2016-06-20T14:54:27.077",
                    "CommentCount": "6",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "6155297",
                "ParentRepo": "https://github.com/minetest/minetest/blob/master/src/noise.cpp",
                "StackOverflow_Post": {
                    "Id": "6155297",
                    "PostTypeId": "2",
                    "ParentId": "6091468",
                    "CreationDate": "2011-05-27T16:42:53.733",
                    "Score": "5",
                    "Body": "<p>You should look at the Minetest source, specifically at the files <a href=\"https://github.com/minetest/minetest/blob/master/src/noise.cpp\" rel=\"nofollow\">noise.cpp</a> and <a href=\"https://github.com/minetest/minetest/blob/master/src/mapgen_v7.cpp\" rel=\"nofollow\">map.cpp</a>.</p>\n",
                    "OwnerUserId": "773469",
                    "LastEditorUserId": "712526",
                    "LastEditDate": "2015-12-02T22:30:26.757",
                    "LastActivityDate": "2015-12-02T22:30:26.757",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "6203877",
                "ParentRepo": "https://github.com/carlmontanari/scrapli/blob/main/requirements-paramiko.txt",
                "StackOverflow_Post": {
                    "Id": "6203877",
                    "PostTypeId": "2",
                    "ParentId": "6203653",
                    "CreationDate": "2011-06-01T15:41:20.480",
                    "Score": "47",
                    "Body": "<h3>Non-Interactive use cases</h3>\n<p>This is a <em>non-interactive</em> example... it sends <code>cd tmp</code>, <code>ls</code> and then <code>exit</code>.</p>\n<pre><code>import sys\nsys.stderr = open('/dev/null')       # Silence silly warnings from paramiko\nimport paramiko as pm\nsys.stderr = sys.__stderr__\nimport os\n\nclass AllowAllKeys(pm.MissingHostKeyPolicy):\n    def missing_host_key(self, client, hostname, key):\n        return\n\nHOST = '127.0.0.1'\nUSER = ''\nPASSWORD = ''\n\nclient = pm.SSHClient()\nclient.load_system_host_keys()\nclient.load_host_keys(os.path.expanduser('~/.ssh/known_hosts'))\nclient.set_missing_host_key_policy(AllowAllKeys())\nclient.connect(HOST, username=USER, password=PASSWORD)\n\nchannel = client.invoke_shell()\nstdin = channel.makefile('wb')\nstdout = channel.makefile('rb')\n\nstdin.write('''\ncd tmp\nls\nexit\n''')\nprint stdout.read()\n\nstdout.close()\nstdin.close()\nclient.close()\n</code></pre>\n<h3>Interactive use cases</h3>\n<p>If you have an interactive ssh use case, <a href=\"https://pypi.org/project/paramiko/\" rel=\"nofollow noreferrer\"><code>paramiko</code></a> can handle it... I personally would drive interactive ssh sessions with <a href=\"https://pypi.org/project/scrapli/\" rel=\"nofollow noreferrer\"><code>scrapli</code></a>.</p>\n<p>Listing all the ways I can think of to use <a href=\"https://pypi.org/project/paramiko/\" rel=\"nofollow noreferrer\"><code>paramiko</code></a> interactively:</p>\n<ul>\n<li>See <a href=\"https://stackoverflow.com/users/3337089/nagabhushan-s-n\">nagabhushan's answer</a> which uses <code>paramiko</code> interactively</li>\n<li>By default, <a href=\"https://github.com/ansible/ansible/blob/devel/lib/ansible/config/base.yml\" rel=\"nofollow noreferrer\">ansible paramiko usage is configurable</a></li>\n<li>By default, <a href=\"https://github.com/knipknap/exscript/blob/master/requirements.txt\" rel=\"nofollow noreferrer\">exscript ssh uses paramiko</a></li>\n<li>By default, <a href=\"https://github.com/ktbyers/netmiko/blob/develop/setup.py\" rel=\"nofollow noreferrer\">netmiko ssh uses paramiko</a></li>\n<li>By default, <a href=\"https://github.com/carlmontanari/scrapli/blob/main/requirements-paramiko.txt\" rel=\"nofollow noreferrer\">scrapli ssh uses paramiko</a></li>\n</ul>\n<p>I might have missed some libraries that use <a href=\"https://pypi.org/project/paramiko/\" rel=\"nofollow noreferrer\"><code>paramiko</code></a>, but it should be clear that <a href=\"https://pypi.org/project/paramiko/\" rel=\"nofollow noreferrer\"><code>paramiko</code></a> is used quite extensively by python libraries that control ssh sessions.</p>\n",
                    "OwnerUserId": "667301",
                    "LastEditorUserId": "667301",
                    "LastEditDate": "2022-10-12T14:09:01.663",
                    "LastActivityDate": "2022-10-12T14:09:01.663",
                    "CommentCount": "13",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "7808247",
                "ParentRepo": "https://github.com/FakeItEasy/FakeItEasy/issues/new",
                "StackOverflow_Post": {
                    "Id": "7808247",
                    "PostTypeId": "2",
                    "ParentId": "7801899",
                    "CreationDate": "2011-10-18T13:47:19.700",
                    "Score": "0",
                    "Body": "<p>I can't reproduce the problem, when running equivalent code it works for me. Could you create a vs-solution that reproduces the problem and <a href=\"https://github.com/FakeItEasy/FakeItEasy/issues/new\" rel=\"nofollow\">submit an issue on GitHub</a>?</p>\n",
                    "OwnerUserId": "46187",
                    "LastEditorUserId": "1199",
                    "LastEditDate": "2016-05-27T19:25:31.860",
                    "LastActivityDate": "2016-05-27T19:25:31.860",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "8287898",
                "ParentRepo": "https://github.com/openplans/OpenTripPlanner/wiki/",
                "StackOverflow_Post": {
                    "Id": "8287898",
                    "PostTypeId": "2",
                    "ParentId": "8283260",
                    "CreationDate": "2011-11-27T18:25:33.073",
                    "Score": "1",
                    "Body": "<p>It's not possible with the API alone.  You'll have to find the route between the two stations and get the path for each segment (which would be constrained to a single line) individually.  There's also no API for the Trip Planner (nor Google Transit), so you'll have to maintain your own database of stations to do the routing.  That's fairly straightforward except in cases where there's more than one logical transfer point (such as going downtown on the Red Line from the Glenmont end, where you can transfer to the Green/Yellow Lines at Fort Totten and at Gallery Place; you'll either have to ask the user which route they want, or pick one arbitrarily).  There are also some edge cases for routing, like when the Yellow Line doesn't go to Fort Totten.  If you wanted to avoid the work of building the routing engine yourself, you might find <a href=\"https://github.com/openplans/OpenTripPlanner/wiki/\" rel=\"nofollow\" title=\"OpenTripPlanner\">OpenTripPlanner</a> to be helpful, since you can just load the WMATA GTFS into OTP, but it might also be overkill for your needs.</p>\n",
                    "OwnerUserId": "1068191",
                    "LastActivityDate": "2011-11-27T18:25:33.073",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "10474537",
                "ParentRepo": "https://github.com/Python-Markdown/markdown/commit/7db56daedf8a6006222f55eeeab748e7789fba89",
                "StackOverflow_Post": {
                    "Id": "10474537",
                    "PostTypeId": "2",
                    "ParentId": "8409284",
                    "CreationDate": "2012-05-06T21:40:34.240",
                    "Score": "5",
                    "Body": "<p>The Python Markdown library appears to be safe as far as anyone knows, <a href=\"https://security.stackexchange.com/q/14664/971\">if you use it properly</a>.  See the link for details about how to use it safely, but the short version is: it is important to use the latest version, to set <code>safe_mode</code>, and to set <code>enable_attributes=False</code>.</p>\n\n<p>Update: <code>safe_mode</code> is now due to be deprecated, because of the security problems with it.  See <a href=\"https://github.com/Python-Markdown/markdown/commit/7db56daedf8a6006222f55eeeab748e7789fba89\" rel=\"nofollow noreferrer\">https://github.com/Python-Markdown/markdown/commit/7db56daedf8a6006222f55eeeab748e7789fba89</a>.  Instead, use a separate HTML sanitizer, such as HTML Purifier.</p>\n",
                    "OwnerUserId": "781723",
                    "LastEditorUserId": "781723",
                    "LastEditDate": "2019-04-11T18:09:02.767",
                    "LastActivityDate": "2019-04-11T18:09:02.767",
                    "CommentCount": "7",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "10920773",
                "ParentRepo": "https://github.com/chrisspen/django-chroniker",
                "StackOverflow_Post": {
                    "Id": "10920773",
                    "PostTypeId": "2",
                    "ParentId": "10918905",
                    "CreationDate": "2012-06-06T19:22:04.423",
                    "Score": "2",
                    "Body": "<p>There are several Django-based scheduling apps, such as <a href=\"https://bitbucket.org/wnielson/django-chronograph/\" rel=\"nofollow\">django-chronograph</a> and <a href=\"https://github.com/chrisspen/django-chroniker\" rel=\"nofollow\">django-chroniker</a> and <a href=\"http://code.google.com/p/django-cron/\" rel=\"nofollow\">django-cron</a>. I forked django-chronograph into django-chroniker to fix a few bugs and extend it for my own use case. I still use Celery in some projects, but like you point out, it's a bit overcomplicated and has a large stack.</p>\n",
                    "OwnerUserId": "247542",
                    "LastActivityDate": "2012-06-06T19:22:04.423",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "11442996",
                "ParentRepo": "https://github.com/encode/django-rest-framework",
                "StackOverflow_Post": {
                    "Id": "11442996",
                    "PostTypeId": "5",
                    "CreationDate": "2012-07-11T23:24:18.447",
                    "Score": "0",
                    "Body": "<p>Django REST framework is a Web API framework for Django and\nis suitable for building complex, highly customizable APIs and web services.</p>\n<p>Features include:</p>\n<ul>\n<li>Built-in support for various authentication, permissions, versioning, throttling and other API policies.</li>\n<li>Creates APIs that can be interacted with directly in the browser (also known as <a href=\"https://www.django-rest-framework.org/topics/browsable-api/\" rel=\"nofollow noreferrer\">Browsable</a> APIs).</li>\n<li>Large ecosystem of <a href=\"https://djangopackages.org/grids/g/django-rest-framework/\" rel=\"nofollow noreferrer\">third party packages</a>.</li>\n</ul>\n<hr />\n<p><a href=\"http://django-rest-framework.org/\" rel=\"nofollow noreferrer\">Documentation</a> | <a href=\"https://github.com/encode/django-rest-framework\" rel=\"nofollow noreferrer\">GitHub</a> | <a href=\"https://groups.google.com/forum/?fromgroups#!forum/django-rest-framework\" rel=\"nofollow noreferrer\">Mailing list</a></p>\n<hr />\n<p>Related tags:</p>\n<p><a href=\"/questions/tagged/rest\" class=\"post-tag\" title=\"show questions tagged &#39;rest&#39;\" rel=\"tag\">rest</a>\n<a href=\"/questions/tagged/web-service\" class=\"post-tag\" title=\"show questions tagged &#39;web-service&#39;\" rel=\"tag\">web-service</a>\n<a href=\"/questions/tagged/django\" class=\"post-tag\" title=\"show questions tagged &#39;django&#39;\" rel=\"tag\">django</a></p>\n",
                    "OwnerUserId": "319931",
                    "LastEditorUserId": "63550",
                    "LastEditDate": "2022-02-08T12:24:05.790",
                    "LastActivityDate": "2022-02-08T12:24:05.790",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "13382453",
                "ParentRepo": "https://github.com/apenwarr/redo/",
                "StackOverflow_Post": {
                    "Id": "13382453",
                    "PostTypeId": "2",
                    "ParentId": "13381169",
                    "CreationDate": "2012-11-14T16:03:17.860",
                    "Score": "1",
                    "Body": "<p>Tup looks interesting...</p>\n\n<p><a href=\"http://gittup.org/tup/\" rel=\"nofollow\">http://gittup.org/tup/</a></p>\n\n<p>and djb redo:</p>\n\n<p><a href=\"https://github.com/apenwarr/redo/\" rel=\"nofollow\">https://github.com/apenwarr/redo/</a></p>\n\n<p>and shake:</p>\n\n<p><a href=\"http://hackage.haskell.org/package/shake\" rel=\"nofollow\">http://hackage.haskell.org/package/shake</a></p>\n",
                    "OwnerUserId": "139802",
                    "LastActivityDate": "2012-11-14T16:03:17.860",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "13538239",
                "ParentRepo": "https://github.com/waylan/Python-Markdown/issues/80",
                "StackOverflow_Post": {
                    "Id": "13538239",
                    "PostTypeId": "2",
                    "ParentId": "1705895",
                    "CreationDate": "2012-11-24T04:23:04.683",
                    "Score": "3",
                    "Body": "<p>The relevant bug report states that the extra extension adds that: <a href=\"https://github.com/waylan/Python-Markdown/issues/80\" rel=\"nofollow\">https://github.com/waylan/Python-Markdown/issues/80</a></p>\n\n<p>Then you can add markdown=\"1\" to div tags to have markdown parsed inside</p>\n\n<pre><code>&lt;div markdown=\"1\"&gt;\n*markdown*\n&lt;/div&gt;\n</code></pre>\n",
                    "OwnerUserId": "7666",
                    "LastEditorUserId": "7666",
                    "LastEditDate": "2013-03-25T11:16:55.427",
                    "LastActivityDate": "2013-03-25T11:16:55.427",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "14503352",
                "ParentRepo": "https://github.com/appium/appium",
                "StackOverflow_Post": {
                    "Id": "14503352",
                    "PostTypeId": "2",
                    "ParentId": "14501503",
                    "CreationDate": "2013-01-24T14:14:03.393",
                    "Score": "3",
                    "Body": "<p>Watir (and Selenium) can automate browsers only (including browsers on mobile devices). If you need to automate native mobile applications, take a look at <a href=\"https://github.com/appium/appium\" rel=\"nofollow\">appium</a>, <a href=\"https://github.com/calabash\" rel=\"nofollow\">calabash</a>, <a href=\"https://github.com/moredip/Frank\" rel=\"nofollow\">Frank</a> or <a href=\"http://code.google.com/p/robotium/\" rel=\"nofollow\">robotium</a>.</p>\n",
                    "OwnerUserId": "17469",
                    "LastEditorUserId": "17469",
                    "LastEditDate": "2013-01-25T11:13:37.123",
                    "LastActivityDate": "2013-01-25T11:13:37.123",
                    "CommentCount": "4",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "14688107",
                "ParentRepo": "https://github.com/apache/spark",
                "StackOverflow_Post": {
                    "Id": "14688107",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "14688259",
                    "CreationDate": "2013-02-04T13:47:25.403",
                    "Score": "7",
                    "ViewCount": "4836",
                    "Body": "<p>I'm trying to use the <code>takeSample()</code> function in <a href=\"https://github.com/apache/spark\" rel=\"nofollow\">Spark</a> and the parameters are - <strong>data, number of samples to be taken and the seed</strong>. But I don't want to use the seed. I want to have a different answer everytime. I'm not able to figure out how I can do that. I tried using <code>System.nanoTime</code> as the seed value but it gave an error since I think the data type didn't match. Is there any other function similar to <code>takeSample()</code> that can be used without the seed? Or is there any other implementation I can use with <code>takeSample()</code> so that I get a different output every time.</p>\n",
                    "OwnerUserId": "1976622",
                    "LastEditorUserId": "4028388",
                    "LastEditDate": "2016-10-06T21:34:47.407",
                    "LastActivityDate": "2016-10-06T21:34:47.407",
                    "Title": "takeSample() function in Spark",
                    "Tags": "<scala><random><seeding>",
                    "AnswerCount": "3",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "15358472",
                "ParentRepo": "https://github.com/marcgibbons/django-rest-swagger",
                "StackOverflow_Post": {
                    "Id": "15358472",
                    "PostTypeId": "2",
                    "ParentId": "15357729",
                    "CreationDate": "2013-03-12T10:16:35.313",
                    "Score": "2",
                    "Body": "<p>Take a look at the <code>django-rest-framework-docs</code> package:</p>\n\n<p><a href=\"https://github.com/marcgibbons/django-rest-framework-docs\" rel=\"nofollow\">https://github.com/marcgibbons/django-rest-framework-docs</a></p>\n\n<p>Also the newer <code>django-rest-swagger</code> package, by the same author:</p>\n\n<p><a href=\"https://github.com/marcgibbons/django-rest-swagger\" rel=\"nofollow\">https://github.com/marcgibbons/django-rest-swagger</a></p>\n",
                    "OwnerUserId": "596689",
                    "LastEditorUserId": "596689",
                    "LastEditDate": "2013-06-28T13:05:11.450",
                    "LastActivityDate": "2013-06-28T13:05:11.450",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "15400386",
                "ParentRepo": "https://github.com/jisaacks/GitGutter",
                "StackOverflow_Post": {
                    "Id": "15400386",
                    "PostTypeId": "2",
                    "ParentId": "14891364",
                    "CreationDate": "2013-03-14T02:58:23.537",
                    "Score": "42",
                    "Body": "<p>Ok a couple things here.</p>\n\n<p>First off, The <code>git blame</code> feature is not a part of my <a href=\"https://github.com/jisaacks/GitGutter\" rel=\"noreferrer\"><strong>GitGutter</strong></a> plugin, it is a part of the <a href=\"https://github.com/kemayo/sublime-text-2-git\" rel=\"noreferrer\"><strong>Git</strong></a> plugin.</p>\n\n<p>Secondly, @skuroda is correct that you can only put an icon in the gutter.</p>\n\n<p>What you can do to simulate this tho: is use the split pane <strong>View > Layout > Columns: 2</strong> and put the git blame on the left pane and the actual file on the right pane. You will want to turn off word wrap <strong>View > Word Wrap</strong></p>\n\n<p>Here is a screen shot:\n<img src=\"https://i.stack.imgur.com/WzB1D.png\" alt=\"enter image description here\"></p>\n\n<hr>\n\n<p>Then your only problem is to keep the 2 views in sync when you scroll. I haven't tested it but it looks like this sublime plugin might do that: <a href=\"https://bitbucket.org/theblacklion/sublime_plugins/commits/3ea0c9e35d2f/#chg-glue_views.py\" rel=\"noreferrer\">glue views</a></p>\n",
                    "OwnerUserId": "46011",
                    "LastActivityDate": "2013-03-14T02:58:23.537",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "15699486",
                "ParentRepo": "https://github.com/v2tec/watchtower",
                "StackOverflow_Post": {
                    "Id": "15699486",
                    "PostTypeId": "5",
                    "CreationDate": "2013-03-29T07:57:14.827",
                    "Score": "0",
                    "Body": "<p>The term <code>docker</code> usually refers to a set of open-source tools that allow developers to build and run containers individually or as a 'stack' of related containers. A container is an isolated package that contains everything, except for the kernel, needed to run a piece of software. Docker was initially written to work with Linux and has recently been implemented on MS Windows. <a href=\"https://www.docker.com/company\" rel=\"nofollow noreferrer\">Docker Inc.</a> is the company behind the open-source <code>docker</code> toolset.</p>\n<p>Docker builds a high-level API over execution drivers, such as OpenVZ, systemd-nspawn, libvirt-lxc, libvirt, QEMU/KVM, BSD Jails, Solaris Zones, and chroot to run processes with some degree of isolation and repeatability across environments. The default execution driver since release 0.9 is Docker's own libcontainer driver. It's mainly written in <a href=\"https://golang.org/\" rel=\"nofollow noreferrer\">Go</a>, and its source code can be found on <a href=\"https://github.com/moby/moby\" rel=\"nofollow noreferrer\">Github</a>. See Docker's <a href=\"https://www.docker.com/\" rel=\"nofollow noreferrer\">official website</a> for details.</p>\n<p>For a docker installation on different operating systems such as Linux, Windows, or OS X, details can be found <a href=\"https://docs.docker.com/\" rel=\"nofollow noreferrer\">here</a>; from this site, information about Docker under Windows, Mac or Linux distributions can be accessed. On Windows and OS-X, docker runs in a variety of VM.</p>\n<p>Releases have three types: stable, edge and test. The latest stable version is given by the following badge (links to the corresponding release notes): <a href=\"https://docs.docker.com/engine/release-notes/\" rel=\"nofollow noreferrer\"><img src=\"https://img.shields.io/docker/v/_/docker/latest\" alt=\"docker:latest version\" /></a></p>\n<p>Note that since May 2017, docker is a <em>product</em> (split into <a href=\"https://www.docker.com/community-edition\" rel=\"nofollow noreferrer\">CE</a> and <a href=\"https://www.docker.com/enterprise-edition\" rel=\"nofollow noreferrer\">EE</a>) built on top of the open-source <em>project</em> <a href=\"https://github.com/moby/moby\" rel=\"nofollow noreferrer\">Moby</a>. In November 2019, Docker Inc. <a href=\"https://techcrunch.com/2019/11/13/mirantis-acquires-docker-enterprise\" rel=\"nofollow noreferrer\">sold its enterprise business and software to Mirantis</a>. For more, see &quot;<a href=\"https://collabnix.com/demystifying-the-relationship-between-moby-docker/\" rel=\"nofollow noreferrer\">Demystifying the Relationship Between Moby &amp; Docker</a>&quot;.</p>\n<h1>Where to ask</h1>\n<p>Questions on Stack Overflow must be programming-related; see the extended description in the <a href=\"https://stackoverflow.com/help/on-topic\">help centre</a> for more details.  Questions about using Docker as a live development environment, mechanics of the Dockerfile system, and other questions that clearly involve application source code are generally welcome.</p>\n<p>Questions about installing Docker or running prebuilt images are typically not programming-oriented and are not on-topic for Stack Overflow.  Consider asking these questions on <a href=\"https://superuser.com\">Super User</a>, or a site more specific to your host operating system (<a href=\"https://askubuntu.com\">Ask Ubuntu</a>, <a href=\"https://unix.stackexchange.com\">Unix &amp; Linux</a>, <a href=\"https://raspberrypi.stackexchange.com\">Raspberry Pi Stack Exchange</a>, <a href=\"https://apple.stackexchange.com\">Ask Different</a> for macOS).  Questions about using a Linux distribution package manager such as <code>apt-get</code> or <code>apk</code> are similarly inappropriate for Stack Overflow, even if they are otherwise in the context of a Dockerfile.</p>\n<p>There are other container-management tools adjacent to Docker.  In particular, <a href=\"/questions/tagged/kubernetes\" class=\"post-tag\" title=\"show questions tagged &#39;kubernetes&#39;\" rel=\"tag\" aria-labelledby=\"kubernetes-container\">kubernetes</a> is often used in combination with images produced with Docker.  The <a href=\"/questions/tagged/docker\" class=\"post-tag\" title=\"show questions tagged &#39;docker&#39;\" rel=\"tag\" aria-labelledby=\"docker-container\">docker</a> tag should be used when a question is principally about native-Docker technologies, including <a href=\"/questions/tagged/docker-compose\" class=\"post-tag\" title=\"show questions tagged &#39;docker-compose&#39;\" rel=\"tag\" aria-labelledby=\"docker-compose-container\">docker-compose</a> and the <a href=\"/questions/tagged/dockerfile\" class=\"post-tag\" title=\"show questions tagged &#39;dockerfile&#39;\" rel=\"tag\" aria-labelledby=\"dockerfile-container\">dockerfile</a> build system; but omit <a href=\"/questions/tagged/docker\" class=\"post-tag\" title=\"show questions tagged &#39;docker&#39;\" rel=\"tag\" aria-labelledby=\"docker-container\">docker</a> if a question is principally about a Kubernetes YAML file or another adjacent technology and only includes a Docker image by reference.</p>\n<h1>Frequently asked questions</h1>\n<ul>\n<li><p>If code in one Compose-managed Docker container needs to connect to another, it needs to use the other container's Compose service name and the standard port for the service, ignoring the Compose <code>ports:</code>.  The unique hostname <code>localhost</code> refers to the current container and not a different container or the host.  See <a href=\"https://docs.docker.com/compose/networking/\" rel=\"nofollow noreferrer\">Networking in Compose</a> in the Docker documentation, or <a href=\"https://stackoverflow.com/questions/42385977/accessing-a-docker-container-from-another-container\">accessing a docker container from another container</a>.</p>\n</li>\n<li><p>If code in a Docker container needs to reach a service such as a database running on the same host but not in a container, on macOS and Windows hosts, it needs to connect to the unique hostname <code>host.docker.internal</code>.  See <a href=\"https://stackoverflow.com/questions/24319662/from-inside-of-a-docker-container-how-do-i-connect-to-the-localhost-of-the-mach\">From inside of a Docker container, how do I connect to the machine's localhost?</a>.</p>\n</li>\n</ul>\n<h1>Where to start</h1>\n<ul>\n<li><a href=\"https://github.com/prakhar1989/docker-curriculum\" rel=\"nofollow noreferrer\">Docker Curriculum</a>: A comprehensive tutorial for getting started with Docker. Teaches how to use Docker and deploy dockerized apps on AWS with Elastic Beanstalk and Elastic Container Service.</li>\n<li><a href=\"https://docs.docker.com/\" rel=\"nofollow noreferrer\">Docker Documentation</a>: the official documentation</li>\n<li><a href=\"https://success.docker.com/training\" rel=\"nofollow noreferrer\">Docker Training :heavy_dollar_sign:</a></li>\n<li><a href=\"https://www.katacoda.com/courses/docker\" rel=\"nofollow noreferrer\">Katacoda</a>: Learn Docker using Interactive Browser-Based Labs</li>\n<li><a href=\"https://github.com/dwyl/learn-docker\" rel=\"nofollow noreferrer\">Learn Docker</a>: a step-by-step tutorial and more resources (video, articles, cheat sheets) by <a href=\"https://github.com/dwyl\" rel=\"nofollow noreferrer\">@dwyl</a></li>\n<li><a href=\"https://training.play-with-docker.com/\" rel=\"nofollow noreferrer\">Play With Docker</a>: PWD is a great way to get started with Docker for beginner to advanced users. Docker runs directly in your browser.</li>\n<li><a href=\"http://play-with-moby.com/\" rel=\"nofollow noreferrer\">Play With Moby</a>: PWM is a web-based Moby playground which allows you to try different components of the platform in seconds. It gives you the experience of having a free Alpine Linux Virtual Machine in the cloud where you can build and run Moby projects and even create clusters to experiment.</li>\n<li><a href=\"https://developers.redhat.com/blog/2018/02/22/container-terminology-practical-introduction/\" rel=\"nofollow noreferrer\">Practical Introduction to Container Terminology</a> The landscape for container technologies is more significant than just docker. Without a good handle on the terminology, It can be challenging to grasp the key differences between docker and (pick your favourites, CRI-O, rkt, lxc/lxd) or understand what the Open Container Initiative is doing to standardize container technology.</li>\n<li><a href=\"https://hashnode.com/post/docker-tutorial-for-beginners-cjrj2hg5001s2ufs1nker9he2\" rel=\"nofollow noreferrer\">Docker Tutorial for Beginners (Updated 2019 version)</a> \u2014\u00a0In this Docker tutorial, you'll learn all the basics and learn how you can containerize Node.js and Go applications. Even if you aren't familiar with these languages, it should be easy for you to follow this tutorial and use any other language.</li>\n</ul>\n<h3>Books</h3>\n<ul>\n<li><a href=\"https://www.dockerbook.com\" rel=\"nofollow noreferrer\">The Docker Book \u2013 Containerization is the new virtualization</a></li>\n<li><a href=\"https://www.apress.com/gp/book/9781484218297\" rel=\"nofollow noreferrer\">Pro Docker</a></li>\n<li><a href=\"https://www.manning.com/books/docker-in-action\" rel=\"nofollow noreferrer\">Docker in Action</a></li>\n<li><a href=\"https://www.manning.com/books/docker-in-practice\" rel=\"nofollow noreferrer\">Docker in Practice</a></li>\n<li><a href=\"https://shop.oreilly.com/product/0636920035671.do\" rel=\"nofollow noreferrer\">Using Docker \u2013 Developing and Deploying Software with Containers</a></li>\n<li><a href=\"https://shop.oreilly.com/product/0636920036142.do\" rel=\"nofollow noreferrer\">Docker: Up &amp; Running \u2013 Shipping Reliable Containers in Production</a></li>\n<li><a href=\"https://www.packtpub.com/virtualization-and-cloud/build-your-own-paas-docker\" rel=\"nofollow noreferrer\">Build Your Own PaaS with Docker</a></li>\n<li><a href=\"https://www.packtpub.com/virtualization-and-cloud/orchestrating-docker\" rel=\"nofollow noreferrer\">Orchestrating Docker</a></li>\n<li><a href=\"https://shop.oreilly.com/product/0636920036791.do\" rel=\"nofollow noreferrer\">Docker Cookbook \u2013 Solutions and Examples for Building Distributed Applications</a></li>\n<li><a href=\"https://rads.stackoverflow.com/amzn/click/com/B00RXFHYZY\" rel=\"nofollow noreferrer\" rel=\"nofollow noreferrer\">Docker Hands-on \u2013 Deploy, Administer Docker Platform</a></li>\n<li><a href=\"https://www.packtpub.com/networking-and-servers/learning-docker-second-edition\" rel=\"nofollow noreferrer\">Learning Docker \u2013 Faster app development and deployment with Docker containers</a></li>\n<li><a href=\"https://shop.oreilly.com/product/9781939902184.do\" rel=\"nofollow noreferrer\">Docker in Production \u2013 Lessons from the Trenches</a></li>\n</ul>\n<h2>Development with Docker</h2>\n<h3>API Client</h3>\n<ul>\n<li><a href=\"https://github.com/instacart/ahab\" rel=\"nofollow noreferrer\">ahab</a> - Docker event handling with Python by <a href=\"https://github.com/instacart\" rel=\"nofollow noreferrer\">@instacart</a></li>\n<li><a href=\"https://github.com/lispyclouds/clj-docker-client\" rel=\"nofollow noreferrer\">clj-docker-client</a> :construction: - Idiomatic Clojure client for the Docker remote API. By <a href=\"https://github.com/lispyclouds\" rel=\"nofollow noreferrer\">@lispyclouds</a></li>\n<li><a href=\"https://github.com/gesellix/docker-client\" rel=\"nofollow noreferrer\">Docker Client for JVM</a> - A Docker remote api client library for the JVM, written in Groovy by [@gesellix][gesellix]</li>\n<li><a href=\"https://gitlab.com/masaeedu/docker-client\" rel=\"nofollow noreferrer\">Docker Client TypeScript</a> - Docker API client for JavaScript, automatically generated from Swagger API definition from moby repository. By <a href=\"https://github.com/masaeedu\" rel=\"nofollow noreferrer\">@masaeedu</a></li>\n<li><a href=\"https://github.com/spotify/docker-client\" rel=\"nofollow noreferrer\">docker-client</a> - Java client for the Docker remote API. By [@spotify][spotify]</li>\n<li><a href=\"https://github.com/whisklabs/docker-it-scala\" rel=\"nofollow noreferrer\">docker-it-scala</a> - Docker integration testing kit with Scala by <a href=\"https://github.com/whisklabs\" rel=\"nofollow noreferrer\">@whisklabs</a></li>\n<li><a href=\"https://github.com/amihaiemil/docker-java-api\" rel=\"nofollow noreferrer\">docker-java-api</a> - Lightweight, truly object-oriented, Java client for Docker's API. By <a href=\"https://github.com/amihaiemil\" rel=\"nofollow noreferrer\">@amihaiemil</a></li>\n<li><a href=\"https://github.com/fabric8io/docker-maven-plugin\" rel=\"nofollow noreferrer\">docker-maven-plugin</a> - A Maven plugin for running and creating Docker images by <a href=\"https://github.com/fabric8io\" rel=\"nofollow noreferrer\">@fabric8io</a></li>\n<li><a href=\"https://github.com/Microsoft/Docker-PowerShell\" rel=\"nofollow noreferrer\">Docker-PowerShell</a> - PowerShell Module for Docker</li>\n<li><a href=\"https://github.com/Microsoft/Docker.DotNet\" rel=\"nofollow noreferrer\">Docker.DotNet</a> - C#/.NET HTTP client for the Docker remote API by @ahmetalpbalkan</li>\n<li><a href=\"https://github.com/spotify/dockerfile-maven\" rel=\"nofollow noreferrer\">dockerfile-maven</a> - A Maven plugin for building and pushing Docker images by [@spotify][spotify]</li>\n<li><a href=\"https://github.com/apocas/dockerode\" rel=\"nofollow noreferrer\">dockerode</a> - Docker Remote API node.js module by <a href=\"https://github.com/apocas\" rel=\"nofollow noreferrer\">@apocas</a></li>\n<li><a href=\"https://github.com/eon01/DoMonit\" rel=\"nofollow noreferrer\">DoMonit</a> - A simple Docker Monitoring wrapper For Docker API</li>\n<li><a href=\"https://github.com/fsouza/go-dockerclient/\" rel=\"nofollow noreferrer\">go-dockerclient</a> - Go HTTP client for the Docker remote API by <a href=\"https://github.com/fsouza/\" rel=\"nofollow noreferrer\">@fsouza</a></li>\n<li><a href=\"https://github.com/gesellix/gradle-docker-plugin\" rel=\"nofollow noreferrer\">Gradle Docker plugin</a> - A Docker remote api plugin for Gradle by [@gesellix][gesellix]</li>\n<li><a href=\"https://github.com/docker/libcompose\" rel=\"nofollow noreferrer\">libcompose</a> - Go library for Docker Compose.</li>\n<li><a href=\"https://github.com/greenled/portainer-stack-utils\" rel=\"nofollow noreferrer\">Portainer stack utils</a> :construction: - Bash script to deploy/update/undeploy Docker stacks in a Portainer instance from a docker-compose yaml file. By <a href=\"https://github.com/greenled\" rel=\"nofollow noreferrer\">@greenled</a>.</li>\n<li><a href=\"https://github.com/Tapad/sbt-docker-compose\" rel=\"nofollow noreferrer\">sbt-docker-compose</a> - Integrates Docker Compose functionality into sbt by <a href=\"https://github.com/kurtkopchik/\" rel=\"nofollow noreferrer\">@kurtkopchik</a></li>\n<li><a href=\"https://github.com/marcuslonnberg/sbt-docker\" rel=\"nofollow noreferrer\">sbt-docker</a> - Create Docker images directly from sbt by <a href=\"https://github.com/marcuslonnberg\" rel=\"nofollow noreferrer\">@marcuslonnberg</a></li>\n</ul>\n<h3>CI/CD</h3>\n<ul>\n<li><a href=\"https://buddy.works\" rel=\"nofollow noreferrer\">Buddy:heavy_dollar_sign:</a> - The best of Git, build &amp; deployment tools combined into one powerful tool that supercharged our development.</li>\n<li><a href=\"https://github.com/harbur/captain\" rel=\"nofollow noreferrer\">Captain</a> - Convert your Git workflow to Docker containers ready for Continuous Delivery by <a href=\"https://github.com/harbur\" rel=\"nofollow noreferrer\">@harbur</a>.</li>\n<li><a href=\"https://github.com/caicloud/cyclone\" rel=\"nofollow noreferrer\">Cyclone</a> - Powerful workflow engine and end-to-end pipeline solutions implemented with native Kubernetes resources by <a href=\"https://github.com/caicloud\" rel=\"nofollow noreferrer\">@caicloud</a>.</li>\n<li><a href=\"https://github.com/jenkinsci/docker-plugin/\" rel=\"nofollow noreferrer\">Docker plugin for Jenkins</a> - The aim of the docker plugin is to be able to use a docker host to dynamically provision a slave, run a single build, and then tear down that slave.</li>\n<li><a href=\"https://github.com/drone/drone\" rel=\"nofollow noreferrer\">Drone</a> - Continuous integration server built on Docker and configured using YAML files.</li>\n<li><a href=\"https://gitlab.com/gitlab-org/gitlab-runner\" rel=\"nofollow noreferrer\">GitLab Runner</a> - GitLab has integrated CI to test, build and deploy your code with the use of GitLab runners.</li>\n<li><a href=\"https://github.com/gocd/gocd-docker\" rel=\"nofollow noreferrer\">GOCD-Docker</a> - Go Server and Agent in docker containers to provision.</li>\n<li><a href=\"https://github.com/francescou/docker-continuous-deployment\" rel=\"nofollow noreferrer\">Microservices Continuous Deployment</a> - Continuous deployment of a microservices application.</li>\n<li><a href=\"https://github.com/stelligent/mu\" rel=\"nofollow noreferrer\">mu</a> - Tool to configure CI/CD of your container applications via AWS CodePipeline, CodeBuild and ECS <a href=\"https://github.com/stelligent\" rel=\"nofollow noreferrer\">@Stelligent</a></li>\n<li><a href=\"http://screwdriver.cd/\" rel=\"nofollow noreferrer\">Screwdriver :heavy_dollar_sign:</a> - Yahoo's OpenSource build platform designed for Continous Delivery.</li>\n<li><a href=\"https://github.com/Stratoscale/skipper\" rel=\"nofollow noreferrer\">Skipper</a> - Easily dockerize your Git repository by <a href=\"https://github.com/Stratoscale\" rel=\"nofollow noreferrer\">@Stratoscale</a></li>\n<li><a href=\"https://github.com/ghostsquad/swarmci\" rel=\"nofollow noreferrer\">SwarmCI</a> - Create a distributed, isolated task pipeline in your Docker Swarm.</li>\n<li><a href=\"https://github.com/v2tec/watchtower\" rel=\"nofollow noreferrer\">Watchtower</a> - Automatically update running Docker containers by [@CenturyLinkLabs][centurylinklabs]</li>\n</ul>\n<hr />\n<h3>More resources</h3>\n<ul>\n<li><a href=\"https://github.com/veggiemonk/awesome-docker\" rel=\"nofollow noreferrer\">Awesome Docker</a></li>\n<li><a href=\"https://www.fullstackpython.com/docker.html\" rel=\"nofollow noreferrer\">Fullstack Python Docker Resources</a></li>\n<li><a href=\"https://training.play-with-docker.com/\" rel=\"nofollow noreferrer\">Play with Docker classroom</a>, an interactive in-browser Docker learning site</li>\n</ul>\n<h3>Related tags</h3>\n<p><a href=\"/questions/tagged/docker\" class=\"post-tag\" title=\"show questions tagged &#39;docker&#39;\" rel=\"tag\" aria-labelledby=\"docker-container\">docker</a> <a href=\"/questions/tagged/docker-image\" class=\"post-tag\" title=\"show questions tagged &#39;docker-image&#39;\" rel=\"tag\" aria-labelledby=\"docker-image-container\">docker-image</a> <a href=\"/questions/tagged/docker-container\" class=\"post-tag\" title=\"show questions tagged &#39;docker-container&#39;\" rel=\"tag\" aria-labelledby=\"docker-container-container\">docker-container</a> <a href=\"/questions/tagged/docker-compose\" class=\"post-tag\" title=\"show questions tagged &#39;docker-compose&#39;\" rel=\"tag\" aria-labelledby=\"docker-compose-container\">docker-compose</a> <a href=\"/questions/tagged/docker-networking\" class=\"post-tag\" title=\"show questions tagged &#39;docker-networking&#39;\" rel=\"tag\" aria-labelledby=\"docker-networking-container\">docker-networking</a> <a href=\"/questions/tagged/docker-build\" class=\"post-tag\" title=\"show questions tagged &#39;docker-build&#39;\" rel=\"tag\" aria-labelledby=\"docker-build-container\">docker-build</a> <a href=\"/questions/tagged/docker-volume\" class=\"post-tag\" title=\"show questions tagged &#39;docker-volume&#39;\" rel=\"tag\" aria-labelledby=\"docker-volume-container\">docker-volume</a> <a href=\"/questions/tagged/dockerfile\" class=\"post-tag\" title=\"show questions tagged &#39;dockerfile&#39;\" rel=\"tag\" aria-labelledby=\"dockerfile-container\">dockerfile</a> <a href=\"/questions/tagged/docker-swarm\" class=\"post-tag\" title=\"show questions tagged &#39;docker-swarm&#39;\" rel=\"tag\" aria-labelledby=\"docker-swarm-container\">docker-swarm</a> <a href=\"/questions/tagged/boot2docker\" class=\"post-tag\" title=\"show questions tagged &#39;boot2docker&#39;\" rel=\"tag\" aria-labelledby=\"boot2docker-container\">boot2docker</a> <a href=\"/questions/tagged/docker-machine\" class=\"post-tag\" title=\"show questions tagged &#39;docker-machine&#39;\" rel=\"tag\" aria-labelledby=\"docker-machine-container\">docker-machine</a> <a href=\"/questions/tagged/docker-registry\" class=\"post-tag\" title=\"show questions tagged &#39;docker-registry&#39;\" rel=\"tag\" aria-labelledby=\"docker-registry-container\">docker-registry</a></p>\n",
                    "OwnerUserId": "1682011",
                    "LastEditorUserId": "4595675",
                    "LastEditDate": "2022-09-02T08:54:58.950",
                    "LastActivityDate": "2022-09-02T08:54:58.950",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "16271255",
                "ParentRepo": "https://github.com/OWASP/CheatSheetSeries/blob/master/cheatsheets/Cross_Site_Scripting_Prevention_Cheat_Sheet.md",
                "StackOverflow_Post": {
                    "Id": "16271255",
                    "PostTypeId": "2",
                    "ParentId": "2334863",
                    "CreationDate": "2013-04-29T04:37:31.130",
                    "Score": "6",
                    "Body": "<p>OWASP has a great cheat sheet.</p>\n\n<ol>\n<li>Golden Rules</li>\n<li>Strategies</li>\n<li>Etc.</li>\n</ol>\n\n<p><a href=\"https://github.com/OWASP/CheatSheetSeries/blob/master/cheatsheets/Cross_Site_Scripting_Prevention_Cheat_Sheet.md\" rel=\"nofollow noreferrer\">https://github.com/OWASP/CheatSheetSeries/blob/master/cheatsheets/Cross_Site_Scripting_Prevention_Cheat_Sheet.md</a></p>\n",
                    "OwnerUserId": "1647851",
                    "LastEditorUserId": "248296",
                    "LastEditDate": "2019-02-25T07:47:23.653",
                    "LastActivityDate": "2019-02-25T07:47:23.653",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "16853458",
                "ParentRepo": "https://github.com/greg0ire/git_template",
                "StackOverflow_Post": {
                    "Id": "16853458",
                    "PostTypeId": "2",
                    "ParentId": "16840184",
                    "CreationDate": "2013-05-31T08:54:53.937",
                    "Score": "29",
                    "Body": "<p>It depends on what option you use when pulling:</p>\n\n<h2>No option : git fetch and git merge are run</h2>\n\n<p>You can write your own <a href=\"https://www.kernel.org/pub/software/scm/git/docs/githooks.html#_post_merge\" rel=\"noreferrer\">post-merge git hook</a>:</p>\n\n<blockquote>\n  <p>This hook is invoked by git merge, which happens when a git pull is done on a local repository. The hook takes a single parameter, a status flag specifying whether or not the merge being done was a squash merge. This hook\n         cannot affect the outcome of git merge and is not executed, if the merge failed due to conflicts.</p>\n</blockquote>\n\n<p>This hook should work for you (save this as executable file <code>.git/hooks/post-merge</code>):</p>\n\n<pre><code>#!/bin/sh\n\nCHANGED=`git diff HEAD@{1} --stat -- $GIT_DIR/../composer.lock | wc -l`\nif [ $CHANGED -gt 0 ];\nthen\n    echo \"composer.lock has changed!\"\n    composer.phar install --dev\nfi\n</code></pre>\n\n<h2>--rebase : git fetch and git rebase are run</h2>\n\n<p>You can write your own <a href=\"https://www.kernel.org/pub/software/scm/git/docs/githooks.html#_post_checkout\" rel=\"noreferrer\">post-checkout git hook</a>:</p>\n\n<blockquote>\n  <p>This hook is invoked when a git checkout is run after having updated the worktree. The hook is given three parameters: the ref of the previous HEAD, the ref of the new HEAD and a flag indicating whether the checkout was a branch checkout or a file checkout</p>\n</blockquote>\n\n<p>This hook should work for you (save this as executable file <code>.git/hooks/post-checkout</code>):</p>\n\n<pre><code>#!/bin/sh\n\nCHANGED=`git diff $1 $2 --stat -- $GIT_DIR/../composer.lock | wc -l`\nif [ $CHANGED -gt 0 ];\nthen\n    echo \"composer.lock has changed!\"\n    composer.phar install --dev\nfi\n</code></pre>\n\n<h2>UPDATE</h2>\n\n<p>Here is <a href=\"https://github.com/greg0ire/git_template\" rel=\"noreferrer\">my personal set of git hooks</a>.</p>\n",
                    "OwnerUserId": "1734130",
                    "LastEditorUserId": "1429387",
                    "LastEditDate": "2016-01-16T07:38:05.753",
                    "LastActivityDate": "2016-01-16T07:38:05.753",
                    "CommentCount": "5",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "17314748",
                "ParentRepo": "https://github.com/lsof-org/lsof",
                "StackOverflow_Post": {
                    "Id": "17314748",
                    "PostTypeId": "2",
                    "ParentId": "16827987",
                    "CreationDate": "2013-06-26T08:07:06.560",
                    "Score": "420",
                    "Body": "<p>You had run another server use the same port like 8080.</p>\n\n<p>Maybe you had run <code>node app</code> in other shell, Please close it and run again.</p>\n\n<p><strong>You can check PORT no. is available or not using</strong></p>\n\n<pre><code>netstat -tulnp | grep &lt;port no&gt;\n</code></pre>\n\n<p>Alternatively, you can use <a href=\"https://github.com/lsof-org/lsof\" rel=\"noreferrer\">lsof</a>:</p>\n\n<pre><code>lsof -i :&lt;port no&gt;\n</code></pre>\n",
                    "OwnerUserId": "1091032",
                    "LastEditorUserId": "2467938",
                    "LastEditDate": "2020-05-29T08:00:02.533",
                    "LastActivityDate": "2020-05-29T08:00:02.533",
                    "CommentCount": "7",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "17341335",
                "ParentRepo": "https://github.com/hugsy/gef",
                "StackOverflow_Post": {
                    "Id": "17341335",
                    "PostTypeId": "2",
                    "ParentId": "209534",
                    "CreationDate": "2013-06-27T10:58:52.330",
                    "Score": "204",
                    "Body": "<h1>.gdbinit</h1>\n\n<p>You can tweak your <code>~/.gdbinit</code> to have colors. You can use mammon's <code>.gdbinit</code> which is available here:</p>\n\n<p><a href=\"https://github.com/gdbinit/gdbinit\" rel=\"noreferrer\">https://github.com/gdbinit/gdbinit</a></p>\n\n<p>You can tweak it as much as you want too. I found this thanks to <a href=\"https://stackoverflow.com/questions/5526432/gdb-in-backtrack\">this SO answer</a>. Here's the kind of output that you can obtain:</p>\n\n<p><img src=\"https://i.stack.imgur.com/Nhuwf.png\" alt=\".gdbinit\"></p>\n\n<p>A GitHub repository is also available: <a href=\"https://github.com/gdbinit/Gdbinit\" rel=\"noreferrer\">https://github.com/gdbinit/Gdbinit</a></p>\n\n<p>On a side note, the same idea was also <a href=\"https://github.com/deroko/lldbinit\" rel=\"noreferrer\">applied to lldb</a>.</p>\n\n<h1>GDB Dashboard</h1>\n\n<p>Following the same concept, <a href=\"https://github.com/cyrus-and/gdb-dashboard\" rel=\"noreferrer\">GDB Dashboard</a> provides a modular visual interface for GDB in Python.</p>\n\n<p><a href=\"https://i.stack.imgur.com/mHC8f.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/mHC8f.png\" alt=\"GDB Dashboard\"></a></p>\n\n<h1>(void)walker</h1>\n\n<p>Another similar project uses GDB's Python support to provide more extensibility, so this is worth checking out: <a href=\"https://github.com/dholm/voidwalker\" rel=\"noreferrer\">https://github.com/dholm/voidwalker</a></p>\n\n<p>@dholm also provides his own <a href=\"https://github.com/dholm/dotgdb\" rel=\"noreferrer\">.gdbinit</a> inspired from the previous one.</p>\n\n<p><img src=\"https://raw.githubusercontent.com/dholm/voidwalker/master/screenshot.png\" alt=\"(void)walker\"></p>\n\n<h1>pwndbg</h1>\n\n<p>Some projects provide a set of useful functions, including improved display. This is the case for <a href=\"https://github.com/longld/peda\" rel=\"noreferrer\">PEDA</a> or <a href=\"https://github.com/zachriggle/pwndbg\" rel=\"noreferrer\">pwndbg</a>. The latter gives the following description:</p>\n\n<blockquote>\n  <p>A PEDA replacement. In the spirit of our good friend <code>windbg</code>, <code>pwndbg</code> is pronounced <code>pwnd-bag</code>.</p>\n  \n  <ul>\n  <li>Speed</li>\n  <li>Resiliency</li>\n  <li>Clean code</li>\n  </ul>\n</blockquote>\n\n<p>It provides commands to support debugging and exploit development similar to the ones from PEDA, and better display (although this is not the main focus of the project). The software is still under development, and has not been properly released yet.</p>\n\n<p><a href=\"https://i.stack.imgur.com/BuVHv.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/BuVHv.png\" alt=\"pwndbg\"></a></p>\n\n<h1>voltron</h1>\n\n<p>The <a href=\"https://github.com/snare/voltron\" rel=\"noreferrer\">project</a> description states:</p>\n\n<blockquote>\n  <p>Voltron is an extensible debugger UI for hackers. It allows you to\n  attach utility views running in other terminals to your debugger (LLDB\n  or GDB), displaying helpful information such as disassembly, stack\n  contents, register values, etc, while still giving you the same\n  debugger CLI you're used to.</p>\n</blockquote>\n\n<p>You can modify your <code>.gdbinit</code> to automatically integrate it. However, the display itself is outside of GDB (e.g. in a tmux split).</p>\n\n<p><a href=\"https://i.stack.imgur.com/7eWF1.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/7eWF1.png\" alt=\"voltron\"></a></p>\n\n<h1>GEF</h1>\n\n<p><a href=\"https://github.com/hugsy/gef\" rel=\"noreferrer\">GEF</a> is another option, and it is described as:</p>\n\n<blockquote>\n  <p>It is aimed to be used mostly by exploiters and reverse-engineers, to\n  provide additional features to GDB using the Python API to assist\n  during the process of dynamic analysis and exploit development.</p>\n</blockquote>\n\n<p><a href=\"https://i.stack.imgur.com/EpxEz.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/EpxEz.png\" alt=\"GEF\"></a></p>\n",
                    "OwnerUserId": "1043187",
                    "LastEditorUserId": "192737",
                    "LastEditDate": "2018-02-22T01:57:31.010",
                    "LastActivityDate": "2018-02-22T01:57:31.010",
                    "CommentCount": "3",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "17342058",
                "ParentRepo": "https://github.com/dulaccc/pygenstrings",
                "StackOverflow_Post": {
                    "Id": "17342058",
                    "PostTypeId": "2",
                    "ParentId": "17341899",
                    "CreationDate": "2013-06-27T11:35:08.717",
                    "Score": "5",
                    "Body": "<p>Check out <a href=\"https://github.com/dulaccc/pygenstrings\" rel=\"noreferrer\">this project</a> on GitHub, which provides a python scripts which makes <code>genstrings</code> a little bit smarter.</p>\n\n<p>Since I don't like link-only answers (links may die), I'll also drop here the python script (all credits go to the author of the linked project)</p>\n\n<pre><code>#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\n# Localize.py - Incremental localization on XCode projects\n# Jo\u00e3o Moreno 2009\n# http://joaomoreno.com/\n\n# Modified by Steve Streeting 2010 http://www.stevestreeting.com\n# Changes\n# - Use .strings files encoded as UTF-8\n#   This is useful because Mercurial and Git treat UTF-16 as binary and can't\n#   diff/merge them. For use on iPhone you can run an iconv script during build to\n#   convert back to UTF-16 (Mac OS X will happily use UTF-8 .strings files).\n# - Clean up .old and .new files once we're done\n\n# Modified by Pierre Dulac 2012 http://friendcashapp.com\n# Changes\n# - use logging instead of print\n# Adds\n# - MIT Licence\n# - the first parameter in the command line to specify the path of *.lproj directories\n# - an optional paramter to control the debug level (set to info by default)\n# Fixes\n# - do not convert a file if it is already in utf-8\n# - allow multiline translations generated by genstrings by modifing the re_translation regex\n# - \n\n# MIT Licence\n#\n# Copyright (C) 2012 Pierre Dulac\n#\n# Permission is hereby granted, free of charge, to any person obtaining a copy of this software and \n# associated documentation files (the \"Software\"), to deal in the Software without restriction, \n# including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, \n# and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, \n# subject to the following conditions:\n#\n# The above copyright notice and this permission notice shall be included in all copies or substantial \n# portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT \n# LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. \n# IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, \n# WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE \n# SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\nfrom sys import argv\nfrom codecs import open\nfrom re import compile\nfrom copy import copy\nimport os\nimport shutil\nimport optparse\nimport logging\nlogging.getLogger().level = logging.INFO\n\n__version__ = \"0.1\"\n__license__ = \"MIT\"\n\nUSAGE = \"%prog [options] &lt;url&gt;\"\nVERSION = \"%prog v\" + __version__\n\nre_translation = compile(r'^\"((?:[^\"]|\\\\\")+)\" = \"((?:[^\"]|\\\\\")+)\";(?:\\n)?$')\nre_comment_single = compile(r'^/\\*.*\\*/$')\nre_comment_start = compile(r'^/\\*.*$')\nre_comment_end = compile(r'^.*\\*/$')\n\nclass LocalizedString():\n    def __init__(self, comments, translation):\n        self.comments, self.translation = comments, translation\n        self.key, self.value = re_translation.match(self.translation).groups()\n\n    def __unicode__(self):\n        return u'%s%s\\n' % (u''.join(self.comments), self.translation)\n\nclass LocalizedFile():\n    def __init__(self, fname=None, auto_read=False):\n        self.fname = fname\n        self.reset()\n\n        if auto_read:\n            self.read_from_file(fname)\n\n    def reset(self):\n        self.strings = []\n        self.strings_d = {}\n\n    def read_from_file(self, fname=None):\n        self.reset()\n\n        fname = self.fname if fname == None else fname\n        try:\n            #f = open(fname, encoding='utf_8', mode='r')\n            f = open(fname, encoding='utf_8', mode='r')\n        except:\n            print 'File %s does not exist.' % fname\n            exit(-1)\n\n        try:\n            line = f.readline()\n            logging.debug(line)\n        except:\n            logging.error(\"Can't read line for file: %s\" % fname)\n            raise\n\n        i = 1\n        while line:\n            comments = [line]\n\n            if not re_comment_single.match(line):\n                while line and not re_comment_end.match(line):\n                    line = f.readline()\n                    comments.append(line)\n\n            line = f.readline()\n            i += 1\n\n            # handle multi lines\n            while len(line) &gt; 1 and line[-2] != u';':\n                line += f.readline()\n                i += 1\n\n            logging.debug(\"%d %s\" % (i, line.rstrip('\\n')))\n            if line and re_translation.match(line):\n                translation = line\n            else:\n                logging.error(\"Line %d of file '%s' raising the exception: %s\" % (i, self.fname, line))\n                raise Exception('invalid file')\n\n            line = f.readline()\n            i += 1\n            while line and line == u'\\n':\n                line = f.readline()\n                i += 1\n\n            string = LocalizedString(comments, translation)\n            self.strings.append(string)\n            self.strings_d[string.key] = string\n\n        f.close()\n\n    def save_to_file(self, fname=None):\n        fname = self.fname if fname == None else fname\n        try:\n            f = open(fname, encoding='utf_8', mode='w')\n        except:\n            print 'Couldn\\'t open file %s.' % fname\n            exit(-1)\n\n        # sort by key\n        self.strings.sort(key=lambda item: item.key)\n\n        for string in self.strings:\n            f.write(string.__unicode__())\n\n        f.close()\n\n    def merge_with(self, new):\n        merged = LocalizedFile()\n\n        for string in new.strings:\n            if self.strings_d.has_key(string.key):\n                new_string = copy(self.strings_d[string.key])\n                new_string.comments = string.comments\n                string = new_string\n\n            merged.strings.append(string)\n            merged.strings_d[string.key] = string\n\n        return merged\n\n    def update_with(self, new):\n        for string in new.strings:\n            if not self.strings_d.has_key(string.key):\n                self.strings.append(string)\n                self.strings_d[string.key] = string\n\ndef merge(merged_fname, old_fname, new_fname):\n    try:\n        old = LocalizedFile(old_fname, auto_read=True)\n        new = LocalizedFile(new_fname, auto_read=True)\n        merged = old.merge_with(new)\n        merged.save_to_file(merged_fname)\n    except Exception, inst:\n        logging.error('Error: input files have invalid format.')\n        raise\n\nSTRINGS_FILE = 'Localizable.strings'\n\ndef localize(path, excluded_paths):\n    languages = [os.path.join(path,name) for name in os.listdir(path) if name.endswith('.lproj') and os.path.isdir(os.path.join(path,name))]\n    print \"languages found\", languages\n\n    for language in languages:\n        original = merged = language + os.path.sep + STRINGS_FILE\n        old = original + '.old'\n        new = original + '.new'\n\n        if os.path.isfile(original):\n            try:\n                open(original, encoding='utf_8', mode='r').read()\n                os.rename(original, old)\n            except:\n                os.system('iconv -f UTF-16 -t UTF-8 \"%s\" &gt; \"%s\"' % (original, old))\n\n            # gen\n            os.system('find %s -name \\*.m -not -path \"%s\" | xargs genstrings -q -o \"%s\"' % (path, excluded_paths, language))\n\n            try:\n                open(original, encoding='utf_8', mode='r').read()\n                shutil.copy(original, new)\n            except:\n                os.system('iconv -f UTF-16 -t UTF-8 \"%s\" &gt; \"%s\"' % (original, new))\n\n            # merge  \n            merge(merged, old, new)\n            logging.info(\"Job done for language: %s\" % language)\n        else:\n            os.system('genstrings -q -o \"%s\" `find %s -name \"*.m\" -not -path \"%s\"`' % (language, path, excluded_paths))\n            os.rename(original, old)\n            try:\n                open(old, encoding='utf_8', mode='r').read()\n            except:\n                os.system('iconv -f UTF-16 -t UTF-8 \"%s\" &gt; \"%s\"' % (old, original))\n\n        if os.path.isfile(old):\n            os.remove(old)\n        if os.path.isfile(new):\n            os.remove(new)\n\ndef parse_options():\n    \"\"\"parse_options() -&gt; opts, args\n\n    Parse any command-line options given returning both\n    the parsed options and arguments.\n    \"\"\"\n\n    parser = optparse.OptionParser(usage=USAGE, version=VERSION)\n\n    parser.add_option(\"-d\", \"--debug\",\n            action=\"store_true\", default=False, dest=\"debug\",\n            help=\"Set to DEBUG the logging level (default to INFO)\")\n\n    parser.add_option(\"-p\", \"--path\",\n            action=\"store\", type=\"str\", default=os.getcwd(), dest=\"path\",\n            help=\"Path (relative or absolute) to use for searching for *.lproj directories\")\n\n    parser.add_option(\"-e\", \"--exclude\",\n            action=\"store\", type=\"str\", default=None, dest=\"excluded_paths\",\n            help=\"Regex for paths to exclude ex. ``./Folder1/*``\")\n\n    opts, args = parser.parse_args()\n    return opts, args\n\nif __name__ == '__main__':\n    opts, args = parse_options()\n    if opts.debug:\n        logging.getLogger().level = logging.DEBUG\n    if opts.path:\n        opts.path = os.path.realpath(opts.path)\n    if opts.excluded_paths:\n        opts.excluded_paths = os.path.realpath(opts.excluded_paths)\n    logging.info(\"Running the script on path %s\" % opts.path)\n    localize(opts.path, opts.excluded_paths)\n</code></pre>\n",
                    "OwnerUserId": "846273",
                    "LastActivityDate": "2013-06-27T11:35:08.717",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "18167861",
                "ParentRepo": "https://github.com/jmoiron/humanize/blob/master/humanize/filesize.py#L33-L38",
                "StackOverflow_Post": {
                    "Id": "18167861",
                    "PostTypeId": "2",
                    "ParentId": "18167818",
                    "CreationDate": "2013-08-11T01:20:08.107",
                    "Score": "4",
                    "Body": "<p>No, this is not possible. The format specifier, <code>%.1f</code>, is hard coded:\n<a href=\"https://github.com/jmoiron/humanize/blob/master/humanize/filesize.py#L33-L38\" rel=\"nofollow noreferrer\">https://github.com/jmoiron/humanize/blob/master/humanize/filesize.py#L33-L38</a></p>\n\n<p><strong>EDIT</strong>:\n<a href=\"https://stackoverflow.com/users/503463/joemaller\">joemaller</a> just submitted a <a href=\"https://github.com/jmoiron/humanize/pull/13\" rel=\"nofollow noreferrer\">pull request</a> for this functionality.</p>\n",
                    "OwnerUserId": "624900",
                    "LastEditorUserId": "-1",
                    "LastEditDate": "2017-05-23T11:56:38.037",
                    "LastActivityDate": "2013-08-11T04:49:01.350",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "18377286",
                "ParentRepo": "https://github.com/ryneeverett/python-markdown-comments",
                "StackOverflow_Post": {
                    "Id": "18377286",
                    "PostTypeId": "2",
                    "ParentId": "4823468",
                    "CreationDate": "2013-08-22T10:00:03.140",
                    "Score": "14",
                    "Body": "<p><em>Disclosure: I wrote the plugin.</em></p>\n\n<p>Since the question doesn't specify a specific markdown implementation I'd like to mention the <a href=\"https://github.com/ryneeverett/python-markdown-comments\" rel=\"noreferrer\">Comments Plugin</a> for <a href=\"https://github.com/waylan/Python-Markdown\" rel=\"noreferrer\">python-markdown</a>, which implements the same pandoc commenting style mentioned above.</p>\n",
                    "OwnerUserId": "1938621",
                    "LastEditorUserId": "1938621",
                    "LastEditDate": "2015-04-07T16:21:43.047",
                    "LastActivityDate": "2015-04-07T16:21:43.047",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "18708190",
                "ParentRepo": "https://github.com/josuebrunel/myql/blob/master/docs/table.md",
                "StackOverflow_Post": {
                    "Id": "18708190",
                    "PostTypeId": "2",
                    "ParentId": "16776932",
                    "CreationDate": "2013-09-09T22:42:18.533",
                    "Score": "0",
                    "Body": "<p>YQL has an execute method which can run JavaScript on the output to transform it into the desired format. Here are a few examples:</p>\n\n<pre><code>&lt;execute&gt;&lt;![CDDATA[\n// request.url == 'http://some_web_service_or_feed\n// This is the same as 'y.rest(request.url).get();'\nvar returned_response = request.get();\n...\n]]&gt;\n&lt;/execute&gt;\n\n&lt;execute&gt;&lt;![CDATA[\n// Include the OAuth libraries from oauth.net\ny.include(\"http://oauth.googlecode.com/svn/code/javascript/oauth.js\");\ny.include(\"http://oauth.googlecode.com/svn/code/javascript/sha1.js\");\n\n// Collect all the parameters\nvar encodedurl = request.url;\nvar accessor = { consumerSecret: cs, tokenSecret: \"\"};\nvar message = { action: encodedurl, method: \"GET\", parameters: [[\"oauth_consumer_key\",ck],[\"oauth_version\",\"1.0\"]]};\nOAuth.setTimestampAndNonce(message);\n\n// Sign the request\nOAuth.SignatureMethod.sign(message, accessor);\n\ntry {\n   // get the content from service along with the OAuth header, and return the result back out\n    response.object = request.contentType('application/xml').header(\"Authorization\", OAuth.getAuthorizationHeader(\"netflix.com\", message.parameters)).get().response;\n    } catch(err) {\n    response.object = {'result':'failure', 'error': err};\n    }\n]]&gt;\n&lt;/execute&gt;\n</code></pre>\n\n<p><strong>References</strong></p>\n\n<ul>\n<li><p><a href=\"https://developer.yahoo.com/yql/guide/yql_code_tutorials.html\" rel=\"nofollow noreferrer\">YQL Code Tutorials</a></p></li>\n<li><p><a href=\"https://github.com/josuebrunel/myql/blob/master/docs/table.md\" rel=\"nofollow noreferrer\">myql/table.md | YQL Open Data Table Docs</a></p></li>\n<li><p><a href=\"https://github.com/bcantoni/yql/blob/master/lorem.ipsum.xml\" rel=\"nofollow noreferrer\">yql/lorem.ipsum.xml | YQL Lorem Ipsum Service Call Example</a></p></li>\n</ul>\n",
                    "OwnerUserId": "1113772",
                    "LastEditorUserId": "1113772",
                    "LastEditDate": "2018-10-17T13:29:07.267",
                    "LastActivityDate": "2018-10-17T13:29:07.267",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "19727632",
                "ParentRepo": "https://github.com/ugrid-conventions/ugrid-conventions",
                "StackOverflow_Post": {
                    "Id": "19727632",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "19768224",
                    "CreationDate": "2013-11-01T13:24:01.957",
                    "Score": "1",
                    "ViewCount": "461",
                    "Body": "<p>We have a group-developed metadata conventions document for a particular group of ocean models stored as github-flavored markdown at <a href=\"https://github.com/ugrid-conventions/ugrid-conventions\" rel=\"nofollow\">https://github.com/ugrid-conventions/ugrid-conventions</a>\nand now we would like to \"release\" the current version of this markdown document at version 1.0 (and continue the development of the conventions for future releases). </p>\n\n<p>I understand that github has releases, but we don't want a zip file containing the markdown document, we just want a  \"version 1.0\" markdown document.  We could also like to preserve the changes so that people can see what changed relative to previous versions as we go forward. </p>\n\n<p>Should we just copy the existing document <code>ugrid-conventions.md</code> to <code>ugrid-conventions_v1.0.0.md</code>, or is there a better way?</p>\n",
                    "OwnerUserId": "2005869",
                    "LastActivityDate": "2013-11-04T12:59:32.377",
                    "Title": "How to handle releases of markdown document on github",
                    "Tags": "<github><markdown><github-flavored-markdown>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "19980209",
                "ParentRepo": "https://github.com/alanjds/drf-nested-routers/",
                "StackOverflow_Post": {
                    "Id": "19980209",
                    "PostTypeId": "2",
                    "ParentId": "17217044",
                    "CreationDate": "2013-11-14T14:27:05.550",
                    "Score": "6",
                    "Body": "<p>You should investigate <a href=\"https://github.com/alanjds/drf-nested-routers/\" rel=\"noreferrer\">https://github.com/alanjds/drf-nested-routers/</a></p>\n\n<p>This has been suggested in <a href=\"https://github.com/tomchristie/django-rest-framework/pull/1048\" rel=\"noreferrer\">https://github.com/tomchristie/django-rest-framework/pull/1048</a></p>\n",
                    "OwnerUserId": "833093",
                    "LastActivityDate": "2013-11-14T14:27:05.550",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "20950539",
                "ParentRepo": "https://github.com/dilawar/Scripts/blob/master/sniff.py",
                "StackOverflow_Post": {
                    "Id": "20950539",
                    "PostTypeId": "2",
                    "ParentId": "16956810",
                    "CreationDate": "2014-01-06T12:56:26.607",
                    "Score": "17",
                    "Body": "<p>I wrote a <a href=\"https://github.com/dilawar/Scripts/blob/master/sniff.py\" rel=\"noreferrer\">Python script</a> which does something similar. This is how one should use this script.</p>\n\n<pre><code>./sniff.py path pattern_to_search [file_pattern]\n</code></pre>\n\n<p>The first argument, <code>path</code>, is the directory in which we will search recursively. The second argument, <code>pattern_to_search</code>, is a regular expression which we want to search in a file. We use the regular expression format defined in the <a href=\"http://en.wikipedia.org/wiki/Python_%28programming_language%29\" rel=\"noreferrer\">Python</a> <code>re</code> library. In this script, the <code>.</code> also matches newline.</p>\n\n<p>The third argument, <code>file_pattern</code>, is optional. This is another regular expression which works on a filename. Only those files which matches this regular expression will be considered. </p>\n\n<p>For example, if I want to search Python files with the extension <code>py</code> containing <code>Pool(</code> followed by word <code>Adaptor</code>, I do the following,</p>\n\n<pre><code>./sniff.py . \"Pool(.*?Adaptor\"  .*py\n./Demos/snippets/cubeMeshSigNeur.py:146 \n./Demos/snippets/testSigNeur.py:259 \n./python/moose/multiscale/core/mumbl.py:206 \n./Demos/snippets/multiComptSigNeur.py:268 \n</code></pre>\n\n<p>And voila, it generates the path of matched files and line number at which the match was found. If more than one match was found, then each line number will be appended to the filename.</p>\n",
                    "OwnerUserId": "1805129",
                    "LastEditorUserId": "63550",
                    "LastEditDate": "2014-06-30T17:59:08.567",
                    "LastActivityDate": "2014-06-30T17:59:08.567",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "21195076",
                "ParentRepo": "https://github.com/dmytrodanylyk/dmytrodanylyk/blob/gh-pages/articles/surface-view-play-video.md",
                "StackOverflow_Post": {
                    "Id": "21195076",
                    "PostTypeId": "2",
                    "ParentId": "5229247",
                    "CreationDate": "2014-01-17T20:17:06.077",
                    "Score": "1",
                    "Body": "<p>Check out my <a href=\"https://github.com/dmytrodanylyk/dmytrodanylyk/blob/gh-pages/articles/surface-view-play-video.md\" rel=\"nofollow\">Surface View - Playing</a> video tutorial</p>\n\n<pre><code>public class VideoAssetActivity extends Activity implements     \n                                            TextureView.SurfaceTextureListener {\n// Log tag.\nprivate static final String TAG = VideoAssetActivity.class.getName();\n\n// Asset video file name.\nprivate static final String FILE_NAME = \"big_buck_bunny.mp4\";\n\n// MediaPlayer instance to control playback of video file.\nprivate MediaPlayer mMediaPlayer;\n\n    @Override\n    public void onCreate(Bundle savedInstanceState) {\n        super.onCreate(savedInstanceState);\n        setContentView(R.layout.texture_video_simple);\n\n        initView();\n    }\n\n    private void initView() {\n        TextureView textureView = (TextureView) findViewById(R.id.textureView);\n        textureView.setSurfaceTextureListener(this);\n    }\n\n    @Override\n    protected void onDestroy() {\n        super.onDestroy();\n        if (mMediaPlayer != null) {\n            mMediaPlayer.stop();\n            mMediaPlayer.release();\n            mMediaPlayer = null;\n        }\n    }\n\n    @Override\n    public void onSurfaceTextureAvailable(SurfaceTexture surfaceTexture, int i, int i2) {\n    Surface surface = new Surface(surfaceTexture);\n\n        try {\n            AssetFileDescriptor afd = getAssets().openFd(FILE_NAME);\n            mMediaPlayer = new MediaPlayer();\n            mMediaPlayer.setDataSource(afd.getFileDescriptor(), afd.getStartOffset(), afd.getLength());\n            mMediaPlayer.setSurface(surface);\n            mMediaPlayer.setLooping(true);\n            mMediaPlayer.prepareAsync();\n\n            // Play video when the media source is ready for playback.\n            mMediaPlayer.setOnPreparedListener(new MediaPlayer.OnPreparedListener() {\n                @Override\n                public void onPrepared(MediaPlayer mediaPlayer) {\n                    mediaPlayer.start();\n                }\n            });\n\n        } catch (IllegalArgumentException e) {\n            Log.d(TAG, e.getMessage());\n        } catch (SecurityException e) {\n            Log.d(TAG, e.getMessage());\n        } catch (IllegalStateException e) {\n            Log.d(TAG, e.getMessage());\n        } catch (IOException e) {\n            Log.d(TAG, e.getMessage());\n        }\n    }\n\n    @Override\n    public void onSurfaceTextureSizeChanged(SurfaceTexture surfaceTexture, int i, int i2) {\n    }\n\n    @Override\n    public boolean onSurfaceTextureDestroyed(SurfaceTexture surfaceTexture) {\n        return true;\n    }\n\n    @Override\n    public void onSurfaceTextureUpdated(SurfaceTexture surfaceTexture) {\n    }\n}\n</code></pre>\n",
                    "OwnerUserId": "1056263",
                    "LastActivityDate": "2014-01-17T20:17:06.077",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "21318739",
                "ParentRepo": "https://github.com/GetBlimp/django-rest-framework-jwt",
                "StackOverflow_Post": {
                    "Id": "21318739",
                    "PostTypeId": "2",
                    "ParentId": "21317899",
                    "CreationDate": "2014-01-23T20:34:01.160",
                    "Score": "37",
                    "Body": "<p>Take a look at the api view from <a href=\"https://github.com/GetBlimp/django-rest-framework-jwt\" rel=\"noreferrer\">django-rest-framework-jwt</a>. It's an implementation for creating auth tokens rather than cookie sessions, but your implementation will be similar.  See <a href=\"https://github.com/GetBlimp/django-rest-framework-jwt/blob/master/rest_framework_jwt/views.py\" rel=\"noreferrer\">views.py</a> and <a href=\"https://github.com/GetBlimp/django-rest-framework-jwt/blob/master/rest_framework_jwt/serializers.py\" rel=\"noreferrer\">serializers.py</a>.  You can probably use the <code>serializers.py</code> unchanged, and just adjust your views to return the right parameters and possibly set the session cookie (can't recall if that's already performed in authentication).</p>\n",
                    "OwnerUserId": "2089197",
                    "LastActivityDate": "2014-01-23T20:34:01.160",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "21553311",
                "ParentRepo": "https://github.com/biometrics/openbr",
                "StackOverflow_Post": {
                    "Id": "21553311",
                    "PostTypeId": "5",
                    "CreationDate": "2014-02-04T13:02:16.090",
                    "Score": "0",
                    "Body": "<p><strong>About</strong></p>\n\n<p>OpenBR is a collaborative research project started by The MITRE Corporation. The MITRE Corporation is a not-for-profit organization chartered to work in the public interest.</p>\n\n<p>OpenBR is supported on Windows, Mac OS X, and Debian Linux. The project is licensed under Apache 2.0 and releases follow the Semantic Versioning convention. Internally the code base uses the CMake build system and requires Qt and OpenCV.</p>\n\n<p><strong>Links</strong></p>\n\n<p><a href=\"http://openbiometrics.org/\" rel=\"nofollow\">Website</a></p>\n\n<p><a href=\"https://github.com/biometrics/openbr\" rel=\"nofollow\">Github</a></p>\n\n<p><a href=\"https://groups.google.com/forum/?fromgroups#!forum/openbr-dev\" rel=\"nofollow\">Google Group</a></p>\n",
                    "OwnerUserId": "2490343",
                    "LastEditorUserId": "2490343",
                    "LastEditDate": "2014-02-04T13:04:22.387",
                    "LastActivityDate": "2014-02-04T13:04:22.387",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "21909165",
                "ParentRepo": "https://github.com/sobhe/hazm",
                "StackOverflow_Post": {
                    "Id": "21909165",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "21911062",
                    "CreationDate": "2014-02-20T13:24:50.530",
                    "Score": "3",
                    "ViewCount": "955",
                    "Body": "<p>I want to run a code that need to stanford postagger.jar. but i have this error:</p>\n\n<pre><code>  File \"/usr/lib/python2.7/site-packages/nltk/internals.py\", line 562, in find_jar\n    (name, path_to_jar))\nValueError: Could not find stanford-postagger.jar jar file at resources/stanford-postagger.jar\n</code></pre>\n\n<p>How i can fix this error?</p>\n\n<p><strong>EDIT:</strong>\ni use from <a href=\"https://github.com/sobhe/hazm\" rel=\"nofollow\">hazm</a> module:</p>\n\n<pre><code>from hazm import POSTagger\ntagger = POSTagger()\ntagger.tag(word_tokenize('\u0645\u0627 \u0628\u0633\u06cc\u0627\u0631 \u06a9\u062a\u0627\u0628 \u0645\u06cc\u200c\u062e\u0648\u0627\u0646\u06cc\u0645'))\n</code></pre>\n\n<p>and full result:</p>\n\n<pre><code>Traceback (most recent call last):\n  File \"pyt.py\", line 8, in &lt;module&gt;\n    tagger = POSTagger()\n  File \"/home/vahid/dev/hazm/hazm/POSTagger.py\", line 14, in __init__\n    super(stanford.POSTagger, self).__init__(*args, **kwargs)\n  File \"/usr/lib/python2.7/site-packages/nltk/tag/stanford.py\", line 42, in __init__\n    verbose=verbose)\n  File \"/usr/lib/python2.7/site-packages/nltk/internals.py\", line 562, in find_jar\n    (name, path_to_jar))\nValueError: Could not find stanford-postagger.jar jar file at resources/stanford-postagger.jar\n</code></pre>\n",
                    "OwnerUserId": "2632266",
                    "LastEditorUserId": "610569",
                    "LastEditDate": "2014-02-20T14:43:27.327",
                    "LastActivityDate": "2014-07-03T14:41:47.880",
                    "Title": "ValueError: Could not find stanford-postagger.jar file for hazm library- python NLP",
                    "Tags": "<java><python><nlp><nltk><pos-tagger>",
                    "AnswerCount": "2",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "22447217",
                "ParentRepo": "https://github.com/opentripplanner/OpenTripPlanner/wiki/SettingUpOTPServer",
                "StackOverflow_Post": {
                    "Id": "22447217",
                    "PostTypeId": "2",
                    "ParentId": "22436078",
                    "CreationDate": "2014-03-17T04:51:13.803",
                    "Score": "6",
                    "Body": "<ol>\n<li><p>No, since you would need to enter into an agreement with Google for them to use your data, and they're unlikely to take you seriously unless you're affiliated with an actual transit agency. But if you're curious you can read about <a href=\"http://maps.google.com/help/maps/mapcontent/transit/participate.html\" rel=\"noreferrer\">the steps involved</a>.</p></li>\n<li><p>Yes, it's possible, and there are open-source routing engines available for you to use, like <a href=\"http://www.opentripplanner.org/\" rel=\"noreferrer\">OpenTripPlanner</a> and <a href=\"http://graphserver.github.io/graphserver/\" rel=\"noreferrer\">Graphserver</a>. This is pretty heavy-duty stuff, however. If what you have is a basic Web-hosting account and you just want to do \"something interesting\" with transit data, setting up an online trip planner is probably not the place to start.</p></li>\n</ol>\n\n<hr>\n\n<p>I think the most straightforward solution would be for you to <strong>run OpenTripPlanner on a server of your own</strong>. This would provide your users with a familiar-looking website they can use to generate trip plans from your data while leaving you complete control over the data itself.</p>\n\n<p>Note that running OpenTripPlanner would require a fairly powerful server plus map data from <a href=\"http://www.openstreetmap.org/\" rel=\"noreferrer\">OpenStreetMap</a> (which I'm assuming is available for your area) in addition to your own transit data. On the project's website you'll find <a href=\"https://github.com/opentripplanner/OpenTripPlanner/wiki/SettingUpOTPServer\" rel=\"noreferrer\">setup instructions</a> for Ubuntu to give you an idea of what's involved.</p>\n\n<p>I'm assuming you're already able to generate a GTFS bundle; that is, to produce a ZIP file containing comma-separated data files as specified in the <a href=\"https://developers.google.com/transit/gtfs/reference\" rel=\"noreferrer\">GTFS Reference</a>. With an OpenTripPlanner server set up, your workflow would be as simple as</p>\n\n<ol>\n<li><p>Making changes to your transit data.</p></li>\n<li><p>Generating a new GTFS bundle.</p></li>\n<li><p>Uploading the bundle to a specific folder on your OpenTripPlanner server.</p></li>\n<li><p>Restarting OpenTripPlanner.</p></li>\n<li><p>Optionally, notifying your users of the changes.</p></li>\n</ol>\n\n<p>Every step except the first could be automated with a script.</p>\n",
                    "OwnerDisplayName": "user473305",
                    "LastEditorDisplayName": "user473305",
                    "LastEditDate": "2014-03-24T07:40:29.593",
                    "LastActivityDate": "2014-03-24T07:40:29.593",
                    "CommentCount": "5",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "22789161",
                "ParentRepo": "https://github.com/timothycrosley/isort",
                "StackOverflow_Post": {
                    "Id": "22789161",
                    "PostTypeId": "2",
                    "ParentId": "22722976",
                    "CreationDate": "2014-04-01T14:39:37.687",
                    "Score": "28",
                    "Body": "<p>Have a look at <a href=\"https://pypi.python.org/pypi/isort\" rel=\"noreferrer\">https://pypi.python.org/pypi/isort</a> or <a href=\"https://github.com/timothycrosley/isort\" rel=\"noreferrer\">https://github.com/timothycrosley/isort</a></p>\n\n<blockquote>\n  <p>isort parses specified files for global level import lines (imports outside of try / excepts blocks, functions, etc..) and puts them all at the top of the file grouped together by the type of import:</p>\n  \n  <ul>\n  <li>Future </li>\n  <li>Python Standard Library </li>\n  <li>Third Party </li>\n  <li>Current Python Project </li>\n  <li>Explicitly Local (. before import, as in: from . import x) </li>\n  </ul>\n  \n  <p>Custom Separate Sections (Defined by forced_separate list in configuration file) \n  Inside of each section the imports are sorted alphabetically. isort automatically removes duplicate python imports, and wraps long from imports to the specified line length (defaults to 80).</p>\n</blockquote>\n\n<p><a href=\"https://pypi.python.org/pypi/flake8-isort\" rel=\"noreferrer\">https://pypi.python.org/pypi/flake8-isort</a> plugs this functionality into flake8</p>\n",
                    "OwnerUserId": "674447",
                    "LastEditorUserId": "674447",
                    "LastEditDate": "2016-02-16T10:58:09.310",
                    "LastActivityDate": "2016-02-16T10:58:09.310",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "23225221",
                "ParentRepo": "https://github.com/deis/workflow",
                "StackOverflow_Post": {
                    "Id": "23225221",
                    "PostTypeId": "5",
                    "CreationDate": "2014-04-22T16:31:43.560",
                    "Score": "0",
                    "Body": "<p>Deis is an open source PaaS that makes it easy to deploy, scale and manage containers used to host applications and services. Deis builds upon Docker and Kubernetes to provide a private PaaS that is lightweight and flexible.</p>\n\n<p><a href=\"http://deis.io\" rel=\"nofollow noreferrer\">Deis homepage</a></p>\n\n<p><a href=\"https://github.com/deis/workflow\" rel=\"nofollow noreferrer\">Deis GitHub page</a></p>\n",
                    "OwnerUserId": "644992",
                    "LastEditorUserId": "161972",
                    "LastEditDate": "2017-03-19T02:03:32.977",
                    "LastActivityDate": "2017-03-19T02:03:32.977",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "23303493",
                "ParentRepo": "https://github.com/telefonicaid/fiware-orion",
                "StackOverflow_Post": {
                    "Id": "23303493",
                    "PostTypeId": "5",
                    "CreationDate": "2014-04-25T21:38:14.867",
                    "Score": "0",
                    "Body": "<p>The Orion Context Broker is an implementation of the Publish/Subscribe Context Broker GE, providing the <a href=\"http://telefonicaid.github.io/fiware-orion/api/v2/stable\" rel=\"nofollow noreferrer\">NGSIv2 interface</a> to manage context information and its availability. Using this interface, clients can do several operations:</p>\n\n<ul>\n<li>Create context information, e.g. a temperature sensor within a room</li>\n<li>Update context information, e.g. send updates of temperature</li>\n<li>Being notified when some condition occurs, e.g. the temperature has changed</li>\n<li>Query context information. The Orion Context Broker stores context\ninformation updated from applications, so queries are resolved based\non that information.</li>\n<li>Register context provider applications, e.g. a temperature sensor\nwithin a room is provided by some third-party context provider</li>\n</ul>\n\n<p><strong>Home Page:</strong> <a href=\"https://github.com/Fiware/catalogue/blob/master/core/README.md#orion\" rel=\"nofollow noreferrer\">https://github.com/Fiware/catalogue/blob/master/core/README.md#orion</a></p>\n\n<p><strong>GitHub Page:</strong> <a href=\"https://github.com/telefonicaid/fiware-orion\" rel=\"nofollow noreferrer\">https://github.com/telefonicaid/fiware-orion</a></p>\n",
                    "OwnerUserId": "3067523",
                    "LastEditorUserId": "1179828",
                    "LastEditDate": "2018-12-12T15:22:01.917",
                    "LastActivityDate": "2018-12-12T15:22:01.917",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "23718985",
                "ParentRepo": "https://github.com/UW-Hydro/VIC",
                "StackOverflow_Post": {
                    "Id": "23718985",
                    "PostTypeId": "1",
                    "CreationDate": "2014-05-18T05:55:57.360",
                    "Score": "2",
                    "ViewCount": "150",
                    "Body": "<p>I am trying to build Variable Infiltration Capacity microscale hydrologic model \u2014 i.e VIC software is to be made executable. </p>\n\n<p>I have extracted the zip file and then on the terminal I wrote <code>make</code> to have an executable file for the software to run.\nThe link from where I downloaded the zip file is <a href=\"https://github.com/UW-Hydro/VIC\" rel=\"nofollow\">https://github.com/UW-Hydro/VIC</a> (from the download Zip option). The folder contains many C files and a makefile.\nI have tried building on both Windows and Linux but could not get the result. Any idea what I'm doing wrong?</p>\n",
                    "OwnerUserId": "2773148",
                    "LastEditorUserId": "15168",
                    "LastEditDate": "2014-05-18T06:17:01.803",
                    "LastActivityDate": "2014-05-18T06:25:11.470",
                    "Title": "Make not successful building VIC on Windows and Linux",
                    "Tags": "<linux><gcc><makefile><zip>",
                    "AnswerCount": "0",
                    "CommentCount": "3",
                    "FavoriteCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "23907506",
                "ParentRepo": "https://github.com/Wirecloud/wirecloud",
                "StackOverflow_Post": {
                    "Id": "23907506",
                    "PostTypeId": "5",
                    "CreationDate": "2014-05-28T09:17:47.313",
                    "Score": "0",
                    "Body": "<p>WireCloud builds on cutting-edge end-user development, RIA and semantic technologies to offer a next-generation end-user centred web application mashup platform aimed at leveraging the long tail of the Internet of Services.</p>\n\n<p>WireCloud builds on cutting-edge end-user (software) development, RIA and semantic technologies to offer a next-generation end-user centred web application mashup platform aimed at allowing end users without programming skills to easily create web applications and dashboards/cockpits (e.g. to visualize their data of interest or to control their domotized home or environment). Web application mashups integrate heterogeneous data, application logic, and UI components (widgets) sourced from the Web to create new coherent and value-adding composite applications. They are targeted at leveraging the \"long tail\" of the Web of Services (a.k.a. the Programmable Web) by exploiting rapid development, DIY, and shareability. They typically serve a specific situational (i.e. immediate, short-lived, customized) need, frequently with high potential for reuse. Is this \"situational\" character which precludes them to be offered as 'off-the-shelf' functionality by solution providers, and therefore creates the need for a tool like WireCloud.</p>\n\n<h3>References</h3>\n\n<p>This project is part of <a href=\"http://www.fiware.org\" rel=\"nofollow\">FIWARE</a>. Check it out in the <a href=\"http://catalogue.fiware.org/enablers/application-mashup-wirecloud\" rel=\"nofollow\">Catalogue</a></p>\n\n<ul>\n<li><a href=\"https://wirecloud.readthedocs.io/en/stable/\" rel=\"nofollow\">Official documentation</a></li>\n<li><a href=\"https://github.com/Wirecloud/wirecloud\" rel=\"nofollow\">GitHub repo</a></li>\n</ul>\n",
                    "OwnerUserId": "2255503",
                    "LastEditorUserId": "2255503",
                    "LastEditDate": "2016-10-10T07:16:34.977",
                    "LastActivityDate": "2016-10-10T07:16:34.977",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "24963364",
                "ParentRepo": "https://github.com/SublimeText-Markdown/MarkdownEditing/issues/183",
                "StackOverflow_Post": {
                    "Id": "24963364",
                    "PostTypeId": "2",
                    "ParentId": "24959801",
                    "CreationDate": "2014-07-25T19:43:17.483",
                    "Score": "8",
                    "Body": "<p>I have found the solution in the buglist of the plugins github profile.</p>\n\n<p><a href=\"https://github.com/SublimeText-Markdown/MarkdownEditing/issues/183\" rel=\"noreferrer\">https://github.com/SublimeText-Markdown/MarkdownEditing/issues/183</a></p>\n\n<p>Preferences > Package Settings > MarkdownEditing > Markdown GFM Settings - User:</p>\n\n<pre><code>\"draw_centered\": false,\n</code></pre>\n\n<p>Here is another helpful site</p>\n\n<ul>\n<li><a href=\"http://www.javatronic.fr/2014/01/10/tuning_sublime_for_markdown_editing.html\" rel=\"noreferrer\">http://www.javatronic.fr/2014/01/10/tuning_sublime_for_markdown_editing.html</a></li>\n</ul>\n",
                    "OwnerUserId": "2745306",
                    "LastEditorUserId": "2745306",
                    "LastEditDate": "2014-07-25T20:14:12.933",
                    "LastActivityDate": "2014-07-25T20:14:12.933",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "25969150",
                "ParentRepo": "https://github.com/capensis/canopsis/wiki/Install-from-packages",
                "StackOverflow_Post": {
                    "Id": "25969150",
                    "PostTypeId": "2",
                    "ParentId": "21671552",
                    "CreationDate": "2014-09-22T07:55:10.637",
                    "Score": "14",
                    "Body": "<p>I was able to download the RPM and then install it locally after reading this <a href=\"https://github.com/capensis/canopsis/wiki/Install-from-packages\" rel=\"noreferrer\">article</a></p>\n\n<pre><code> wget http://vault.centos.org/6.2/os/x86_64/Packages/xorg-x11-server-Xvfb-1.10.4-6.el6.x86_64.rpm\n yum localinstall xorg-x11-server-Xvfb-1.10.4-6.el6.x86_64.rpm\n</code></pre>\n",
                    "OwnerUserId": "533419",
                    "LastEditorUserId": "1075324",
                    "LastEditDate": "2015-12-16T11:26:07.073",
                    "LastActivityDate": "2015-12-16T11:26:07.073",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "26357685",
                "ParentRepo": "https://github.com/kimmobrunfeldt/progressbar.js",
                "StackOverflow_Post": {
                    "Id": "26357685",
                    "PostTypeId": "2",
                    "ParentId": "2559268",
                    "CreationDate": "2014-10-14T09:48:58.257",
                    "Score": "1",
                    "Body": "<p>You could use <a href=\"https://github.com/kimmobrunfeldt/progressbar.js\" rel=\"nofollow\">ProgressBar.js</a>. No dependencies, easy API and supports major browsers. </p>\n\n<pre><code>var line = new ProgressBar.Line('#container');\nline.animate(1);\n</code></pre>\n\n<p>See more examples of usage <a href=\"http://kimmobrunfeldt.github.io/progressbar.js/#examples\" rel=\"nofollow\">in the demo page.</a></p>\n",
                    "OwnerUserId": "1446092",
                    "LastEditorUserId": "1446092",
                    "LastEditDate": "2014-10-14T09:59:41.050",
                    "LastActivityDate": "2014-10-14T09:59:41.050",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "26650206",
                "ParentRepo": "https://github.com/michaeljoseph/changes",
                "StackOverflow_Post": {
                    "Id": "26650206",
                    "PostTypeId": "2",
                    "ParentId": "9226100",
                    "CreationDate": "2014-10-30T10:10:13.270",
                    "Score": "0",
                    "Body": "<p>There is <a href=\"https://github.com/michaeljoseph/changes\" rel=\"nofollow\">changes</a>, software that makes the pypi publish just a single step. Looks like that is quite similar to <a href=\"http://seed.readthedocs.org\" rel=\"nofollow\">seed</a>.</p>\n\n<p>Anyway, it would be nice if pypi could just check if on github there is a new tagged release and release it on pypi.</p>\n",
                    "OwnerUserId": "1216074",
                    "LastActivityDate": "2014-10-30T10:10:13.270",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "27358786",
                "ParentRepo": "https://github.com/swcarpentry/amy/",
                "StackOverflow_Post": {
                    "Id": "27358786",
                    "PostTypeId": "1",
                    "CreationDate": "2014-12-08T13:10:40.653",
                    "Score": "3",
                    "ViewCount": "2571",
                    "Body": "<p>We're trying once again to build <a href=\"https://github.com/swcarpentry/amy/\" rel=\"nofollow noreferrer\">a web-based tool</a> to help us manage <a href=\"http://software-carpentry.org\" rel=\"nofollow noreferrer\">Software Carpentry</a> workshops. We're using <a href=\"https://www.djangoproject.com/\" rel=\"nofollow noreferrer\">Django</a>, which despite its age is still the most widely used (and best documented) web programming framework for Python. It's been a few years since I built anything in it, though, and I'm stumbling over a few things.</p>\n\n<p>For example, my data model looks like this (with lots of irrelevant stuff stripped out):</p>\n\n<pre><code>class Person(models.Model):\n    '''Someone we know.'''\n    email      = models.CharField(max_length=STR_LONG, unique=True, null=True)\n\nclass Event(models.Model):\n    '''A workshop or other event.'''\n    slug       = models.CharField(max_length=STR_LONG, unique=True)\n\nclass Role(models.Model):\n    '''The kinds of things people can do at workshops.'''\n    name       = models.CharField(max_length=STR_MED)\n\nclass Task(models.Model):\n    '''Someone did something at some workshop.'''\n    event      = models.ForeignKey(Event)\n    person     = models.ForeignKey(Person)\n    role       = models.ForeignKey(Role)\n</code></pre>\n\n<p>One of the pages in the application displays information about a particular event.  I want to add the names of all the people who were instructors at that event to the page.  If I was using SQL directly, I'd write something like:</p>\n\n<pre><code>select   Event.slug, group_contact(Person.email, ', ')\nfrom     Person join Event join Role join Task\non       Person.id=Task.person and Event.id=Task.event and Role.id=Task.role\nwhere    Role.name='instructor'\ngroup by Event.id;\n</code></pre>\n\n<p>How can I do this with Django's ORM? According to <a href=\"https://stackoverflow.com/questions/10340684/group-concat-equivalent-in-django\">this Stack Overflow question</a>, I can use <a href=\"https://docs.djangoproject.com/en/dev/ref/templates/builtins/#regroup\" rel=\"nofollow noreferrer\">the 'regroup' tag in the view</a> or <a href=\"http://harkablog.com/inside-the-django-orm-aggregates.html\" rel=\"nofollow noreferrer\">build a custom aggregator</a>. The former is complicated by the multi-step nature of the join, and the latter feels... complicated. My instinct is that I ought to be able to attach all the <code>Person</code> objects corresponding to instructors at a particular <code>Event</code> to that event, then loop over them in my view. If you know how to do this, I'd be grateful for a pointer.</p>\n",
                    "OwnerUserId": "1403470",
                    "LastEditorUserId": "-1",
                    "LastEditDate": "2017-05-23T12:15:32.357",
                    "LastActivityDate": "2014-12-09T14:55:20.350",
                    "Title": "Equivalent of group_concat in Django ORM",
                    "Tags": "<python><django><orm>",
                    "AnswerCount": "5",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "28046800",
                "ParentRepo": "https://github.com/flask-api/flask-api",
                "StackOverflow_Post": {
                    "Id": "28046800",
                    "PostTypeId": "2",
                    "ParentId": "28032278",
                    "CreationDate": "2015-01-20T13:41:15.157",
                    "Score": "41",
                    "Body": "<p><strong>Short answer</strong>:</p>\n<p>restful.Resource is from a <a href=\"https://flask-restful.readthedocs.io/en/latest/\" rel=\"nofollow noreferrer\">Flask-Restful</a> extension, which is not Flask itself. <a href=\"http://blog.miguelgrinberg.com/post/designing-a-restful-api-with-python-and-flask\" rel=\"nofollow noreferrer\">Miguel's tutorial</a> uses <a href=\"http://flask.pocoo.org/\" rel=\"nofollow noreferrer\">Flask</a> to write a restful interface.</p>\n<p><strong>Long answer</strong>:</p>\n<p>First of all, along with Flask, there are a number of <a href=\"http://flask.pocoo.org/extensions/\" rel=\"nofollow noreferrer\">Flask extensions</a>. Although they work together, they are separate packages and are written by individual authors. <strong>Flask-Restful</strong> is an extension to <strong>Flask</strong>.</p>\n<p>Miguel's tutorial explains how you can make a restful api using Flask by itself.</p>\n<p><a href=\"https://flask-restful.readthedocs.io/en/latest/\" rel=\"nofollow noreferrer\">Flask-Restful</a> with the aim to saving some of us from re-inventing the wheel, promises to turn a custom class(or a custom Python data structure) to a restful web service. <a href=\"https://flask-restx.readthedocs.io/en/stable/\" rel=\"nofollow noreferrer\">Flask-RESTX</a>, a fork of <strong>Flask-Restful</strong>, auto-generates api documentation with swagger UI.</p>\n<p>In addition, Flask also <a href=\"https://flask-doc.readthedocs.io/en/latest/views.html#method-views-for-apis\" rel=\"nofollow noreferrer\">documented</a> the usage of <strong>MethodView</strong> to allow developers to write their own restful APIs. In parallel, <a href=\"https://flask-restless.readthedocs.org/en/latest/\" rel=\"nofollow noreferrer\">Flask-Restless</a> promises to turn a SqlAlchemy class into a restful web service.</p>\n<p>An update(18/07/2016), <a href=\"https://github.com/flask-api/flask-api\" rel=\"nofollow noreferrer\">flask-api</a> turns a function/view into a restful interface and is designed by Tom Christie, the author of <a href=\"http://www.django-rest-framework.org/\" rel=\"nofollow noreferrer\">django restful framework</a>.</p>\n<p>an update(17/03/2021), <a href=\"https://flask-restplus.readthedocs.io/en/stable/\" rel=\"nofollow noreferrer\">Flask-RESTPlus</a> does smiliar things as above libraries but it also helps you construct swagger API documentation, which is an extra bonus.</p>\n<p><em>There are many roads to Roma</em>.</p>\n",
                    "OwnerUserId": "2689383",
                    "LastEditorUserId": "2689383",
                    "LastEditDate": "2021-03-17T18:54:30.003",
                    "LastActivityDate": "2021-03-17T18:54:30.003",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "28560094",
                "ParentRepo": "https://github.com/codegangsta/cli",
                "StackOverflow_Post": {
                    "Id": "28560094",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "28560175",
                    "CreationDate": "2015-02-17T10:42:58.160",
                    "Score": "-1",
                    "ViewCount": "52",
                    "Body": "<p>This code is from the <code>cli</code> Go package: <a href=\"https://github.com/codegangsta/cli\" rel=\"nofollow\">https://github.com/codegangsta/cli</a></p>\n\n<pre><code>package main\n\nimport (\n    \"github.com/codegangsta/cli\"\n    \"os\"\n)\n\nfunc main() {\n    app := cli.NewApp()\n    app.Name = \"greet\"\n    app.Usage = \"fight the loneliness!\"\n    app.Flags = []cli.Flag{\n        cli.StringFlag{\n            Name:  \"lang, l\",\n            Value: \"english\",\n            Usage: \"language for the greeting\",\n        },\n    }\n\n    app.Action = func(c *cli.Context) {\n        name := \"someone\"\n        if len(c.Args()) &gt; 0 {\n            name = c.Args()[0]\n        }\n        if c.String(\"lang\") == \"spanish\" {\n            println(\"Hola\", name)\n        } else {\n            println(\"Hello\", name)\n        }\n    }\n\n    app.Run(os.Args)\n}\n</code></pre>\n\n<p>I'm a Go beginner and I understand everything, except this part:</p>\n\n<pre><code>if len(c.Args()) &gt; 0 {\n    name = c.Args()[0]\n}\n</code></pre>\n\n<p>What does that block says? Why is it necessary?</p>\n",
                    "OwnerUserId": "122536",
                    "LastActivityDate": "2015-02-17T10:47:10.320",
                    "Title": "What's the use of the following c.Args() > 0",
                    "Tags": "<go>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "28586644",
                "ParentRepo": "https://github.com/nodemcu/nodemcu-firmware/wiki/nodemcu_api_en",
                "StackOverflow_Post": {
                    "Id": "28586644",
                    "PostTypeId": "1",
                    "CreationDate": "2015-02-18T14:58:16.973",
                    "Score": "5",
                    "ViewCount": "8069",
                    "Body": "<p>I have been trying to stream speech( May extend to audio) at 16Khz over the wifi HTTP TCP/IP. I have started of with ESP8266 wifi module considering its compatibility with Arduino and other platforms. </p>\n\n<p>During the course I had to figure out the feasibility of ESP8266 to stream at 16KHz. This link says  ( <a href=\"http://espressif.com/en/products/esp8266/\" rel=\"noreferrer\">http://espressif.com/en/products/esp8266/</a> ) it's capable but found contradicting views over other forums. </p>\n\n<ol>\n<li>But is it really possible to have a I2S on such a small cpu..? </li>\n</ol>\n\n<p>I proceeded with the Idea of bit banking and using GPIO but the max frequency available with GPIO is 1KHz( ie. the PWM). The firmware used here was NODEmcu and LUA script- <a href=\"https://github.com/nodemcu/nodemcu-firmware/wiki/nodemcu_api_en\" rel=\"noreferrer\">https://github.com/nodemcu/nodemcu-firmware/wiki/nodemcu_api_en</a>. </p>\n\n<ol start=\"2\">\n<li><p>Is it a hardware limitation or the firmware limitation..?</p></li>\n<li><p>Can anyone guide me to access I2S on ESP and also assure its compatibility to stream at 16KHZ. </p></li>\n</ol>\n",
                    "OwnerUserId": "3770871",
                    "LastActivityDate": "2022-09-25T01:00:35.090",
                    "Title": "Speech streaming over Wifi",
                    "Tags": "<audio><lua><embedded><wifi><speech>",
                    "AnswerCount": "1",
                    "CommentCount": "4",
                    "FavoriteCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "28763695",
                "ParentRepo": "https://github.com/arteria/django-hijack",
                "StackOverflow_Post": {
                    "Id": "28763695",
                    "PostTypeId": "2",
                    "ParentId": "2242909",
                    "CreationDate": "2015-02-27T11:10:46.720",
                    "Score": "15",
                    "Body": "<p>It looks like quite a few other people have had this problem and have written re-usable apps to do this and at least some are listed on the <a href=\"https://www.djangopackages.com/grids/g/user-switching/\" rel=\"noreferrer\">django packages page for user switching</a>. The most active at time of writing appear to be:</p>\n\n<ul>\n<li><a href=\"https://github.com/arteria/django-hijack\" rel=\"noreferrer\">django-hijack</a> puts a \"hijack\" button in the user list in the admin, along with a bit at the top of page for while you've hijacked an account.</li>\n<li><a href=\"https://github.com/samastur/Impostor\" rel=\"noreferrer\">impostor</a> means you can login with username \"me as other\" and your own password</li>\n<li><a href=\"https://bitbucket.org/petersanchez/django-impersonate/\" rel=\"noreferrer\">django-impersonate</a> sets up URLs to start impersonating a user, stop, search etc</li>\n</ul>\n",
                    "OwnerUserId": "3189",
                    "LastActivityDate": "2015-02-27T11:10:46.720",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "29063279",
                "ParentRepo": "https://github.com/mbraak/django-file-form",
                "StackOverflow_Post": {
                    "Id": "29063279",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "29063564",
                    "CreationDate": "2015-03-15T16:42:59.120",
                    "Score": "1",
                    "ViewCount": "98",
                    "Body": "<p>im getting this error \"NOT NULL constraint failed: myfiles_document.user_id\"\nwhat im trying to do is attach files to user ForeignKey so user can only see what they upload im using this app <a href=\"https://github.com/mbraak/django-file-form\" rel=\"nofollow\">django-file-form</a> here the code for the project </p>\n\n<p>model.py</p>\n\n<pre><code>class Example2(models.Model):\n    title = models.CharField(max_length=255)\n\nclass ExampleFile(models.Model):\n    fs = FileSystemStorage(location=settings.MEDIA_ROOT)\n    input_file = models.FileField(max_length=255, upload_to='uploads/%Y.%m.%d' , storage=fs)\n    user = models.ForeignKey('auth.User')\n\n\n    def get_upload_path(self,filename):\n        return \"static/uploads/\"+str(self.user.id)+\"/\"+filename\n</code></pre>\n\n<p>forms.py</p>\n\n<pre><code>class BaseForm(FileFormMixin, django_bootstrap3_form.BootstrapForm):\n    title = django_bootstrap3_form.CharField()\n\n\nclass MultipleFileExampleForm(BaseForm):\n    input_file = MultipleUploadedFileField()\n\ndef save(self):\n    example = Example2.objects.create(\n        title=self.cleaned_data['title']\n    )\n\n    for f in self.cleaned_data['input_file']:\n        ExampleFile.objects.create(\n            input_file=f\n        )\n\n    self.delete_temporary_files()\n</code></pre>\n\n<p>views.py</p>\n\n<pre><code> class BaseFormView(generic.FormView):\n    template_name = 'example_form.html'\n\n def get_success_url(self):\n    return reverse('example_success')\n\n def form_valid(self, form):\n    form.save()\n    return super(BaseFormView, self).form_valid(form)    \n\nclass ExampleSuccessView(generic.TemplateView):\n    template_name = 'success.html'\n\nclass MultipleExampleView(LoginRequiredMixin, BaseFormView):\n    form_class = forms.MultipleFileExampleForm\n</code></pre>\n",
                    "OwnerUserId": "4673451",
                    "LastActivityDate": "2015-03-15T17:05:46.237",
                    "Title": "User Specific Uploads Django 1.7",
                    "Tags": "<python><django><django-1.7><ajax-upload>",
                    "AnswerCount": "1",
                    "CommentCount": "3",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "29089287",
                "ParentRepo": "https://github.com/jhamman/nco-bindings",
                "StackOverflow_Post": {
                    "Id": "29089287",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "33020544",
                    "CreationDate": "2015-03-17T00:22:15.987",
                    "Score": "2",
                    "ViewCount": "671",
                    "Body": "<p>There is not much help on troubleshooting the outside package NCO for netCDF4 files when downloading. I am following the steps from <a href=\"https://github.com/jhamman/nco-bindings\" rel=\"nofollow\">https://github.com/jhamman/nco-bindings</a>. The first step is to <code>run setup.py install</code> and I was able to see it install. Below is the end of the output saying it installed.</p>\n\n<pre><code>Installed c:\\users\\...\\appdata\\local\\enthought\\canopy\\user\\lib\\site- \npackages\\nco-0.0.2-py2.7.egg\nProcessing dependencies for nco==0.0.2\nFinished processing dependencies for nco==0.0.2\n</code></pre>\n\n<p>but I am running into a problem when Running operators. The step is:</p>\n\n<pre><code>From nco import Nco\nnco=Nco()\n</code></pre>\n\n<p>and I get an error for <code>nco = Nco()</code>saying  </p>\n\n<blockquote>\n  <p>TypeError: 'NoneType' object has no attribute '<strong>getitem</strong>'</p>\n</blockquote>\n\n<p>meaning there is nothing within that function. I am using Enthought Canopy for python but I do not think that is a problem. Any help on getting function like <code>ncra</code> running would be appreciated. Thanks</p>\n",
                    "OwnerUserId": "3984094",
                    "LastActivityDate": "2015-10-08T15:54:13.800",
                    "Title": "NCO download Python",
                    "Tags": "<python><nco>",
                    "AnswerCount": "2",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "29292430",
                "ParentRepo": "https://github.com/jondot/awesome-react-native",
                "StackOverflow_Post": {
                    "Id": "29292430",
                    "PostTypeId": "5",
                    "CreationDate": "2015-03-27T02:43:08.960",
                    "Score": "0",
                    "Body": "<p><a href=\"https://reactnative.dev/\" rel=\"nofollow noreferrer\"><strong>React Native</strong></a> is an open-source framework created by Facebook that lets you build mobile apps using only <a href=\"/questions/tagged/javascript\" class=\"post-tag\" title=\"show questions tagged &#39;javascript&#39;\" rel=\"tag\">javascript</a> and some basic <a href=\"/questions/tagged/html\" class=\"post-tag\" title=\"show questions tagged &#39;html&#39;\" rel=\"tag\">html</a> and <a href=\"/questions/tagged/css\" class=\"post-tag\" title=\"show questions tagged &#39;css&#39;\" rel=\"tag\">css</a>. It uses the same design as React, letting you compose a rich mobile UI from declarative components.</p>\n<p>React Native apps are not &quot;mobile web apps&quot; or &quot;hybrid apps&quot;. They are real cross-platform mobile apps that are indistinguishable from apps built using <a href=\"/questions/tagged/objective-c\" class=\"post-tag\" title=\"show questions tagged &#39;objective-c&#39;\" rel=\"tag\">objective-c</a> or <a href=\"/questions/tagged/java\" class=\"post-tag\" title=\"show questions tagged &#39;java&#39;\" rel=\"tag\">java</a>. <a href=\"/questions/tagged/typescript\" class=\"post-tag\" title=\"show questions tagged &#39;typescript&#39;\" rel=\"tag\">typescript</a> is often used to bring clarity in development.</p>\n<p>The idea behind React Native can best be captured by the slogan &quot;Learn once, write anywhere&quot;, enabling developers to use the same development approach for both desktop/browser and mobile apps.</p>\n<p>Technically React Native runs the JavaScript code for a React app in a background thread. Updates to the virtual DOM are collected, and all changes are sent through an API into the native portion of the app. By doing this, React Native avoids slowing down the FPS rate of the app by not making the app wait for unfinished JavaScript operations.</p>\n<h3>Resources</h3>\n<ul>\n<li><a href=\"https://reactnative.dev/\" rel=\"nofollow noreferrer\">Official site</a></li>\n<li><a href=\"https://reactnative.dev/docs/getting-started\" rel=\"nofollow noreferrer\">Getting started</a></li>\n<li><a href=\"https://egghead.io/q/react-native\" rel=\"nofollow noreferrer\">Video tutorials from EggHead.io</a></li>\n<li><a href=\"https://js.coach/?menu%5Bcollections%5D=React%20Native&amp;page=1\" rel=\"nofollow noreferrer\">Catalog of React Native components</a></li>\n<li><a href=\"https://snack.expo.dev/\" rel=\"nofollow noreferrer\">Expo's Snack</a></li>\n<li><a href=\"https://www.reactnative.express/\" rel=\"nofollow noreferrer\">Tutorials and Guide on reactnativeexpress.com</a></li>\n<li><a href=\"https://github.com/jondot/awesome-react-native\" rel=\"nofollow noreferrer\">Awesome React Native</a></li>\n<li><a href=\"https://native.directory/\" rel=\"nofollow noreferrer\">Native Directory</a></li>\n<li><a href=\"https://react-native-community.github.io/upgrade-helper/\" rel=\"nofollow noreferrer\">Upgrade helper by react-native-community</a></li>\n<li><a href=\"https://reactnative.directory/\" rel=\"nofollow noreferrer\">React Native Directory</a></li>\n</ul>\n<hr />\n<h3>Related tags</h3>\n<ul>\n<li><a href=\"/questions/tagged/javascript\" class=\"post-tag\" title=\"show questions tagged &#39;javascript&#39;\" rel=\"tag\">javascript</a></li>\n<li><a href=\"/questions/tagged/reactjs\" class=\"post-tag\" title=\"show questions tagged &#39;reactjs&#39;\" rel=\"tag\">reactjs</a></li>\n<li><a href=\"/questions/tagged/expo\" class=\"post-tag\" title=\"show questions tagged &#39;expo&#39;\" rel=\"tag\">expo</a></li>\n<li><a href=\"/questions/tagged/reactjs-flux\" class=\"post-tag\" title=\"show questions tagged &#39;reactjs-flux&#39;\" rel=\"tag\">reactjs-flux</a></li>\n<li><a href=\"/questions/tagged/react-redux\" class=\"post-tag\" title=\"show questions tagged &#39;react-redux&#39;\" rel=\"tag\">react-redux</a></li>\n<li><a href=\"/questions/tagged/redux-thunk\" class=\"post-tag\" title=\"show questions tagged &#39;redux-thunk&#39;\" rel=\"tag\">redux-thunk</a></li>\n<li><a href=\"/questions/tagged/redux-saga\" class=\"post-tag\" title=\"show questions tagged &#39;redux-saga&#39;\" rel=\"tag\">redux-saga</a></li>\n<li><a href=\"/questions/tagged/reactjs-testutils\" class=\"post-tag\" title=\"show questions tagged &#39;reactjs-testutils&#39;\" rel=\"tag\">reactjs-testutils</a></li>\n<li><a href=\"/questions/tagged/react-native-navigation\" class=\"post-tag\" title=\"show questions tagged &#39;react-native-navigation&#39;\" rel=\"tag\">react-native-navigation</a></li>\n<li><a href=\"/questions/tagged/react-navigation\" class=\"post-tag\" title=\"show questions tagged &#39;react-navigation&#39;\" rel=\"tag\">react-navigation</a></li>\n<li><a href=\"/questions/tagged/react-native-ios\" class=\"post-tag\" title=\"show questions tagged &#39;react-native-ios&#39;\" rel=\"tag\">react-native-ios</a></li>\n<li><a href=\"/questions/tagged/react-native-android\" class=\"post-tag\" title=\"show questions tagged &#39;react-native-android&#39;\" rel=\"tag\">react-native-android</a></li>\n<li><a href=\"/questions/tagged/react-router\" class=\"post-tag\" title=\"show questions tagged &#39;react-router&#39;\" rel=\"tag\">react-router</a></li>\n<li><a href=\"/questions/tagged/react-native-sentry\" class=\"post-tag\" title=\"show questions tagged &#39;react-native-sentry&#39;\" rel=\"tag\">react-native-sentry</a></li>\n<li><a href=\"/questions/tagged/react-native-device-info\" class=\"post-tag\" title=\"show questions tagged &#39;react-native-device-info&#39;\" rel=\"tag\">react-native-device-info</a></li>\n</ul>\n",
                    "OwnerUserId": "454967",
                    "LastEditorUserId": "13170636",
                    "LastEditDate": "2021-09-13T04:03:46.753",
                    "LastActivityDate": "2021-09-13T04:03:46.753",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "29342810",
                "ParentRepo": "https://github.com/facebook/osquery/wiki",
                "StackOverflow_Post": {
                    "Id": "29342810",
                    "PostTypeId": "2",
                    "ParentId": "25328135",
                    "CreationDate": "2015-03-30T09:36:12.870",
                    "Score": "3",
                    "Body": "<p>Had the same issue and landed here, maybe this helps somebody.</p>\n\n<p>I didn't find a way to embed the .pdf into a page but what I did was to add the .pdf to the wiki folder (like a normal page). Initially this didn't show up in the sidebar nor was it searchable from Github.</p>\n\n<p>It is possible however to link it directly from other pages or a custom sidebar (see for example <a href=\"https://github.com/facebook/osquery/wiki\" rel=\"nofollow\">osquery's wiki</a> for a nice sidebar). Clicking on the link allows you to download the .pdf (didn't find a way to preview it in the browser)</p>\n",
                    "OwnerUserId": "2259743",
                    "LastActivityDate": "2015-03-30T09:36:12.870",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "29776890",
                "ParentRepo": "https://github.com/telefonicaid/fiware-cygnus/blob/master/flume/doc/quick_start_guide.md",
                "StackOverflow_Post": {
                    "Id": "29776890",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "29791236",
                    "CreationDate": "2015-04-21T15:39:34.810",
                    "Score": "3",
                    "ViewCount": "773",
                    "Body": "<p>I have read all the documentation about how cygnus works, I specifically tested <a href=\"https://github.com/telefonicaid/fiware-cygnus/blob/master/flume/doc/quick_start_guide.md\" rel=\"nofollow\">this one</a> successfully. I also finished reading <a href=\"https://github.com/telefonicaid/fiware-cygnus/blob/0.7.1/flume/README.md\" rel=\"nofollow\">this</a> tutorial, but I am sure I haven't configured something correctly.</p>\n\n<p>in cygnus_instance_1.conf I created:</p>\n\n<pre><code>CYGNUS_USER=root\nCONFIG_FOLDER=/usr/cygnus/conf\nCONFIG_FILE=/usr/cygnus/conf/agent_1.conf\nAGENT_NAME=cygnusagent\nLOGFILE_NAME=cygnus.log\nADMIN_PORT=8081\n</code></pre>\n\n<p>and in agent_1.conf I created:</p>\n\n<pre><code>#=============================================\n# To be put in APACHE_FLUME_HOME/conf/cygnus.conf\n#\n# General configuration template explaining how to setup a sink of each of the available types (HDFS, CKAN, MySQL).\n\n#=============================================\n# The next tree fields set the sources, sinks and channels used by Cygnus. You could use different names than the\n# ones suggested below, but in that case make sure you keep coherence in properties names along the configuration file.\n# Regarding sinks, you can use multiple types at the same time; the only requirement is to provide a channel for each\n# one of them (this example shows how to configure 3 sink types at the same time). Even, you can define more than one\n# sink of the same type and sharing the channel in order to improve the performance (this is like having\n# multi-threading).\ncygnusagent.sources = http-source\ncygnusagent.sinks = hdfs-sink mysql-sink ckan-sink\ncygnusagent.channels = hdfs-channel mysql-channel ckan-channel\n\n#=============================================\n# source configuration\n# channel name where to write the notification events\ncygnusagent.sources.http-source.channels = hdfs-channel mysql-channel ckan-channel\n# source class, must not be changed\ncygnusagent.sources.http-source.type = org.apache.flume.source.http.HTTPSource\n# listening port the Flume source will use for receiving incoming notifications\ncygnusagent.sources.http-source.port = 5050\n# Flume handler that will parse the notifications, must not be changed\ncygnusagent.sources.http-source.handler = es.tid.fiware.fiwareconnectors.cygnus.handlers.OrionRestHandler\n# URL target\ncygnusagent.sources.http-source.handler.notification_target = /notify\n# Default service (service semantic depends on the persistence sink)\ncygnusagent.sources.http-source.handler.default_service = def_serv\n# Default service path (service path semantic depends on the persistence sink)\ncygnusagent.sources.http-source.handler.default_service_path = def_servpath\n# Number of channel re-injection retries before a Flume event is definitely discarded (-1 means infinite retries)\ncygnusagent.sources.http-source.handler.events_ttl = 10\n# Source interceptors, do not change\ncygnusagent.sources.http-source.interceptors = ts de\n# Interceptor type, do not change\ncygnusagent.sources.http-source.interceptors.ts.type = timestamp\n# Destination extractor interceptor, do not change\ncygnusagent.sources.http-source.interceptors.de.type = es.tid.fiware.fiwareconnectors.cygnus.interceptors.DestinationExtractor$Builder\n# Matching table for the destination extractor interceptor, put the right absolute path to the file if necessary\n# See the doc/design/interceptors document for more details\ncygnusagent.sources.http-source.interceptors.de.matching_table = /usr/cygnus/conf/matching_table.conf\n\n# ============================================\n# OrionHDFSSink configuration\n# channel name from where to read notification events\ncygnusagent.sinks.hdfs-sink.channel = hdfs-channel\n# sink class, must not be changed\ncygnusagent.sinks.hdfs-sink.type = es.tid.fiware.fiwareconnectors.cygnus.sinks.OrionHDFSSink\n# Comma-separated list of FQDN/IP address regarding the Cosmos Namenode endpoints\n# If you are using Kerberos authentication, then the usage of FQDNs instead of IP addresses is mandatory\ncygnusagent.sinks.hdfs-sink.cosmos_host = x1.y1.z1.w1,x2.y2.z2.w2\n# port of the Cosmos service listening for persistence operations; 14000 for httpfs, 50070 for webhdfs and free choice for inifinty\ncygnusagent.sinks.hdfs-sink.cosmos_port = 14000\n# default username allowed to write in HDFS\ncygnusagent.sinks.hdfs-sink.cosmos_default_username = cosmos_username\n# default password for the default username\ncygnusagent.sinks.hdfs-sink.cosmos_default_password = xxxxxxxxxxxxx\n# HDFS backend type (webhdfs, httpfs or infinity)\ncygnusagent.sinks.hdfs-sink.hdfs_api = httpfs\n# how the attributes are stored, either per row either per column (row, column)\ncygnusagent.sinks.hdfs-sink.attr_persistence = column\n# Hive FQDN/IP address of the Hive server\ncygnusagent.sinks.hdfs-sink.hive_host = x.y.z.w\n# Hive port for Hive external table provisioning\ncygnusagent.sinks.hdfs-sink.hive_port = 10000\n# Kerberos-based authentication enabling\ncygnusagent.sinks.hdfs-sink.krb5_auth = false\n# Kerberos username\ncygnusagent.sinks.hdfs-sink.krb5_auth.krb5_user = krb5_username\n# Kerberos password\ncygnusagent.sinks.hdfs-sink.krb5_auth.krb5_password = xxxxxxxxxxxxx\n# Kerberos login file\ncygnusagent.sinks.hdfs-sink.krb5_auth.krb5_login_conf_file = /usr/cygnus/conf/krb5_login.conf\n# Kerberos configuration file\ncygnusagent.sinks.hdfs-sink.krb5_auth.krb5_conf_file = /usr/cygnus/conf/krb5.conf\n\n# ============================================\n# OrionCKANSink configuration\n# channel name from where to read notification events\ncygnusagent.sinks.ckan-sink.channel = ckan-channel\n# sink class, must not be changed\ncygnusagent.sinks.ckan-sink.type = es.tid.fiware.fiwareconnectors.cygnus.sinks.OrionCKANSink\n# the CKAN API key to use\ncygnusagent.sinks.ckan-sink.api_key = ckanapikey\n# the FQDN/IP address for the CKAN API endpoint\ncygnusagent.sinks.ckan-sink.ckan_host = x.y.z.w\n# the port for the CKAN API endpoint\ncygnusagent.sinks.ckan-sink.ckan_port = 80\n# Orion URL used to compose the resource URL with the convenience operation URL to query it\ncygnusagent.sinks.ckan-sink.orion_url = http://localhost:1026\n# how the attributes are stored, either per row either per column (row, column)\ncygnusagent.sinks.ckan-sink.attr_persistence = row\n# enable SSL for secure Http transportation; 'true' or 'false'\ncygnusagent.sinks.ckan-sink.ssl = false\n\n# ============================================\n# OrionMySQLSink configuration\n# channel name from where to read notification events\ncygnusagent.sinks.mysql-sink.channel = mysql-channel\n# sink class, must not be changed\ncygnusagent.sinks.mysql-sink.type = es.tid.fiware.fiwareconnectors.cygnus.sinks.OrionMySQLSink\n# the FQDN/IP address where the MySQL server runs \ncygnusagent.sinks.mysql-sink.mysql_host = localhost\n# the port where the MySQL server listes for incomming connections\ncygnusagent.sinks.mysql-sink.mysql_port = 3306\n# a valid user in the MySQL server\ncygnusagent.sinks.mysql-sink.mysql_username = root\n# password for the user above\ncygnusagent.sinks.mysql-sink.mysql_password = klasika\n# how the attributes are stored, either per row either per column (row, column)\ncygnusagent.sinks.mysql-sink.attr_persistence = column\n\n#=============================================\n# hdfs-channel configuration\n# channel type (must not be changed)\ncygnusagent.channels.hdfs-channel.type = memory\n# capacity of the channel\ncygnusagent.channels.hdfs-channel.capacity = 1000\n# amount of bytes that can be sent per transaction\ncygnusagent.channels.hdfs-channel.transactionCapacity = 100\n\n#=============================================\n# ckan-channel configuration\n# channel type (must not be changed)\ncygnusagent.channels.ckan-channel.type = memory\n# capacity of the channel\ncygnusagent.channels.ckan-channel.capacity = 1000\n# amount of bytes that can be sent per transaction\ncygnusagent.channels.ckan-channel.transactionCapacity = 100\n\n#=============================================\n# mysql-channel configuration\n# channel type (must not be changed)\ncygnusagent.channels.mysql-channel.type = memory\n# capacity of the channel\ncygnusagent.channels.mysql-channel.capacity = 1000\n# amount of bytes that can be sent per transaction\ncygnusagent.channels.mysql-channel.transactionCapacity = 100\n</code></pre>\n\n<p>Although I dont use OrionHDFSSink and OrionCKANSink, I  didnt touch those configurations because I really am not sure weather I should.</p>\n\n<p><strong>When I finally subscribeContext and target cygnus @ default port 5050, I get a normal response, but nothing is created in my database</strong></p>\n\n<p>What am I doing wrong here?</p>\n",
                    "OwnerUserId": "3791955",
                    "LastEditorUserId": "13302",
                    "LastEditDate": "2015-04-21T15:43:18.343",
                    "LastActivityDate": "2015-04-22T08:00:16.030",
                    "Title": "How to store data in MySql using cygnus?",
                    "Tags": "<mysql><fiware><fiware-orion><fiware-cygnus>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "FavoriteCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "30144432",
                "ParentRepo": "https://github.com/square/leakcanary",
                "StackOverflow_Post": {
                    "Id": "30144432",
                    "PostTypeId": "1",
                    "CreationDate": "2015-05-09T19:59:42.647",
                    "Score": "20",
                    "ViewCount": "7136",
                    "Body": "<p>I am using the <a href=\"https://github.com/square/leakcanary\" rel=\"noreferrer\">LeakCanary</a> library to monitor memory leaks in my app.  I received this memory leak and not sure how to track down what is causing it.</p>\n<pre><code>05-09 09:32:14.731  28497-31220/? D/LeakCanary\ufe55 In com.etiennelawlor.minesweeper:0.0.21:21.\n    * com.etiennelawlor.minesweeper.fragments.MinesweeperFragment has leaked:\n    * GC ROOT com.google.android.gms.games.internal.GamesClientImpl$PopupLocationInfoBinderCallbacks.zzahO\n    * references com.google.android.gms.games.internal.PopupManager$PopupManagerHCMR1.zzajo\n    * references com.google.android.gms.games.internal.GamesClientImpl.mContext\n    * references com.etiennelawlor.minesweeper.activities.MinesweeperActivity.mFragments\n    * references android.app.FragmentManagerImpl.mAdded\n    * references java.util.ArrayList.array\n    * references array java.lang.Object[].[0]\n    * leaks com.etiennelawlor.minesweeper.fragments.MinesweeperFragment instance\n    * Reference Key: 2f367393-6dfd-4797-8d85-7ac52c431d07\n    * Device: LGE google Nexus 5 hammerhead\n    * Android Version: 5.1 API: 22\n    * Durations: watch=5015ms, gc=141ms, heap dump=1978ms, analysis=23484ms\n</code></pre>\n<p>This is my repo :  <a href=\"https://github.com/lawloretienne/Minesweeper\" rel=\"noreferrer\">https://github.com/lawloretienne/Minesweeper</a></p>\n<p>This seems to be an elusive one. I set up an <code>Interface</code> to communicate between a <code>Fragment</code> and an <code>Activity</code>. I set this <code>mCoordinator</code> <code>Interface</code> variable up in <code>onAttach()</code> then I realized I was not nulling it out in <code>onDetach()</code>. I fixed that issue but still am getting a memory leak. Any ideas?</p>\n<h3>Update</h3>\n<p>I disabled the <code>Fragment</code> leak watching, and I still get a notification about the activity leaking with the following leak trace :</p>\n<pre><code>05-09 17:07:33.074  12934-14824/? D/LeakCanary\ufe55 In com.etiennelawlor.minesweeper:0.0.21:21.\n    * com.etiennelawlor.minesweeper.activities.MinesweeperActivity has leaked:\n    * GC ROOT com.google.android.gms.games.internal.GamesClientImpl$PopupLocationInfoBinderCallbacks.zzahO\n    * references com.google.android.gms.games.internal.PopupManager$PopupManagerHCMR1.zzajo\n    * references com.google.android.gms.games.internal.GamesClientImpl.mContext\n    * leaks com.etiennelawlor.minesweeper.activities.MinesweeperActivity instance\n    * Reference Key: f4d06830-0e16-43a2-9750-7e2cb77ae24d\n    * Device: LGE google Nexus 5 hammerhead\n    * Android Version: 5.1 API: 22\n    * Durations: watch=5016ms, gc=164ms, heap dump=3430ms, analysis=39535ms\n</code></pre>\n",
                    "OwnerUserId": "502671",
                    "LastEditorUserId": "-1",
                    "LastEditDate": "2020-06-20T09:12:55.060",
                    "LastActivityDate": "2017-01-19T12:57:03.137",
                    "Title": "Memory leak in Fragment",
                    "Tags": "<android><memory-leaks><leakcanary>",
                    "AnswerCount": "4",
                    "CommentCount": "10",
                    "FavoriteCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "30438910",
                "ParentRepo": "https://github.com/drgarcia1986/drf-pdf",
                "StackOverflow_Post": {
                    "Id": "30438910",
                    "PostTypeId": "2",
                    "ParentId": "30438729",
                    "CreationDate": "2015-05-25T12:56:43.143",
                    "Score": "2",
                    "Body": "<p>You can use <strong><a href=\"https://github.com/drgarcia1986/drf-pdf\" rel=\"nofollow\">DRF-PDF</a></strong> project with <em>PDFFileResponse</em>:</p>\n\n<pre><code>from rest_framework import status\nfrom rest_framework.views import APIView\nfrom drf_pdf.response import PDFFileResponse\nfrom drf_pdf.renderer import PDFRenderer\n\n\nclass PDFHandler(APIView):\n\n    renderer_classes = (PDFRenderer, )\n\n    def get(self, request):\n        return PDFFileResponse(\n            file_path='/path/to/file.pdf',\n            status=status.HTTP_200_OK\n        )\n</code></pre>\n\n<p>But, maybe you cannot respond in both formats (json and stream).</p>\n",
                    "OwnerUserId": "2079352",
                    "LastEditorUserId": "2079352",
                    "LastEditDate": "2015-05-25T13:02:47.263",
                    "LastActivityDate": "2015-05-25T13:02:47.263",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "30494958",
                "ParentRepo": "https://github.com/umutbozkurt/django-rest-framework-mongoengine",
                "StackOverflow_Post": {
                    "Id": "30494958",
                    "PostTypeId": "2",
                    "ParentId": "30487938",
                    "CreationDate": "2015-05-27T23:44:04.047",
                    "Score": "0",
                    "Body": "<p>The issue here is that you are passing a string (<code>unicode</code> type) to DRF but you are expecting DRF to turn it into a nested representation. Without anything extra, DRF is not possible to do this, as it's way out of the general scope that it tries to maintain.</p>\n\n<p><a href=\"https://github.com/umutbozkurt/django-rest-framework-mongoengine\" rel=\"nofollow\">Django REST framework Mongoengine</a> on the other hand is perfectly fine with handling the abstraction layer, and it's recommended for those using Django REST framework with Mongoengine.</p>\n\n<p>Without an abstraction layer, you are going to be forced to <a href=\"http://www.django-rest-framework.org/api-guide/fields/#custom-fields\" rel=\"nofollow\">create a custom field</a> that converts the object ids into the actual objects, and then serializes them into the nested representations.</p>\n",
                    "OwnerUserId": "359284",
                    "LastActivityDate": "2015-05-27T23:44:04.047",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "30729030",
                "ParentRepo": "https://github.com/kwikteam/phy/blob/master/tools/api.py",
                "StackOverflow_Post": {
                    "Id": "30729030",
                    "PostTypeId": "2",
                    "ParentId": "30728660",
                    "CreationDate": "2015-06-09T10:07:01.677",
                    "Score": "2",
                    "Body": "<p>Here are two links that you might find useful:</p>\n\n<ul>\n<li><p><a href=\"https://github.com/rossant/ipymd\" rel=\"nofollow\">https://github.com/rossant/ipymd</a>: this lets you use the IPython notebook frontend on Markdown documents. There is also a md&lt;->ipynb conversion CLI tool. It can be easier to deal with Markdown documents than ipynb files in a doc-generation tool.</p></li>\n<li><p><a href=\"https://github.com/kwikteam/phy/blob/master/tools/api.py\" rel=\"nofollow\">https://github.com/kwikteam/phy/blob/master/tools/api.py</a>: a quick script that I wrote to generate an API documentation in Markdown from a Python project. There is no notebook involved here, but you can use ipymd to convert it to a notebook, or to edit it in the notebook frontend.</p></li>\n</ul>\n",
                    "OwnerUserId": "1595060",
                    "LastActivityDate": "2015-06-09T10:07:01.677",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "30852422",
                "ParentRepo": "https://github.com/josuebrunel/yahoo-oauth",
                "StackOverflow_Post": {
                    "Id": "30852422",
                    "PostTypeId": "2",
                    "ParentId": "30832915",
                    "CreationDate": "2015-06-15T18:28:49.393",
                    "Score": "0",
                    "Body": "<p>You have to use <a href=\"https://developer.yahoo.com/oauth/guide/about.html\" rel=\"nofollow\">OAuth1</a> to be able to use you <em>consumer_key</em> and <em>consumer_secret</em>.</p>\n\n<p>Once you acquire <strong>access_token</strong> and <strong>access_token_secret</strong>, you will be able to query data as an authenticated user</p>\n\n<p>If by any chance, you're working with <strong>python</strong>, i've made a library called <a href=\"https://github.com/josuebrunel/yahoo-oauth\" rel=\"nofollow\">yahoo-oauth</a> to easily use <strong><em>OAuth1</em></strong> with <strong>YQL</strong>.</p>\n\n<p>Hope it answers your question</p>\n",
                    "OwnerUserId": "975774",
                    "LastActivityDate": "2015-06-15T18:28:49.393",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "30895065",
                "ParentRepo": "https://github.com/telefonicaid/sigfox-iotagent",
                "StackOverflow_Post": {
                    "Id": "30895065",
                    "PostTypeId": "2",
                    "ParentId": "30884390",
                    "CreationDate": "2015-06-17T14:49:14.243",
                    "Score": "0",
                    "Body": "<p>The fast answer is: \"using the iotagentLib.update() method\".  The slow and complete one imply some other steps you will need to complete to have a fully working agent. I suggest you take a look at the code of <a href=\"https://github.com/telefonicaid/sigfox-iotagent\" rel=\"nofollow\">https://github.com/telefonicaid/sigfox-iotagent</a>. That's one of the latest IOTAs we started to develop, and makes use of the IoT Agent Node Lib. Sigfox callbacks use HTTP calls much like your approach, so it should be really easy to modify the Sigfox Agent's code to feet your needs. Most of the interesting code is in this file:</p>\n\n<p><a href=\"https://github.com/telefonicaid/sigfox-iotagent/blob/develop/lib/sigfoxHandlers.js\" rel=\"nofollow\">https://github.com/telefonicaid/sigfox-iotagent/blob/develop/lib/sigfoxHandlers.js</a></p>\n\n<p>I think you can reuse most of the code, excluding the sigfoxParser. If you have further doubts, you should be able to solve your doubts using iotagent-node-lib documentation. </p>\n",
                    "OwnerUserId": "4340880",
                    "LastActivityDate": "2015-06-17T14:49:14.243",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "30913145",
                "ParentRepo": "https://github.com/commercialhaskell/stack",
                "StackOverflow_Post": {
                    "Id": "30913145",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "30922706",
                    "CreationDate": "2015-06-18T10:42:57.027",
                    "Score": "154",
                    "ViewCount": "43320",
                    "Body": "<p>Yesterday I learnt about a new Haskell tool called <a href=\"https://github.com/commercialhaskell/stack\" rel=\"noreferrer\">Stack</a>. At the first blush, it looks like it does much the same job as Cabal. So, what is the difference between them? Is stack a replacement for Cabal? In which cases should I use Stack instead of Cabal? What can Stack do that Cabal can't?</p>\n",
                    "OwnerUserId": "706317",
                    "LastEditorUserId": "2751851",
                    "LastEditDate": "2017-03-04T20:49:11.117",
                    "LastActivityDate": "2021-11-22T23:18:54.373",
                    "Title": "What is the difference between Cabal and Stack?",
                    "Tags": "<haskell><cabal><haskell-stack>",
                    "AnswerCount": "3",
                    "CommentCount": "4",
                    "FavoriteCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "31105546",
                "ParentRepo": "https://github.com/axiomatic-systems/Bento4/blob/master/Source/C%2B%2B/Apps/Mp4Decrypt/Mp4Decrypt.cpp",
                "StackOverflow_Post": {
                    "Id": "31105546",
                    "PostTypeId": "2",
                    "ParentId": "27169759",
                    "CreationDate": "2015-06-28T22:46:54.387",
                    "Score": "12",
                    "Body": "<p>MPEG-CENC is simply AES-128 CTR encryption on an ISO BMFF (mp4) file. The specification for how this is applied to CENC is here: <a href=\"https://www.w3.org/TR/2014/WD-encrypted-media-20140828/cenc-format.html\" rel=\"noreferrer\">https://www.w3.org/TR/2014/WD-encrypted-media-20140828/cenc-format.html</a>\nand\n<a href=\"https://www.iso.org/obp/ui/#iso:std:iso-iec:23001:-7:ed-1:v1\" rel=\"noreferrer\">https://www.iso.org/obp/ui/#iso:std:iso-iec:23001:-7:ed-1:v1</a></p>\n\n<p>And a good explanation of AES-128 CTR\n<a href=\"https://en.wikipedia.org/wiki/Block_cipher_mode_of_operation#Counter_.28CTR.29\" rel=\"noreferrer\">https://en.wikipedia.org/wiki/Block_cipher_mode_of_operation#Counter_.28CTR.29</a></p>\n\n<p>To decrypt you will need the key and also the Initialization Vector (IV) that was used to encrypt the content. This is available from the senc and tenc boxes in the mp4 file. Once you will have those you will simply need to go through the samples or fragments of the file and decrypt and reassemble the mp4 (assuming you want to play it).</p>\n\n<p>As mentioned by Bento tools mp4decrypt gives an example on how to do this: <a href=\"https://github.com/axiomatic-systems/Bento4/blob/master/Source/C%2B%2B/Apps/Mp4Decrypt/Mp4Decrypt.cpp\" rel=\"noreferrer\">https://github.com/axiomatic-systems/Bento4/blob/master/Source/C%2B%2B/Apps/Mp4Decrypt/Mp4Decrypt.cpp</a></p>\n",
                    "OwnerUserId": "1782065",
                    "LastEditorUserId": "1554386",
                    "LastEditDate": "2018-02-11T08:47:11.807",
                    "LastActivityDate": "2018-02-11T08:47:11.807",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "31341773",
                "ParentRepo": "https://github.com/mbraak/django-mptt-admin",
                "StackOverflow_Post": {
                    "Id": "31341773",
                    "PostTypeId": "2",
                    "ParentId": "31341527",
                    "CreationDate": "2015-07-10T13:16:50.643",
                    "Score": "0",
                    "Body": "<p>remove <code>Sub_Specialization</code> it is redundant </p>\n\n<p>use <code>django-mptt</code> <a href=\"https://django-mptt.github.io/django-mptt/models.html#setting-up-a-django-model-for-mptt\" rel=\"nofollow\">https://django-mptt.github.io/django-mptt/models.html#setting-up-a-django-model-for-mptt</a></p>\n\n<p>and <code>django-mptt-admin</code> <a href=\"https://github.com/mbraak/django-mptt-admin\" rel=\"nofollow\">https://github.com/mbraak/django-mptt-admin</a></p>\n",
                    "OwnerUserId": "3033586",
                    "LastActivityDate": "2015-07-10T13:16:50.643",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "31457855",
                "ParentRepo": "https://github.com/josuebrunel/yahoo-fantasy-sport/blob/master/fantasy_sport/roster.py",
                "StackOverflow_Post": {
                    "Id": "31457855",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "31458576",
                    "CreationDate": "2015-07-16T15:00:35.950",
                    "Score": "54",
                    "ViewCount": "121042",
                    "Body": "<p>I'm working on a kind of lib, and for a weird reason i have this error.</p>\n<ul>\n<li><a href=\"https://github.com/josuebrunel/yahoo-fantasy-sport/blob/master/fantasy_sport/roster.py\" rel=\"nofollow noreferrer\">Here</a> is my code. Of course <em>@abc.abstractmethod have to be uncommented</em></li>\n<li><a href=\"https://github.com/josuebrunel/yahoo-fantasy-sport/blob/master/tests.py#L206-247\" rel=\"nofollow noreferrer\">Here</a> are my tests</li>\n</ul>\n<p><em>Sorry couldn't just copy and paste it</em></p>\n<p>I went on the basis that the code below works.</p>\n<h3>test.py:</h3>\n<pre><code>import abc\nimport six\n\n@six.add_metaclass(abc.ABCMeta)\nclass Base(object):\n\n    @abc.abstractmethod\n    def whatever(self,):\n        raise NotImplementedError\n\nclass SubClass(Base):\n\n    def __init__(self,):\n    \n        super(Base, self).__init__()\n        self.whatever()\n\n    def whatever(self,):\n        print(&quot;whatever&quot;)\n</code></pre>\n<p>In the python shell:</p>\n<pre><code>&gt;&gt;&gt; from test import *\n&gt;&gt;&gt; s = SubClass()\nwhatever\n</code></pre>\n<p>Why for my <em>roster</em> module i'm having this error:</p>\n<pre><code>Can't instantiate abstract class Player with abstract methods _Base__json_builder, _Base__xml_builder\n</code></pre>\n<p>Thanks in advance.</p>\n",
                    "OwnerUserId": "975774",
                    "LastEditorUserId": "8172439",
                    "LastEditDate": "2022-11-20T21:15:18.977",
                    "LastActivityDate": "2022-11-21T09:43:37.210",
                    "Title": "Can't instantiate abstract class ... with abstract methods",
                    "Tags": "<python><python-3.x><abstract-class><python-2.x><abstract-methods>",
                    "AnswerCount": "3",
                    "CommentCount": "0",
                    "FavoriteCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "31475614",
                "ParentRepo": "https://github.com/ethz-asl/libpointmatcher",
                "StackOverflow_Post": {
                    "Id": "31475614",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "31502482",
                    "CreationDate": "2015-07-17T12:13:26.150",
                    "Score": "5",
                    "ViewCount": "8767",
                    "Body": "<p>My intention is to take <a href=\"https://github.com/ethz-asl/libpointmatcher\" rel=\"nofollow\">a C++ library</a>, wrap it for C# with <a href=\"http://www.swig.org\" rel=\"nofollow\">SWIG</a> (<a href=\"http://sourceforge.net/projects/swig/\" rel=\"nofollow\">alt. link</a>), and compile both C++ and C# components as DLLs for Unity 5. (The C# DLL provides Unity with an interface to the C++ DLL.)</p>\n\n<p>To the best of my knowledge, compiling C++ and C# DLLs always requires Visual Studio (or tools like <code>msbuild</code> that come with VS). However, I am currently struggling to get VS installed, which has led me to question that assumption.</p>\n\n<p>Are there any other options for compiling Unity-ready DLLs on Windows?</p>\n\n<p>(Even if I get VS installed, I'm still curious to know.)</p>\n",
                    "OwnerUserId": "236081",
                    "LastEditorUserId": "236081",
                    "LastEditDate": "2015-07-21T11:00:54.250",
                    "LastActivityDate": "2015-07-21T11:00:54.250",
                    "Title": "Can I compile DLLs without Visual Studio?",
                    "Tags": "<c#><c++><visual-studio><dll><unity3d>",
                    "AnswerCount": "4",
                    "CommentCount": "2",
                    "FavoriteCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "31670496",
                "ParentRepo": "https://github.com/manahl/arctic",
                "StackOverflow_Post": {
                    "Id": "31670496",
                    "PostTypeId": "2",
                    "ParentId": "23071352",
                    "CreationDate": "2015-07-28T07:57:16.167",
                    "Score": "1",
                    "Body": "<p>We've built an open source library for storing numeric data (Pandas, numpy, etc.) in MongoDB:</p>\n\n<p><a href=\"https://github.com/manahl/arctic\" rel=\"nofollow\">https://github.com/manahl/arctic</a></p>\n\n<p>Best of all, it's easy to use, pretty fast and supports data versioning, multiple data libraries and more.  </p>\n",
                    "OwnerUserId": "115144",
                    "LastActivityDate": "2015-07-28T07:57:16.167",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "32106716",
                "ParentRepo": "https://github.com/Netflix/edda/blob/48de14fc185d8b2d8605c51630c0906c7e923925/src/main/scala/com/netflix/edda/aws/DynamoDBElector.scala",
                "StackOverflow_Post": {
                    "Id": "32106716",
                    "PostTypeId": "2",
                    "ParentId": "32090469",
                    "CreationDate": "2015-08-19T22:31:42.350",
                    "Score": "0",
                    "Body": "<p>I think the problem lies between steps 5 &amp; 6. S1 shouldn't attempt to write immediately after healing the partition since it should have lost its leadership status during the partition.</p>\n\n<p>S1 should be aware of this since it would have to re-establish connectivity to zookeeper.</p>\n\n<p><a href=\"http://zookeeper.apache.org/doc/trunk/recipes.html#sc_leaderElection\" rel=\"nofollow\">http://zookeeper.apache.org/doc/trunk/recipes.html#sc_leaderElection</a> has a description of the basic process. I'd look at Apache Curator for an implementation.</p>\n\n<p>Or for something non-zookeeper this could happen via timeout values.</p>\n\n<p><a href=\"https://github.com/Netflix/edda/blob/48de14fc185d8b2d8605c51630c0906c7e923925/src/main/scala/com/netflix/edda/aws/DynamoDBElector.scala\" rel=\"nofollow\">https://github.com/Netflix/edda/blob/48de14fc185d8b2d8605c51630c0906c7e923925/src/main/scala/com/netflix/edda/aws/DynamoDBElector.scala</a> has a nice implementation of that approach.</p>\n\n<p>I haven't tried to use Consul for this yet, but I suspect it should fall into one of these two categories.</p>\n",
                    "OwnerUserId": "69002",
                    "LastActivityDate": "2015-08-19T22:31:42.350",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "32214261",
                "ParentRepo": "https://github.com/telefonicaid/IoT-STH",
                "StackOverflow_Post": {
                    "Id": "32214261",
                    "PostTypeId": "2",
                    "ParentId": "31700088",
                    "CreationDate": "2015-08-25T21:17:45.583",
                    "Score": "0",
                    "Body": "<p>Orion Context Broker contains the latest snapshot of the sensor values, it's not intended for publication of static datasets. But you can connect Orion to CKAN (especially if you are confortable with Open Data) as explained at:</p>\n\n<p><a href=\"https://www.fiware.org/devguides/publishing-open-data-in-fiware/how-to-publish-context-information-as-open-data-in-ckan/\" rel=\"nofollow\">https://www.fiware.org/devguides/publishing-open-data-in-fiware/how-to-publish-context-information-as-open-data-in-ckan/</a></p>\n\n<p>If you don't want to deal with CKAN, you should consider taking a look at IoT-STH, a GE candidate for \"Short Term Historic\":</p>\n\n<p><a href=\"https://github.com/telefonicaid/IoT-STH\" rel=\"nofollow\">https://github.com/telefonicaid/IoT-STH</a></p>\n",
                    "OwnerUserId": "4787962",
                    "LastActivityDate": "2015-08-25T21:17:45.583",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "32362820",
                "ParentRepo": "https://github.com/cloudera/ibis/",
                "StackOverflow_Post": {
                    "Id": "32362820",
                    "PostTypeId": "2",
                    "ParentId": "32338006",
                    "CreationDate": "2015-09-02T20:47:22.943",
                    "Score": "5",
                    "Body": "<p>You're going to love <a href=\"https://github.com/cloudera/ibis/\" rel=\"noreferrer\">Ibis</a>! It has the HDFS functions (<code>put</code>, namely) and wraps the Impala DML and DDL you'll need to make this easy. </p>\n\n<p>The general approach I've used for something similar is to save your pandas table to a CSV, <code>HDFS.put</code> that on to the cluster, and then create a new table using that CSV as the data source.</p>\n\n<p>You don't <em>need</em> Ibis for this, but it should make it a little bit easier and may be a nice tool for you if you're already familiar with pandas (Ibis was also created by Wes, who wrote pandas).</p>\n",
                    "OwnerUserId": "142240",
                    "LastActivityDate": "2015-09-02T20:47:22.943",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "32393257",
                "ParentRepo": "https://github.com/ericmjl/Network-Analysis-Made-Simple",
                "StackOverflow_Post": {
                    "Id": "32393257",
                    "PostTypeId": "2",
                    "ParentId": "32377991",
                    "CreationDate": "2015-09-04T08:14:50.547",
                    "Score": "1",
                    "Body": "<p>\"Practical Graph/Network Analysis Made Simple\" - using NetworkX - was a fantastic presentation at PyCon 2015:</p>\n\n<ul>\n<li><a href=\"https://www.youtube.com/watch?v=_k4MOh7J7YY\" rel=\"nofollow\">https://www.youtube.com/watch?v=_k4MOh7J7YY</a></li>\n</ul>\n\n<p>And here you can find 7 ipython notebooks with almost self-explaining examples:</p>\n\n<ul>\n<li><a href=\"https://github.com/ericmjl/Network-Analysis-Made-Simple\" rel=\"nofollow\">https://github.com/ericmjl/Network-Analysis-Made-Simple</a></li>\n</ul>\n\n<p>Definitely the best introduction I found.</p>\n\n<p>The first 30 minutes here are also quite interesting:</p>\n\n<ul>\n<li><a href=\"https://www.youtube.com/watch?v=6Lauxn9oTt4\" rel=\"nofollow\">https://www.youtube.com/watch?v=6Lauxn9oTt4</a></li>\n<li><a href=\"https://github.com/sarguido/networkx-tutorial\" rel=\"nofollow\">https://github.com/sarguido/networkx-tutorial</a></li>\n</ul>\n",
                    "OwnerDisplayName": "user1602492",
                    "LastActivityDate": "2015-09-04T08:14:50.547",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "32744600",
                "ParentRepo": "https://github.com/telefonicaid/lightweightm2m-iotagent",
                "StackOverflow_Post": {
                    "Id": "32744600",
                    "PostTypeId": "2",
                    "ParentId": "26884291",
                    "CreationDate": "2015-09-23T16:15:24.793",
                    "Score": "0",
                    "Body": "<p>Figway is just a python example of how you can make the queries to the Ultralight 2.0 IoT-Agent.</p>\n\n<p>You may port Figway to your new platform if it supports python or, alternatively you can check the HTTP POST requests to code at any other platform/language.\nIt is really easy, have a look at:   <a href=\"http://www.slideshare.net/FI-WARE/fiware-iotidasintroul20v2\" rel=\"nofollow\">http://www.slideshare.net/FI-WARE/fiware-iotidasintroul20v2</a> </p>\n\n<p>Additionally, do not forget that Ultralight2.0/HTTP is one of the technology options that we support for IoT. If your devices are to use other standard such as MQTT/TCP or LWM2M/CoAP/UDP you can check other IoT-Agents (that connect as well to the same Orion contextbroker):</p>\n\n<p>UL2.0 and MQTT are here: <a href=\"https://github.com/telefonicaid/fiware-IoTAgent-Cplusplus\" rel=\"nofollow\">https://github.com/telefonicaid/fiware-IoTAgent-Cplusplus</a>\nLWM2M is here: <a href=\"https://github.com/telefonicaid/lightweightm2m-iotagent\" rel=\"nofollow\">https://github.com/telefonicaid/lightweightm2m-iotagent</a></p>\n\n<p>Also, if you want to use any other standard (or even your own propietary protocol) you may build up your own IoT Agent using the skeleton provided here:\n <a href=\"https://github.com/telefonicaid/iotagent-node-lib\" rel=\"nofollow\">https://github.com/telefonicaid/iotagent-node-lib</a> </p>\n\n<p>Thanks for using IDAS!\nCheers,</p>\n",
                    "OwnerUserId": "4809383",
                    "LastActivityDate": "2015-09-23T16:15:24.793",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "32744600",
                "ParentRepo": "https://github.com/telefonicaid/iotagent-node-lib",
                "StackOverflow_Post": {
                    "Id": "32744600",
                    "PostTypeId": "2",
                    "ParentId": "26884291",
                    "CreationDate": "2015-09-23T16:15:24.793",
                    "Score": "0",
                    "Body": "<p>Figway is just a python example of how you can make the queries to the Ultralight 2.0 IoT-Agent.</p>\n\n<p>You may port Figway to your new platform if it supports python or, alternatively you can check the HTTP POST requests to code at any other platform/language.\nIt is really easy, have a look at:   <a href=\"http://www.slideshare.net/FI-WARE/fiware-iotidasintroul20v2\" rel=\"nofollow\">http://www.slideshare.net/FI-WARE/fiware-iotidasintroul20v2</a> </p>\n\n<p>Additionally, do not forget that Ultralight2.0/HTTP is one of the technology options that we support for IoT. If your devices are to use other standard such as MQTT/TCP or LWM2M/CoAP/UDP you can check other IoT-Agents (that connect as well to the same Orion contextbroker):</p>\n\n<p>UL2.0 and MQTT are here: <a href=\"https://github.com/telefonicaid/fiware-IoTAgent-Cplusplus\" rel=\"nofollow\">https://github.com/telefonicaid/fiware-IoTAgent-Cplusplus</a>\nLWM2M is here: <a href=\"https://github.com/telefonicaid/lightweightm2m-iotagent\" rel=\"nofollow\">https://github.com/telefonicaid/lightweightm2m-iotagent</a></p>\n\n<p>Also, if you want to use any other standard (or even your own propietary protocol) you may build up your own IoT Agent using the skeleton provided here:\n <a href=\"https://github.com/telefonicaid/iotagent-node-lib\" rel=\"nofollow\">https://github.com/telefonicaid/iotagent-node-lib</a> </p>\n\n<p>Thanks for using IDAS!\nCheers,</p>\n",
                    "OwnerUserId": "4809383",
                    "LastActivityDate": "2015-09-23T16:15:24.793",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "33113091",
                "ParentRepo": "https://github.com/TerriaJS/terriajs",
                "StackOverflow_Post": {
                    "Id": "33113091",
                    "PostTypeId": "2",
                    "ParentId": "33105708",
                    "CreationDate": "2015-10-13T21:38:01.310",
                    "Score": "1",
                    "Body": "<p>Core Cesium is based solely on WebGL, and requires it.  But there's a fork called <a href=\"https://github.com/TerriaJS/terriajs\" rel=\"nofollow\">TerriaJS</a> that uses Leaflet as its 2D fallback for non-WebGL systems.  TerriaJS was built for <a href=\"http://nationalmap.gov.au/\" rel=\"nofollow\">Australia's National Map</a>, and can be installed via npm.</p>\n",
                    "OwnerUserId": "836708",
                    "LastActivityDate": "2015-10-13T21:38:01.310",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "33205416",
                "ParentRepo": "https://github.com/angvp/drf-lafv",
                "StackOverflow_Post": {
                    "Id": "33205416",
                    "PostTypeId": "2",
                    "ParentId": "16753173",
                    "CreationDate": "2015-10-19T01:50:00.170",
                    "Score": "4",
                    "Body": "<p>I know is late for this, but I wrote a little app that extends for ListAPIView and do this easier, check it out:</p>\n\n<p><a href=\"https://github.com/angvp/drf-lafv\" rel=\"nofollow\">https://github.com/angvp/drf-lafv</a></p>\n",
                    "OwnerUserId": "1940241",
                    "LastActivityDate": "2015-10-19T01:50:00.170",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "33387950",
                "ParentRepo": "https://github.com/aio-libs/aioredis",
                "StackOverflow_Post": {
                    "Id": "33387950",
                    "PostTypeId": "2",
                    "ParentId": "33374718",
                    "CreationDate": "2015-10-28T09:59:32.527",
                    "Score": "0",
                    "Body": "<p>Definitely have a look at <a href=\"https://github.com/aio-libs/aioredis\" rel=\"nofollow\">aioredis</a> and <a href=\"https://github.com/jonathanslenders/asyncio-redis\" rel=\"nofollow\">asyncio-redis</a>. </p>\n\n<p>I've used both, currently I'm liking aioredis. It has context managers (see the docs for examples) and they are incorporating Python 3.5 syntax.</p>\n",
                    "OwnerUserId": "1190200",
                    "LastActivityDate": "2015-10-28T09:59:32.527",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "33603454",
                "ParentRepo": "https://github.com/lindenb/jvarkit",
                "StackOverflow_Post": {
                    "Id": "33603454",
                    "PostTypeId": "1",
                    "CreationDate": "2015-11-09T06:18:44.437",
                    "Score": "13",
                    "ViewCount": "44356",
                    "Body": "<p>I'm trying to compile a tool which uses apache ant on linux</p>\n\n<p><a href=\"https://github.com/lindenb/jvarkit\" rel=\"noreferrer\">https://github.com/lindenb/jvarkit</a></p>\n\n<p>When I tried to compile the tool , I get n error.</p>\n\n<pre><code>$ make vcffilterjs\n</code></pre>\n\n<p>this is what I get when I'm running the command</p>\n\n<pre><code>echo \"Compiling htsjdk with ${JAVA_HOME} = /usr/lib/jvm/java/jre/\"\nCompiling htsjdk with /usr/lib/jvm/java/jre/ = /usr/lib/jvm/java/jre/\necho \"Compiling htsjdk library for java. Requires  apache ANT. If it fails      here, it's a not a problem with jvarkit.\"\nCompiling htsjdk library for java. Requires  apache ANT. If it fails here,  it's a not a problem with jvarkit.\necho \"And ${JAVA_HOME}/bin/javac should be &gt;=1.7\"\nAnd /usr/lib/jvm/java/jre//bin/javac should be &gt;=1.7\n(cd /home/jannahS/jvarkit/htsjdk-1.139 &amp;&amp; ant )\nError: Could not find or load main class  org.apache.tools.ant.launch.Launcher\nmake: *** [/home/jannahS/jvarkit/htsjdk-1.139/dist/htsjdk-1.139.jar] Error 1\n</code></pre>\n\n<p>I have installed apache ant and tried to set ANT_HOME following google instruction</p>\n\n<pre><code>export ANT_HOME=apache-ant-1.9.6\nANT_OPTS=\"-Xms256M -Xmx512M\"\nPATH=$PATH:$HOME/bin:$ANT_HOME/bin\nexport ANT_HOME ANT_OPTS PAT\n</code></pre>\n\n<p>I also have set JAVA_HOME</p>\n\n<pre><code>export JAVA_HOME=/usr/lib/jvm/jre-1.7.0\nexport PATH=$JAVA_HOME/jre/bin:$PATH\n</code></pre>\n\n<p>When I run </p>\n\n<p>ant --execdebug</p>\n\n<pre><code>exec \"/usr/lib/jvm/java/jre//bin/java\" -Xmx256M -classpath \"apache-ant-  1.9.6/lib/ant-launcher.jar\" -Dant.home=\"apache-ant-1.9.6\" -Dant.library.dir=\"apache-ant-1.9.6/lib\" org.apache.tools.ant.launch.Launcher -cp \"\"\nBuildfile: build.xml does not exist!\nBuild failed\n</code></pre>\n\n<p>I don't know what else to do to make things to work. I can't compile the tool that I want to use without  apache ant</p>\n",
                    "OwnerUserId": "4845182",
                    "LastEditorUserId": "1606632",
                    "LastEditDate": "2015-11-09T08:58:59.340",
                    "LastActivityDate": "2021-03-04T12:26:22.780",
                    "Title": "apache ant Could not find or load main class org.apache.tools.ant.launch.Launcher",
                    "Tags": "<java><linux><ant>",
                    "AnswerCount": "6",
                    "CommentCount": "1",
                    "FavoriteCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "33609977",
                "ParentRepo": "https://github.com/mapzen/vector-datasource/wiki/Mapzen-Vector-Tile-Service",
                "StackOverflow_Post": {
                    "Id": "33609977",
                    "PostTypeId": "2",
                    "ParentId": "31487520",
                    "CreationDate": "2015-11-09T13:17:19.920",
                    "Score": "3",
                    "Body": "<p>You can use your own tiles. I tried 2 things. Generating my own <a href=\"https://github.com/mapzen/vector-datasource/wiki/Mapzen-Vector-Tile-Service\" rel=\"nofollow noreferrer\">Mapzen vector tiles</a> (they use same format as Mapbox) And you can also use them for free. Here is their <a href=\"https://mapzen.com/documentation/vector-tiles/layers/#landuse\" rel=\"nofollow noreferrer\">layer descriptions</a>. This is quite work intensive. You need to have postgresql and load whole OSM PBF export into the database, then you run python server which requests data from this database and renders vector tiles. I think it is meant to render all the tiles in queue since it took couple of seconds per page to render visible tiles. Most of the time was spend in python after DB server was queried.\nIt's advantage is that you get nice tiles back. It has basically everything you need, but is much harder to customize. For example if you want to add specific style to cycle ways. You need to go deep into the code and change couple of query templates and a lot of other things.</p>\n\n<p>Then I tried <a href=\"https://github.com/systemed/tilemaker\" rel=\"nofollow noreferrer\">Tilemaker</a>. This is just C++ program which reads OSM PBF dumps and lua config script (where you specify what tags to send into tile) and spits out mapbox tiles. It's advantage is that it is much easier to set up and customize and that all tiles are rendered at once. But it is harder to create nice tiles. (AKA load all the different highway tags are roads just of different kind. It is up to you to specify that but this already works in previously mentioned Mapzen and also Mapbox).</p>\n\n<p>For example <a href=\"https://mapzen.com/documentation/vector-tiles/layers/#roads\" rel=\"nofollow noreferrer\">kind in Mapzen roads layer</a> In mapzen this is already taken care of but in tilemaker it is up to you to write all the conditionals that get road type from different OSM tags into a layer. And it gets more complicated in landuse tags since kind is a:</p>\n\n<blockquote>\n  <p>combination of the landuse, leisure, natural, highway, aeroway, and amenity OSM tags, or urban area and park or protected land for Natural Earth areas.</p>\n</blockquote>\n\n<p>Of course you can have completely different tags but it is nice to have one which tells you what landuse you are looking at.</p>\n\n<p>You ned to know that Mapbox, mapzen your custom mapbox tiles all use same format, but each will have different tags. So the style you create for one probably won't work for the other. </p>\n\n<p>For creating styles you can use Mapbox Studio (but is probably useless since it is in public beta currently and I'm not sure if you can specify own tiles there).</p>\n\n<p>I used <a href=\"http://www.macwright.org/2015/08/17/mapbox-gl-codeflow.html\" rel=\"nofollow noreferrer\">Mapbox codeflow</a>, which is basically nodejs server with gulp script that reloads site with a map when style file changes. It also supports writing styles in toml, JSON5 and yml in addition to JSON. It also shows errors kinda nicely. (only line numbers are missing) Currently it support version 7 of styles but 8 is currently out. For getting line numbers of errors I used <a href=\"https://github.com/mapbox/mapbox-gl-style-spec\" rel=\"nofollow noreferrer\">Mapbox GL style spec</a> which can also update style to the new version.\nYou can also try <a href=\"https://github.com/systemed/glug\" rel=\"nofollow noreferrer\">Glug</a> which is a different style language which compiles to Mapbox GL style. It is a little more compact.</p>\n\n<p>For using tiles you can also create mbtiles with <a href=\"https://github.com/mapbox/mbutil\" rel=\"nofollow noreferrer\">mb-util</a> and use them.</p>\n",
                    "OwnerUserId": "1008528",
                    "LastEditorUserId": "973919",
                    "LastEditDate": "2017-07-27T12:24:24.817",
                    "LastActivityDate": "2017-07-27T12:24:24.817",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "35137222",
                "ParentRepo": "https://github.com/telefonicaid/iotagent-mqtt",
                "StackOverflow_Post": {
                    "Id": "35137222",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "35139027",
                    "CreationDate": "2016-02-01T17:58:34.963",
                    "Score": "0",
                    "ViewCount": "207",
                    "Body": "<p>Why are there two MQTT agents:</p>\n\n<ol>\n<li><a href=\"https://github.com/telefonicaid/iotagent-mqtt\" rel=\"nofollow\">https://github.com/telefonicaid/iotagent-mqtt</a></li>\n<li><a href=\"https://github.com/telefonicaid/fiware-IoTAgent-Cplusplus\" rel=\"nofollow\">https://github.com/telefonicaid/fiware-IoTAgent-Cplusplus</a></li>\n</ol>\n\n<p>Isn't this duplicated work?</p>\n\n<p>Which one should be used?</p>\n\n<p>BR,</p>\n\n<p>Drasko</p>\n",
                    "OwnerUserId": "2782165",
                    "LastActivityDate": "2016-02-01T19:47:56.780",
                    "Title": "Two MQTT IoT agents - which one to use?",
                    "Tags": "<fiware>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "35243787",
                "ParentRepo": "https://github.com/tomchristie/django-rest-marshmallow",
                "StackOverflow_Post": {
                    "Id": "35243787",
                    "PostTypeId": "2",
                    "ParentId": "35235297",
                    "CreationDate": "2016-02-06T17:02:26.727",
                    "Score": "0",
                    "Body": "<p>Use <a href=\"http://marshmallow.readthedocs.org/en/latest/index.html\" rel=\"nofollow\">Marshmallow</a> (serialization library inspired in part by DRF serializers).  It solves this problem, by allowing nested schemas to be reference as strings.  <a href=\"https://marshmallow.readthedocs.org/en/latest/nesting.html#two-way-nesting\" rel=\"nofollow\">See Marshmallow: Two Way Nesting</a></p>\n\n<pre><code>class AuthorSchema(Schema):\n    # Make sure to use the 'only' or 'exclude' params to avoid infinite recursion\n    books = fields.Nested('BookSchema', many=True, exclude=('author', ))\n    class Meta:\n        fields = ('id', 'name', 'books')\n\nclass BookSchema(Schema):\n    author = fields.Nested(AuthorSchema, only=('id', 'name'))\n    class Meta:\n        fields = ('id', 'title', 'author')\n</code></pre>\n\n<p>You can use directly or use via <a href=\"https://github.com/tomchristie/django-rest-marshmallow\" rel=\"nofollow\">django-rest-marshmellow</a> by <a href=\"https://github.com/tomchristie\" rel=\"nofollow\">Tom Christie</a>, which allows use of Marshmallow, while maintaining the same API as REST framework's <code>Serializer</code> class.</p>\n\n<p>I'm not aware of a way to achieve the same result using just DRFs serializers.</p>\n\n<p>See also: <a href=\"https://marshmallow.readthedocs.org/en/latest/why.html#why\" rel=\"nofollow\">Why Marshmallow?</a></p>\n",
                    "OwnerUserId": "4744937",
                    "LastEditorUserId": "4744937",
                    "LastEditDate": "2016-02-06T17:07:45.760",
                    "LastActivityDate": "2016-02-06T17:07:45.760",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "35655831",
                "ParentRepo": "https://github.com/SnappyDataInc/snappydata",
                "StackOverflow_Post": {
                    "Id": "35655831",
                    "PostTypeId": "1",
                    "CreationDate": "2016-02-26T15:38:41.897",
                    "Score": "1",
                    "ViewCount": "759",
                    "Body": "<p>What is the status of the indexedRDD work in Spark? Has anyone looked at <a href=\"https://github.com/SnappyDataInc/snappydata\" rel=\"nofollow\">SnappyData</a>? They make some claims around being able to do fast random reads and writes on dataframes.</p>\n",
                    "OwnerUserId": "5986811",
                    "LastEditorUserId": "2415539",
                    "LastEditDate": "2016-02-26T16:41:18.513",
                    "LastActivityDate": "2016-02-27T19:08:13.197",
                    "Title": "How does indexedRDD in spark compare to SnappyData?",
                    "Tags": "<apache-spark><snappydata>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "35863234",
                "ParentRepo": "https://github.com/willthames/ansible-lint",
                "StackOverflow_Post": {
                    "Id": "35863234",
                    "PostTypeId": "1",
                    "CreationDate": "2016-03-08T09:11:51.250",
                    "Score": "3",
                    "ViewCount": "970",
                    "Body": "<p>I want to lint a playbook to detect following few among many other possibilities:</p>\n\n<ol>\n<li>Undefined variable</li>\n<li>Unused variable</li>\n<li>See if vars defined, when case-ignored, are same( conflicting vars hereafter)</li>\n</ol>\n\n<p>I'm not able to figure out what is the good way to do this? I don't want to re-invent the wheel, in the sense that:</p>\n\n<ol>\n<li>I don't want to do text processing. Ansible does this to accomplish its task.</li>\n<li>Hooks or callbacks if I'm not wrong are couple of levels higher than where I think my solution should hop in.</li>\n</ol>\n\n<p>My intention is to write a tool that seamlessly, and optionally, works with ansible. I would like not to modify ansible's code if I can do without.</p>\n\n<p>Any help or hack or suggestion is appreciated.</p>\n\n<p>PS: Syntax check wouldn't tell me about what I have mentioned above.\nI've taken a look at the <a href=\"https://github.com/willthames/ansible-lint\" rel=\"nofollow\">ansible-lint</a> tool. It does text processing, doesn't support inventory(for host_vars etc) and doesn't use ansible python API. So in order to do what I need, I'd have to call many internal APIs of ansible and I would end up writing ansible's code in my tool.</p>\n",
                    "OwnerUserId": "2696209",
                    "LastActivityDate": "2016-03-09T08:35:34.143",
                    "Title": "Playbook linting",
                    "Tags": "<ansible><ansible-2.x>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "35876251",
                "ParentRepo": "https://github.com/square/sqldelight/issues/123",
                "StackOverflow_Post": {
                    "Id": "35876251",
                    "PostTypeId": "2",
                    "ParentId": "34653744",
                    "CreationDate": "2016-03-08T19:24:24.587",
                    "Score": "2",
                    "Body": "<p>I'm guessing you use SQLDelight? I ran into this problem today. Apparently there is currently a conflict where you cannot use both Data Binding and SQLDelight, although it should be fixed soon.\n<a href=\"https://github.com/square/sqldelight/issues/123\" rel=\"nofollow\">https://github.com/square/sqldelight/issues/123</a></p>\n\n<p>An important debugging note for mysterious problems like this with no clear error message: do your Gradle build from the command line or Terminal pane in Android Studio.\nMac:</p>\n\n<pre><code>./gradlew assembleDebug --stacktrace\n</code></pre>\n\n<p>PC:</p>\n\n<pre><code>gradlew.bat assembleDebug --stacktrace\n</code></pre>\n\n<p>You can also try the --info or --debug flags. Using these commands you can get much more information which can help when Googling for an answer.</p>\n",
                    "OwnerUserId": "967131",
                    "LastActivityDate": "2016-03-08T19:24:24.587",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "35876277",
                "ParentRepo": "https://github.com/adi-/django-markdownx",
                "StackOverflow_Post": {
                    "Id": "35876277",
                    "PostTypeId": "1",
                    "CreationDate": "2016-03-08T19:25:49.483",
                    "Score": "0",
                    "ViewCount": "42",
                    "Body": "<p>I want to use <a href=\"https://github.com/adi-/django-markdownx\" rel=\"nofollow\">markdownx</a> plugin for Django. Documentation says about <a href=\"https://github.com/adi-/django-markdownx#js-event-handlers\" rel=\"nofollow\">js event handlers</a>, but I can't run this simple example:</p>\n\n<pre><code>$('.markdownx').on('markdownx.update', function(e, response) {\n    console.log(\"UPDATE\" + response);\n});\n</code></pre>\n\n<p>I copy &amp; paste this string into Chrome JavaScript Console, but nothing happened on updating markdown field (no <code>UPDATE</code> in console). How can I use this trigger? </p>\n\n<p>Sorry, I'm very newbie in js and jquery.</p>\n",
                    "OwnerUserId": "6035986",
                    "LastActivityDate": "2016-03-08T19:25:49.483",
                    "Title": "How can I use jquery trigger from custom js file?",
                    "Tags": "<javascript><jquery><django><markdown>",
                    "AnswerCount": "0",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "36069096",
                "ParentRepo": "https://github.com/CenturyLinkLabs/watchtower",
                "StackOverflow_Post": {
                    "Id": "36069096",
                    "PostTypeId": "1",
                    "CreationDate": "2016-03-17T18:42:01.027",
                    "Score": "1",
                    "ViewCount": "154",
                    "Body": "<p>We are running <a href=\"https://github.com/CenturyLinkLabs/watchtower\" rel=\"nofollow\">Century Link's Watchtower</a> container. This allows us to have a watch a docker registry and download new images when they are created. When watchtower finds a new image it runs <code>docker rmi</code> which deletes the old container. With that the old logs go with it.</p>\n\n<p>Is there a way without using a logging service to retain the logs when docker does it's clean up?</p>\n",
                    "OwnerUserId": "453985",
                    "LastEditorUserId": "453985",
                    "LastEditDate": "2016-03-17T19:15:24.483",
                    "LastActivityDate": "2016-05-30T07:14:48.323",
                    "Title": "Docker Container Logs",
                    "Tags": "<docker><docker-registry>",
                    "AnswerCount": "1",
                    "CommentCount": "3",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "36101365",
                "ParentRepo": "https://github.com/dreipol/django-scarface/blob/master/setup.py#L30",
                "StackOverflow_Post": {
                    "Id": "36101365",
                    "PostTypeId": "2",
                    "ParentId": "36100771",
                    "CreationDate": "2016-03-19T11:53:01.607",
                    "Score": "1",
                    "Body": "<p>In the packaging instructions Python 2.7 is supported <a href=\"https://github.com/dreipol/django-scarface/blob/master/setup.py#L30\" rel=\"nofollow\">https://github.com/dreipol/django-scarface/blob/master/setup.py#L30</a>.</p>\n\n<p>You could run the package tests <a href=\"https://github.com/dreipol/django-scarface/blob/master/scarface/tests.py\" rel=\"nofollow\">https://github.com/dreipol/django-scarface/blob/master/scarface/tests.py</a> inside a virtualenv with Python 2.7.10 to see if they pass. If they don't then there's nothing wrong with your code. If they do pass then the problem might not be in the package itself.</p>\n",
                    "OwnerUserId": "6086333",
                    "LastActivityDate": "2016-03-19T11:53:01.607",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "36123076",
                "ParentRepo": "https://github.com/electron-userland/electron-builder",
                "StackOverflow_Post": {
                    "Id": "36123076",
                    "PostTypeId": "2",
                    "ParentId": "36116638",
                    "CreationDate": "2016-03-21T04:19:22.823",
                    "Score": "0",
                    "Body": "<p>Try to use <a href=\"https://github.com/electron-userland/electron-builder\" rel=\"nofollow\">electron-builder</a> if you get painful with Squirrel. You can use the command as below to make your installer for Windows:\n<code>electron-builder path/to/your-electron-packager-output --platform=win --out=path/to/your-installer-output --config=path/to/builder.json --target=win</code></p>\n\n<p>Sample content for builder.json:</p>\n\n<blockquote>\n  <p>{\n    \"win\": {\n      \"title\": \"My Production Name\",\n      \"icon\": \"path/to/your-icon.ico\",\n      \"version\": \"1.0.0\",\n      \"publisher\": \"Your Company Name\"\n    }\n  }</p>\n</blockquote>\n\n<p>P.s: You must install <a href=\"http://prdownloads.sourceforge.net/nsis/nsis-2.50-setup.exe?download\" rel=\"nofollow\">NSIS</a> and add NSIS path into PATH environment before you run the above command.</p>\n",
                    "OwnerUserId": "3614616",
                    "LastActivityDate": "2016-03-21T04:19:22.823",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "36313865",
                "ParentRepo": "https://github.com/theskumar/python-dotenv",
                "StackOverflow_Post": {
                    "Id": "36313865",
                    "PostTypeId": "2",
                    "ParentId": "36310706",
                    "CreationDate": "2016-03-30T15:52:00.967",
                    "Score": "2",
                    "Body": "<p>Yes, storing this token into a config var is the right way to go.<br>\nAs for <code>HEROKU_API_KEY</code>, this will happen because locally, the toolbelt will look for the environment variable as one solution to try to fetch your token.</p>\n\n<p>This won't impact your production environment (the heroku toolbelt isn't available within dynos).<br>\nLocally, you can also set it easily with a tool like <a href=\"https://github.com/theskumar/python-dotenv\" rel=\"nofollow\">python-dotenv</a>, which will allow you to have a local <code>.env</code> file (don't check it into source control, or your token could be corrupted), with all of it's values available as env vars in your dev app.</p>\n",
                    "OwnerUserId": "122080",
                    "LastActivityDate": "2016-03-30T15:52:00.967",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "36415094",
                "ParentRepo": "https://github.com/AgileObjects/ReadableExpressions",
                "StackOverflow_Post": {
                    "Id": "36415094",
                    "PostTypeId": "2",
                    "ParentId": "1402839",
                    "CreationDate": "2016-04-05T00:23:32.033",
                    "Score": "14",
                    "Body": "<p>I've just happened across this; I've written a free, open-source library which provides an extension method to create a source-code-like string from an Expression:</p>\n<pre><code>using AgileObjects.ReadableExpressions;\n\nvar myExpression = CreateBigExpressionTree();\nvar expressionSource = myExpression.ToReadableString();\n</code></pre>\n<p>I've written <a href=\"https://agileobjects.co.uk/readable-expression-trees-debug-visualizer\" rel=\"nofollow noreferrer\">a blog</a> about it, the source is <a href=\"https://github.com/AgileObjects/ReadableExpressions\" rel=\"nofollow noreferrer\">on GitHub</a>, there's <a href=\"https://www.nuget.org/packages/AgileObjects.ReadableExpressions\" rel=\"nofollow noreferrer\">a NuGet package</a> containing the extension method, and I've written a set of Debugger Visualizers for VS 2010 -&gt; 2019 which are in <a href=\"https://marketplace.visualstudio.com/items?itemName=vs-publisher-1232914.ReadableExpressionsVisualizers\" rel=\"nofollow noreferrer\">the Visual Studio Marketplace</a>.</p>\n",
                    "OwnerUserId": "721236",
                    "LastEditorUserId": "721236",
                    "LastEditDate": "2020-08-20T08:53:34.763",
                    "LastActivityDate": "2020-08-20T08:53:34.763",
                    "CommentCount": "3",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "36502845",
                "ParentRepo": "https://github.com/containous/traefik",
                "StackOverflow_Post": {
                    "Id": "36502845",
                    "PostTypeId": "2",
                    "ParentId": "36496506",
                    "CreationDate": "2016-04-08T14:56:19.413",
                    "Score": "1",
                    "Body": "<p>I think most of the time there is a load balancer in front of the application. The DNS entry points at the load balancer, and you can have it reconfigure itself when the containers stop and start.</p>\n\n<p>There are a few projects out there that handle that for you from <code>docker events</code>. Here are just a few of the ones I know of:</p>\n\n<ul>\n<li><a href=\"https://github.com/ehazlett/interlock\" rel=\"nofollow\">https://github.com/ehazlett/interlock</a></li>\n<li><a href=\"https://github.com/containous/traefik\" rel=\"nofollow\">https://github.com/containous/traefik</a></li>\n<li><a href=\"https://github.com/jwilder/nginx-proxy\" rel=\"nofollow\">https://github.com/jwilder/nginx-proxy</a></li>\n</ul>\n",
                    "OwnerUserId": "444646",
                    "LastActivityDate": "2016-04-08T14:56:19.413",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "36691177",
                "ParentRepo": "https://github.com/DataSystemsLab/GeoSpark",
                "StackOverflow_Post": {
                    "Id": "36691177",
                    "PostTypeId": "1",
                    "CreationDate": "2016-04-18T10:19:07.893",
                    "Score": "0",
                    "ViewCount": "462",
                    "Body": "<p>As mentioned in the below link, Geospark takes the data in CSV or Tab delimited format. We can take the data from HDFS, convert it into CSV and pass it to Geospark for processing. </p>\n\n<p>Can we directly use Geospark on HDFS and do the processing?</p>\n\n<p><a href=\"https://github.com/DataSystemsLab/GeoSpark\" rel=\"nofollow\">https://github.com/DataSystemsLab/GeoSpark</a></p>\n\n<blockquote>\n  <p>GeoSpark supports either Comma-Separated Values (CSV) or Tab-separated\n  values (TSV) as the input format. Users only need to specify input\n  format as Splitter and the start column of spatial info in one tuple\n  as Offset when call Constructors.</p>\n</blockquote>\n",
                    "OwnerUserId": "5808464",
                    "LastActivityDate": "2016-08-30T00:30:59.637",
                    "Title": "Geospark: Is it possible to input the data from HDFS",
                    "Tags": "<apache-spark><geospatial>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "36724111",
                "ParentRepo": "https://github.com/drivendata/cookiecutter-data-science",
                "StackOverflow_Post": {
                    "Id": "36724111",
                    "PostTypeId": "2",
                    "ParentId": "35067412",
                    "CreationDate": "2016-04-19T16:21:47.667",
                    "Score": "8",
                    "Body": "<p>We've started a cookiecutter-data-science project designed for Python data scientists that might be of interest to you, check it out <a href=\"https://github.com/drivendata/cookiecutter-data-science\" rel=\"noreferrer\">here</a>. Structure is explained <a href=\"http://drivendata.github.io/cookiecutter-data-science/\" rel=\"noreferrer\">here</a>.</p>\n\n<p>Would love feedback if you have it! Feel free to respond here, open PRs or file issues.</p>\n\n<hr>\n\n<p>In response to your issue about re-using code by importing .py files into notebooks, the most effective way that our team has found is to append to the system path. This may make some people cringe, but it seems like the cleanest way of importing code into a notebook without lots of module boilerplate and a pip -e install.</p>\n\n<p>One tip is to use the <code>%autoreload</code> and <code>%aimport</code> <a href=\"http://ipython.readthedocs.org/en/stable/config/extensions/autoreload.html\" rel=\"noreferrer\">magics</a> with the above. Here's an example:</p>\n\n<pre><code># Load the \"autoreload\" extension\n%load_ext autoreload\n\n# always reload modules marked with \"%aimport\"\n%autoreload 1\n\nimport os\nimport sys\n\n# add the 'src' directory as one where we can import modules\nsrc_dir = os.path.join(os.getcwd(), os.pardir, 'src')\nsys.path.append(src_dir)\n\n# import my method from the source code\n%aimport preprocess.build_features\n</code></pre>\n\n<p>The above code comes from <a href=\"https://github.com/pjbull/data-science-is-software/blob/master/notebooks/data-science-is-software-talk.ipynb\" rel=\"noreferrer\">section 3.5 in this notebook</a> for some context.</p>\n",
                    "OwnerUserId": "1692709",
                    "LastEditorUserId": "1692709",
                    "LastEditDate": "2016-04-28T13:00:02.353",
                    "LastActivityDate": "2016-04-28T13:00:02.353",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "36943171",
                "ParentRepo": "https://github.com/edsu/twarc",
                "StackOverflow_Post": {
                    "Id": "36943171",
                    "PostTypeId": "2",
                    "ParentId": "36942112",
                    "CreationDate": "2016-04-29T16:18:45.890",
                    "Score": "2",
                    "Body": "<p>Do you only need the Twitter JSON? Because of the scope of your collecting area, you may want to try twarc: <a href=\"https://github.com/edsu/twarc\" rel=\"nofollow\">https://github.com/edsu/twarc</a></p>\n",
                    "OwnerUserId": "5884189",
                    "LastActivityDate": "2016-04-29T16:18:45.890",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "37006819",
                "ParentRepo": "https://github.com/metacloud/molecule",
                "StackOverflow_Post": {
                    "Id": "37006819",
                    "PostTypeId": "2",
                    "ParentId": "36998112",
                    "CreationDate": "2016-05-03T14:22:03.543",
                    "Score": "5",
                    "Body": "<p>There are Infrastructure Testing Frameworks for this:</p>\n\n<ul>\n<li><a href=\"http://serverspec.org/\" rel=\"nofollow noreferrer\">ServerSpec</a> / <a href=\"https://www.inspec.io/\" rel=\"nofollow noreferrer\">InSpec</a> - ruby-based. Famous, big community, nice looking and best in his class.</li>\n<li><a href=\"https://github.com/sstephenson/bats\" rel=\"nofollow noreferrer\">BATS</a> - Bash Automated Testing System, which is a bit easier.</li>\n<li><a href=\"https://github.com/philpep/testinfra\" rel=\"nofollow noreferrer\">TestInfra</a> - Python-based infra testing framework. Still pretty young, very small community. <a href=\"https://philpep.org/blog/infrastructure-testing-with-testinfra\" rel=\"nofollow noreferrer\">Intro</a>.</li>\n<li><a href=\"https://github.com/aelsabbahy/goss\" rel=\"nofollow noreferrer\">Goss</a> - Fast (written in Go), small tool for validating server/infra configuration. Test scenarios are written in <code>yaml</code>.</li>\n</ul>\n\n<p>Automation:</p>\n\n<ul>\n<li>There is interesting <a href=\"https://github.com/metacloud/molecule\" rel=\"nofollow noreferrer\">Molecule</a> project - some automation for testing Ansible roles, designed by Cisco. Never tried it yet.</li>\n<li>Step further would be using <a href=\"http://kitchen.ci/\" rel=\"nofollow noreferrer\">TestKitchen</a> which handles automation to spin up Vagrant or Docker or even AWS instance and test Puppet/Chef/Ansible with Rspec/BATS against just spinned up machines.</li>\n</ul>\n\n<p>So what you need - pick up framework, write tests and run your playbooks/recipes &amp; tests against mock VMs.</p>\n\n<p>Ideally is to keep your \"infra as code\" in <a href=\"/questions/tagged/vcs\" class=\"post-tag\" title=\"show questions tagged &#39;vcs&#39;\" rel=\"tag\">vcs</a> and configure <a href=\"/questions/tagged/ci\" class=\"post-tag\" title=\"show questions tagged &#39;ci&#39;\" rel=\"tag\">ci</a> like TravisCI to run your tests for every PR once you bring new changes in your repository. \nYou can even follow <a href=\"/questions/tagged/tdd\" class=\"post-tag\" title=\"show questions tagged &#39;tdd&#39;\" rel=\"tag\">tdd</a> here: write tests first, make them fail, then write actual implementation in your favorite configuration management tool and see if that change makes tests green/passed.</p>\n\n<p><br>\nMOAR Infrastructure Testing &amp; Automation!</p>\n",
                    "OwnerUserId": "4533625",
                    "LastEditorUserId": "4533625",
                    "LastEditDate": "2017-09-05T10:51:07.943",
                    "LastActivityDate": "2017-09-05T10:51:07.943",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "37349459",
                "ParentRepo": "https://github.com/agileobjects/ReadableExpressions/commit/f33d94b63db24f1c1ec88ed0f607c888c2e0bd88",
                "StackOverflow_Post": {
                    "Id": "37349459",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "37553852",
                    "CreationDate": "2016-05-20T14:33:13.463",
                    "Score": "2",
                    "ViewCount": "327",
                    "Body": "<p>I've written <a href=\"https://visualstudiogallery.msdn.microsoft.com/2d5de770-50e9-4dcf-87e9-ea1ed1b43b68\" rel=\"nofollow noreferrer\">a Visual Studio extension</a> which installs using an MSI. The install puts a <code>extension.vsixmanifest</code> file in the right place, and the extension appears in the Extension Manager as expected:</p>\n\n<p><a href=\"https://i.stack.imgur.com/2m303.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/2m303.png\" alt=\"Extension Manager details\"></a></p>\n\n<p>The problem is, when I publish a new version on the Visual Studio Gallery, the Extension Manager does not report it. I add the new version by creating a new installer and editing the existing page. Each new installer has a new ProductCode, PackageCode and ProductVersion (I update the MSI setup project and the version number in the included extension.vsixmanifest), but the same UpgradeCode; an example 'upgrade' commit can be found on GitHub <a href=\"https://github.com/agileobjects/ReadableExpressions/commit/f33d94b63db24f1c1ec88ed0f607c888c2e0bd88\" rel=\"nofollow noreferrer\">here</a>.</p>\n\n<p>The issue appears to be that when Visual Studio Extension Manager queries <a href=\"https://visualstudiogallery.msdn.microsoft.com/Services/VStudio/Extension.svc\" rel=\"nofollow noreferrer\">the extensions service</a> for the latest version of my extension, it returns a blank string - the same result as if you query with an invalid extension identifier:</p>\n\n<p><a href=\"https://i.stack.imgur.com/5xO3d.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/5xO3d.png\" alt=\"Service query results\"></a></p>\n\n<p>The two extensions successfully queried in the example are the <a href=\"https://visualstudiogallery.msdn.microsoft.com/5d345edc-2e2d-4a9c-b73b-d53956dc458d\" rel=\"nofollow noreferrer\">NuGet client tools</a> for VS2015 and the <a href=\"https://visualstudiogallery.msdn.microsoft.com/0e313dfd-be80-4afb-b5e9-6e74d369f7a1?SRC=Home\" rel=\"nofollow noreferrer\">SQL Server Compact/SQLite Toolbox</a>.</p>\n\n<p>What am I missing?</p>\n",
                    "OwnerUserId": "721236",
                    "LastEditorUserId": "721236",
                    "LastEditDate": "2016-05-30T22:43:06.677",
                    "LastActivityDate": "2016-05-31T19:13:17.130",
                    "Title": "VS2015 Extension Manager not reporting update for MSI-intalled extension",
                    "Tags": "<visual-studio><windows-installer><upgrade>",
                    "AnswerCount": "3",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "37392478",
                "ParentRepo": "https://github.com/JetBrains/spek/blob/master/spek-samples/src/main/kotlin/org/jetbrains/spek/samples/SimpleTest.kt",
                "StackOverflow_Post": {
                    "Id": "37392478",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "37394394",
                    "CreationDate": "2016-05-23T13:34:36.623",
                    "Score": "2",
                    "ViewCount": "1337",
                    "Body": "<p>Gotten familiar a bit with Kotlin I wanted to introduce it another Android-Java project, as a first step for testing only. I decided to start straight with <a href=\"https://jetbrains.github.io/spek/\" rel=\"nofollow\">Spek</a>.</p>\n\n<p>I added the following dependencies to build.gradle of the module to be tested:</p>\n\n<pre><code>testCompile 'junit:junit:4.12'\ntestCompile \"org.jetbrains.kotlin:kotlin-stdlib:1.0.2\"\ntestCompile \"org.jetbrains.kotlin:kotlin-test-junit:1.0.2\"\ntestCompile \"org.jetbrains.spek:spek:1.0.25\"\n</code></pre>\n\n<p>Among others I used the <a href=\"https://github.com/JetBrains/spek/blob/master/spek-samples/src/main/kotlin/org/jetbrains/spek/samples/SimpleTest.kt\" rel=\"nofollow\">SimpleTest</a> class of spek-samples of the git repo:</p>\n\n<pre><code>import org.jetbrains.spek.api.Spek\nimport kotlin.test.assertEquals\n\n\nclass SampleCalculator\n{\n    fun sum(x: Int, y: Int) = x + y\n    fun subtract(x: Int, y: Int) = x - y\n}\n\nclass SimpleTest : Spek({\n    describe(\"a calculator\") {\n        val calculator = SampleCalculator()\n\n        it(\"should return the result of adding the first number to the second number\") {\n            val sum = calculator.sum(2, 4)\n            assertEquals(6, sum)\n        }\n\n        it(\"should return the result of subtracting the second number from the first number\") {\n            val subtract = calculator.subtract(4, 2)\n            assertEquals(2, subtract)\n        }\n    }\n})\n</code></pre>\n\n<p>The code compiles and in Android Studio I am shown a green play button next to the class declaration to run the tests of the class. However, doing so results in </p>\n\n<pre><code>Process finished with exit code 1\nClass not found: \"com.anfema.ionclient.serialization.SimpleTest\"Empty test suite.\n</code></pre>\n\n<p>I created JUnit3 and JUnit4 tests of which all ran without any problems.</p>\n\n<p>Did I miss any additional configuration step for Spek tests?</p>\n",
                    "OwnerUserId": "2011622",
                    "LastEditorUserId": "2011622",
                    "LastEditDate": "2016-05-23T13:42:38.007",
                    "LastActivityDate": "2016-05-23T15:01:02.673",
                    "Title": "Running Spek test shows error \"Empty test suite\"",
                    "Tags": "<android><unit-testing><android-studio><testing><kotlin>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "37691028",
                "ParentRepo": "https://github.com/urfave/cli",
                "StackOverflow_Post": {
                    "Id": "37691028",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "37691095",
                    "CreationDate": "2016-06-07T23:27:35.257",
                    "Score": "1",
                    "ViewCount": "2141",
                    "Body": "<p>I'm not sure how this would work but I'm basically trying to write a command line app that I can run commands and subcommands from.  I'm using this popular third party library for parsing command line parameters:</p>\n<p><a href=\"https://github.com/urfave/cli\" rel=\"nofollow noreferrer\">https://github.com/urfave/cli</a></p>\n<p>My problem is I have a project folder where my .go files will live:</p>\n<pre><code>MyProject\n</code></pre>\n<p>so even if in the code in my main.go file, using their example, I have:</p>\n<pre><code>package main\n\nimport (\n  &quot;fmt&quot;\n  &quot;os&quot;\n\n  &quot;github.com/urfave/cli&quot;\n)\n\nfunc main() {\n  app := cli.NewApp()\n  app.Name = &quot;greet&quot;\n  app.Usage = &quot;fight the loneliness!&quot;\n  app.Action = func(c *cli.Context) error {\n    fmt.Println(&quot;Hello friend!&quot;)\n    return nil\n  }\n\n  app.Run(os.Args)\n}\n</code></pre>\n<p>when I run <code>go install</code>,</p>\n<p>in my $GOPATH/bin directory, I actually get MyProject built.  And then when I run <code>MyProject</code> from the terminal, I get</p>\n<pre><code>USAGE:\nmyproject [global options] command [command options] [arguments...]\n</code></pre>\n<p>But in reality, I don't need the <code>myproject</code> command first.  Is there a way this is normally done with command line apps or third party packages to create command line apps so that I can run <code>greet</code> from the command line instead of <code>myproject</code> as the first command?</p>\n",
                    "OwnerUserId": "207524",
                    "LastEditorUserId": "472495",
                    "LastEditDate": "2020-11-28T11:00:08.783",
                    "LastActivityDate": "2020-11-28T11:00:08.783",
                    "Title": "Command line application install using GoLang",
                    "Tags": "<go>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "37908749",
                "ParentRepo": "https://github.com/Khan/frankenserver",
                "StackOverflow_Post": {
                    "Id": "37908749",
                    "PostTypeId": "2",
                    "ParentId": "27088363",
                    "CreationDate": "2016-06-19T15:16:17.197",
                    "Score": "2",
                    "Body": "<p>You are correct that there is currently no command-line or configuration option to specify files/directories to be ignored by the watcher.</p>\n\n<h2>. (dot) hack</h2>\n\n<p>As you've discovered, files and directories beginning with <code>.</code> are ignored.  This is a fairly standard convention for many *nix systems.  It is not really scalable however with python projects with many local dependencies.</p>\n\n<h2>Modifying the watcher file</h2>\n\n<p>You can modify this file but this too is unfavorable as it makes for very brittle changes and is prone to breaking if updates overwrite the file.</p>\n\n<p>Barring the above workarounds, there's no way to achieve this.  I've also not seen any mention of this being implemented in the <a href=\"https://code.google.com/p/googleappengine/wiki/SdkReleaseNotes\" rel=\"nofollow noreferrer\">App Engine release notes</a>.  There is however an <a href=\"https://code.google.com/p/googleappengine/issues/detail?id=9300\" rel=\"nofollow noreferrer\">open feature request</a> on the public issue tracker to have the watcher ignore files specified by the <code>skip_files</code> yaml directive.  Feel free to star that issue to get updates regarding its progress.</p>\n\n<h1>EDIT: Jan 4, 2017</h1>\n\n<h2>NPM 3</h2>\n\n<p>For users of NPM encountering this limitation, you may find it helpful to use NPM v3 as it <a href=\"https://docs.npmjs.com/how-npm-works/npm3\" rel=\"nofollow noreferrer\">resolves dependencies differently</a>.</p>\n\n<blockquote>\n  <p>npm3 attempts this [mitigate deep trees and redundancy] by installing some secondary dependencies (dependencies of dependencies) in a flat way, in the same directory as the primary dependency that requires it.</p>\n</blockquote>\n\n<p>This can be very effective for Node users encountering the file watching limitation.</p>\n\n<h2>Frankenserver</h2>\n\n<p>Khan Academy has developed a fork of the App Engine devserver called <a href=\"https://github.com/Khan/frankenserver\" rel=\"nofollow noreferrer\">Frankenserver</a>.  While I've not explored this option myself, there seems to be a fair amount of support and recent updates to it.  From it's readme:</p>\n\n<blockquote>\n  <p>frankenserver's biggest advantage over the vanilla SDK is in how it watches the files in your app for changes. It does this much more efficiently by 1) using a native FSEvents-based file watcher on Mac OS X and 2) respecting the skip_files directive in your app.yaml.</p>\n</blockquote>\n\n<p>Though this is not an official Google solution, it may be a worthwhile workaround for time being if this limitation affects you direly.</p>\n",
                    "OwnerUserId": "5317173",
                    "LastEditorUserId": "5317173",
                    "LastEditDate": "2017-01-04T15:47:27.260",
                    "LastActivityDate": "2017-01-04T15:47:27.260",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "38415092",
                "ParentRepo": "https://github.com/testcontainers/testcontainers-java",
                "StackOverflow_Post": {
                    "Id": "38415092",
                    "PostTypeId": "2",
                    "ParentId": "38398386",
                    "CreationDate": "2016-07-16T20:00:50.330",
                    "Score": "1",
                    "Body": "<p>Ok, so I've decided that if I really want/have to use oracle proprietary features/syntax, then let's test it against live oracle. </p>\n\n<p>So if you don't care about execution time and happen to have access do Docker on your CI server, then I recommend you these excellent libraries:\n<a href=\"https://mvnrepository.com/artifact/org.testcontainers\" rel=\"nofollow\">https://mvnrepository.com/artifact/org.testcontainers</a> (<a href=\"https://github.com/testcontainers/testcontainers-java\" rel=\"nofollow\">https://github.com/testcontainers/testcontainers-java</a>), including oracle-xe module. </p>\n\n<p>I was able to spin up oracle-xe container during my integration tests and test against live oracle instance.</p>\n",
                    "OwnerUserId": "3080422",
                    "LastActivityDate": "2016-07-16T20:00:50.330",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "38643195",
                "ParentRepo": "https://github.com/odooku/odooku",
                "StackOverflow_Post": {
                    "Id": "38643195",
                    "PostTypeId": "2",
                    "ParentId": "25424018",
                    "CreationDate": "2016-07-28T17:36:30.120",
                    "Score": "7",
                    "Body": "<p>2 years late, but right now it is possible. Shameless plug: </p>\n\n<p><a href=\"https://github.com/odooku/odooku\" rel=\"nofollow noreferrer\">https://github.com/odooku/odooku</a></p>\n\n<p>Like sepulchered said the file storage is one of the first problems. </p>\n\n<ul>\n<li><p>This can be solved by using S3 as a fallback in combination with a big /tmp cache in Heroku.</p></li>\n<li><p>Second problem: db permissions, right now I've patched Odoo to work with a single database. You can also use AWS rdbs with Heroku, which completely solves the single db problem.</p></li>\n<li><p>Third problem: Long polling running on secondary port. However Odoo can be run in \"gevent mode\", also currently being patched for best compatibility with Heroku's timeouts.</p></li>\n<li><p>Fourth problem: Heroku's python buildpack is insufficient for compiling Odoo's dependencies. Was easily fixed with a custom buildpack.</p></li>\n</ul>\n\n<p>Hope this helps anyone in the future.</p>\n",
                    "OwnerUserId": "6650962",
                    "LastEditorUserId": "2026508",
                    "LastEditDate": "2020-01-22T19:34:15.780",
                    "LastActivityDate": "2020-01-22T19:34:15.780",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "38682395",
                "ParentRepo": "https://github.com/ekonstantinidis/django-rest-framework-docs/issues/120",
                "StackOverflow_Post": {
                    "Id": "38682395",
                    "PostTypeId": "2",
                    "ParentId": "38577959",
                    "CreationDate": "2016-07-31T08:59:58.897",
                    "Score": "4",
                    "Body": "<p>This is a bug in package. See <a href=\"https://github.com/ekonstantinidis/django-rest-framework-docs/issues/120\" rel=\"nofollow\">issue #120</a></p>\n\n<p>Wait for <a href=\"https://github.com/ekonstantinidis/django-rest-framework-docs/milestone/3\" rel=\"nofollow\">v0.1.0</a> or download <a href=\"https://pypi.python.org/packages/e5/9e/3a9aa6908ad7bd95b46f7fe05256681f4101de9a7769b6928159a986ef61/drfdocs-0.0.11.tar.gz\" rel=\"nofollow\">package from PyPI</a>, remove <code>site</code> directory from this package, install patched package.</p>\n",
                    "OwnerUserId": "5493302",
                    "LastActivityDate": "2016-07-31T08:59:58.897",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "38859185",
                "ParentRepo": "https://github.com/jodeleeuw/jsPsych/issues/259",
                "StackOverflow_Post": {
                    "Id": "38859185",
                    "PostTypeId": "2",
                    "ParentId": "38514186",
                    "CreationDate": "2016-08-09T19:43:42.300",
                    "Score": "0",
                    "Body": "<p>Option C is your best bet given the current state of the library. The array containing the timeline is converted into an internal set of TimelineNode objects when you call jsPsych.init(), and it can't be modified when the experiment is running. </p>\n\n<p>Version 6.0 of the library will add the ability to <a href=\"https://github.com/jodeleeuw/jsPsych/issues/259\" rel=\"nofollow\">insert timelines onto the end of the experiment</a>, which would open up a new way of solving this. This feature is available on the master branch of the GitHub repository, but that branch is not stable.</p>\n",
                    "OwnerUserId": "3726673",
                    "LastActivityDate": "2016-08-09T19:43:42.300",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "38942604",
                "ParentRepo": "https://github.com/belgattitude/soluble-japha",
                "StackOverflow_Post": {
                    "Id": "38942604",
                    "PostTypeId": "2",
                    "ParentId": "38651573",
                    "CreationDate": "2016-08-14T13:14:00.213",
                    "Score": "1",
                    "Body": "<p>Assuming you want to fix the missing properties and not discard the display of the E_NOTICE via <code>error_reporting(error_reporting() &amp; ~E_NOTICE)</code> (which could be harmful)</p>\n\n<p><strong>Option 1</strong> Fixing missing properties in Java.inc</p>\n\n<p>If you try to fix missing properties on the Java.inc file and the error still appears, it's probably because you are still loading the remote file. You can check if a remote loading is made by looking for initialization sequence:</p>\n\n<pre><code>include_once 'http://localhost:8080/JavaBridge/java/Java.inc';\n</code></pre>\n\n<p>If it's the case, make a local copy of the 'Java.inc' php code content (<code>wget http://localhost:8080/JavaBridge/java/Java.inc</code>), apply your fixes and require the local file instead of the remote one:</p>\n\n<pre><code>require_once '/my/local/path/RefactoredJava.inc.php';\n</code></pre>\n\n<p><em>(If you already done those steps and face the same error message, you might also have a problem with your opcache, ensure file is reloaded)</em></p>\n\n<p><strong>Option 2</strong> Use the <code>soluble/japha</code> client instead ?</p>\n\n<p>You can have a look to <a href=\"https://github.com/belgattitude/soluble-japha\" rel=\"nofollow\">soluble-japha repo on Gitub</a> which provides an alternative java bridge client (with fixes for undefined properties as well as many other changes).</p>\n\n<p>The soluble-japha API is not backward compatible, but you can install a <a href=\"https://github.com/belgattitude/soluble-japha-pjb62-compat\" rel=\"nofollow\">legacy compatibility wrapper</a> which expose most of the original <code>java_*()</code> global functions.  </p>\n\n<p><em>Disclaimer: It's not and official client, just a rework I did some years ago and decided to opensource.</em></p>\n",
                    "OwnerUserId": "5490184",
                    "LastEditorUserId": "5490184",
                    "LastEditDate": "2016-08-14T13:29:16.020",
                    "LastActivityDate": "2016-08-14T13:29:16.020",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "39357603",
                "ParentRepo": "https://github.com/bitwalker/distillery",
                "StackOverflow_Post": {
                    "Id": "39357603",
                    "PostTypeId": "2",
                    "ParentId": "31861544",
                    "CreationDate": "2016-09-06T20:49:04.770",
                    "Score": "12",
                    "Body": "<p>Make sure you checkout <a href=\"https://github.com/bitwalker/distillery\" rel=\"nofollow noreferrer\">Distillery</a>. It does what you need, without having to deal with Rebar.</p>\n\n<p>Add this to your <em>mix.exs</em> file's dependencies then run <code>mix release</code>. </p>\n\n<pre><code>defp deps do\n  [{:distillery, \"~&gt; 0.9\"}]\nend\n</code></pre>\n\n<p>Their documentation is great:</p>\n\n<ul>\n<li><a href=\"https://hexdocs.pm/distillery/home.html\" rel=\"nofollow noreferrer\">Home - Distillery Documentation</a></li>\n</ul>\n",
                    "OwnerUserId": "1062960",
                    "LastEditorUserId": "173497",
                    "LastEditDate": "2019-07-05T16:01:10.590",
                    "LastActivityDate": "2019-07-05T16:01:10.590",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "39682278",
                "ParentRepo": "https://github.com/denysdovhan/spaceship-zsh-theme/blob/master/spaceship.zsh",
                "StackOverflow_Post": {
                    "Id": "39682278",
                    "PostTypeId": "1",
                    "CreationDate": "2016-09-25T00:32:53.560",
                    "Score": "1",
                    "ViewCount": "1432",
                    "Body": "<p>I'm trying to modify an existing zsh prompt to work with zsh 5.0 and 4.3 because those the versions the systems that I use. <strong>How would I make a zsh-script be aware of the current working directory instead of the directory that the file is in?</strong> </p>\n\n<p>For context,</p>\n\n<p>This is a function in the script that checks if we're currently in a git directory and adds to the prompt if we are: </p>\n\n<pre><code># Git status.\n# Collect indicators, git branch and pring string.\nspaceship_git_status() {\n  [[ $SPACESHIP_GIT_SHOW == false ]] &amp;&amp; return\n\n  # Check if the current directory is in a Git repository.\n  command git rev-parse --is-inside-work-tree &amp;&gt;/dev/null || return\n\n  # Check if the current directory is in .git before running git checks.\n  if [[ \"$(git rev-parse --is-inside-git-dir 2&gt; /dev/null)\" == 'false' ]]; then\n    # Ensure the index is up to date.\n    git update-index --really-refresh -q &amp;&gt;/dev/null\n\n    # String of indicators\n    local indicators=''\n\n    indicators+=\"$(spaceship_git_uncomitted)\"\n    indicators+=\"$(spaceship_git_unstaged)\"\n    indicators+=\"$(spaceship_git_untracked)\"\n    indicators+=\"$(spaceship_git_stashed)\"\n    indicators+=\"$(spaceship_git_unpushed_unpulled)\"\n\n    [ -n \"${indicators}\" ] &amp;&amp; indicators=\" [${indicators}]\";\n\n    echo -n \" %Bon%b \"\n    echo -n \"%{$fg_bold[magenta]%}\"\n    echo -n \"$(git_current_branch)\"\n    echo -n \"%{$reset_color%}\"\n    echo -n \"%{$fg_bold[red]%}\"\n    echo -n \"$indicators\"\n    echo -n \"%{$reset_color%}\"\n  fi\n}\n</code></pre>\n\n<p>However, based on my debugging, it appears that the function always believes that it is in the directory from which the script was sourced. In other words, as I change directory, the script continues to reference the directory where the script is located. </p>\n\n<p>The <code>spaceship_git_status</code> function is called here:</p>\n\n<pre><code># Build prompt line\nspaceship_build_prompt() {\n  spaceship_host\n  spaceship_current_dir\n  spaceship_git_status\n  spaceship_nvm_status\n  spaceship_ruby_version\n  spaceship_venv_status\n}\n</code></pre>\n\n<p>And this is the <code>PROMPT</code> environment variable is: </p>\n\n<pre><code># Compose PROMPT\nPROMPT=''\n[[ $SPACESHIP_PROMPT_ADD_NEWLINE == true ]] &amp;&amp; PROMPT=\"$PROMPT$NEWLINE\"\nPROMPT=\"$PROMPT $(spaceship_build_prompt) \"\n[[ $SPACESHIP_PROMPT_SEPARATE_LINE == true ]] &amp;&amp; PROMPT=\"$PROMPT$NEWLINE\"\nPROMPT=\"$PROMPT $(spaceship_return_status) \"\n</code></pre>\n\n<p>I think this is an issue with zsh versions &lt; 5.2 because the prompt renders fine on my other computer with 5.2.</p>\n\n<p>Full code: <a href=\"https://github.com/denysdovhan/spaceship-zsh-theme/blob/master/spaceship.zsh\" rel=\"nofollow\">https://github.com/denysdovhan/spaceship-zsh-theme/blob/master/spaceship.zsh</a></p>\n",
                    "OwnerUserId": "5173765",
                    "LastActivityDate": "2016-09-25T00:32:53.560",
                    "Title": "Changing path to current working directory in zsh prompt",
                    "Tags": "<zsh><zshrc>",
                    "AnswerCount": "0",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "39707154",
                "ParentRepo": "https://github.com/theonion/djes/tree/master/example",
                "StackOverflow_Post": {
                    "Id": "39707154",
                    "PostTypeId": "2",
                    "ParentId": "39664698",
                    "CreationDate": "2016-09-26T15:48:55.337",
                    "Score": "2",
                    "Body": "<p>I think the issue here is that the test runner is setting up the tables <em>before</em> you add the app with <code>@override_settings</code>.</p>\n\n<p>Normally what I do with reusable apps is to run the tests in the context of an \"example\" app, with settings that include the app your want to test. Usually works pretty well, as I'm packaging the reusable app separately. Here's an <a href=\"https://github.com/theonion/djes/tree/master/example\" rel=\"nofollow\">example</a> of this from a past project of mine.</p>\n\n<p>However, if that's not possible, you might try to override <code>setUp</code> in your tests, and call the \"migrate\" command within that code. For example:</p>\n\n<pre><code>from django.core.management import call_command\n\n@override_settings(INSTALLED_APPS=['reusable_app'])\nMyTestCase(TestCase):\n    def setUp(self):\n        call_command('migrate', 'reusable_app')\n</code></pre>\n\n<p>This is a bit messy, but it might be worth trying. Depending on how things go, you might also have to run <a href=\"https://docs.djangoproject.com/en/1.10/ref/applications/#django.setup\" rel=\"nofollow\"><code>django.setup()</code></a>.</p>\n",
                    "OwnerUserId": "931098",
                    "LastActivityDate": "2016-09-26T15:48:55.337",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "39723042",
                "ParentRepo": "https://github.com/RPi-Distro/python-sense-hat/blob/458b55f5b8f32d855ba0e5850aed517b06e91f84/sense_hat/sense_hat.py#L78",
                "StackOverflow_Post": {
                    "Id": "39723042",
                    "PostTypeId": "2",
                    "ParentId": "39719193",
                    "CreationDate": "2016-09-27T11:05:24.903",
                    "Score": "2",
                    "Body": "<p>I've never used the Sense HAT before, but I'm guessing it's using I2C behind the scenes. In theory it should be possible to reimplement the code in Processing using it's <a href=\"https://processing.org/reference/libraries/io/I2C.html\" rel=\"nofollow\">I2C io library</a>, but in practice it may take quite a bit of effort, looking at the <a href=\"https://github.com/RPi-Distro/python-sense-hat/blob/458b55f5b8f32d855ba0e5850aed517b06e91f84/sense_hat/sense_hat.py#L78\" rel=\"nofollow\">sense-hat library uses RTIMU</a> and all the fancy filtering that does on it's own.</p>\n\n<p>To get your Python program to talk to Processing you have at least two options:</p>\n\n<ol>\n<li><a href=\"https://docs.oracle.com/javase/7/docs/api/java/lang/ProcessBuilder.html\" rel=\"nofollow\">pipe the output</a> from the python program into Processing's <code>stdin</code> and parse what's coming through</li>\n<li>Use sockets.</li>\n</ol>\n\n<p>The second option should be simpler and I can think of mutiple options:</p>\n\n<ol>\n<li>raw UDP sockets</li>\n<li>OSC using <a href=\"https://pypi.python.org/pypi/pyOSC\" rel=\"nofollow\">PyOSC</a> for the Python and <a href=\"http://www.sojamo.de/libraries/oscP5/\" rel=\"nofollow\">oscP5</a> for Processing</li>\n<li>Using WebSockets</li>\n</ol>\n\n<p>I'd recommend the second option again: UDP is pretty fast and OSC on top of that makes it east to pass messages with arguments.</p>\n\n<p>The Python script would:</p>\n\n<ul>\n<li>poll orientation data</li>\n<li>share orientation values via a message like <code>/orientation</code></li>\n</ul>\n\n<p>The Processing sketch would:</p>\n\n<ul>\n<li>be an OSC Server server and wait for data</li>\n<li>fetch the 3 float arguments from the <code>/orientation</code> message received and draw</li>\n</ul>\n\n<p>Here's an <strong>untested</strong> proof of concept sender script in Python:</p>\n\n<pre><code>import time\nfrom sense_hat import SenseHat\nfrom OSC import OSCClient, OSCMessage\n\n#update 60 times a second -&gt; feel free to adjust this what works best\ndelay = 1.0/60.0 \n# sense hat\nsense = SenseHat()\n# OSC client -&gt; Processing\nclient = OSCClient()\nclient.connect( (\"localhost\", 12000) )\n\n\nwhile True:\n    # read sense hat\n    orientation = sense.get_orientation_degrees()\n    print(\"p: {pitch}, r: {roll}, y: {yaw}\".format(**orientation))\n    # send data to Processing\n    client.send( OSCMessage(\"/orientation\", [orientation[\"pitch\"],orientation[\"roll\"],orientation[\"yaw\"] ] ) )\n    # wait\n    time.sleep(delay)\n</code></pre>\n\n<p>and the Processing receiver:</p>\n\n<pre><code>import oscP5.*;\nimport netP5.*;\n\nOscP5 oscP5;\n\nfloat pitch,roll,yaw;\n\nvoid setup() {\n  size(400,400,P3D);\n  frameRate(25);\n  /* start oscP5, listening for incoming messages at port 12000 */\n  oscP5 = new OscP5(this,12000);\n}\n\n\nvoid draw() {\n  background(0);  \n  text(\"pitch: \" + pitch + \"\\nroll: \" + roll + \"\\nyaw: \" + yaw,10,15);\n}\n\n/* incoming osc message are forwarded to the oscEvent method. */\nvoid oscEvent(OscMessage message) {\n  message.print();\n  if(message.checkAddrPattern(\"/orientation\")==true) {\n    /* check if the typetag is the right one. -&gt; expecting float (pitch),float (roll), float (yaw)*/\n    if(message.checkTypetag(\"fff\")) {\n      pitch = message.get(0).floatValue();\n      roll  = message.get(1).floatValue();\n      yaw   = message.get(2).floatValue();\n    }\n  }\n}\n</code></pre>\n\n<p><strong>Note</strong> that you'll need to install PyOSC and run the Processing sketch before hand, otherwise you might get a Python error about the OSCClient not being able to connect. The idea is Processing becomes an OSC Server and the Python Script is an OSCClient and the server need to be available for the client to connect. (You can make the Python script an OSC Server if you want and the Processing sketch a client if that works better for you)</p>\n\n<p>To install PyOSC try:</p>\n\n<pre><code>sudo pip install pyosc\n</code></pre>\n\n<p>Otherwise:</p>\n\n<pre><code>cd ~/Downloads\nwget https://pypi.python.org/packages/7c/e4/6abb118cf110813a7922119ed0d53e5fe51c570296785ec2a39f37606d85/pyOSC-0.3.5b-5294.tar.gz\ntar xvzf pyOSC-0.3.5b-5294.tar.gz\ncd pyOSC-0.3.5b-5294\nsudo python setup.py install\n</code></pre>\n\n<p>Again, the above is untested, but the idea is to:</p>\n\n<ol>\n<li>Download the library</li>\n<li>Unzip it</li>\n<li>Navigate to the unzipped folder</li>\n<li>Install it via <code>sudo python setup.py install</code></li>\n</ol>\n",
                    "OwnerUserId": "89766",
                    "LastEditorUserId": "89766",
                    "LastEditDate": "2016-10-26T00:33:30.323",
                    "LastActivityDate": "2016-10-26T00:33:30.323",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "39912665",
                "ParentRepo": "https://github.com/telefonicaid/fiware-sth-comet",
                "StackOverflow_Post": {
                    "Id": "39912665",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "39915400",
                    "CreationDate": "2016-10-07T08:20:23.063",
                    "Score": "0",
                    "ViewCount": "212",
                    "Body": "<p>I'm using the master branch of the <a href=\"https://github.com/telefonicaid/fiware-sth-comet\" rel=\"nofollow\">sth-comet's github repo</a> (currently a prerelease of <code>2.0.0-next</code>) and I am able to install and execute it. The problem appears when I want to create the subscription on the context broker (v1.4.0). Both services are installed in the same FIWARE Lab machine and I accessing them remotely using a public IP address.</p>\n\n<p>I've been trying to create the subscription using the template provided in your <a href=\"https://github.com/telefonicaid/fiware-sth-comet/blob/master/doc/manuals/data-storage.md\" rel=\"nofollow\">documentation</a>, but the STH is always complaining about the <code>FIWARE-Service</code> and the <code>FIWARE-ServicePath</code> headers (seems the context broker is not sending them along the notifications). This is the command for creating the subscription:</p>\n\n<pre><code>curl http://$(server):1026/v1/subscribeContext -s -S --header 'Content-Type: application/json' --header 'Accept: application/json' -H 'FIWARE-Service: default' -H 'FIWARE-ServicePath: /' -d @- &lt;&lt;EOF\n{\n    \"entities\": [\n        {\n            \"type\": \"weather.station\",\n            \"isPattern\": \"true\",\n            \"id\": \".*\"\n        }\n    ],\n    \"attributes\": [\n        \"temperature\",\n        \"humidity\"\n    ],\n    \"reference\": \"http://$(server):8666/notify\",\n    \"duration\": \"P1M\",\n    \"notifyConditions\": [\n        {\n            \"type\": \"ONCHANGE\",\n            \"condValues\": [\n                \"temperature\",\n                \"humidity\"\n            ]\n        }\n    ],\n    \"throttling\": \"PT5S\"\n}\nEOF\n</code></pre>\n\n<p>This is the reported error:</p>\n\n<pre><code>time=2016-10-06T15:56:30.124Z | lvl=WARN | corr=7220efae-8bdd-11e6-96a8-fa163ea89c59 | trans=11ef935c-f749-46b7-bcd4-942ffddedd27 | op=OPER_STH_POST | srv=default | subsrv=n/a | msg=POST /notify, event={\"request\":\"1475769390111:robots:23181:ityixskh:10000\",\"timestamp\":1475769390123,\"tags\":[\"validation\",\"error\",\"headers\"],\"data\":{\"data\":{\"data\":null,\"isBoom\":true,\"isServer\":false,\"output\":{\"statusCode\":400,\"payload\":{\"statusCode\":400,\"error\":\"Bad Request\",\"message\":\"child \\\"fiware-servicepath\\\" fails because [fiware-servicepath is required]\"},\"headers\":{}}},\"isBoom\":true,\"isServer\":false,\"output\":{\"statusCode\":400,\"payload\":{\"statusCode\":400,\"error\":\"Bad Request\",\"message\":\"child \\\"fiware-servicepath\\\" fails because [fiware-servicepath is required]\",\"validation\":{\"source\":\"headers\",\"keys\":[]}},\"headers\":{}}},\"internal\":true}\n</code></pre>\n\n<p>If I use v2 of the context broker API, I'm able to force it to send the <code>FIWARE-Service</code> and <code>FIWARE-ServicePath</code> headers:</p>\n\n<pre><code>curl http://$(server):1026/v2/subscriptions -s -S --header 'Content-Type: application/json' --header 'Accept: application/json' -H 'FIWARE-Service: default' -H 'FIWARE-ServicePath: /' -d @- &lt;&lt;EOF\n{\n    \"description\": \"STH subscription\",\n    \"subject\": {\n        \"entities\": [\n            {\n                \"type\": \"weather.station\",\n                \"idPattern\": \".*\"\n            }\n        ],\n        \"condition\": {  \n            \"attrs\":[  \n                \"temperature\",\n                \"humidity\"\n            ]\n        }\n    },\n    \"notification\": {\n        \"httpCustom\": {\n            \"url\": \"http://$(server):8666/notify\",\n            \"headers\": {\n                \"FIWARE-Service\": \"default\",\n                \"FIWARE-ServicePath\": \"/\"\n            }\n        },\n        \"attrs\": [\n            \"temperature\",\n            \"humidity\"\n        ]\n    },\n    \"expires\": \"2018-04-05T14:00:00.00Z\",\n    \"throttling\": 5\n}\nEOF\n</code></pre>\n\n<p>This way, the STH server does not compliant about the headers, although it raises other errors:</p>\n\n<pre><code>time=2016-10-06T15:46:57.564Z | lvl=ERROR | corr=19e59f02-8bdc-11e6-8534-fa163ea89c59 | trans=1b7fc29a-7f5c-449d-9238-d2e644154b05 | op=OPER_STH_POST | srv=default | subsrv=/ | msg=POST /notify, event={\"request\":\"1475768812582:robots:8985:itycaq0o:10003\",\"timestamp\":1475768817564,\"tags\":[\"request\",\"closed\",\"error\"],\"internal\":true}\ntime=2016-10-06T15:47:02.592Z | lvl=ERROR | corr=19e59f02-8bdc-11e6-8534-fa163ea89c59 | trans=7e5bf417-0b1d-4b53-b47b-838cead91b94 | op=OPER_STH_POST | srv=default | subsrv=/ | msg=POST /notify, event={\"request\":\"1475768817606:robots:8985:itycaq0o:10004\",\"timestamp\":1475768822592,\"tags\":[\"request\",\"closed\",\"error\"],\"internal\":true}\n</code></pre>\n",
                    "OwnerUserId": "2255503",
                    "LastEditorUserId": "2255503",
                    "LastEditDate": "2016-10-07T10:45:38.960",
                    "LastActivityDate": "2017-07-09T02:06:48.740",
                    "Title": "Unable to create the STH context broker subscription",
                    "Tags": "<fiware><fiware-orion><fiware-sth-comet>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "40021992",
                "ParentRepo": "https://github.com/Ericsson/codechecker",
                "StackOverflow_Post": {
                    "Id": "40021992",
                    "PostTypeId": "2",
                    "ParentId": "36657869",
                    "CreationDate": "2016-10-13T13:10:58.047",
                    "Score": "5",
                    "Body": "<ul>\n<li>The <a href=\"http://coala.io/\" rel=\"noreferrer\">coala</a> project attempts to make the tools it wraps produce the same structured output formats (see <a href=\"http://wordpress.schuirmann.eu/2016/02/coala-at-fosdem-2016/#comment-123\" rel=\"noreferrer\">http://wordpress.schuirmann.eu/2016/02/coala-at-fosdem-2016/#comment-123</a> ). Sadly there doesn't seem to be an already made \"bear\" to wrap a compiler.</li>\n<li>On a similar note to the above, Ericsson have built a tool called <a href=\"https://github.com/Ericsson/codechecker\" rel=\"noreferrer\">CodeChecker</a> that lets you track a project's clang static analysis warnings over time.</li>\n<li>There is an moribund project called <a href=\"https://github.com/fedora-static-analysis/firehose\" rel=\"noreferrer\">firehose</a> that wrapped the output of gcc and several C static analysis tools.</li>\n<li><a href=\"http://clang.llvm.org/docs/UsersManual.html#cmdoption-fdiagnostics-format\" rel=\"noreferrer\">clang has <code>-fdiagnostics-format=msvc</code></a> which can make its output <em>slightly</em> more structured.</li>\n</ul>\n\n<p>Something that might help you in the meantime is to <a href=\"https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html\" rel=\"noreferrer\">turn those compiler warnings you deem critical into errors using <code>-Werror=</code></a> so you notice them breaking the build above the noise of the warnings.</p>\n",
                    "OwnerUserId": "4985326",
                    "LastActivityDate": "2016-10-13T13:10:58.047",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "40054179",
                "ParentRepo": "https://github.com/JMSwag/PyUpdater",
                "StackOverflow_Post": {
                    "Id": "40054179",
                    "PostTypeId": "2",
                    "ParentId": "17428199",
                    "CreationDate": "2016-10-15T01:54:52.353",
                    "Score": "5",
                    "Body": "<p>You should definetely try out pynsist which can bundle Python with your packages and is based on well-established NSIS open-source installer:</p>\n\n<p><a href=\"https://pypi.python.org/pypi/pynsist\" rel=\"noreferrer\">https://pypi.python.org/pypi/pynsist</a></p>\n\n<p>Anaconda team provides Constructor which is based on conda and NSIS again:</p>\n\n<p><a href=\"https://github.com/conda/constructor\" rel=\"noreferrer\">https://github.com/conda/constructor</a></p>\n\n<p>Finally this approach using WinPython and most stable installer called InnoSetup:</p>\n\n<p><a href=\"http://cyrille.rossant.net/create-a-standalone-windows-installer-for-your-python-application/\" rel=\"noreferrer\">http://cyrille.rossant.net/create-a-standalone-windows-installer-for-your-python-application/</a></p>\n\n<p>But if your package is not a library but an application then you can bundle it (freeze) with Python and all dependencies, even compress it using pyinstaller:</p>\n\n<p><a href=\"http://www.pyinstaller.org\" rel=\"noreferrer\">http://www.pyinstaller.org</a></p>\n\n<p>This is what I use for all of my apps even with crazy interop dependencies!</p>\n\n<p>Bonus - auto update tool for pyinstaller:</p>\n\n<p><a href=\"https://github.com/JMSwag/PyUpdater\" rel=\"noreferrer\">https://github.com/JMSwag/PyUpdater</a></p>\n",
                    "OwnerUserId": "2230844",
                    "LastEditorUserId": "2230844",
                    "LastEditDate": "2016-10-15T02:10:06.853",
                    "LastActivityDate": "2016-10-15T02:10:06.853",
                    "CommentCount": "6",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "40371383",
                "ParentRepo": "https://github.com/NaturalHistoryMuseum/ckanext-ldap",
                "StackOverflow_Post": {
                    "Id": "40371383",
                    "PostTypeId": "2",
                    "ParentId": "39914070",
                    "CreationDate": "2016-11-02T02:02:34.170",
                    "Score": "1",
                    "Body": "<p>The short answer is that <a href=\"https://github.com/NaturalHistoryMuseum/ckanext-ldap\" rel=\"nofollow noreferrer\">ckanext-ldap</a> doesn't do that. What it does is provide a custom login form (username and password) that authenticates the credentials via LDAP. It then creates a session for the corresponding CKAN user, creating a user account first if required. Having it do anything else would require customisation of the extension although there are a number of options documented in its readme that alter the behaviour in small ways.</p>\n\n<p>Whether ckanext-ldap would be a suitable extension to build upon to achieve what you want depends on what you want to do, which isn't clear from your question.</p>\n",
                    "OwnerUserId": "7102391",
                    "LastActivityDate": "2016-11-02T02:02:34.170",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "40442468",
                "ParentRepo": "https://github.com/manosim/django-rest-framework-docs",
                "StackOverflow_Post": {
                    "Id": "40442468",
                    "PostTypeId": "1",
                    "CreationDate": "2016-11-05T19:42:15.937",
                    "Score": "0",
                    "ViewCount": "391",
                    "Body": "<p>I'm using the <a href=\"https://github.com/manosim/django-rest-framework-docs\" rel=\"nofollow noreferrer\">Django Rest Docs</a> to describe my API built in the Django Rest Framework, but the urls it's displaying are incorrect. Specifically, they prepend /admin/ to everything:</p>\n\n<p><a href=\"https://i.stack.imgur.com/qQmR0.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/qQmR0.png\" alt=\"enter image description here\"></a></p>\n\n<p>These paths should be /session-auth/, /session/, etc. I don't know why the /admin/ is being preprended. Here's my urls.py file:</p>\n\n<pre><code># URLs for serving static media and user uploaded media\nurlpatterns = patterns('',\n    (r'^static/(?P&lt;path&gt;.*)$', 'django.views.static.serve',{'document_root': settings.STATIC_URL, 'show_indexes': True}),\n) + static(settings.STATIC_URL, document_root=settings.STATIC_ROOT)\n\n\nurlpatterns += patterns('myapp.views',\n    #Home page\n    (r'^$', 'home'),\n\n    url(r'^docs/', include('rest_framework_docs.urls')),\n\n    # Refresh all locations\n    (r'^admin/refresh-all-locations/$', 'refresh_all_locations'),\n    # Admin all locations page\n    (r'^admin/all-locations/$', admin.site.admin_view(all_locations)),\n    # Admin\n    (r'^admin/', include(admin.site.urls)),\n\n    ####API urls####\n    # Authenticate a user\n    url(r'^session-auth/$', API.Session.SessionAuth.as_view(), name='authenticate'),\n    # Update user password or email\n    url(r'^session/$', API.Session.SessionDetail.as_view()),\n\n    # Get the detail on one entity\n    url(r'^entities/(?P&lt;entity_id&gt;[0-9]+)/$', API.Entity.EntityDetail.as_view()),\n</code></pre>\n",
                    "OwnerUserId": "3749797",
                    "LastActivityDate": "2016-11-05T19:42:15.937",
                    "Title": "Django Rest Docs Show Wrong Urls",
                    "Tags": "<python><django><rest><django-rest-framework><api-design>",
                    "AnswerCount": "0",
                    "CommentCount": "5",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "40591478",
                "ParentRepo": "https://github.com/JanusGraph/janusgraph/pull/192",
                "StackOverflow_Post": {
                    "Id": "40591478",
                    "PostTypeId": "2",
                    "ParentId": "40585417",
                    "CreationDate": "2016-11-14T14:47:43.437",
                    "Score": "8",
                    "Body": "<p>So there are a few things that can be happening here:</p>\n\n<ol>\n<li><p>If both of those indices you describe were not created in the same transaction (and the problem index in question was created in after the <code>name</code> <code>propertyKey</code> was already defined) then you should issue a reindex, as per <a href=\"http://s3.thinkaurelius.com/docs/titan/0.5.0/indexes.html\" rel=\"nofollow noreferrer\">Titan docs</a>:</p>\n\n<blockquote>\n  <p>The name of a graph index must be unique. Graph indexes built against\n  newly defined property keys, i.e. property keys that are defined in\n  the same management transaction as the index, are immediately\n  available. Graph indexes built against property keys that are already\n  in use require the execution of a reindex procedure to ensure that the\n  index contains all previously added elements. Until the reindex\n  procedure has completed, the index will not be available. It is\n  encouraged to define graph indexes in the same transaction as the\n  initial schema.</p>\n</blockquote></li>\n<li><p>The index may be timing out the process that takes to move from <code>REGISTERED</code> to <code>INSTALLED</code>, in which case you want to use <code>mgmt.awaitGraphIndexStatus()</code>. You can even specify the amount of time you are willing to wait here.</p></li>\n<li><p>Make sure there are no open transactions on your graph or the index status will indeed not change, as described <a href=\"https://stackoverflow.com/questions/34643409/titandb-index-not-changing-state\">here</a>.</p></li>\n<li><p>This is clearly not the case for you, but there is a bug in Titan (fixed in JanusGraph via <a href=\"https://github.com/JanusGraph/janusgraph/pull/192\" rel=\"nofollow noreferrer\">this PR</a>) such that if you create an index against a newly created propertyKey as well as a previously used propertyKey, the index will get stuck in the <code>REGISTERED</code> state</p></li>\n<li><p>Indexes will not move to <code>REGISTERED</code> unless every Titan/JanusGraph node in the cluster acknowledges the index creation. If your indexes are getting stuck in the <code>INSTALLED</code> state, there is a chance that the other nodes in the system are not acknowledging the indexes existence. This can be due to issues with another server in the cluster, backfill in the messaging queue Titan/JanusGraph uses to talk with each other, or most unexpectedly: the existence of phantom instances. These can occur every time your server is killed through non-normal JVM shutdown processes, i.e. <code>kill -9</code> the server due to it being stuck in thrash the world garbage collection. If you expect backfill to be the problem, the comments in <a href=\"https://github.com/JanusGraph/janusgraph/blob/master/janusgraph-core/src/main/java/org/janusgraph/diskstorage/log/kcvs/KCVSLog.java\" rel=\"nofollow noreferrer\">this class</a> offer good insight to customizable configuration options that may help fix the problem. To check for the existence of phantom nodes, use <a href=\"https://github.com/JanusGraph/janusgraph/blob/master/janusgraph-core/src/main/java/org/janusgraph/graphdb/database/management/ManagementSystem.java#L200\" rel=\"nofollow noreferrer\">this function</a> and then <a href=\"https://github.com/JanusGraph/janusgraph/blob/master/janusgraph-core/src/main/java/org/janusgraph/graphdb/database/management/ManagementSystem.java#L210\" rel=\"nofollow noreferrer\">this function</a> to kill the phantom instances.</p></li>\n</ol>\n",
                    "OwnerUserId": "5153436",
                    "LastEditorUserId": "3618671",
                    "LastEditDate": "2017-08-04T20:10:24.010",
                    "LastActivityDate": "2017-08-04T20:10:24.010",
                    "CommentCount": "6",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "41075208",
                "ParentRepo": "https://github.com/rochacbruno/Flask-GoogleMaps",
                "StackOverflow_Post": {
                    "Id": "41075208",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "41075855",
                    "CreationDate": "2016-12-10T11:52:40.927",
                    "Score": "0",
                    "ViewCount": "440",
                    "Body": "<p>I am trying a code from <a href=\"https://github.com/rochacbruno/Flask-GoogleMaps\" rel=\"nofollow noreferrer\">https://github.com/rochacbruno/Flask-GoogleMaps</a></p>\n\n<p>in app:</p>\n\n<pre><code>from flask import Flask, render_template\nfrom flask_googlemaps import GoogleMaps\nfrom flask_googlemaps import Map\n\napp = Flask(__name__, template_folder=\"templates\")\nGoogleMaps(app, key='mmm')\n\n@app.route(\"/\")\ndef mapview():\n    mymap = Map()\n    sndmap = Map()\n\n    return render_template('example.html', mymap=mymap, sndmap=sndmap)\n\nif __name__ == \"__main__\":\n    app.run(debug=True)\n</code></pre>\n\n<p>in templates: <code>{{googlemap(\"my_awesome_map\", lat=0.23234234, lng=-0.234234234, markers=[(0.12, -0.45345), ...])}}</code></p>\n\n<p>with</p>\n\n<pre><code>myproject/\n    app.py\n    templates/\n        examples.html\n</code></pre>\n\n<p>And I got this error : <em>jinja2.exceptions.TemplateSyntaxError: unexpected '.'</em></p>\n\n<p>How to fix it?</p>\n",
                    "OwnerUserId": "5630180",
                    "LastActivityDate": "2016-12-10T13:04:46.513",
                    "Title": "Flask-GoogleMaps : jinja2.exceptions.TemplateSyntaxError: unexpected '.'",
                    "Tags": "<python><google-maps><flask>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "41128771",
                "ParentRepo": "https://github.com/patr0nus/DeskGap/",
                "StackOverflow_Post": {
                    "Id": "41128771",
                    "PostTypeId": "2",
                    "ParentId": "25897951",
                    "CreationDate": "2016-12-13T19:09:59.860",
                    "Score": "46",
                    "Body": "<p>I recommend using an HTML/JS/CSS Framework</p>\n\n<p><em>Option #1:</em> <strong>Electron</strong> by <strong>GitHub</strong>.<br>\n<a href=\"https://electronjs.org/\" rel=\"noreferrer\">Website</a>  |  <a href=\"https://github.com/electron/electron\" rel=\"noreferrer\">GitHub Repo</a> |  <a href=\"https://github.com/electron/electron/releases\" rel=\"noreferrer\">Releases</a></p>\n\n<blockquote>\n  <p>It's easier than you think</p>\n  \n  <p>If you can build a website, you can build a desktop app. Electron is a\n  framework for creating native applications with web technologies like\n  JavaScript, HTML, and CSS. It takes care of the hard parts so you can\n  focus on the core of your application.</p>\n</blockquote>\n\n<p><em>Option #2:</em> <strong>NW.js</strong> (previously known as node-webkit).<br>\n<a href=\"https://nwjs.io/\" rel=\"noreferrer\">Website</a>  |  <a href=\"https://github.com/nwjs/nw.js\" rel=\"noreferrer\">GitHub Repo</a> |  <a href=\"https://nwjs.io/downloads/\" rel=\"noreferrer\">Releases</a></p>\n\n<blockquote>\n  <p>Call all Node.js modules directly from DOM/WebWorker and enable a new\n  way of writing applications with all Web technologies.</p>\n</blockquote>\n\n<p><strong>Electron and NWJS Pros:</strong></p>\n\n<ul>\n<li><p>AppJS is officially deprecated</p></li>\n<li><p>Electron is similar to NW.js but newer, more popular and has a bigger community <s>and updates more frequently.</s> I recommend it.</p></li>\n<li><p>NWJS always uses the latest Versions of Chromium and Node while Electron takes more time to catch up.</p></li>\n<li><p>NWJS supports [JavaScript Source Protection][1] by compiling it to V8 native code. Electron does not.</p></li>\n<li><p>NWJS have a Legacy release for Windows XP and Mac OS X 10.6 support.</p></li>\n<li><p>Electron and NWJS both use MIT license.</p></li>\n</ul>\n\n<p>You can compare the contributions to <a href=\"https://github.com/electron/electron/graphs/contributors\" rel=\"noreferrer\">electron</a> with <a href=\"https://github.com/nwjs/nw.js/graphs/contributors\" rel=\"noreferrer\">NW.js</a></p>\n\n<hr>\n\n<p><strong>Electron and NWJS Cons:</strong></p>\n\n<ul>\n<li>there is no out-of-the-bag run-time solution currently, so you'll have to ship it with your code (~50MB compressed and +100MB uncompressed) or find a way around it.</li>\n<li>depending on your app, Electron/NWJS might considered an overkill especially since its startup time is less than ideal, just something to take into account. </li>\n<li>no native look, you'll have to create your own UI elements using CSS or using some framework.</li>\n</ul>\n\n<hr>\n\n<p><em>Option #3:</em> <strong>DeskGap</strong>.<br>\n<a href=\"https://deskgap.com/\" rel=\"noreferrer\">Website</a>  |  <a href=\"https://github.com/patr0nus/DeskGap/\" rel=\"noreferrer\">GitHub Repo</a> |  <a href=\"https://deskgap.com/#downloads\" rel=\"noreferrer\">Releases</a></p>\n\n<blockquote>\n  <p>DeskGap is a framework for building cross-platform desktop apps with\n  web technologies (JavaScript, HTML and CSS).</p>\n  \n  <p>To enable native capabilities while keeping the size down, DeskGap\n  bundles a Node.js runtime and leaves the HTML rendering to the\n  operating system\u2018s webview.</p>\n</blockquote>\n\n<ul>\n<li><p>Lightweight since the webview is provided by the operating system.</p></li>\n<li><p>The API is still quite limited (pretty much a work in progress).</p></li>\n<li><p>Requires new OS versions.</p></li>\n</ul>\n",
                    "OwnerUserId": "1360954",
                    "LastEditorUserId": "1360954",
                    "LastEditDate": "2019-03-20T18:46:59.750",
                    "LastActivityDate": "2019-03-20T18:46:59.750",
                    "CommentCount": "10",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "41335921",
                "ParentRepo": "https://github.com/kizniche/Mycodo/issues/43#issuecomment-156718451",
                "StackOverflow_Post": {
                    "Id": "41335921",
                    "PostTypeId": "1",
                    "CreationDate": "2016-12-26T20:19:18.720",
                    "Score": "4",
                    "ViewCount": "8531",
                    "Body": "<p>Based on the following links:\n<a href=\"https://forums.adafruit.com/viewtopic.php?f=19&amp;t=83918&amp;p=541562&amp;hilit=TCA9548A#p541562\" rel=\"nofollow noreferrer\">https://forums.adafruit.com/viewtopic.php?f=19&amp;t=83918&amp;p=541562&amp;hilit=TCA9548A#p541562</a>\n<a href=\"https://github.com/kizniche/Mycodo/issues/43#issuecomment-156718451\" rel=\"nofollow noreferrer\">https://github.com/kizniche/Mycodo/issues/43#issuecomment-156718451</a></p>\n\n<p>I have created the following\u00d1:</p>\n\n<p>Multiplexer.py</p>\n\n<pre><code>#!/usr/bin/python\n\n# Change channel of TCA9548A\n# Example: sudo ./multiplexer_channel.py 0\n\nimport smbus\nimport time\nimport sys\n\nI2C_address = 0x77\nI2C_bus_number = 1\nI2C_ch_0 = 0b00000001\nI2C_ch_1 = 0b00000010\nI2C_ch_2 = 0b00000100\nI2C_ch_3 = 0b00001000\nI2C_ch_4 = 0b00010000\nI2C_ch_5 = 0b00100000\nI2C_ch_6 = 0b01000000\nI2C_ch_7 = 0b10000000\n\ndef I2C_setup(i2c_channel_setup):\n    bus = smbus.SMBus(I2C_bus_number)\n    bus.write_byte(I2C_address,i2c_channel_setup)\n    time.sleep(0.1)\n    print \"TCA9548A I2C channel status:\", bin(bus.read_byte(I2C_address))\n\nI2C_setup(int(sys.argv[1]))\n</code></pre>\n\n<p>and \nindex2.py</p>\n\n<pre><code>from tentacle_pi.BMP180 import BMP180\nimport time\nbmp = BMP180(0x70,\"/dev/i2c-1\")\n\n\nfor x in range(0,1005):\n        print \"temperature: %s\" % bmp.temperature()\n        print \"pressure: %s\" % bmp.pressure()\n        print \"altitude: %s\" % bmp.altitude()\n        print\n        time.sleep(2)\n</code></pre>\n\n<p>If I execute the first file with parameters 0 to 7 (multiplexer ports), I get always a connection time out.</p>\n\n<p>Please note I am using a raspberry PI 3 and everything is connected.</p>\n\n<p>If I execute the 2nd file, I GET readings, but they are always misleading (fixed readings), and btw, I think the second file will not work if I have many sensors(BMP180)</p>\n\n<p>EDIT1:\n1. When we try i2cdetect y, we get nothing.\n2. We found another Pythong program to work with the multiplexer\u00d1</p>\n\n<pre><code># coding=utf-8\n\nimport argparse\nimport smbus\nimport time\n\n\nclass TCA9548A(object):\n    def __init__(self, bus, address=0x70, ):\n        self.i2c_address = address\n        self.i2c_bus = bus\n        self.bus = smbus.SMBus(self.i2c_bus)\n\n    def setup(self, channel):\n        try:\n            self.bus.write_byte(self.i2c_address, channel)\n            return 1, \"Success\"\n        except Exception as msg:\n            return 0, \"Fail: {}\".format(msg)\n\n    def read(self):\n        time.sleep(0.1)\n        return self.bus.read_byte(self.i2c_address)\n\n\ndef menu():\n    parser = argparse.ArgumentParser(description='Select I2C address and channel of TCA9548A I2C multiplexer')\n    parser.add_argument('-a', '--address', metavar='ADDRESS', type=int,\n                        help='I2C address of the multiplexer, only last two digits, (ex. enter \"70\" if 0x70)',\n                        required=True)\n    parser.add_argument('-b', '--bus', metavar='BUS', type=int,\n                        help='I2C bus of the multiplexer',\n                        required=True)\n    group = parser.add_mutually_exclusive_group()\n    group.add_argument('-c', '--channel', metavar='CHANNEL', type=int,\n                       help='Channel to be activated with the multiplexer')\n    group.add_argument('-r', '--read', action='store_true',\n                       help='Only read multiplexer and return channel number')\n\n    args = parser.parse_args()\n\n    i2c_address = int(str(args.address), 16)\n    multiplexer = TCA9548A(args.bus, i2c_address)\n    if args.channel:\n        multiplexer.setup(args.channel)\n    read_response = multiplexer.read()\n    print(\"TCA9548A I2C channel status: {} (channel {})\".format(bin(read_response), read_response))\n\n\nif __name__ == \"__main__\":\n    menu()\n</code></pre>\n\n<p>When we try to execute it like this:</p>\n\n<pre><code>sudo python index3py -a 70 -b 1\n</code></pre>\n\n<p>we also get a connection timeout</p>\n\n<p>I am starting to believe that maaybe we have something wrongly connected.</p>\n\n<p>We used adafruit wiring sample</p>\n\n<p>EDIT2: coming with pics</p>\n\n<p><a href=\"https://i.stack.imgur.com/MZiHe.jpg\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/MZiHe.jpg\" alt=\"enter image description here\"></a></p>\n\n<p><a href=\"https://i.stack.imgur.com/IItSz.jpg\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/IItSz.jpg\" alt=\"enter image description here\"></a></p>\n\n<p><a href=\"https://i.stack.imgur.com/dwhlv.jpg\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/dwhlv.jpg\" alt=\"enter image description here\"></a></p>\n\n<p>Edit3:\nI restarted the PI, and now I can see the i2c on 77 address.</p>\n\n<p>However I am getting misleading results, I tried all 7 channels with the same program (index2.py)changed 70 to 77. and I get always a temperature which makes no sense.</p>\n\n<pre><code>pi@pi1:~/Documents/NodeJSProjects/PythonTests $ sudo python index3.py -a 77 -b 1 -c 0\nTCA9548A I2C channel status: 0b11111000 (channel 248)\npi@pi1:~/Documents/NodeJSProjects/PythonTests $ sudo python index2.py\ntemperature: -125.599998474\npressure: 40287\naltitude: -31.4230690002\n\ntemperature: -52.5\npressure: 40183\naltitude: -31.5887317657\n\ntemperature: -52.5\npressure: 40281\naltitude: -37.2313270569\n\ntemperature: -52.5\npressure: 40284\naltitude: -34.078414917\n\n^CTraceback (most recent call last):\n  File \"index2.py\", line 11, in &lt;module&gt;\n    time.sleep(2)\nKeyboardInterrupt\npi@pi1:~/Documents/NodeJSProjects/PythonTests $ sudo python index3.py -a 77 -b 1 -c 1\nTCA9548A I2C channel status: 0b1 (channel 1)\npi@pi1:~/Documents/NodeJSProjects/PythonTests $ sudo python index2.py\ntemperature: -125.699996948\npressure: 40166\naltitude: -31.7548980713\n\ntemperature: -52.4000015259\npressure: 40163\naltitude: -34.5762786865\n\n^CTraceback (most recent call last):\n  File \"index2.py\", line 11, in &lt;module&gt;\n    time.sleep(2)\nKeyboardInterrupt\npi@pi1:~/Documents/NodeJSProjects/PythonTests $ sudo python index3.py -a 77 -b 1 -c 2\nTCA9548A I2C channel status: 0b0 (channel 0)\npi@pi1:~/Documents/NodeJSProjects/PythonTests $ sudo python index2.py\ntemperature: -125.699996948\npressure: 28375\naltitude: 1204.44226074\n\ntemperature: -52.4000015259\npressure: 28303\naltitude: 1222.52453613\n\n^CTraceback (most recent call last):\n  File \"index2.py\", line 11, in &lt;module&gt;\n    time.sleep(2)\nKeyboardInterrupt\npi@pi1:~/Documents/NodeJSProjects/PythonTests $ sudo python index3.py -a 77 -b 1 -c 3\nTCA9548A I2C channel status: 0b0 (channel 0)\npi@pi1:~/Documents/NodeJSProjects/PythonTests $ sudo python index2.py\ntemperature: -125.699996948\npressure: 28304\naltitude: 1205.19128418\n\ntemperature: -52.5\npressure: 28301\naltitude: 1222.90002441\n\n^CTraceback (most recent call last):\n  File \"index2.py\", line 11, in &lt;module&gt;\n    time.sleep(2)\nKeyboardInterrupt\npi@pi1:~/Documents/NodeJSProjects/PythonTests $ sudo python index3.py -a 77 -b 1 -c 4\nTCA9548A I2C channel status: 0b100 (channel 4)\npi@pi1:~/Documents/NodeJSProjects/PythonTests $ sudo python index2.py\ntemperature: -125.699996948\npressure: 40136\naltitude: -46.9332351685\n\ntemperature: -52.5\npressure: 40116\naltitude: -47.5958938599\n\n^CTraceback (most recent call last):\n  File \"index2.py\", line 11, in &lt;module&gt;\n    time.sleep(2)\nKeyboardInterrupt\npi@pi1:~/Documents/NodeJSProjects/PythonTests $ sudo python index3.py -a 77 -b 1 -c 5\nTCA9548A I2C channel status: 0b101 (channel 5)\npi@pi1:~/Documents/NodeJSProjects/PythonTests $ sudo python index2.py\ntemperature: -125.699996948\npressure: 40185\naltitude: -46.9332351685\n\ntemperature: -52.5\npressure: 40136\naltitude: -47.0986480713\n\n^CTraceback (most recent call last):\n  File \"index2.py\", line 11, in &lt;module&gt;\n    time.sleep(2)\nKeyboardInterrupt\npi@pi1:~/Documents/NodeJSProjects/PythonTests $ sudo python index3.py -a 77 -b 1 -c 6\nTCA9548A I2C channel status: 0b0 (channel 0)\npi@pi1:~/Documents/NodeJSProjects/PythonTests $ sudo python index2.py\ntemperature: -125.699996948\npressure: 28365\naltitude: 1216.15002441\n\ntemperature: -52.5\npressure: 28297\naltitude: 1215.96289062\n\n^CTraceback (most recent call last):\n  File \"index2.py\", line 11, in &lt;module&gt;\n    time.sleep(2)\nKeyboardInterrupt\npi@pi1:~/Documents/NodeJSProjects/PythonTests $ sudo python index3.py -a 77 -b 1 -c 7\nTCA9548A I2C channel status: 0b0 (channel 0)\npi@pi1:~/Documents/NodeJSProjects/PythonTests $ sudo python index2.p\npython: can't open file 'index2.p': [Errno 2] No such file or directory\npi@pi1:~/Documents/NodeJSProjects/PythonTests $ sudo python index2.py\ntemperature: -125.699996948\npressure: 28368\naltitude: 1219.89953613\n\ntemperature: -52.5\npressure: 28283\naltitude: 1219.71179199\n\ntemperature: -52.5\npressure: 28353\naltitude: 1219.71179199\n\n^CTraceback (most recent call last):\n  File \"index2.py\", line 11, in &lt;module&gt;\n    time.sleep(2)\nKeyboardInterrupt\npi@pi1:~/Documents/NodeJSProjects/PythonTests $ ^C\n</code></pre>\n",
                    "OwnerUserId": "1014217",
                    "LastActivityDate": "2022-08-23T10:55:24.367",
                    "Title": "How to read from multiplexer with python I2C TCA9548A",
                    "Tags": "<python><raspberry-pi><raspbian>",
                    "AnswerCount": "1",
                    "CommentCount": "3",
                    "FavoriteCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "41592783",
                "ParentRepo": "https://github.com/fchauvel/flap",
                "StackOverflow_Post": {
                    "Id": "41592783",
                    "PostTypeId": "1",
                    "CreationDate": "2017-01-11T13:54:48.857",
                    "Score": "2",
                    "ViewCount": "334",
                    "Body": "<p>I am trying to publish documentation on <code>pythonhosted.org</code> using setuptools, but while <code>python setup.py upload_docs</code> succeeds, nothing changes online, and no update of the documentation is reported in my package's journal on PyPI either.</p>\n\n<p>Yet, I can still manually upload a ZIP file using the PyPI web interface, and this works just fine. </p>\n\n<p>I used to build and deploy the documentation with MkDocs using:</p>\n\n<pre><code>$ mkdocs build --clean\n$ python setup.py upload_docs\n</code></pre>\n\n<p>None of them reports any error. The new website is properly generated and can be served locally by MkDocs.</p>\n\n<p>I tried Python 3.4.2, 3.5 and 3.6, as well as with several versions of setuptools. I must be missing something obvious.</p>\n\n<p>Below is the output of the <code>upload_docs</code> command (with debug info). Note that the content of the website is stored under \"./site\", as detected. See also my <a href=\"https://github.com/fchauvel/flap\" rel=\"nofollow noreferrer\">project configuration</a>, especially <code>setup.py</code> and <code>setup.cfg</code>.</p>\n\n<pre><code>$ python setup.py upload_docs\noptions (after parsing config files):\noptions (after parsing command line):\noption dict for 'aliases' command:\n{}\noption dict for 'metadata' command:\n{'description_file': ('setup.cfg', 'README.adoc')}\noption dict for 'upload_docs' command:\n{'upload_dir': ('setup.cfg', 'site')}\nrunning upload_docs\nDistribution.get_command_obj(): creating 'upload_docs' command object\nsetting options for 'upload_docs' command:\nupload_dir = site (from setup.cfg)\nUpload_docs command is deprecated. Use RTD instead.\nSubmitting documentation to https://pypi.python.org/pypi/\nServer response (200): OK\n</code></pre>\n\n<p>Thanks in advance for any help.</p>\n",
                    "OwnerUserId": "7404838",
                    "LastEditorUserId": "7404838",
                    "LastEditDate": "2017-01-12T20:34:00.110",
                    "LastActivityDate": "2017-10-05T22:12:32.813",
                    "Title": "`python setup.py upload_docs` succeeds but nothing changes online",
                    "Tags": "<python><upload><setuptools><static-site>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "41603531",
                "ParentRepo": "https://github.com/numeristical/introspective",
                "StackOverflow_Post": {
                    "Id": "41603531",
                    "PostTypeId": "2",
                    "ParentId": "30285551",
                    "CreationDate": "2017-01-12T01:08:42.183",
                    "Score": "8",
                    "Body": "<p>There are a couple of issues with the isotonic regression method (and its implementation in sklearn) that make it a suboptimal choice for calibration.</p>\n\n<p>Specifically:</p>\n\n<p>1) It fits a piecewise constant function rather than a smoothly varying curve for the calibration function.</p>\n\n<p>2) The Cross-Validation averages the results of the models/calibrations that it gets from each fold.  However, each of those results is still fit and calibrated only on the respective folds.</p>\n\n<p>Often, a better choice is the <code>SplineCalibratedClassifierCV</code> class in the <a href=\"https://pypi.python.org/pypi/ml-insights/\" rel=\"nofollow noreferrer\">ML-insights</a> package (Disclaimer: I am an author of that package).  The github repo for the package is <a href=\"https://github.com/numeristical/introspective\" rel=\"nofollow noreferrer\">here</a>.</p>\n\n<p>It has the following advantages:</p>\n\n<p>1) It fits a cubic smoothing spline rather than a piecewise constant function.</p>\n\n<p>2) It uses the entire (cross-validated) answer set for calibration and refits the base model on the full data set.  Thus, both the calibration function and the base model are effectively trained on the full data set.</p>\n\n<p>You can see examples of comparisons <a href=\"https://github.com/numeristical/introspective/blob/master/examples/Calibration_Example_ICU_MIMIC.ipynb\" rel=\"nofollow noreferrer\">here</a> and <a href=\"https://github.com/numeristical/introspective/blob/master/examples/Calibration_Example_ICU_MIMIC_Short.ipynb\" rel=\"nofollow noreferrer\">here</a>.</p>\n\n<p>From the first example, here is a graph which shows the binned probabilities of a training set (red dots), independent test set (green + signs), and the calibrations computed by the ML-insights spline method (blue line) and the isotonic-sklearn method (gray dots/line).</p>\n\n<p><a href=\"https://i.stack.imgur.com/avtVA.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/avtVA.png\" alt=\"Spline vs Isotonic Calibration\"></a></p>\n\n<p>I modified your code to compare the methods (and hiked up the number of examples).  It demonstrates that the spline approach typicall performs better (as do the examples I linked to above).</p>\n\n<p>Here is the code and the results:</p>\n\n<p>Code (you will have to <code>pip install ml_insights</code> first):</p>\n\n<pre><code>import numpy as np\nfrom sklearn.datasets import make_classification\nfrom sklearn import ensemble\nfrom sklearn.calibration import CalibratedClassifierCV\nfrom sklearn.metrics import log_loss\nfrom sklearn import cross_validation\nimport ml_insights as mli\n\nX, y = make_classification(n_samples=10000,\n                           n_features=100,\n                           n_informative=30,\n                           n_redundant=0,\n                           n_repeated=0,\n                           n_classes=9,\n                           random_state=0,\n                           shuffle=False)\n\nskf = cross_validation.StratifiedShuffleSplit(y, 5)\n\nfor train, test in skf:\n\n    X_train, X_test = X[train], X[test]\n    y_train, y_test = y[train], y[test]\n\n    clf = ensemble.GradientBoostingClassifier(n_estimators=100)    \n    clf_cv_mli = mli.SplineCalibratedClassifierCV(clf, cv=3)\n    clf_cv_mli.fit(X_train, y_train)\n    probas_cv_mli = clf_cv_mli.predict_proba(X_test)\n    cv_score_mli = log_loss(y_test, probas_cv_mli)\n\n    clf = ensemble.GradientBoostingClassifier(n_estimators=100)    \n    clf_cv = CalibratedClassifierCV(clf, cv=3, method='isotonic')\n    clf_cv.fit(X_train, y_train)\n    probas_cv = clf_cv.predict_proba(X_test)\n    cv_score = log_loss(y_test, probas_cv)\n\n    clf = ensemble.GradientBoostingClassifier(n_estimators=100)\n    clf.fit(X_train, y_train)\n    probas = clf.predict_proba(X_test)\n    clf_score = log_loss(y_test, probas) \n\n    clf = ensemble.GradientBoostingClassifier(n_estimators=100)    \n    clf_cv_mli = mli.SplineCalibratedClassifierCV(clf, cv=10)\n    clf_cv_mli.fit(X_train, y_train)\n    probas_cv_mli = clf_cv_mli.predict_proba(X_test)\n    cv_score_mli_10 = log_loss(y_test, probas_cv_mli)\n\n    clf = ensemble.GradientBoostingClassifier(n_estimators=100)    \n    clf_cv = CalibratedClassifierCV(clf, cv=10, method='isotonic')\n    clf_cv.fit(X_train, y_train)\n    probas_cv = clf_cv.predict_proba(X_test)\n    cv_score_10 = log_loss(y_test, probas_cv)\n\n    print('\\nuncalibrated score: {}'.format(clf_score))\n    print('\\ncalibrated score isotonic-sklearn (3-fold): {}'.format(cv_score))\n    print('calibrated score mli (3-fold): {}'.format(cv_score_mli))\n    print('\\ncalibrated score isotonic-sklearn (10-fold): {}'.format(cv_score_10))\n    print('calibrated score mli (10-fold): {}\\n'.format(cv_score_mli_10))\n</code></pre>\n\n<p>Results</p>\n\n<pre><code>uncalibrated score: 1.4475396740876696\n\ncalibrated score isotonic-sklearn (3-fold): 1.465140552847886\ncalibrated score mli (3-fold): 1.3651638065446683\n\ncalibrated score isotonic-sklearn (10-fold): 1.4158622673607426\ncalibrated score mli (10-fold): 1.3620771116522705\n\n\nuncalibrated score: 1.5097320476479625\n\ncalibrated score isotonic-sklearn (3-fold): 1.5189534673089442\ncalibrated score mli (3-fold): 1.4386253950100405\n\ncalibrated score isotonic-sklearn (10-fold): 1.4976505139437257\ncalibrated score mli (10-fold): 1.4408912879989917\n\n\nuncalibrated score: 1.4654527691892194\n\ncalibrated score isotonic-sklearn (3-fold): 1.493355643575107\ncalibrated score mli (3-fold): 1.388789694535648\n\ncalibrated score isotonic-sklearn (10-fold): 1.419760490609242\ncalibrated score mli (10-fold): 1.3830851694161692\n\n\nuncalibrated score: 1.5163851866969407\n\ncalibrated score isotonic-sklearn (3-fold): 1.5532628847926322\ncalibrated score mli (3-fold): 1.459797287154743\n\ncalibrated score isotonic-sklearn (10-fold): 1.4748100659449732\ncalibrated score mli (10-fold): 1.4620173012979816\n\n\nuncalibrated score: 1.4760935523959617\n\ncalibrated score isotonic-sklearn (3-fold): 1.469434735152088\ncalibrated score mli (3-fold): 1.402024502986732\n\ncalibrated score isotonic-sklearn (10-fold): 1.4702032019673137\ncalibrated score mli (10-fold): 1.3983943648572212\n</code></pre>\n",
                    "OwnerUserId": "4722706",
                    "LastEditorUserId": "4037",
                    "LastEditDate": "2019-11-17T14:19:41.597",
                    "LastActivityDate": "2019-11-17T14:19:41.597",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "41896400",
                "ParentRepo": "https://github.com/LouisCAD/Splitties/blob/master/publish.gradle",
                "StackOverflow_Post": {
                    "Id": "41896400",
                    "PostTypeId": "2",
                    "ParentId": "34331713",
                    "CreationDate": "2017-01-27T14:35:05.463",
                    "Score": "14",
                    "Body": "<p>I faced the same challenge, and here's the best I could make yet:</p>\n\n<p>Using <code>mavenPublications</code> and the gradle <code>maven-publish</code> plugin along the bintray plugin, you can publish any variant to mavenLocal and bintray.</p>\n\n<p>Here's the <a href=\"https://github.com/LouisCAD/Splitties/blob/master/publish.gradle\" rel=\"noreferrer\"><code>publish.gradle</code></a> file I apply at the end of all my project's library modules I want to publish:</p>\n\n<pre><code>def pomConfig = {\n    licenses {\n        license {\n            name 'The Apache Software License, Version 2.0'\n            url 'http://www.apache.org/licenses/LICENSE-2.0.txt'\n        }\n    }\n    developers {\n        developer {\n            id 'louiscad'\n            name 'Louis CAD'\n            email 'louis.cognault@gmail.com'\n        }\n    }\n    scm {\n        connection 'https://github.com/LouisCAD/Splitties.git'\n        developerConnection 'https://github.com/LouisCAD/Splitties.git'\n        url siteUrl\n    }\n}\n\ndef publicationNames = []\npublishing.publications {\n    android.libraryVariants.all { variant -&gt;\n        if (variant.buildType.name == \"debug\") return // Prevents publishing debug library\n\n        def flavored = !variant.flavorName.isEmpty()\n\n        /**\n         * Translates \"_\" in flavor names to \"-\" for artifactIds, because \"-\" in flavor name is an\n         * illegal character, but is well used in artifactId names.\n         */\n        def variantArtifactId = flavored ? variant.flavorName.replace('_', '-') : project.name\n\n        /**\n         * If the javadoc destinationDir wasn't changed per flavor, the libraryVariants would\n         * overwrite the javaDoc as all variants would write in the same directory\n         * before the last javadoc jar would have been built, which would cause the last javadoc\n         * jar to include classes from other flavors that it doesn't include.\n         *\n         * Yes, tricky.\n         *\n         * Note that \"${buildDir}/docs/javadoc\" is the default javadoc destinationDir.\n         */\n        def javaDocDestDir = file(\"${buildDir}/docs/javadoc ${flavored ? variantArtifactId : \"\"}\")\n\n        /**\n         * Includes\n         */\n        def sourceDirs = variant.sourceSets.collect {\n            it.javaDirectories // Also includes kotlin sources if any.\n        }\n        def javadoc = task(\"${variant.name}Javadoc\", type: Javadoc) {\n            description \"Generates Javadoc for ${variant.name}.\"\n            source = variant.javaCompile.source // Yes, javaCompile is deprecated,\n            // but I didn't find any working alternative. Please, tweet @Louis_CAD if you find one.\n            destinationDir = javaDocDestDir\n            classpath += files(android.getBootClasspath().join(File.pathSeparator))\n            classpath += files(configurations.compile)\n            options.links(\"http://docs.oracle.com/javase/7/docs/api/\");\n            options.links(\"http://d.android.com/reference/\");\n            exclude '**/BuildConfig.java'\n            exclude '**/R.java'\n            failOnError false\n        }\n        def javadocJar = task(\"${variant.name}JavadocJar\", type: Jar, dependsOn: javadoc) {\n            description \"Puts Javadoc for ${variant.name} in a jar.\"\n            classifier = 'javadoc'\n            from javadoc.destinationDir\n        }\n        def sourcesJar = task(\"${variant.name}SourcesJar\", type: Jar) {\n            description \"Puts sources for ${variant.name} in a jar.\"\n            from sourceDirs\n            classifier = 'sources'\n        }\n\n        def publicationName = \"splitties${variant.name.capitalize()}Library\"\n        publicationNames.add(publicationName)\n\n        \"$publicationName\"(MavenPublication) {\n            artifactId variantArtifactId\n            group groupId\n            version libraryVersion\n\n            artifact variant.outputs[0].packageLibrary // This is the aar library\n            artifact sourcesJar\n            artifact javadocJar\n\n            pom {\n                packaging 'aar'\n                withXml {\n                    def root = asNode()\n                    root.appendNode(\"name\", 'Splitties')\n                    root.appendNode(\"url\", siteUrl)\n                    root.children().last() + pomConfig\n                    def depsNode = root[\"dependencies\"][0] ?: root.appendNode(\"dependencies\")\n\n                    def addDep = {\n                        if (it.group == null) return // Avoid empty dependency nodes\n                        def dependencyNode = depsNode.appendNode('dependency')\n                        dependencyNode.appendNode('groupId', it.group)\n                        dependencyNode.appendNode('artifactId', it.name)\n                        dependencyNode.appendNode('version', it.version)\n                        if (it.hasProperty('optional') &amp;&amp; it.optional) {\n                            dependencyNode.appendNode('optional', 'true')\n                        }\n                    }\n\n                    // Add deps that everyone has\n                    configurations.compile.allDependencies.each addDep\n                    // Add flavor specific deps\n                    if (flavored) {\n                        configurations[\"${variant.flavorName}Compile\"].allDependencies.each addDep\n                    }\n                    // NOTE: This library doesn't use builtTypes specific dependencies, so no need to add them.\n                }\n            }\n        }\n    }\n}\n\ngroup = groupId\nversion = libraryVersion\n\nafterEvaluate {\n    bintray {\n        user = bintray_user\n        key = bintray_api_key\n        publications = publicationNames\n\n        override = true\n        pkg {\n            repo = 'splitties'\n            name = project.name\n            desc = libraryDesc\n            websiteUrl = siteUrl\n            issueTrackerUrl = 'https://github.com/LouisCAD/Splitties/issues'\n            vcsUrl = gitUrl\n            licenses = ['Apache-2.0']\n            labels = ['aar', 'android']\n            publicDownloadNumbers = true\n            githubRepo = 'LouisCAD/Splitties'\n        }\n    }\n}\n</code></pre>\n\n<p>In order for this to work, I need to have the <code>bintray_user</code> and <code>bintray_api_key</code> properties defined. I personally just have them in my <code>~/.gradle/gradle.properties</code> file like this:</p>\n\n<pre><code>bintray_user=my_bintray_user_name\nbintray_api_key=my_private_bintray_api_key\n</code></pre>\n\n<p>I also need to define the following ext properties I used in the <a href=\"https://github.com/LouisCAD/Splitties/blob/master/publish.gradle\" rel=\"noreferrer\"><code>publish.gradle</code></a> file in my root project's <a href=\"https://github.com/LouisCAD/Splitties/blob/master/build.gradle\" rel=\"noreferrer\"><code>build.gradle</code></a> file:</p>\n\n<pre><code>allprojects {\n    ...\n    ext {\n        ...\n        // Libraries\n        groupId = \"xyz.louiscad.splitties\"\n        libraryVersion = \"1.2.1\"\n        siteUrl = 'https://github.com/LouisCAD/Splitties'\n        gitUrl = 'https://github.com/LouisCAD/Splitties.git'\n    }\n}\n</code></pre>\n\n<p>And now, I can finally use it in my android library module, where I have multiple <code>productFlavors</code>. Here's a snippet from a publishable library module's <a href=\"https://github.com/LouisCAD/Splitties/blob/master/concurrency/build.gradle\" rel=\"noreferrer\"><code>build.gradle</code></a> file:</p>\n\n<pre><code>plugins {\n    id \"com.jfrog.bintray\" version \"1.7.3\" // Enables publishing to bintray\n    id \"com.github.dcendents.android-maven\" version \"1.5\" // Allows aar in mavenPublications\n}\n\napply plugin: 'com.android.library'\napply plugin: 'maven-publish' // Used for mavenPublications\n\nandroid {\n    ...\n    defaultPublishConfig \"myLibraryDebug\" // Allows using this library in another\n    // module in this project without publishing to mavenLocal or Bintray.\n    // Useful for debug purposes, or for your library's sample app.\n    defaultConfig {\n        ...\n        versionName libraryVersion\n        ...\n    }\n    ...\n    productFlavors {\n        myLibrary\n        myLibrary_logged // Here, the \"_\" will be replaced \"-\" in artifactId when publishing.\n        myOtherLibraryFlavor\n    }\n    ...\n}\n\ndependencies {\n    ...\n    // Timber, a log utility.\n    myLibrary_loggedCompile \"com.jakewharton.timber:timber:${timberVersion}\"; // Just an example\n}\n...\n\next {\n    libraryDesc = \"Delegates for kotlin on android that check UI thread\"\n}\n\napply from: '../publish.gradle' // Makes this library publishable\n</code></pre>\n\n<p>When you have all of this setup properly, with the name of your library instead of <a href=\"https://github.com/LouisCAD/Splitties\" rel=\"noreferrer\">mine's</a> (which you can use as an example), you can try publishing a version of your flavored library by trying to first publishing to mavenLocal.\nTo do so, run this command:</p>\n\n<pre><code>myLibrary $ ../gradlew publishToMavenLocal\n</code></pre>\n\n<p>You can then try adding <code>mavenLocal</code> in your app's repositories <a href=\"https://github.com/LouisCAD/Splitties/blob/4d9401124bdb4c9ab67a8ffd7fa5bbde3f2a752d/sample/build.gradle#L88\" rel=\"noreferrer\">(example here)</a> and try adding your library as a dependency (artifactId should be the flavor name, with \"_\" replaced with \"-\") and building it.\nYou can also check with your file explorer (use cmd+shift+G on Mac in Finder to access hidden folder) the directory <code>~/.m2</code> and look for your library.</p>\n\n<p>When it's time to publish to bintray/jcenter, you just have to run this command:</p>\n\n<pre><code>myLibrary $ ../gradlew bintrayUpload\n</code></pre>\n\n<p><strong>Important:</strong></p>\n\n<p>Before you publish your library to mavenLocal, Bintray or another maven repository, you'll usually want to try your library against a sample app which uses the library. This sample app, which should be another module in the same project just need to have the project dependency, which should look like this: <code>compile project(':myLibrary')</code>. However, since your library has multiple productFlavors, you'll want to test all of them. Unfortunately, it's currently impossible to specify which configuration you want to use from your sample app's <code>build.gradle</code> file (unless, you use <code>publishNonDefault true</code> in your library's <code>build.gradle</code> file, which breaks maven and bintray publications), but you can specify the default configuration (i.e. buildVariant) in your library's module as such: <code>defaultPublishConfig \"myLibraryDebug\"</code> in the <code>android</code> closure. You can see the available build variants for your library in the \"Build Variants\" tool Windows in Android Studio.</p>\n\n<p>Feel free to explore <a href=\"https://github.com/LouisCAD/Splitties\" rel=\"noreferrer\">my library \"Splitties\" here</a> if you need an example. The flavored module is named <code>concurrency</code>, but I use my script for unflavored library modules too, and I tested it throughly on all the library modules in my project.</p>\n\n<p>You can reach me out if you need help setting it up for you.</p>\n",
                    "OwnerUserId": "4433326",
                    "LastEditorUserId": "4433326",
                    "LastEditDate": "2017-03-01T21:10:12.240",
                    "LastActivityDate": "2017-03-01T21:10:12.240",
                    "CommentCount": "6",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "43351129",
                "ParentRepo": "https://github.com/s9e/TextFormatter/blob/master/src/Configurator.php#L223",
                "StackOverflow_Post": {
                    "Id": "43351129",
                    "PostTypeId": "2",
                    "ParentId": "43350482",
                    "CreationDate": "2017-04-11T16:09:35.407",
                    "Score": "1",
                    "Body": "<p>This line</p>\n\n<pre><code>extract( $configurator-&gt;finalize() );\n</code></pre>\n\n<p>defines those variables. This is because <a href=\"http://php.net/extract\" rel=\"nofollow noreferrer\">extract()</a> will \"<em>Import variables into the current symbol table from an array</em>\"<sup><a href=\"http://php.net/extract\" rel=\"nofollow noreferrer\">1</a></sup> (referring to <a href=\"http://php.net/manual/en/function.extract.php#example-5635\" rel=\"nofollow noreferrer\">the PHP documentation example</a> might help with understanding this). Look at the docblock for <a href=\"https://github.com/s9e/TextFormatter/blob/master/src/Configurator.php#L223\" rel=\"nofollow noreferrer\">Configurator::finalize()</a>:</p>\n\n<blockquote>\n<pre><code>/**\n* Finalize this configuration and return all the relevant objects\n*\n* Options: (also see addHTMLRules() options)\n*\n*  - addHTML5Rules:    whether to call addHTML5Rules()\n*  - finalizeParser:   callback executed after the parser is created (gets the parser as arg)\n*  - finalizeRenderer: same with the renderer\n*  - optimizeConfig:   whether to optimize the parser's config using references\n*  - returnParser:     whether to return an instance of Parser in the \"parser\" key\n*  - returnRenderer:   whether to return an instance of Renderer in the \"renderer\" key\n*\n* @param  array $options\n* @return array One \"parser\" element and one \"renderer\" element unless specified otherwise\n*/\n</code></pre>\n  \n  <p><sup><a href=\"https://github.com/s9e/TextFormatter/blob/master/src/Configurator.php#L223\" rel=\"nofollow noreferrer\">2</a></sup></p>\n</blockquote>\n\n<p>Those last two options (<em>returnParser</em> and <em>returnRenderer</em>) default to true.</p>\n\n<p>Try running these lines (after configuring the Configurator instance):</p>\n\n<pre><code>extract( $configurator-&gt;finalize() );\necho 'typeof $parser: '.get_class($parser).'&lt;br&gt;';\necho 'typeof $renderer: '.get_class($renderer).'&lt;br&gt;';\n</code></pre>\n\n<p>This should yield this text:</p>\n\n<blockquote>\n  <p>typeof $parser: s9e\\TextFormatter\\Parser</p>\n  \n  <p>typeof $renderer: s9e\\TextFormatter\\Renderers\\XSLT</p>\n</blockquote>\n\n<hr>\n\n<p><sup>1</sup><sub><a href=\"http://php.net/extract\" rel=\"nofollow noreferrer\">http://php.net/extract</a></sub></p>\n\n<p><sup>2</sup><sub><a href=\"https://github.com/s9e/TextFormatter/blob/master/src/Configurator.php#L223\" rel=\"nofollow noreferrer\">https://github.com/s9e/TextFormatter/blob/master/src/Configurator.php#L223</a></sub></p>\n",
                    "OwnerUserId": "1575353",
                    "LastActivityDate": "2017-04-11T16:09:35.407",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "43772265",
                "ParentRepo": "https://github.com/coreos/alb-ingress-controller",
                "StackOverflow_Post": {
                    "Id": "43772265",
                    "PostTypeId": "2",
                    "ParentId": "39350376",
                    "CreationDate": "2017-05-04T01:07:47.427",
                    "Score": "3",
                    "Body": "<p>An AWS ALB Ingress Controller has been built which you can find on GitHub: <a href=\"https://github.com/coreos/alb-ingress-controller\" rel=\"nofollow noreferrer\">https://github.com/coreos/alb-ingress-controller</a></p>\n",
                    "OwnerUserId": "2152602",
                    "LastActivityDate": "2017-05-04T01:07:47.427",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "43880985",
                "ParentRepo": "https://github.com/MrPowers/chispa",
                "StackOverflow_Post": {
                    "Id": "43880985",
                    "PostTypeId": "2",
                    "ParentId": "31197353",
                    "CreationDate": "2017-05-09T22:44:46.243",
                    "Score": "37",
                    "Body": "<p><strong>Scala (see below for PySpark)</strong></p>\n<p>The <a href=\"https://github.com/MrPowers/spark-fast-tests\" rel=\"noreferrer\">spark-fast-tests</a> library has two methods for making DataFrame comparisons (I'm the creator of the library):</p>\n<p>The <code>assertSmallDataFrameEquality</code> method collects DataFrames on the driver node and makes the comparison</p>\n<pre><code>def assertSmallDataFrameEquality(actualDF: DataFrame, expectedDF: DataFrame): Unit = {\n  if (!actualDF.schema.equals(expectedDF.schema)) {\n    throw new DataFrameSchemaMismatch(schemaMismatchMessage(actualDF, expectedDF))\n  }\n  if (!actualDF.collect().sameElements(expectedDF.collect())) {\n    throw new DataFrameContentMismatch(contentMismatchMessage(actualDF, expectedDF))\n  }\n}\n</code></pre>\n<p>The <code>assertLargeDataFrameEquality</code> method compares DataFrames spread on multiple machines (the code is basically copied from <a href=\"https://github.com/holdenk/spark-testing-base\" rel=\"noreferrer\">spark-testing-base</a>)</p>\n<pre><code>def assertLargeDataFrameEquality(actualDF: DataFrame, expectedDF: DataFrame): Unit = {\n  if (!actualDF.schema.equals(expectedDF.schema)) {\n    throw new DataFrameSchemaMismatch(schemaMismatchMessage(actualDF, expectedDF))\n  }\n  try {\n    actualDF.rdd.cache\n    expectedDF.rdd.cache\n\n    val actualCount = actualDF.rdd.count\n    val expectedCount = expectedDF.rdd.count\n    if (actualCount != expectedCount) {\n      throw new DataFrameContentMismatch(countMismatchMessage(actualCount, expectedCount))\n    }\n\n    val expectedIndexValue = zipWithIndex(actualDF.rdd)\n    val resultIndexValue = zipWithIndex(expectedDF.rdd)\n\n    val unequalRDD = expectedIndexValue\n      .join(resultIndexValue)\n      .filter {\n        case (idx, (r1, r2)) =&gt;\n          !(r1.equals(r2) || RowComparer.areRowsEqual(r1, r2, 0.0))\n      }\n\n    val maxUnequalRowsToShow = 10\n    assertEmpty(unequalRDD.take(maxUnequalRowsToShow))\n\n  } finally {\n    actualDF.rdd.unpersist()\n    expectedDF.rdd.unpersist()\n  }\n}\n</code></pre>\n<p><code>assertSmallDataFrameEquality</code> is faster for small DataFrame comparisons and I've found it sufficient for my test suites.</p>\n<p><strong>PySpark</strong></p>\n<p>Here's a simple function that returns true if the DataFrames are equal:</p>\n<pre class=\"lang-py prettyprint-override\"><code>def are_dfs_equal(df1, df2):\n    if df1.schema != df2.schema:\n        return False\n    if df1.collect() != df2.collect():\n        return False\n    return True\n</code></pre>\n<p>or simplified</p>\n<pre class=\"lang-py prettyprint-override\"><code>def are_dfs_equal(df1, df2): \n    return (df1.schema == df2.schema) and (df1.collect() == df2.collect())\n</code></pre>\n<p>You'll typically perform DataFrame equality comparisons in a test suite and will want a descriptive error message when the comparisons fail (a <code>True</code> / <code>False</code> return value doesn't help much when debugging).</p>\n<p>Use the <a href=\"https://github.com/MrPowers/chispa\" rel=\"noreferrer\">chispa</a> library to access the <code>assert_df_equality</code> method that returns descriptive error messages for test suite workflows.</p>\n",
                    "OwnerUserId": "1125159",
                    "LastEditorUserId": "3831137",
                    "LastEditDate": "2022-05-26T07:53:47.580",
                    "LastActivityDate": "2022-05-26T07:53:47.580",
                    "CommentCount": "5",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "43972453",
                "ParentRepo": "https://github.com/djangopackages/djangopackages",
                "StackOverflow_Post": {
                    "Id": "43972453",
                    "PostTypeId": "1",
                    "CreationDate": "2017-05-15T06:01:19.010",
                    "Score": "2",
                    "ViewCount": "326",
                    "Body": "<p>I am trying to run Django-packages in Docker, but I am unable to.</p>\n\n<p>I am getting the following:-</p>\n\n<pre><code>django_1    | Postgres is up - continuing...\ndjango_1    | python: can't open file 'manage.py': [Errno 2] No such file or directory\ndjango_1    | python: can't open file 'manage.py': [Errno 2] No such file or directory\n</code></pre>\n\n<p>Everything seems to be fine though.The daemon is running. </p>\n\n<p><strong>docker ps</strong></p>\n\n<pre><code>C:\\djangopackages-master&gt;docker ps\nCONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES\n</code></pre>\n\n<p><strong>docker volume ls</strong></p>\n\n<pre><code>C:\\djangopackages-master&gt;docker volume ls\nDRIVER              VOLUME NAME\nlocal               djangopackagesmaster_postgres_backup_dev\nlocal               djangopackagesmaster_postgres_data_dev\nlocal               ef5505952d82c1472e74e21a8d2921018b2f7ee5570742268c8560335fe5762b\n</code></pre>\n\n<p>Cant seem to figure  out what might be the issue. </p>\n\n<p><strong>How i built the docker container:</strong>\nRan <strong>docker-compose -f dev.yml up</strong> after cloning the following repo.\n<a href=\"https://github.com/djangopackages/djangopackages\" rel=\"nofollow noreferrer\">https://github.com/djangopackages/djangopackages</a></p>\n\n<p>Docker Files present for creation:-</p>\n\n<p><a href=\"https://github.com/djangopackages/djangopackages/blob/master/compose/caddy/Dockerfile\" rel=\"nofollow noreferrer\">https://github.com/djangopackages/djangopackages/blob/master/compose/caddy/Dockerfile</a></p>\n\n<p><a href=\"https://github.com/djangopackages/djangopackages/blob/master/compose/django/Dockerfile\" rel=\"nofollow noreferrer\">https://github.com/djangopackages/djangopackages/blob/master/compose/django/Dockerfile</a></p>\n\n<p><a href=\"https://github.com/djangopackages/djangopackages/blob/master/compose/django/Dockerfile-dev\" rel=\"nofollow noreferrer\">https://github.com/djangopackages/djangopackages/blob/master/compose/django/Dockerfile-dev</a></p>\n\n<p><a href=\"https://github.com/djangopackages/djangopackages/blob/master/compose/postgres/Dockerfile\" rel=\"nofollow noreferrer\">https://github.com/djangopackages/djangopackages/blob/master/compose/postgres/Dockerfile</a></p>\n\n<p><a href=\"https://github.com/djangopackages/djangopackages/blob/master/compose/redis/Dockerfile\" rel=\"nofollow noreferrer\">https://github.com/djangopackages/djangopackages/blob/master/compose/redis/Dockerfile</a></p>\n\n<p><strong>In this particular dockerfile</strong></p>\n\n<pre><code>FROM python:3.6\n\nENV PYTHONUNBUFFERED 1\n\n# Requirements have to be pulled and installed here, otherwise caching won't work\nCOPY ./requirements.txt /requirements.txt\n\nCOPY ./manage.py /manage.py\n\nRUN pip install -r /requirements.txt\n\nCOPY ./compose/django/entrypoint.sh /entrypoint.sh\nRUN sed -i 's/\\r//' /entrypoint.sh\nRUN chmod +x /entrypoint.sh\n\nCOPY ./compose/django/start-dev.sh /start-dev.sh\nRUN sed -i 's/\\r//' /start-dev.sh\nRUN chmod +x /start-dev.sh\n\n\nWORKDIR /app\n\nENTRYPOINT [\"/entrypoint.sh\"]\n</code></pre>\n\n<p>If I tell to copy manage.py as well then manage.py runs(with errors of course). It seems it is not running the manage.py in the correct path. not sure what to do here anymore.</p>\n",
                    "OwnerUserId": "2770024",
                    "LastEditorUserId": "2770024",
                    "LastEditDate": "2017-05-15T15:10:36.420",
                    "LastActivityDate": "2017-05-15T15:10:36.420",
                    "Title": "Cannot Start Django in Docker",
                    "Tags": "<django><docker>",
                    "AnswerCount": "0",
                    "CommentCount": "4",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "44055580",
                "ParentRepo": "https://github.com/square/kotlinpoet/blob/master/CHANGELOG.md#version-010",
                "StackOverflow_Post": {
                    "Id": "44055580",
                    "PostTypeId": "2",
                    "ParentId": "44052909",
                    "CreationDate": "2017-05-18T18:41:09.220",
                    "Score": "8",
                    "Body": "<p>No. Kotlin has <a href=\"https://kotlinlang.org/docs/reference/null-safety.html#nullable-types-and-non-null-types\" rel=\"noreferrer\">Nullable types and Non-Null Types</a> but it does not have a concept of nullable <em>classes</em> and non-null <em>classes</em>. A <a href=\"https://kotlinlang.org/api/latest/jvm/stdlib/kotlin.reflect/-k-type/\" rel=\"noreferrer\"><code>KType</code></a> is a classifier plus nullability where a classifier can be a <a href=\"https://kotlinlang.org/api/latest/jvm/stdlib/kotlin.reflect/-k-class/\" rel=\"noreferrer\"><code>KClass</code></a>.</p>\n\n<p>KotlinPoet <a href=\"https://github.com/square/kotlinpoet/blob/master/CHANGELOG.md#version-010\" rel=\"noreferrer\">0.1.0</a> did not have a way to represent nullable types but support for such was added in <a href=\"https://github.com/square/kotlinpoet/blob/master/CHANGELOG.md#version-020\" rel=\"noreferrer\">0.2.0</a> via <code>TypeName.asNullable</code>. e.g.:</p>\n\n<pre><code>val type = TypeName.get(String::class).asNullable()\n</code></pre>\n",
                    "OwnerUserId": "3255152",
                    "LastEditorUserId": "3255152",
                    "LastEditDate": "2017-05-22T12:57:09.447",
                    "LastActivityDate": "2017-05-22T12:57:09.447",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "44225400",
                "ParentRepo": "https://github.com/coreos/matchbox",
                "StackOverflow_Post": {
                    "Id": "44225400",
                    "PostTypeId": "1",
                    "CreationDate": "2017-05-28T08:46:23.280",
                    "Score": "1",
                    "ViewCount": "514",
                    "Body": "<p>I am following the CoreOS tutorial for <a href=\"https://coreos.com/matchbox/docs/latest/bootkube.html\" rel=\"nofollow noreferrer\">self-hosted Kubernetes</a> and I am having some issues with the Bootkube API server. Using the Bootkube example from the <a href=\"https://github.com/coreos/matchbox\" rel=\"nofollow noreferrer\">recommended repository</a> I have only changed the <code>ssh_authorized_keys</code> metadata field in nodes 1,2 and 3. All other settings are the same as in the repository. However, after running <code>bootkube-start</code> via <code>systemctl</code> on <code>node1</code> I check the logs using <code>ssh core@node1.example.com 'journalctl -f -u bootkube'</code> and I am getting <code>Unable to determine api-server readiness: Get https://node1.example.com:443/version: dial tcp 172.17.0.21:443: getsockopt: connection refused</code>. Does anyone know of the best ways to debug such an issue?</p>\n",
                    "OwnerUserId": "6180803",
                    "LastEditorUserId": "6180803",
                    "LastEditDate": "2017-05-28T08:52:07.040",
                    "LastActivityDate": "2017-06-01T10:57:02.290",
                    "Title": "Bootkube API server unable to start",
                    "Tags": "<kubernetes><coreos><coreos-ignition>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "44411828",
                "ParentRepo": "https://github.com/yeasy/cello/blob/master/docs/deployment.md",
                "StackOverflow_Post": {
                    "Id": "44411828",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "44412406",
                    "CreationDate": "2017-06-07T11:49:31.283",
                    "Score": "6",
                    "ViewCount": "10577",
                    "Body": "<p>I have installed Docker on Ubuntu 16.04 server, using the manual on this page: <a href=\"https://docs.docker.com/cs-engine/1.13/\" rel=\"noreferrer\">https://docs.docker.com/cs-engine/1.13/</a>, so, using these steps:</p>\n\n<pre><code>curl -fsSL 'https://sks-keyservers.net/pks/lookup?op=get&amp;search=0xee6d536cf7dc86e2d7d56f59a178ac6c6238f52e' | sudo apt-key add -\nsudo add-apt-repository    \"deb https://packages.docker.com/1.13/apt/repo/ \\\nubuntu-$(lsb_release -cs) \\\nmain\"\n\nsudo apt-get update\nsudo apt-get -y install docker-engine\n</code></pre>\n\n<p>I have installed it on two servers and I need them to see each other, I needed to let Docker daemon listen on port 2375 (probably doesn't matter, but using this manual: <a href=\"https://github.com/yeasy/cello/blob/master/docs/deployment.md\" rel=\"noreferrer\">https://github.com/yeasy/cello/blob/master/docs/deployment.md</a>)</p>\n\n<p>So I created the conf file:</p>\n\n<pre><code>sudo mkdir -p /etc/systemd/system/docker.service.d\nsudo vim /etc/systemd/system/docker.service.d/override.conf\n</code></pre>\n\n<p>Added this to the override.conf:</p>\n\n<pre><code>[Service]\nDOCKER_OPTS=\"$DOCKER_OPTS -H tcp://0.0.0.0:2375 -H unix:///var/run/docker.sock --api-cors-header='*' --default-ulimit=nofile=8192:16384 --default-ulimit=nproc=8192:16384\"\nEnvironmentFile=-/etc/default/docker\nExecStart=\nExecStart=/usr/bin/dockerd -H fd:// $DOCKER_OPTS\n</code></pre>\n\n<p>Then:</p>\n\n<pre><code>$ sudo systemctl daemon-reload\n$ sudo systemctl restart docker.service\n</code></pre>\n\n<p>Tested the connection between servers like this:</p>\n\n<pre><code>$ docker -H 10.101.35.61:2375 version\n</code></pre>\n\n<p>The response:</p>\n\n<pre><code>Client:\n Version:      1.13.1-cs4\n API version:  1.27\n Go version:   go1.7.5\n Git commit:   e46aec0\n Built:        Mon May 22 18:46:40 2017\n OS/Arch:      linux/amd64\nCannot connect to the Docker daemon at tcp://10.101.35.61:2375. Is the docker daemon running?\n</code></pre>\n\n<p>Tried restarting the server, same problem. Tried to run with sudo. Tried adding the user to group docker:</p>\n\n<pre><code>sudo usermod -aG docker $USER\n</code></pre>\n\n<p>Didn't help. I have disabled firewall on both servers. When I check the ports open on the server with <code>sudo lsof -i</code>, I can't see anything listening to port 2375 - I am guessing Docker should be listening to it?</p>\n",
                    "OwnerUserId": "1819209",
                    "LastActivityDate": "2017-06-07T13:05:43.170",
                    "Title": "Cannot connect to the Docker daemon (port 2375)",
                    "Tags": "<linux><docker>",
                    "AnswerCount": "1",
                    "CommentCount": "2",
                    "FavoriteCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "44444548",
                "ParentRepo": "https://github.com/Dans-labs/dariah/blob/master/client/src/js/lib/utils.js",
                "StackOverflow_Post": {
                    "Id": "44444548",
                    "PostTypeId": "2",
                    "ParentId": "34202895",
                    "CreationDate": "2017-06-08T19:58:35.900",
                    "Score": "0",
                    "Body": "<p>See memoize in <a href=\"https://github.com/Dans-labs/dariah/blob/master/client/src/js/lib/utils.js\" rel=\"nofollow noreferrer\">https://github.com/Dans-labs/dariah/blob/master/client/src/js/lib/utils.js</a>\nIt solves the problem in a generic way by building a WeakMap index of all arguments that are objects. The WeakMap index assigns unique integers to objects, which can then be put together with the other arguments by stringify.</p>\n",
                    "OwnerUserId": "8133508",
                    "LastActivityDate": "2017-06-08T19:58:35.900",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "44674833",
                "ParentRepo": "https://github.com/portphp/portphp",
                "StackOverflow_Post": {
                    "Id": "44674833",
                    "PostTypeId": "2",
                    "ParentId": "38282864",
                    "CreationDate": "2017-06-21T11:28:14.533",
                    "Score": "0",
                    "Body": "<p>This project is not developed anymore so the documentaion is obsolete: they are working on a replacement <a href=\"https://github.com/portphp/portphp\" rel=\"nofollow noreferrer\">https://github.com/portphp/portphp</a> which, as they say, is a data import/export workflow for PHP <a href=\"http://portphp.org\" rel=\"nofollow noreferrer\">http://portphp.org</a></p>\n\n<p>Also a symfony bundle is planned but as of today they didn't start on it:\n<a href=\"https://github.com/portphp/symfony-bundle\" rel=\"nofollow noreferrer\">https://github.com/portphp/symfony-bundle</a></p>\n\n<p>So your only help is search the github repo for the code you need and check the <a href=\"https://github.com/ddeboer/data-import/blob/master/tests/WorkflowTest.php\" rel=\"nofollow noreferrer\">tests files</a> for examples.</p>\n",
                    "OwnerUserId": "232082",
                    "LastActivityDate": "2017-06-21T11:28:14.533",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "44686641",
                "ParentRepo": "https://github.com/TestArmada/flank",
                "StackOverflow_Post": {
                    "Id": "44686641",
                    "PostTypeId": "2",
                    "ParentId": "41746344",
                    "CreationDate": "2017-06-21T21:34:49.917",
                    "Score": "2",
                    "Body": "<p>Might take a look at the <a href=\"https://github.com/TestArmada/flank\" rel=\"nofollow noreferrer\">Flank open source project</a> which seemed to be built with pretty much the same goal in mind: <a href=\"https://medium.com/walmartlabs/flank-smart-test-runner-for-firebase-cf65e1b1eca7\" rel=\"nofollow noreferrer\">https://medium.com/walmartlabs/flank-smart-test-runner-for-firebase-cf65e1b1eca7</a></p>\n\n<blockquote>\n  <p>Flank is a Firebase Test Lab tool for massively-scaling your automated Android tests. Run large test suites across many devices/versions/configurations at the same time, in parallel. Flank can easily be used in a CI environment where Gradle (or similar) first builds the APK:s and then Flank is used to execute the tests.</p>\n</blockquote>\n",
                    "OwnerUserId": "2169923",
                    "LastEditorUserId": "2169923",
                    "LastEditDate": "2017-06-21T21:41:55.293",
                    "LastActivityDate": "2017-06-21T21:41:55.293",
                    "CommentCount": "3",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "44923813",
                "ParentRepo": "https://github.com/edgarroman/zappa-django-guide",
                "StackOverflow_Post": {
                    "Id": "44923813",
                    "PostTypeId": "2",
                    "ParentId": "44903487",
                    "CreationDate": "2017-07-05T10:34:41.543",
                    "Score": "1",
                    "Body": "<p>As per <a href=\"https://github.com/edgarroman/zappa-django-guide\" rel=\"nofollow noreferrer\">Zappa-django-guide</a>, I moved over to using django-storages (<a href=\"https://edgarroman.github.io/zappa-django-guide/walk_static/\" rel=\"nofollow noreferrer\">tutorial setting up with zappa</a>). </p>\n\n<p>Whilst I did manage to get WhiteNoise to work with Zappa, our app was very slow. The django-storages solution is zippy!</p>\n",
                    "OwnerUserId": "960471",
                    "LastActivityDate": "2017-07-05T10:34:41.543",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "45611187",
                "ParentRepo": "https://github.com/danpoland/drf-reverse-proxy",
                "StackOverflow_Post": {
                    "Id": "45611187",
                    "PostTypeId": "2",
                    "ParentId": "45610287",
                    "CreationDate": "2017-08-10T10:28:33.003",
                    "Score": "7",
                    "Body": "<ol>\n<li><p>You can solve the status code part by modifying your <code>Response</code>:</p>\n\n<pre><code>return Response(resp.json(), status=resp.status_code)\n</code></pre></li>\n<li><p>For the second part though, this is the essence of Proxying... (True, sometimes you want to manipulate the request and/or the response in the middleman of the proxy, but what you do is the essence).</p></li>\n</ol>\n\n<p><em>Notes:</em></p>\n\n<ul>\n<li>The <a href=\"https://github.com/eofs/django-rest-framework-proxy\" rel=\"noreferrer\">DRF Proxy</a> that you are suggesting seems to do the job just\nfine, without the need for you to write a specific view just for the\nroundtrip.</li>\n<li>There exist another tool, <a href=\"https://github.com/danpoland/drf-reverse-proxy\" rel=\"noreferrer\">DRF Reverse Proxy</a> which is a DRF port of <a href=\"https://github.com/TracyWebTech/django-revproxy\" rel=\"noreferrer\">Django Revproxy</a> and you may want to consider.</li>\n</ul>\n\n<p>The general idea of both of the above is that you create a URL path specifically to Proxy the path to another API:</p>\n\n<p><strong>DRF Proxy:</strong></p>\n\n<p>Add your proxy to <code>settings.py</code>:</p>\n\n<pre><code>REST_PROXY = {\n    'HOST': 'http://service-b.com/api/'\n}\n</code></pre>\n\n<p>In <code>urls.py</code>:</p>\n\n<pre><code>url(\n    r'^somewere_in_a/$', \n    ProxyView.as_view(source='somewere_in_b/'), \n    name='a_name'\n) \n</code></pre>\n\n<p><strong>DRF Reverse Proxy:</strong></p>\n\n<p>Pretty much similar with the above, without the settings part:</p>\n\n<pre><code>url(\n    r'^(?P&lt;path&gt;.*)$', \n    ProxyView.as_view(upstream='http://service-b.com/api/somewere_in_b/'),\n    name='a_name'\n)\n</code></pre>\n\n<p><em>Opinion:</em> the <a href=\"https://github.com/eofs/django-rest-framework-proxy\" rel=\"noreferrer\">DRF Proxy</a> seems more solid...</p>\n",
                    "OwnerUserId": "7414939",
                    "LastEditorUserId": "7414939",
                    "LastEditDate": "2017-08-10T11:57:56.560",
                    "LastActivityDate": "2017-08-10T11:57:56.560",
                    "CommentCount": "5",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "46169342",
                "ParentRepo": "https://github.com/confluentinc/ksql/",
                "StackOverflow_Post": {
                    "Id": "46169342",
                    "PostTypeId": "2",
                    "ParentId": "46151582",
                    "CreationDate": "2017-09-12T06:26:29.533",
                    "Score": "2",
                    "Body": "<p>Yes you can use Kafka Connect to apply changes from one database to another. You would typically use a CDC tool to take the events directly from the redo/transaction log on your source database, which pushes each event to a Kafka topic. An example would be Oracle GoldenGate, or the Debezium project.</p>\n\n<p>Once on a Kafka topic, you can then use Kafka Connect's JDBC Sink to push these changes to a target database. </p>\n\n<p>Where this may not meet your requirement is if you want to also mirror deletes directly in your target, since usually CDC records will have a column indicating the operation (e.g. \"D\" for delete) and you will get a row <em>inserted</em> on the target with this value. </p>\n\n<p>However, if you are looking to literally mirror a set of tables from one DB to another DB, you should be looking at a database replication tool, not Kafka. </p>\n\n<p>Where Kafka fits is if you want to stream events from one place to another (and want to store delete events, than delete them from the target), with the option of using that same data to land to other targets, or drive other direct applications. This could be Kafka Streams, a Kafka Consumer - or any of the other multitude of technologies and tools out there that integrate with Kafka. </p>\n\n<p>In terms of Kafka Streams this would be useful if you want to do some processing on the data you're pulling in from your source database - for example, joins/filtering/aggregation. As well as writing Java code directly with Kafka Streams, you now have the option of using a SQL-like interface on top of Kafka, with <a href=\"https://github.com/confluentinc/ksql/\" rel=\"nofollow noreferrer\">KSQL from Confluent</a>.</p>\n",
                    "OwnerUserId": "350613",
                    "LastActivityDate": "2017-09-12T06:26:29.533",
                    "CommentCount": "4",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "46242999",
                "ParentRepo": "https://github.com/tilezen/vector-datasource/blob/e87ac739b3e98f7c5363df3af06944bcec774c1c/queries.yaml#L231",
                "StackOverflow_Post": {
                    "Id": "46242999",
                    "PostTypeId": "2",
                    "ParentId": "46231640",
                    "CreationDate": "2017-09-15T15:28:35.387",
                    "Score": "0",
                    "Body": "<p>Try the <code>clip_factor</code> parameter. </p>\n\n<p>Here is Mapzen's configuration: <a href=\"https://github.com/tilezen/vector-datasource/blob/e87ac739b3e98f7c5363df3af06944bcec774c1c/queries.yaml#L231\" rel=\"nofollow noreferrer\">https://github.com/tilezen/vector-datasource/blob/e87ac739b3e98f7c5363df3af06944bcec774c1c/queries.yaml#L231</a></p>\n\n<p>A <code>clip_factor: 3.0</code> will clip buildings only when they span more than three tiles.</p>\n",
                    "OwnerUserId": "7318654",
                    "LastActivityDate": "2017-09-15T15:28:35.387",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "46384461",
                "ParentRepo": "https://github.com/apache/incubator-iceberg",
                "StackOverflow_Post": {
                    "Id": "46384461",
                    "PostTypeId": "2",
                    "ParentId": "46375631",
                    "CreationDate": "2017-09-23T21:30:03.530",
                    "Score": "9",
                    "Body": "<p>Update: \nIf you use AWS Elastic MapReduce, clusters with version >= 5.19 can now safely use speculative execution, <strong>but your Spark job can still fail part-way through and leave incomplete results</strong>. </p>\n\n<p>The partial data from your incomplete results are queryable if you are directly scanning AWS S3 which can lead to incorrect results for downstream jobs, so you need a strategy to deal with that!</p>\n\n<p>If your are running Spark 2.3.0 or greater I would recommend writing new partitions to a deterministic location using <code>SaveMode.Overwrite</code> and retrying on failure, this will avoid duplicate or corrupt data in your output.</p>\n\n<p>If you are using <code>SaveMode.Append</code> then retrying a Spark job will produce duplicate data in your output.</p>\n\n<p>The recommended approach:</p>\n\n<pre><code>df.write\n  .mode(SaveMode.Overwrite)\n  .partitionBy(\"date\")\n  .parquet(\"s3://myBucket/path/to/table.parquet\")\n</code></pre>\n\n<p>Then on successful writing of a partition, atomically register it to a metastore such as Hive, and query Hive as your source of truth, not S3 directly.</p>\n\n<p>Eg.</p>\n\n<pre><code>ALTER TABLE my_table ADD PARTITION (date='2019-01-01') location 's3://myBucket/path/to/table.parquet/date=2019-01-01'\n</code></pre>\n\n<p>If your Spark job fails and you are using <code>SaveMode.Overwrite</code> it is then it is always safe to retry because the data has not been made available to metastore queries, and you are only overwriting data in the failed partition.</p>\n\n<p>Note: In order to only override specific partitions rather than the entire dataset you need to configure:</p>\n\n<p><code>spark.conf.set(\"spark.sql.sources.partitionOverwriteMode\",\"dynamic\")</code></p>\n\n<p>which is only available from Spark 2.3.0.</p>\n\n<p><a href=\"https://aws.amazon.com/blogs/big-data/improve-apache-spark-write-performance-on-apache-parquet-formats-with-the-emrfs-s3-optimized-committer/\" rel=\"nofollow noreferrer\">https://aws.amazon.com/blogs/big-data/improve-apache-spark-write-performance-on-apache-parquet-formats-with-the-emrfs-s3-optimized-committer/</a>\n<a href=\"https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-spark-s3-optimized-committer.html\" rel=\"nofollow noreferrer\">https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-spark-s3-optimized-committer.html</a></p>\n\n<p>You might also want to consider the Iceberg project as an alternative to a Hive / Glue metastore as it matures.\n<a href=\"https://github.com/apache/incubator-iceberg\" rel=\"nofollow noreferrer\">https://github.com/apache/incubator-iceberg</a></p>\n\n<p><strong>A background on why this is necessary and for non-AWS users</strong></p>\n\n<p>Running with Spark speculation on when committing to an object store is usually a <em>VERY</em> bad idea, depending on what is looking at that data downstream and your consistency model.</p>\n\n<p>Ryan Blue from Netflix has an excellent (and pretty funny) talk which explains exactly why: <a href=\"https://www.youtube.com/watch?v=BgHrff5yAQo\" rel=\"nofollow noreferrer\">https://www.youtube.com/watch?v=BgHrff5yAQo</a></p>\n\n<p>Judging by the OP's description I suspect they are writing Parquet.</p>\n\n<p>The TL;dr version is that in S3, a rename operation is actually a copy and delete under the hood and this has consistency implications. Usually in Spark, output data is written to a temp file location and renamed when the calculation is complete. This means if speculative execution is on then multiple executors can be working on the same result and then the one that finishes first 'wins' by renaming temp file to a final result and the other task is cancelled. This rename operation happens on a single task to ensure that only one speculative task wins, which is not a problem on HDFS since a rename is a cheap metadata operation, a few thousand or million of them takes very little time.</p>\n\n<p>But when using S3, a rename is not an atomic operation, it is actually a copy which takes time. Therefore you can get into a situation whereby you have to copy a whole bunch of files in S3 a second time for the rename, in series, and this is a synchronous operation which is causing your slowdown. If your executor has multiple cores, you may actually have one task clobber the results of another, which should be ok in theory because one file ends up winning, but you're not in control of what is happening at that point.</p>\n\n<p>The issue with this is, what happens if the final rename task fails? You end up with some of your files committed to S3 and not all of them, which means partial/duplicate data and lots of problems downstream depending on your application.</p>\n\n<p>While I don't like it, the prevailing wisdom presently is to write locally to HDFS, then upload the data with a tool like S3Distcp.</p>\n\n<p>Have a look at HADOOP-13786.\nSteve Loughran is the go to guy for this issue.</p>\n\n<p>If you don't want to wait Ryan Blue has a repo \"rdblue/s3committer\" which allows you to fix this for all outputs except parquet files, but it looks like a bit of work to integrate and subclass correctly.</p>\n\n<p>Update:\n<code>HADOOP-13786</code> has now been fixed and released into Hadoop 3.1 libraries.\nAt present Steven Loughran is working on getting a fix based on Hadoop 3.1 libs merged into apache/spark, (<code>SPARK-23977</code>) however latest according to the ticket comment thread is that the fix will not be merged before Spark 2.4 is released so we may be waiting a bit longer for this to become mainstream.</p>\n\n<p>Update v2:\nNote: You can halve the window of time in which the final output partition rename task may fail by setting <code>mapreduce.fileoutputcommitter.algorithm.version</code> to <code>2</code> in your Hadoop config, since the original output commit mechanism actually performed <strong>two</strong> renames.</p>\n",
                    "OwnerUserId": "5813962",
                    "LastEditorUserId": "5813962",
                    "LastEditDate": "2019-03-17T02:08:38.110",
                    "LastActivityDate": "2019-03-17T02:08:38.110",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "46551104",
                "ParentRepo": "https://github.com/hyperledger/cello",
                "StackOverflow_Post": {
                    "Id": "46551104",
                    "PostTypeId": "2",
                    "ParentId": "46547117",
                    "CreationDate": "2017-10-03T18:27:32.043",
                    "Score": "6",
                    "Body": "<ol>\n<li><p>I think that for a production deployment, you'd likely want to implement Swarm or Kubernetes. See <a href=\"https://github.com/hyperledger/cello\" rel=\"noreferrer\">Hyperledger Cello</a> for instance. You will also want to have a process and automation for managing the code going forward. Updating images, chaincode, etc. Further, you might want to further automate some of the on-boarding process which at present is rather bare bones. </p></li>\n<li><p>As noted above, the Docker Compose is designed for a single system. You'd likely want to use Swarm or Kubernetes to manage nodes on different systems and you want decentralized operations when you are engaging multiple entities into a consortia where the members want to choose where they run their nodes.</p></li>\n<li><p>There is a developer sandbox offering that you can deploy to IBM's Container service (Kubernetes) but you won't be getting the benefits of the crypto acceleration, HSM, and added security of the LinuxOne platform on which IBM deploys the IBM Blockchain Platform. The good things in life may be free, but I would want to have the added value of a vendor provided cloud offering like IBM Blockchain Platform for my production system. YMMV.</p></li>\n</ol>\n",
                    "OwnerUserId": "4774061",
                    "LastActivityDate": "2017-10-03T18:27:32.043",
                    "CommentCount": "4",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "46991855",
                "ParentRepo": "https://github.com/agileobjects/AgileMapper",
                "StackOverflow_Post": {
                    "Id": "46991855",
                    "PostTypeId": "2",
                    "ParentId": "7052002",
                    "CreationDate": "2017-10-28T16:18:03.833",
                    "Score": "5",
                    "Body": "<p>This is an old question, but there's now also <a href=\"https://github.com/agileobjects/AgileMapper\" rel=\"noreferrer\">https://github.com/agileobjects/AgileMapper</a></p>\n",
                    "OwnerUserId": "89584",
                    "LastActivityDate": "2017-10-28T16:18:03.833",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "47005085",
                "ParentRepo": "https://github.com/sdispater/pendulum/issues/156",
                "StackOverflow_Post": {
                    "Id": "47005085",
                    "PostTypeId": "2",
                    "ParentId": "47004673",
                    "CreationDate": "2017-10-29T20:47:15.760",
                    "Score": "0",
                    "Body": "<p>Not quite as neat as I was looking for, but this is pretty expressive and definitely feels less hacky:</p>\n\n<pre><code>from datetime import datetime as dt\nimport pendulum\n\npointDT = pendulum.parse(pointTimeString)\nstartTime = dt.strptime(startTimeString, \"%H:%M\").time()\nstartDT = pendulum.instance(dt.combine(pointDT.date(), startTime), tz=\"Europe/London\")\n\nif pointDT &gt; startDT:\n    # Do stuff\n</code></pre>\n\n<p>Inspired by the answer to <a href=\"https://github.com/sdispater/pendulum/issues/156\" rel=\"nofollow noreferrer\">an issue</a> on the project's Github site.</p>\n",
                    "OwnerUserId": "1749551",
                    "LastActivityDate": "2017-10-29T20:47:15.760",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "47018200",
                "ParentRepo": "https://github.com/py-pa/django-minio-storage",
                "StackOverflow_Post": {
                    "Id": "47018200",
                    "PostTypeId": "1",
                    "CreationDate": "2017-10-30T14:50:14.803",
                    "Score": "0",
                    "ViewCount": "420",
                    "Body": "<p><strong>Context:</strong></p>\n\n<p>I am trying to build a Django app that uses this package:<a href=\"https://github.com/py-pa/django-minio-storage\" rel=\"nofollow noreferrer\">django-minio-storage</a>.\nI am trying to extend a certain class in the package with the following class:</p>\n\n<pre><code>@deconstructible\nclass MinioStoreStorage(MinioStorage):\n    def __init__(self, bucket_name):\n        client = create_minio_client_from_settings()\n        base_url = bucket_name\n        # base_url = get_setting(\"MINIO_STORAGE_STATIC_URL\", None)\n        bucket_name = bucket_name\n        auto_create_bucket = True\n        presign_urls = True\n\n        super(MinioStoreStorage, self).__init__(\n            client,\n            bucket_name,\n            auto_create_bucket=auto_create_bucket,\n            base_url=base_url,\n            presign_urls=presign_urls\n        )\n</code></pre>\n\n<p><strong>Problem:</strong></p>\n\n<p>I can not import the function <code>create_minio_client_from_settings</code>.\nThis function resides in the file <code>storage.py</code> of the package. The same file where resides the class <code>MinioStorage</code>.\nI can also import successfully another function (<code>get_setting</code>) that is in the same file and use it with no problem, but trying to do the same for <code>create_minio_client_from_settings</code> raises an <code>ImportError</code>.\nHere are the import I am using:</p>\n\n<pre><code>from minio_storage.storage import get_setting\n# Succeeds\nfrom minio_storage.storage import create_minio_client_from_settings\nTraceback (most recent call last):\n  File \"&lt;console&gt;\", line 1, in &lt;module&gt;\nImportError: cannot import name 'create_minio_client_from_settings'\n</code></pre>\n\n<p><strong>storage.py</strong></p>\n\n<p>Here is a snippet of the code of the package:</p>\n\n<pre><code>@deconstructible\nclass MinioStorage(Storage):\n    \"\"\"An implementation of Django's file storage using the minio client.\n\n    The implementation should comply with\n    https://docs.djangoproject.com/en/dev/ref/files/storage/.\n\n    \"\"\"\n    ...\n    ...\n    ...\n\ndef get_setting(name, default=_NoValue, ):\n    result = getattr(settings, name, default)\n    if result is _NoValue:\n        print(\"Attr {} : {}\".format(name, getattr(settings, name,                     default)))\n        raise ImproperlyConfigured\n    else:\n        return result\n\n\ndef create_minio_client_from_settings():\n    endpoint = get_setting(\"MINIO_STORAGE_ENDPOINT\")\n    access_key = get_setting(\"MINIO_STORAGE_ACCESS_KEY\")\n    secret_key = get_setting(\"MINIO_STORAGE_SECRET_KEY\")\n    secure = get_setting(\"MINIO_STORAGE_USE_HTTPS\", True)\n    client = minio.Minio(endpoint,\n                         access_key=access_key,\n                         secret_key=secret_key,\n                         secure=secure)\n    return client\n</code></pre>\n\n<p><strong>Questions:</strong></p>\n\n<ul>\n<li>How can I import the create_minio_client_from_settings function?</li>\n<li>Is there a workaround to solve this problem? (I know I can simply copy it as a helper function straight into my project)</li>\n<li>What can be the reasons to not being able ti import a function from a package, while I can do the same for a function that is in the same file?</li>\n</ul>\n\n<p><strong>Further investigation:</strong></p>\n\n<p>I have been looking into this problem more, and here is some remarks and a more reproducible way of seeing the anomaly.\nAfter creating a Django project and installing the package in question, I fired up the shell using : <code>python manage.py shell</code> and used the following commands:</p>\n\n<pre><code>&gt;&gt;&gt; import minio_storage\n&gt;&gt;&gt; dir(minio_storage)\n['__builtins__', '__cached__', '__doc__', '__file__', '__loader__',         '__name__', '__package__', '__path__', '__spec__', '__version__',     'storage']\n&gt;&gt;&gt; help(minio_storage.storage)\n</code></pre>\n\n<p>The <code>help(minio_storage.storage)</code> will show a manual page that describes the Classes and Functions provided by the package. Under functions category, only one function is available and it's the <code>get_setting()</code> function.</p>\n\n<ul>\n<li>Why the <code>create_minio_client_from_settings()</code> does not show up the same way <code>get_setting()</code> does?</li>\n<li>Is it possible for a package developer to hide some of his functions?</li>\n</ul>\n\n<p><strong>Versions and dependencies</strong></p>\n\n<p>Here is the result of the command: <code>pipenv graph</code></p>\n\n<pre><code>django-minio-storage==0.1.0\n  - django [required: &gt;=1.9, installed: 1.11.6]\n    - pytz [required: Any, installed: 2017.2]\n  - minio [required: &gt;=1.0.2, installed: 2.2.5]\n    - certifi [required: Any, installed: 2017.7.27.1]\n    - pytz [required: Any, installed: 2017.2]\n    - urllib3 [required: Any, installed: 1.22]\ndjangorestframework==3.7.1\nflake8==3.5.0\n  - mccabe [required: &gt;=0.6.0,&lt;0.7.0, installed: 0.6.1]\n  - pycodestyle [required: &gt;=2.0.0,&lt;2.4.0, installed: 2.3.1]\n  - pyflakes [required: &gt;=1.5.0,&lt;1.7.0, installed: 1.6.0]\nPillow==4.3.0\n  - olefile [required: Any, installed: 0.44]\n</code></pre>\n",
                    "OwnerUserId": "4017403",
                    "LastEditorUserId": "4017403",
                    "LastEditDate": "2017-10-31T13:10:10.313",
                    "LastActivityDate": "2017-10-31T18:04:24.850",
                    "Title": "ImportError raised trying to import a function",
                    "Tags": "<django><django-rest-framework><python-import><minio>",
                    "AnswerCount": "2",
                    "CommentCount": "6",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "47138881",
                "ParentRepo": "https://github.com/ibis-project/ibis/blob/master/README.md",
                "StackOverflow_Post": {
                    "Id": "47138881",
                    "PostTypeId": "5",
                    "CreationDate": "2017-11-06T14:12:33.463",
                    "Score": "0",
                    "Body": "<p>From <a href=\"https://ibis-project.org/docs/3.2.0/tutorial/01-Introduction-to-Ibis\" rel=\"nofollow noreferrer\">https://ibis-project.org/docs/3.2.0/tutorial/01-Introduction-to-Ibis</a>:</p>\n<blockquote>\n<h1>Introduction to Ibis</h1>\n<p>Ibis is a Python framework to access data and perform analytical\ncomputations from different sources, in a standard way.</p>\n<p>In a way, you can think of Ibis as writing SQL in Python, with a focus\non analytics, more than simply accessing data. And aside from SQL\ndatabases, you can use it with other backends, including big data\nsystems.</p>\n<p>Why not simply use SQL instead? SQL is great and widely used. However,\nSQL has different flavors for different database engines, and SQL is\nvery difficult to maintain when your queries are very complex. Ibis\nsolves both problems by standardizing your code across backends and\nmaking it maintainable. Since Ibis is Python, you can structure your\ncode in different files, functions, name variables, write tests, etc.</p>\n</blockquote>\n<p>Based on the <a href=\"https://github.com/ibis-project/ibis/blob/master/README.md\" rel=\"nofollow noreferrer\">ibis/README.md</a> it currently supports the following:</p>\n<blockquote>\n<ul>\n<li>Apache Impala</li>\n<li>Google BigQuery</li>\n<li>ClickHouse</li>\n<li>HeavyAI</li>\n<li>Dask</li>\n<li>DuckDb</li>\n<li>MySQL</li>\n<li>Pandas</li>\n<li>PostgreSQL</li>\n<li>PySpark</li>\n<li>Sqlite</li>\n</ul>\n</blockquote>\n<h2>References</h2>\n<ul>\n<li><a href=\"http://www.ibis-project.org\" rel=\"nofollow noreferrer\">Project Home</a>\n<ul>\n<li><a href=\"https://ibis-project.org/docs/3.2.0/tutorial/01-Introduction-to-Ibis/#getting-started\" rel=\"nofollow noreferrer\">Tutorial</a></li>\n</ul>\n</li>\n<li><a href=\"https://github.com/ibis-project/ibis\" rel=\"nofollow noreferrer\">GitHub</a></li>\n</ul>\n",
                    "OwnerUserId": "7852833",
                    "LastEditorUserId": "202694",
                    "LastEditDate": "2022-09-23T16:29:44.257",
                    "LastActivityDate": "2022-09-23T16:29:44.257",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "47166910",
                "ParentRepo": "https://github.com/crystal-lang/crystal-book/pull/138",
                "StackOverflow_Post": {
                    "Id": "47166910",
                    "PostTypeId": "2",
                    "ParentId": "46858823",
                    "CreationDate": "2017-11-07T20:31:01.630",
                    "Score": "3",
                    "Body": "<p>The documentation has been published: <a href=\"https://crystal-lang.org/docs/syntax_and_semantics/constants.html\" rel=\"nofollow noreferrer\">https://crystal-lang.org/docs/syntax_and_semantics/constants.html</a></p>\n\n<p>Original issue: <a href=\"https://github.com/crystal-lang/crystal-book/pull/138\" rel=\"nofollow noreferrer\">https://github.com/crystal-lang/crystal-book/pull/138</a></p>\n",
                    "OwnerUserId": "841803",
                    "LastEditorUserId": "841803",
                    "LastEditDate": "2017-11-30T06:43:57.383",
                    "LastActivityDate": "2017-11-30T06:43:57.383",
                    "CommentCount": "1",
                    "CommunityOwnedDate": "2017-11-07T20:31:01.630",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "47229750",
                "ParentRepo": "https://github.com/percona/percona-xtrabackup",
                "StackOverflow_Post": {
                    "Id": "47229750",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "47232136",
                    "CreationDate": "2017-11-10T19:18:25.810",
                    "Score": "3",
                    "ViewCount": "307",
                    "Body": "<p>While trying to compile <a href=\"https://www.percona.com/doc/percona-xtrabackup/LATEST/installation.html\" rel=\"nofollow noreferrer\"><code>xtrabackup</code></a> from <a href=\"https://github.com/percona/percona-xtrabackup\" rel=\"nofollow noreferrer\">source</a> I've found a peculiar line of code in <code>sql/sql_acl.cc</code> that GCC is refusing to compile without a more permissive setting. This line is the problem:</p>\n\n<pre><code>if (combo-&gt;plugin.str == NULL || combo-&gt;plugin.str == '\\0')\n</code></pre>\n\n<p>Which immediately raises the following error:</p>\n\n<blockquote>\n  <p>error: ISO C++ forbids comparison between pointer and integer</p>\n</blockquote>\n\n<p>This seems entirely reasonable given the code in question. The <code>plugin</code> value is of this type:</p>\n\n<pre><code>struct st_mysql_lex_string\n{\n  char *str;\n  size_t length;\n};\n</code></pre>\n\n<p>Where that's a simple MySQL internal structure that represents a string pointer + length pair, so in this case <code>str</code> is merely <code>char*</code>, nothing special.</p>\n\n<p>I know that cross-platform development and dealing with baroque compiler environments can require a certain level of paranoia, but what, if any, justification is there for this double NULL check? I can't think of how the second clause would ever be true if the first wasn't, but I might be missing some unusual edge case.</p>\n",
                    "OwnerUserId": "87189",
                    "LastEditorUserId": "87189",
                    "LastEditDate": "2017-11-10T19:24:40.933",
                    "LastActivityDate": "2017-11-10T22:39:05.907",
                    "Title": "Purpose behind comparing string pointer to NULL as well as NULL character",
                    "Tags": "<c++><gcc><cross-platform>",
                    "AnswerCount": "1",
                    "CommentCount": "9",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "47352386",
                "ParentRepo": "https://github.com/dhlab-basel/Knora/blob/develop/salsah/src/public/js/datehelpers.js",
                "StackOverflow_Post": {
                    "Id": "47352386",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "47400894",
                    "CreationDate": "2017-11-17T14:01:53.100",
                    "Score": "0",
                    "ViewCount": "793",
                    "Body": "<p>I am getting familiar with Angular Material's Datepicker (<a href=\"https://material.angular.io/components/datepicker/overview\" rel=\"nofollow noreferrer\">https://material.angular.io/components/datepicker/overview</a>).</p>\n\n<p>For my use case, I need the following features:</p>\n\n<ul>\n<li>support of dates Before Christ (BC) / Before Common Era (BCE) </li>\n<li>support of other calendar formats besides Gregorian (e.g., Julian calendar), including automatic conversion of the selected date when changing the calendar</li>\n<li>support of precision: day, month, year</li>\n</ul>\n\n<p>In our old GUI, we provided our own implementation of a date picker, applying calculations based on Julian Day Numbers (<a href=\"https://github.com/dhlab-basel/Knora/blob/develop/salsah/src/public/js/datehelpers.js\" rel=\"nofollow noreferrer\">https://github.com/dhlab-basel/Knora/blob/develop/salsah/src/public/js/datehelpers.js</a>, <a href=\"https://github.com/dhlab-basel/Knora/blob/develop/salsah/src/public/js/jquery.dateobj.js\" rel=\"nofollow noreferrer\">https://github.com/dhlab-basel/Knora/blob/develop/salsah/src/public/js/jquery.dateobj.js</a>). However, the code was based on jQuery and is going to be replaced by the new Angular based GUI. I also admit that it is hard to understand.</p>\n\n<p>I would be glad for any advice of how to support historical dates with Angular Material!</p>\n",
                    "OwnerUserId": "3891631",
                    "LastEditorUserId": "3891631",
                    "LastEditDate": "2017-11-20T20:09:08.040",
                    "LastActivityDate": "2018-04-05T21:36:50.007",
                    "Title": "Angular Material Datepicker: Support of BCE Dates and Calendars",
                    "Tags": "<angular><datepicker><calendar><angular-material>",
                    "AnswerCount": "2",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "47364294",
                "ParentRepo": "https://github.com/seleniumbase/SeleniumBase",
                "StackOverflow_Post": {
                    "Id": "47364294",
                    "PostTypeId": "2",
                    "ParentId": "46909893",
                    "CreationDate": "2017-11-18T09:01:49.837",
                    "Score": "0",
                    "Body": "<p>u can use this python package \nlink= <a href=\"https://github.com/seleniumbase/SeleniumBase\" rel=\"nofollow noreferrer\">https://github.com/seleniumbase/SeleniumBase</a></p>\n\n<p>This package is very powerful in automation testing.\nit will auto screenshot when your pytest result is fail.</p>\n",
                    "OwnerUserId": "7978802",
                    "LastActivityDate": "2017-11-18T09:01:49.837",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "47465705",
                "ParentRepo": "https://github.com/MrPowers/quinn",
                "StackOverflow_Post": {
                    "Id": "47465705",
                    "PostTypeId": "2",
                    "ParentId": "35540974",
                    "CreationDate": "2017-11-24T02:53:42.463",
                    "Score": "4",
                    "Body": "<p>Here's a function that removes all whitespace in a string:</p>\n\n<pre><code>import pyspark.sql.functions as F\n\ndef remove_all_whitespace(col):\n    return F.regexp_replace(col, \"\\\\s+\", \"\")\n</code></pre>\n\n<p>You can use the function like this:</p>\n\n<pre><code>actual_df = source_df.withColumn(\n    \"words_without_whitespace\",\n    quinn.remove_all_whitespace(col(\"words\"))\n)\n</code></pre>\n\n<p>The <code>remove_all_whitespace</code> function is defined in the <a href=\"https://github.com/MrPowers/quinn\" rel=\"nofollow noreferrer\">quinn library</a>.  quinn also defines <code>single_space</code> and <code>anti_trim</code> methods to manage whitespace.  PySpark defines <code>ltrim</code>, <code>rtrim</code>, and <code>trim</code> methods to manage whitespace.</p>\n",
                    "OwnerUserId": "1125159",
                    "LastActivityDate": "2017-11-24T02:53:42.463",
                    "CommentCount": "4",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "47501051",
                "ParentRepo": "https://github.com/lock8/django-rest-framework-jwt-refresh-token",
                "StackOverflow_Post": {
                    "Id": "47501051",
                    "PostTypeId": "2",
                    "ParentId": "42547579",
                    "CreationDate": "2017-11-26T21:09:55.780",
                    "Score": "13",
                    "Body": "<h1>Refreshing tokens in django-rest-framework-jwt</h1>\n<p>The <a href=\"https://github.com/GetBlimp/django-rest-framework-jwt\" rel=\"noreferrer\">django-rest-framework-jwt</a> (v. 1.11.0) does not support &quot;Refresh Tokens&quot; as described for example <a href=\"https://auth0.com/docs/tokens/refresh-token/current\" rel=\"noreferrer\">here</a>. It only supports refreshing <em>non-expired tokens</em>; It makes easy to implement a sliding expiration window with width of <code>JWT_EXPIRATION_DELTA</code>. For example, with settings</p>\n<pre><code>'JWT_EXPIRATION_DELTA': datetime.timedelta(seconds=300),\n'JWT_REFRESH_EXPIRATION_DELTA': datetime.timedelta(days=7),\n</code></pre>\n<p>user cannot be inactive for more than five minutes in order to stay logged in (<a href=\"https://getblimp.github.io/django-rest-framework-jwt/#security\" rel=\"noreferrer\">docs</a>).</p>\n<h1>Real Refresh Tokens, please?</h1>\n<p>It is possible to implement the &quot;Refresh Tokens&quot;, which are very long lived (&quot;never expiring&quot;) tokens, stored in a database, just like in conventional &quot;HTTP Sessions &amp; SessionIDs&quot;. This is actually already been implemented for the django-rest-framework-jwt in <a href=\"https://github.com/lock8/django-rest-framework-jwt-refresh-token\" rel=\"noreferrer\">django-rest-framework-jwt-refresh-token</a>. Another possibility is to use <a href=\"https://github.com/davesque/django-rest-framework-simplejwt\" rel=\"noreferrer\">django-rest-framework-simplejwt</a> which also implements the JWT with Access and Refresh Tokens (full example at <a href=\"https://medium.com/netscape/full-stack-django-quick-start-with-jwt-auth-and-react-redux-part-i-37853685ab57\" rel=\"noreferrer\">Medium</a>).</p>\n<h3>But.. why?</h3>\n<p>Compared to using only Access Token JWT's, using Refresh Tokens makes possible to revoke access after the Access Token is expired. Refesh Tokens make it possible to have very long (&quot;lifetime of a mobile device&quot;) lasting tokens. One may ask why shouldn't you just stick with sessions (sessionid in a Cookie, and session data in database table), if you are creating collection of Refresh Tokens in a database, and accessing that. Using an Access token with expiration time of one hour will mean that database must be accessed once per hour (instead once per PUT/POST request when using &quot;traditional&quot; sessions). In addition, you gain all the usual benefits of JWT tokens (ease of use in microservice network, for example).</p>\n",
                    "OwnerUserId": "3015186",
                    "LastEditorUserId": "-1",
                    "LastEditDate": "2020-06-20T09:12:55.060",
                    "LastActivityDate": "2017-11-28T19:49:05.190",
                    "CommentCount": "4",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "47601687",
                "ParentRepo": "https://github.com/epigen/pypiper",
                "StackOverflow_Post": {
                    "Id": "47601687",
                    "PostTypeId": "2",
                    "ParentId": "47600126",
                    "CreationDate": "2017-12-01T21:23:59.283",
                    "Score": "0",
                    "Body": "<p>PyCharm looks for packages in the repositories that it has been told to look in. By default it looks at <code>https://pypi.python.org/simple</code>. </p>\n\n<p>Effectively this means that if you cannot install something through pip, you cannot install through the PyCharm interface.</p>\n\n<p>What you need to do is to figure out:</p>\n\n<ol>\n<li><a href=\"https://stackoverflow.com/questions/14261614/how-do-i-install-the-yaml-package-for-python\">How to install yaml</a> </li>\n</ol>\n\n<p><code>sudo pip install pyyaml</code></p>\n\n<ol start=\"2\">\n<li><a href=\"https://github.com/epigen/pypiper\" rel=\"nofollow noreferrer\">How to install pypiper</a> </li>\n</ol>\n\n<p><code>pip install --user https://github.com/epigen/pypiper/zipball/master</code></p>\n\n<p>When I run into these issues it's easiest for me to just install on the command line opposed to through <code>PyCharm</code> unless it's a virtual env. Just make sure your <code>pip</code> is referencing the same python interpreter you are using in <code>PyCharm</code> or you still wont see it in PyCharm.</p>\n",
                    "OwnerUserId": "3821425",
                    "LastActivityDate": "2017-12-01T21:23:59.283",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "47642415",
                "ParentRepo": "https://github.com/ElementsProject/libwally-core",
                "StackOverflow_Post": {
                    "Id": "47642415",
                    "PostTypeId": "1",
                    "CreationDate": "2017-12-04T21:39:12.473",
                    "Score": "2",
                    "ViewCount": "1146",
                    "Body": "<p>Trying to build libwally-core C library for Android on Windows in Cygwin with supplied autotools scripts:</p>\n\n<p><a href=\"https://github.com/ElementsProject/libwally-core\" rel=\"nofollow noreferrer\">libwally-core</a></p>\n\n<p>After running </p>\n\n<pre><code>bash tools/build_android_libraries.sh\n</code></pre>\n\n<p>or</p>\n\n<pre><code>bash tools/autogen.sh\n</code></pre>\n\n<p>I get the following error:</p>\n\n<pre><code>libtoolize: putting auxiliary files in AC_CONFIG_AUX_DIR, 'build-aux'.\nlibtoolize: copying file 'build-aux/ltmain.sh'\nlibtoolize:   error: AC_CONFIG_MACRO_DIRS([build-aux/m4]) conflicts with \nACLOCAL.AMFLAGS=-I build-aux/m4\nautoreconf-2.69: libtoolize failed with exit status: 1\n</code></pre>\n\n<p>I tried the following things to no avail:</p>\n\n<ul>\n<li>Re-saved all scripts with Unix line-endings (LF only)</li>\n<li>Commenting out \"ACLOCAL_AMFLAGS = -I tools/build-aux/m4\" in Makefile.am</li>\n</ul>\n\n<p>The error happens at the following place in libtool's source in libtoolize.in:</p>\n\n<pre><code>macrodir=\"$ac_macrodir\"\ntest -z \"$macrodir\" &amp;&amp; macrodir=\"$am_macrodir\"\n\nif test -n \"$am_macrodir\" &amp;&amp; test -n \"$ac_macrodir\"; then\n  test \"$am_macrodir\" = \"$ac_macrodir\" \\\n    || func_fatal_error \"AC_CONFIG_MACRO_DIR([$ac_macrodir]) conflicts with ACLOCAL_AMFLAGS=-I $am_macrodir.\"\nfi\n</code></pre>\n\n<p>I assume that the above makes sure that AC_CONFIG_MACRO_DIR and value after \"-I\" in ACLOCAL_AMFLAGS are identical (checked for identical line endings with hex editor too). The values are identical in both configure.ac and Makefile.am. However, even if I comment out setting ACLOCAL_AMFLAGS in Makefile.am, the error persits.</p>\n\n<p>I would like to compile the library and generate libwallycore.so. Any insight would be much appreciated.</p>\n",
                    "OwnerUserId": "2272503",
                    "LastActivityDate": "2018-06-27T11:48:35.807",
                    "Title": "Building with autotools: AC_CONFIG_MACRO_DIRS conflicts with ACLOCAL.AMFLAGS",
                    "Tags": "<android><c><autoconf><automake><libtool>",
                    "AnswerCount": "0",
                    "CommentCount": "0",
                    "FavoriteCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "47768028",
                "ParentRepo": "https://github.com/fiware/dataModels",
                "StackOverflow_Post": {
                    "Id": "47768028",
                    "PostTypeId": "1",
                    "CreationDate": "2017-12-12T08:17:51.500",
                    "Score": "1",
                    "ViewCount": "123",
                    "Body": "<p>I am trying to import all current FIWARE DATA MODELS on my Orion Context Broker (POST data to an Orion Context Broker instance using NGSIv2 API) as my base data models but when using exact json format provided in <strong>repository of data models</strong> - <a href=\"https://github.com/fiware/dataModels\" rel=\"nofollow noreferrer\">https://github.com/fiware/dataModels</a> - as below, getting this error in my Restlet Client:</p>\n\n<p>{\n\"error\": \"BadRequest\",\n\"description\": \"attribute must be a JSON object, unless keyValues option is used\"\n}</p>\n\n<p>This Payload is for PointOfInterest but same I'm getting same error for other FIWARE DATA MODELS as well: </p>\n\n<pre><code>POST http://localhost/v2/entities\nContent-Type: application/json\n\n{\n        \"id\": \"PointOfInterest-A-Concha-123456\",\n        \"type\": \"PointOfInterest\",\n        \"name\": \"Playa de a Concha\",\n        \"description\": \"La Playa de A Concha se presenta como una continuaci\u00f3n de la Playa de Compostela, una de las m\u00e1s frecuentadas de Vilagarc\u00eda.\",\n        \"address\": {\n          \"addressCountry\": \"ES\",\n          \"addressLocality\": \"Vilagarc\u00eda de Arousa\"\n        },\n        \"category\": [\"113\"],\n        \"location\": {\n          \"type\": \"Point\",\n          \"coordinates\": [\n            -8.768460000000001,\n            42.60214472222222\n          ]\n        },\n        \"source\": \"http://www.tourspain.es\",\n        \"refSeeAlso\": [\"Beach-A-Concha-123456\"]\n  }\n</code></pre>\n\n<p>Simply as FIWARE data models have been harmonized to enable data portability for different applications, I want to clone all current models to my orion context broker with my own data but can't use example json schema provide in repository.</p>\n\n<p>I'm able to create simpler entities on Orion but not FIWARE DATA MODELS. Does anyone know what is wrong I'm doing?</p>\n",
                    "OwnerUserId": "9054421",
                    "LastActivityDate": "2017-12-20T00:11:26.900",
                    "Title": "Clone FIWARE DATA MODELS on my Orion Context Broker",
                    "Tags": "<fiware><fiware-orion>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "48015960",
                "ParentRepo": "https://github.com/ezored/ezored/blob/issue_1/tests/models/test_target.py#L76",
                "StackOverflow_Post": {
                    "Id": "48015960",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "48016029",
                    "CreationDate": "2017-12-29T00:14:12.220",
                    "Score": "-1",
                    "ViewCount": "49",
                    "Body": "<p>can anyone help me with s strange problem?  </p>\n\n<p><a href=\"https://travis-ci.org/ezored/ezored/jobs/322719711\" rel=\"nofollow noreferrer\">https://travis-ci.org/ezored/ezored/jobs/322719711</a></p>\n\n<p>On test log, i print:</p>\n\n<blockquote>\n  <p>Current data:<br>\n  ['flag']<br>\n  ['flag']  </p>\n</blockquote>\n\n<p>That is the lines:</p>\n\n<pre><code>new_target_data.c_flags.extend(['flag'])\n\nprint('Current data:')\nprint(target_data.c_flags)\nprint(new_target_data.c_flags)\n</code></pre>\n\n<p>The problem is when i extend <strong>\"new_target_data.c_flags\"</strong>. The same data is applied to <strong>\"target_data.c_flags\"</strong>. They are different objects, you can see on log the memory reference:</p>\n\n<pre><code>&lt;ezored.models.target_data.TargetData object at 0x2b59c0673590&gt;\n&lt;ezored.models.target_data.TargetData object at 0x2b59c0673510&gt;\n</code></pre>\n\n<p>The file with test code is here (method <strong>test_merge_target_data</strong>):</p>\n\n<p><a href=\"https://github.com/ezored/ezored/blob/issue_1/tests/models/test_target.py#L76\" rel=\"nofollow noreferrer\">https://github.com/ezored/ezored/blob/issue_1/tests/models/test_target.py#L76</a></p>\n\n<p>Anyone understand this problem? What im doing wrong?</p>\n",
                    "OwnerUserId": "1001566",
                    "LastActivityDate": "2017-12-29T00:27:36.273",
                    "Title": "Duplicated data in two different objects in python",
                    "Tags": "<python><memory><duplicates>",
                    "AnswerCount": "1",
                    "CommentCount": "4",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "48405439",
                "ParentRepo": "https://github.com/dbkaplan/dry-rest-permissions/commit/98088dc61453b8603c6d567fa8702c99998fcd78",
                "StackOverflow_Post": {
                    "Id": "48405439",
                    "PostTypeId": "2",
                    "ParentId": "48397998",
                    "CreationDate": "2018-01-23T15:33:59.873",
                    "Score": "1",
                    "Body": "<p>I guess you're using incompatible version of dry-rest-permission with your current django framework. In <code>@authenticated_users</code> decorator <code>request.user.is_authenticated()</code> is called but in newer version of django <code>is_authenticated</code> has changed to a <code>bool</code> attribute from a function returning <code>bool</code>.</p>\n\n<p>You could refer to their last <a href=\"https://github.com/dbkaplan/dry-rest-permissions/commit/98088dc61453b8603c6d567fa8702c99998fcd78\" rel=\"nofollow noreferrer\">commits</a> that correct usage of <code>is_authenticated</code>.</p>\n\n<p>As it seems they doesn't release that commit yet you have to apply referred path manually to get rid of the error.</p>\n",
                    "OwnerUserId": "3383936",
                    "LastActivityDate": "2018-01-23T15:33:59.873",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "48461199",
                "ParentRepo": "https://github.com/msys2/msys2.github.io",
                "StackOverflow_Post": {
                    "Id": "48461199",
                    "PostTypeId": "2",
                    "ParentId": "3144082",
                    "CreationDate": "2018-01-26T12:15:25.497",
                    "Score": "0",
                    "Body": "<p>This is an answer from 2018...</p>\n<p><a href=\"http://gitforwindows.org/\" rel=\"nofollow noreferrer\">Git for Windows</a> is based on <a href=\"https://github.com/msys2/msys2.github.io\" rel=\"nofollow noreferrer\">MSYS2</a>.</p>\n<blockquote>\n<p>MSYS2 was started with the idea to restart the MSys project, frequently updating with Cygwin and just keeping the spirit of MSys to provide a very stripped-down POSIX layer, essentially a bare-minimum version of Cygwin. MSYS2 also sports a package manager (pacman) and keeps those packages up-to-date very well.</p>\n</blockquote>\n<p>..</p>\n<blockquote>\n<p>MSYS2's runtime is a stripped-down, slightly modified Cygwin runtime running on top of the Windows kernel, while Linux' runtime is the Linux kernel, running as a separate OS altogether.</p>\n</blockquote>\n<p><a href=\"https://github.com/git-for-windows/git/wiki\" rel=\"nofollow noreferrer\">https://github.com/git-for-windows/git/wiki</a></p>\n<blockquote>\n<p>Cygwin provides a runtime library called cygwin1.dll that provides the POSIX compatibility layer where necessary. The MSYS2 variant of this library is called msys-2.0.dll and includes the following changes to support using native Windows programs: <a href=\"https://github.com/msys2/msys2/wiki/How-does-MSYS2-differ-from-Cygwin\" rel=\"nofollow noreferrer\">How does MSYS2 differ from Cygwin</a></p>\n</blockquote>\n<p><a href=\"https://i.stack.imgur.com/ezHfq.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/ezHfq.png\" alt=\"Dependency Walker Git Bash\" /></a></p>\n",
                    "OwnerUserId": "503025",
                    "LastEditorUserId": "-1",
                    "LastEditDate": "2020-06-20T09:12:55.060",
                    "LastActivityDate": "2018-01-26T12:15:25.497",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "48712536",
                "ParentRepo": "https://github.com/nco/pynco",
                "StackOverflow_Post": {
                    "Id": "48712536",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "48776099",
                    "CreationDate": "2018-02-09T19:07:36.287",
                    "Score": "0",
                    "ViewCount": "557",
                    "Body": "<p>I'm using <a href=\"https://github.com/nco/pynco\" rel=\"nofollow noreferrer\">pynco</a> to run a <a href=\"https://linux.die.net/man/1/ncks\" rel=\"nofollow noreferrer\">ncks</a> command from within a Python script. It's reporting an error when trying to perform a move within the <code>nco_fl_mv()</code> function:</p>\n<pre><code>$ C:/home/Anaconda3/Library/bin/ncks --dmn=lon,0,28,1 --output=C:/home/data/nclimgrid/201801_nclimgrid_dsd/work/lowres_nclimgrid_tavg_slice00.nc C:/home/data/nclimgrid/201801_nclimgrid_dsd/lowres_nclimgrid_tavg.nc\nThe system cannot find the path specified.\nncks: ERROR nco_fl_mv() unable to execute mv command &quot;move C:/home/data/nclimgrid/201801_nclimgrid_dsd/work/lowres_nclimgrid_tavg_slice00.nc.pid11800.ncks.tmp C:/home/data/nclimgrid/201801_nclimgrid_dsd/work/lowres_nclimgrid_tavg_slice00.nc&quot;\n</code></pre>\n<p>However, it appears that the file is present:</p>\n<pre><code>$ ls -l C:/home/data/nclimgrid/201801_nclimgrid_dsd/work/lowres_nclimgrid_tavg_slice00.nc.pid11800.ncks.tmp \n-rw-r--r-- 1 James.Adams Domain Users 2.9M Feb  9 13:45 C:/home/data/nclimgrid/201801_nclimgrid_dsd/work/lowres_nclimgrid_tavg_slice00.nc.pid11800.ncks.tmp\n</code></pre>\n<p>When I debug into the pynco module I can see the cmd object within nco.py (line 263) looks like this:</p>\n<pre><code>&lt;class 'list'&gt;: ['C:\\\\home\\\\Anaconda3\\\\Library\\\\bin\\\\ncks', \n                 '--dmn=lon,0,28,1', \n                 '--output=C:/home/data/nclimgrid/201801_nclimgrid_dsd/work/lowres_nclimgrid_tavg_slice00.nc',\n              ` \n                 'C:/home/data/nclimgrid/201801_nclimgrid_dsd/lowres_nclimgrid_tavg.nc']`\n</code></pre>\n<p>Perhaps this is a permissions issue? I am using NCO/pynco installed on Anaconda on a Windows machine. This happens at the command line (vanilla NCO) as well as within my script using the pynco NCO wrapper.</p>\n",
                    "OwnerUserId": "85248",
                    "LastEditorUserId": "472495",
                    "LastEditDate": "2022-01-21T20:55:36.530",
                    "LastActivityDate": "2022-01-21T20:55:36.530",
                    "Title": "NCO/pynco: ncks command unable to find/move file, file is present",
                    "Tags": "<python><netcdf><netcdf4><nco><pynco>",
                    "AnswerCount": "1",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "49046273",
                "ParentRepo": "https://github.com/OWASP/owasp-mstg/blob/master/Document/0x05d-Testing-Data-Storage.md#shared-preferences",
                "StackOverflow_Post": {
                    "Id": "49046273",
                    "PostTypeId": "2",
                    "ParentId": "10161266",
                    "CreationDate": "2018-03-01T09:13:25.473",
                    "Score": "18",
                    "Body": "<p>SharedPreferences <a href=\"https://github.com/OWASP/owasp-mstg/blob/master/Document/0x05d-Testing-Data-Storage.md#shared-preferences\" rel=\"noreferrer\">is not</a> a secure location itself. On a rooted device we easily can read and modify all applications' SharedPrefereces xml's. So tokens should expire relatively frequent. But even if a token expires every hour, newer tokens can still be stolen from SharedPreferences. Android KeyStore should be used for long term storage and retrieval of cryptographic keys which will be used to encrypt our tokens in order to store them in e.g. SharedPreferences or a database. The keys are not stored within an application's process, so they <a href=\"https://developer.android.com/training/articles/keystore.html#SecurityFeatures\" rel=\"noreferrer\">are harder</a> to be compromised.</p>\n\n<p>So more relevant than a place is how they can be itself secure e.g. using cryptographically signed short-living JWTs, encrypting them using Android KeyStore and sending them with a secure protocol </p>\n",
                    "OwnerUserId": "2949696",
                    "LastEditorUserId": "2949696",
                    "LastEditDate": "2019-03-12T15:42:26.657",
                    "LastActivityDate": "2019-03-12T15:42:26.657",
                    "CommentCount": "3",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "49097763",
                "ParentRepo": "https://github.com/ElementsProject/lightning",
                "StackOverflow_Post": {
                    "Id": "49097763",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "49109611",
                    "CreationDate": "2018-03-04T16:44:41.810",
                    "Score": "1",
                    "ViewCount": "481",
                    "Body": "<p>I am playing around with the lightning implementation from <a href=\"https://github.com/ElementsProject/lightning\" rel=\"nofollow noreferrer\">https://github.com/ElementsProject/lightning</a> and after the following steps the cli-client cannot list funds which I deposited at the generated address from the internal wallet</p>\n\n<ol>\n<li>I installed bitcoind-0.16 and fully synced the mainnet-blockchain</li>\n<li>I installed c-lightning and synced with the local full node</li>\n<li>I generated a new address with <code>./lightning-cli newaddr</code></li>\n<li>I funded this address from my Electrum wallet (not from the local node wallet) and saw the incoming transaction with <code>./lightning-cli listfunds</code></li>\n<li>Then I accidentally deleted the file <code>.lightning/lightningd.sqlite3</code></li>\n<li>After restart the lightningd recreated the file but now <code>./lightning-cli listfunds</code> is showing empty results but the funds have to be there because the funding transaction is visible in the blockchain.</li>\n</ol>\n\n<p>I investigated <code>./lightning-cli dev-listaddrs</code> which shows all addresses of the internal wallet and there is my funding address. So I think I need to re-sync the lightningd with the bitcoin blockchain, but a <code>./lightning-cli dev-rescan-outputs</code> had no success.</p>\n\n<p>What can I do to be able to see and spend the funds again? Or, how can I get the seed/private key of the internal (lightning) wallet?</p>\n",
                    "OwnerUserId": "8265284",
                    "LastActivityDate": "2018-03-08T12:25:23.210",
                    "Title": "How to re-sync c-lightning with mainnet blockchain?",
                    "Tags": "<bitcoin><lightning>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "49105144",
                "ParentRepo": "https://github.com/allenai/allennlp/blob/master/allennlp/nn/util.py#L675",
                "StackOverflow_Post": {
                    "Id": "49105144",
                    "PostTypeId": "2",
                    "ParentId": "49104307",
                    "CreationDate": "2018-03-05T07:10:41.710",
                    "Score": "2",
                    "Body": "<p>What you are looking for is actually called <code>batched_index_select</code> and I looked for such functionality before but couldn't find any native function in PyTorch that can do the job. But we can simply use:</p>\n\n<pre><code>A = torch.randn(10, 16, 5)\nindex = torch.from_numpy(numpy.random.randint(0, 16, size=10))\nB = torch.stack([a[i] for a, i in zip(A, index)])\n</code></pre>\n\n<p>You can see the discussion <a href=\"https://discuss.pytorch.org/t/batched-index-select/9115\" rel=\"nofollow noreferrer\">here</a>. You can also check out the function <a href=\"https://github.com/allenai/allennlp/blob/master/allennlp/nn/util.py#L675\" rel=\"nofollow noreferrer\">batched_index_select</a> provided in the <a href=\"https://allenai.github.io/allennlp-docs/index.html\" rel=\"nofollow noreferrer\">AllenNLP</a> library. I would be happy to know if there is a better solution.</p>\n",
                    "OwnerUserId": "5352399",
                    "LastEditorUserId": "5352399",
                    "LastEditDate": "2018-03-05T07:18:45.367",
                    "LastActivityDate": "2018-03-05T07:18:45.367",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "49216713",
                "ParentRepo": "https://github.com/OWASP/Top10/blob/master/2017/OWASP%20Top%2010-2017%20(en).pdf",
                "StackOverflow_Post": {
                    "Id": "49216713",
                    "PostTypeId": "2",
                    "ParentId": "49193893",
                    "CreationDate": "2018-03-11T04:45:34.730",
                    "Score": "0",
                    "Body": "<p>The OWASP top 10 does not aim to be a standard, please read the <a href=\"https://github.com/OWASP/Top10/blob/master/2017/OWASP%20Top%2010-2017%20(en).pdf\" rel=\"nofollow noreferrer\">Introduction</a> of the document carefully. Building a good, secure software is hard - the top 10 is a good start, but you should always remember that it's only a start. Building a good, secure development lifecycle is what you're aiming for, and for that projects like <a href=\"https://www.owasp.org/index.php/OWASP_SAMM_Project\" rel=\"nofollow noreferrer\">OWASP SAMM</a> or <a href=\"https://www.owasp.org/index.php/Category:OWASP_Application_Security_Verification_Standard_Project\" rel=\"nofollow noreferrer\">OWASP ASVS</a> could help with. If you have a security team at your work - reach out to them and ask for help. If you don't have - me and so many other at the AppSec community would love to help you started. </p>\n",
                    "OwnerUserId": "4792970",
                    "LastActivityDate": "2018-03-11T04:45:34.730",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "49252033",
                "ParentRepo": "https://github.com/darvid/python-hyperscan",
                "StackOverflow_Post": {
                    "Id": "49252033",
                    "PostTypeId": "2",
                    "ParentId": "49173770",
                    "CreationDate": "2018-03-13T09:02:54.037",
                    "Score": "9",
                    "Body": "<p>To get a reasonable speed while matching 80k patterns, you definitely need some preprocessing on the patterns, single-shot algorithms like <code>Boyer-Moore</code> won't help much. </p>\n\n<p>You'll probably also need to do the work in compiled code (think C extension) to get reasonable throughput. Regarding how to preprocess the patterns - one option is state machines like <code>Aho-Corasick</code> or some generic <a href=\"http://www.openfst.org\" rel=\"nofollow noreferrer\">finite state transducer</a>. The next option is something like a <code>suffix array</code> based index, and the last one that comes to my mind is inverted index. </p>\n\n<p>If your matches are exact and the patterns respect word boundaries, chances are that a well implemented word or word-ngram keyed <code>inverted index</code> will be fast enough even in pure Python. The index is not a complete solution, it will rather give you a few candidate phrases which you need to check with normal string matching for a complete match.</p>\n\n<p>If you need approximate matching, character-ngram inverted index is your choice.</p>\n\n<p>Regarding real implementations - <a href=\"https://github.com/vi3k6i5/flashtext\" rel=\"nofollow noreferrer\">flashtext</a> mentioned in other answer here seems to be a reasonable pure Python solution if you're OK with the full-phrase-only limitation.</p>\n\n<p>Otherwise you can get reasonable results with generic multi-pattern capable regexp libraries: one of the fastest should be Intel's <a href=\"https://www.hyperscan.io/\" rel=\"nofollow noreferrer\">hyperscan</a> - there are even some rudimentary <a href=\"https://github.com/darvid/python-hyperscan\" rel=\"nofollow noreferrer\">python</a> <a href=\"https://github.com/grrrrrrrrr/hyperscan-python\" rel=\"nofollow noreferrer\">bindings</a> available.</p>\n\n<p>Other option is Google's <a href=\"https://github.com/google/re2/\" rel=\"nofollow noreferrer\">RE2</a> with <a href=\"https://github.com/facebook/pyre2\" rel=\"nofollow noreferrer\">Python bindings</a> from Facebook. You want to use <code>RE2::Set</code> in this case.</p>\n",
                    "OwnerUserId": "1496234",
                    "LastEditorUserId": "1496234",
                    "LastEditDate": "2018-03-20T13:33:41.240",
                    "LastActivityDate": "2018-03-20T13:33:41.240",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "49302086",
                "ParentRepo": "https://github.com/dansiegel/Prism.Plugin.Popups",
                "StackOverflow_Post": {
                    "Id": "49302086",
                    "PostTypeId": "2",
                    "ParentId": "49301765",
                    "CreationDate": "2018-03-15T14:27:56.890",
                    "Score": "1",
                    "Body": "<p>As already answered on GitHub. No 3rd party libraries can or will be supported directly from Prism. However support for adding PopupPage's from Rg.Plugins.Popup is supported with Prism.Plugin.Popups.</p>\n\n<p>The plugin is of course <a href=\"https://github.com/dansiegel/Prism.Plugin.Popups\" rel=\"nofollow noreferrer\">open source</a>. There is a full sample in the repo. When using Prism 7 be sure to use the <code>Prism.Plugin.Popups</code> package and not one of the container specific packages as this is no longer necessary. Also as of today it is still in preview until Rg.Plugins.Popup releases a new \"stable\" package.</p>\n",
                    "OwnerUserId": "5699454",
                    "LastActivityDate": "2018-03-15T14:27:56.890",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "49487690",
                "ParentRepo": "https://github.com/keras-rl/keras-rl",
                "StackOverflow_Post": {
                    "Id": "49487690",
                    "PostTypeId": "2",
                    "ParentId": "39693259",
                    "CreationDate": "2018-03-26T09:06:23.690",
                    "Score": "2",
                    "Body": "<blockquote>\n  <p>I'm using a multi layer perceptron as Q-function with 1 hidden layer with 512 hidden units.</p>\n</blockquote>\n\n<p>Might be too big. Depends on your input / output dimensionality and the problem. Did you try fewer?</p>\n\n<h2>Sanity checks</h2>\n\n<p><strong>Can the network possibly learn the necessary function?</strong></p>\n\n<p>Collect ground truth input/output. Fit the network in a supervised way. Does it give the desired output?</p>\n\n<p>A common error is to have the last activation function something wrong. Most of the time, you will want a linear activation function (as you have). Then you want the network to be as small as possible, because RL is pretty unstable: You can have 99 runs where it doesn't work and 1 where it works.</p>\n\n<p><strong>Do I explore enough?</strong></p>\n\n<p>Check how much you explore. Maybe you need more exploration, especially in the beginning?</p>\n\n<h2>See also</h2>\n\n<ul>\n<li><a href=\"https://github.com/MartinThoma/algorithms/blob/master/ML/rl/dqn_agent.py\" rel=\"nofollow noreferrer\">My DQN agent</a></li>\n<li><a href=\"https://github.com/keras-rl/keras-rl\" rel=\"nofollow noreferrer\"><code>keras-rl</code></a></li>\n</ul>\n",
                    "OwnerUserId": "562769",
                    "LastActivityDate": "2018-03-26T09:06:23.690",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "49536208",
                "ParentRepo": "https://github.com/toniblyx/prowler/",
                "StackOverflow_Post": {
                    "Id": "49536208",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "49536730",
                    "CreationDate": "2018-03-28T13:43:43.340",
                    "Score": "0",
                    "ViewCount": "391",
                    "Body": "<p>I am trying to convert the output of <a href=\"https://github.com/toniblyx/prowler/\" rel=\"nofollow noreferrer\">Prowler</a> in the following format to a dictionary, and then converting the dictionary into a JSON file.</p>\n\n<pre><code> 0.1  Generating AWS IAM Credential Report... \n\n 1  Identity and Access Management **************************************** \n\n 1.1  Avoid the use of the root account (Scored).\n       INFO! Root account last accessed (password key_1 key_2): 1970-01-01 00:00:00 N/A N/A \n\n 1.2  Ensure multi-factor authentication (MFA) is enabled for all IAM users that have a console password (Scored)\n       WARNING! User XXXX has Password enabled but MFA disabled \n       WARNING! User XXXX has Password enabled but MFA disabled \n\n 1.3  Ensure credentials unused for 90 days or greater are disabled (Scored)\n       WARNING! User \"XXXX\" has not logged in during the last 90 days  \n       WARNING! User \"XXXX\" has not logged in during the last 90 days   \n       OK!  User \"XXXX\" found with credentials used in the last 90 days\n       OK!  User \"XXXX\" found with credentials used in the last 90 days\n\n 1.4  Ensure access keys are rotated every 90 days or less (Scored)\n       WARNING!  XXXXXXX has not rotated access key1 in over 90 days   \n\n 1.5  Ensure IAM password policy requires at least one uppercase letter (Scored)\n       OK!  Password Policy requires upper case\n\n 1.6  Ensure IAM password policy require at least one lowercase letter (Scored)\n       OK!  Password Policy requires lower case\n</code></pre>\n\n<p>In python, I have this function to parse the prowler.txt file, which uses regex to find the section header as a key value for the dictionary, and then parse the text file after a header match to add the lines underneath as the value for the key.</p>\n\n<pre><code>def create_master_report(ec2_info):\n    prowler_file = 'reports/prowler.txt'\n    findings = {}\n    with open(prowler_file, 'r') as f:\n        for line in f:\n            if re.search('\\s\\d\\.\\d\\d*\\s\\s\\w', line):\n                header = line.strip()\n                findings.update({header: []})\n    for i in findings:\n        prowler_findings = []\n        with open(prowler_file, 'r') as f:\n            for index, line in enumerate(f, start=1):\n                if line.strip() == i:\n                    for line in enumerate(f, start=index+1):\n                        if line != r'\\\\n':\n                            #if re.search('WARNING!', line):\n                            prowler_findings.append(str(line).strip())\n                        if line == r'\\\\n':\n                            break\n        findings.update({i: prowler_findings})\n    report_json['Prowler Results'].update(findings)\n    with open(master_report, 'w') as outfile:\n        json.dump(report_json, outfile, sort_keys=True)\n</code></pre>\n\n<p>However, I seem to be looping through the entire document and adding much more than anticipated as the key value. The end goal here is to parse the document starting at the line after the header, and then break once a new line is detected. I think a while loop would work, but I can't seem to implement one that loops through each line and breaks on a new line. In addition, I would only want to pull in lines that contain <code>'WARNING!'</code>, but I have that commented out in order to test the basic functionality.</p>\n\n<p>Can anyone provide any insight on how to do this?</p>\n",
                    "OwnerUserId": "9421267",
                    "LastActivityDate": "2018-03-28T14:14:51.290",
                    "Title": "Convert text snippets to dictionary key value pairs/JSON in python",
                    "Tags": "<python><json>",
                    "AnswerCount": "2",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "49892549",
                "ParentRepo": "https://github.com/eclipse/sumo/commit/3da7939ea19b246fb845267aa60f0d23ce66908a",
                "StackOverflow_Post": {
                    "Id": "49892549",
                    "PostTypeId": "2",
                    "ParentId": "49870631",
                    "CreationDate": "2018-04-18T06:22:56.683",
                    "Score": "0",
                    "Body": "<p>There seems to be a problem with loading the OpenStreetMap tiles. We recently had a proposed fix for using https instead of http when loading the tiles. You could try to apply this patch <a href=\"https://github.com/eclipse/sumo/commit/3da7939ea19b246fb845267aa60f0d23ce66908a\" rel=\"nofollow noreferrer\">https://github.com/eclipse/sumo/commit/3da7939ea19b246fb845267aa60f0d23ce66908a</a> or simply replace manually in tools/webWizard/script.js</p>\n\n<p>the line </p>\n\n<pre><code>map.addLayer(new OpenLayers.Layer.OSM);\n</code></pre>\n\n<p>with</p>\n\n<pre><code>var maplayer = new OpenLayers.Layer.OSM(\"OpenStreetMap\", \n// Official OSM tileset as protocol-independent URLs\n[\n    'https://a.tile.openstreetmap.org/${z}/${x}/${y}.png',\n    'https://b.tile.openstreetmap.org/${z}/${x}/${y}.png',\n    'https://c.tile.openstreetmap.org/${z}/${x}/${y}.png'\n], null);\nmap.addLayer(maplayer);\n</code></pre>\n",
                    "OwnerUserId": "5731587",
                    "LastActivityDate": "2018-04-18T06:22:56.683",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "49916260",
                "ParentRepo": "https://github.com/spekframework/spek/issues/265#issuecomment-331200634",
                "StackOverflow_Post": {
                    "Id": "49916260",
                    "PostTypeId": "2",
                    "ParentId": "46347220",
                    "CreationDate": "2018-04-19T08:28:16.923",
                    "Score": "0",
                    "Body": "<p>Looks like you asked on github and got an answer: <a href=\"https://github.com/spekframework/spek/issues/265#issuecomment-331200634\" rel=\"nofollow noreferrer\">https://github.com/spekframework/spek/issues/265#issuecomment-331200634</a>  . Leaving it here for others who have the same problem.</p>\n",
                    "OwnerUserId": "1432640",
                    "LastActivityDate": "2018-04-19T08:28:16.923",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "50016861",
                "ParentRepo": "https://github.com/rook/rook",
                "StackOverflow_Post": {
                    "Id": "50016861",
                    "PostTypeId": "2",
                    "ParentId": "50016515",
                    "CreationDate": "2018-04-25T07:54:36.077",
                    "Score": "1",
                    "Body": "<p>This depends on your use case, if the files you want to share across the cluster are more than a few megabytes in size, you'll need some kind of storage operator. Local storage is probably not what you're looking for.</p>\n<hr />\n<h2>For small files (configs, keys, init scripts)</h2>\n<p>If the files are small, such as configuration files or ssh keys or similar you can use a kubernetes configmap (or secret). This will allow you to setup a few files or directories with a few files. <a href=\"https://kubernetes.io/docs/tasks/configure-pod-container/configure-pod-configmap/\" rel=\"nofollow noreferrer\">Checkout the documentation</a></p>\n<hr />\n<h2>For large files (shared data, graphics, binaries)</h2>\n<p>If however you want to share a few hundred megabytes or gigabytes of files, you need a storage provider with your cluster.</p>\n<p>If you are using a cloud provider, such as Google, AWS or Azure, this should be straightforward, you need to create a persistent disk with your cloud provider and copy your required data onto the disk. Once that's done, simply follow the guide for the relevant cloud providers:</p>\n<ul>\n<li>Google Cloud - <a href=\"https://kubernetes.io/docs/concepts/storage/volumes/#gcepersistentdisk\" rel=\"nofollow noreferrer\">GCE Persistent Disk</a></li>\n<li><strike>AWS - <a href=\"https://kubernetes.io/docs/concepts/storage/volumes/#awselasticblockstore\" rel=\"nofollow noreferrer\">Elastic Block Storage</a></strike></li>\n<li><strike>Azure - <a href=\"https://kubernetes.io/docs/concepts/storage/volumes/#azuredisk\" rel=\"nofollow noreferrer\">Azure Disk</a></strike></li>\n</ul>\n<p>(@justcompile pointed out that AWS doesn't support multiple read-only mounts to instances, I was unable to find similar information for Azure)</p>\n<p>If however, you're running your own kubernetes cluster on &quot;baremetal&quot;, you'll have to setup either an NFS server, a <a href=\"https://ceph.com/\" rel=\"nofollow noreferrer\">Ceph cluster</a> and probably use something like <a href=\"https://github.com/rook/rook\" rel=\"nofollow noreferrer\">rook</a> on top.</p>\n",
                    "OwnerUserId": "1220089",
                    "LastEditorUserId": "-1",
                    "LastEditDate": "2020-06-20T09:12:55.060",
                    "LastActivityDate": "2018-04-25T08:50:26.300",
                    "CommentCount": "4",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "50086620",
                "ParentRepo": "https://github.com/amadeus4dev/developer-guides/blob/master/guides/authorization.md",
                "StackOverflow_Post": {
                    "Id": "50086620",
                    "PostTypeId": "2",
                    "ParentId": "50080663",
                    "CreationDate": "2018-04-29T12:35:42.480",
                    "Score": "3",
                    "Body": "<p>The API you are trying to target is secured using <a href=\"https://www.rfc-editor.org/rfc/rfc6749#section-4.4\" rel=\"nofollow noreferrer\">Client credentials grant</a> type.</p>\n<p>Before making the call, you should generate an access token using your API key/secret, please refer to this <a href=\"https://github.com/amadeus4dev/developer-guides/blob/master/guides/authorization.md\" rel=\"nofollow noreferrer\">guide</a>. Once you have generated an access token, your request should look like:</p>\n<pre><code>$.ajax({\n        type: &quot;get&quot;,\n        url: &quot;https://test.api.amadeus.com/v1/shopping/flight-dates?origin=MIA&amp;destination=SFO\u02c6duration=15&amp;nonStop=true&quot;,\n        dataType: 'json',\n        async: true,\n        beforeSend: function(xhr) {\n            xhr.setRequestHeader('Authorization',\n                'Bearer ' + amadeusAccessToken);\n        },                \n        success: function(json) {\n            console.log(json);\n        }\n    });\n</code></pre>\n<p>Alternatively, Amadeus provides some <a href=\"https://github.com/amadeus4dev\" rel=\"nofollow noreferrer\">SDKs</a> to abstract this complexity.</p>\n",
                    "OwnerUserId": "3694458",
                    "LastEditorUserId": "-1",
                    "LastEditDate": "2021-10-07T10:55:51.000",
                    "LastActivityDate": "2018-04-29T12:35:42.480",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "50315702",
                "ParentRepo": "https://github.com/boisgera/bitstream",
                "StackOverflow_Post": {
                    "Id": "50315702",
                    "PostTypeId": "2",
                    "ParentId": "3059301",
                    "CreationDate": "2018-05-13T11:38:30.723",
                    "Score": "0",
                    "Body": "<p>If you are willing to use NumPy and <a href=\"https://github.com/boisgera/bitstream\" rel=\"nofollow noreferrer\">bitstream</a>, you can do</p>\n\n<pre><code>&gt;&gt;&gt; from numpy import *\n&gt;&gt;&gt; from bitstream import BitStream\n&gt;&gt;&gt; raw = '\\xbe\\x00\\xc8d\\xf8d\\x08\\xe4.\\x07~\\x03\\x9e\\x07\\xbe\\x03\\xde\\x07\\xfe\\n'\n&gt;&gt;&gt; stream = BitStream(raw)\n&gt;&gt;&gt; stream.read(raw, uint8, len(stream) // 8)\narray([190,   0, 200, 100, 248, 100,   8, 228,  46,   7, 126,   3, 158,\n         7, 190,   3, 222,   7, 254,  10], dtype=uint8)\n</code></pre>\n",
                    "OwnerUserId": "4308675",
                    "LastActivityDate": "2018-05-13T11:38:30.723",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "50381035",
                "ParentRepo": "https://github.com/neutronX/django-markdownx",
                "StackOverflow_Post": {
                    "Id": "50381035",
                    "PostTypeId": "2",
                    "ParentId": "50381001",
                    "CreationDate": "2018-05-16T22:53:13.417",
                    "Score": "1",
                    "Body": "<p>You need to implement a markdown widget or rich text widget. There are plenty of open source packages available that implements or integrates with Django.</p>\n\n<p>For example:\n<a href=\"https://github.com/neutronX/django-markdownx\" rel=\"nofollow noreferrer\">https://github.com/neutronX/django-markdownx</a>\n<a href=\"https://github.com/summernote/django-summernote\" rel=\"nofollow noreferrer\">https://github.com/summernote/django-summernote</a></p>\n\n<p>In the end, you need to find one you like and integrate it (or write your own!)</p>\n",
                    "OwnerUserId": "292477",
                    "LastActivityDate": "2018-05-16T22:53:13.417",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "50401075",
                "ParentRepo": "https://github.com/cesar-rodriguez/terrascan",
                "StackOverflow_Post": {
                    "Id": "50401075",
                    "PostTypeId": "2",
                    "ParentId": "47065279",
                    "CreationDate": "2018-05-17T21:57:23.483",
                    "Score": "1",
                    "Body": "<p>You want to use static code analysis to find security issues in your Terraform setup.</p>\n\n<p>Trying to converting Terraform to CloudFormation to later use cfn-nag is one way. However, there exist tools now that directly operate on the Terraform setup.</p>\n\n<p>I would recommend to take a look at <a href=\"https://github.com/cesar-rodriguez/terrascan\" rel=\"nofollow noreferrer\">terrascan</a>. It is built on <a href=\"https://github.com/elmundio87/terraform_validate\" rel=\"nofollow noreferrer\">terraform_validate</a>.</p>\n",
                    "OwnerUserId": "783510",
                    "LastActivityDate": "2018-05-17T21:57:23.483",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "50564572",
                "ParentRepo": "https://github.com/Fiware/dataModels/blob/master/Weather/WeatherObserved/harvest/spain_weather_observed_harvest.py#L235",
                "StackOverflow_Post": {
                    "Id": "50564572",
                    "PostTypeId": "2",
                    "ParentId": "50553119",
                    "CreationDate": "2018-05-28T10:44:39.077",
                    "Score": "0",
                    "Body": "<p>instead of opening a new connection per entity why don't you use </p>\n\n<pre><code>POST /v2/op/update \n</code></pre>\n\n<p>and create all entities in just one batch? or a couple of batches</p>\n\n<p>See some code at</p>\n\n<p><a href=\"https://github.com/Fiware/dataModels/blob/master/Weather/WeatherObserved/harvest/spain_weather_observed_harvest.py#L235\" rel=\"nofollow noreferrer\">https://github.com/Fiware/dataModels/blob/master/Weather/WeatherObserved/harvest/spain_weather_observed_harvest.py#L235</a></p>\n",
                    "OwnerUserId": "1433753",
                    "LastEditorUserId": "1485926",
                    "LastEditDate": "2018-05-28T18:46:45.473",
                    "LastActivityDate": "2018-05-28T18:46:45.473",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "50601203",
                "ParentRepo": "https://github.com/garethr/kubeval",
                "StackOverflow_Post": {
                    "Id": "50601203",
                    "PostTypeId": "2",
                    "ParentId": "50589703",
                    "CreationDate": "2018-05-30T09:32:54.420",
                    "Score": "1",
                    "Body": "<p>Client-go library for Kubernetes contains no validation functions for YAML/JSON configuration files.</p>\n\n<p>But take a look at this <a href=\"https://github.com/garethr/kubeval\" rel=\"nofollow noreferrer\">utiliy</a>, you can use it for validation on a client\u2019s side and also use its code as an example of validation implementation.</p>\n",
                    "OwnerUserId": "9524052",
                    "LastActivityDate": "2018-05-30T09:32:54.420",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "50865756",
                "ParentRepo": "https://github.com/Breakthrough/DVR-Scan",
                "StackOverflow_Post": {
                    "Id": "50865756",
                    "PostTypeId": "2",
                    "ParentId": "10103687",
                    "CreationDate": "2018-06-14T20:51:49.437",
                    "Score": "0",
                    "Body": "<p><a href=\"https://github.com/Breakthrough/DVR-Scan\" rel=\"nofollow noreferrer\">https://github.com/Breakthrough/DVR-Scan</a> </p>\n\n<blockquote>\n  <p>DVR-Scan is a cross-platform command-line (CLI) application that\n  automatically detects motion events in video files (e.g. security\n  camera footage). In addition to locating both the time and duration of\n  each motion event, DVR-Scan will save the footage of each motion event\n  to a new, separate video clip. Not only is DVR-Scan free and\n  open-source software (FOSS), written in Python, and based on Numpy and\n  OpenCV, it was built to be extendable and hackable.</p>\n</blockquote>\n\n<p>I can confirm that it works perfectly with MPEG4 (H264) AVI files.\nScanning speed is about 30 fps at my laptop with i5 4300U CPU for 1200x900 video.</p>\n\n<p>You can check the sources for the algorithm used.</p>\n\n<p>And here are some explaning tutorial links from the same author:\n<a href=\"https://github.com/Breakthrough/python-scene-detection-tutorial\" rel=\"nofollow noreferrer\">https://github.com/Breakthrough/python-scene-detection-tutorial</a></p>\n\n<p>See also <a href=\"https://stackoverflow.com/questions/3273196/python-scene-change-detection\">Python scene change detection</a>.</p>\n",
                    "OwnerUserId": "603516",
                    "LastEditorUserId": "603516",
                    "LastEditDate": "2018-06-15T11:17:07.230",
                    "LastActivityDate": "2018-06-15T11:17:07.230",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "50876864",
                "ParentRepo": "https://github.com/encode/uvicorn/issues/68#issuecomment-384943732",
                "StackOverflow_Post": {
                    "Id": "50876864",
                    "PostTypeId": "2",
                    "ParentId": "50835054",
                    "CreationDate": "2018-06-15T13:43:58.217",
                    "Score": "1",
                    "Body": "<p>Nginx closes connections after a predefined time. If you want to have long lived connections, you need to set custom timeout. I also had <a href=\"https://github.com/encode/uvicorn/issues/68#issuecomment-384943732\" rel=\"nofollow noreferrer\">same issue</a> and got fixed after setting <code>proxy_read_timeout</code> to <code>86400</code>.</p>\n\n<pre><code>  location / {\n        proxy_pass http://0.0.0.0:8001;\n        proxy_http_version 1.1;\n        proxy_set_header Upgrade $http_upgrade;\n        proxy_set_header Connection \"upgrade\";\n\n        proxy_read_timeout 86400;\n}\n</code></pre>\n",
                    "OwnerUserId": "2698552",
                    "LastActivityDate": "2018-06-15T13:43:58.217",
                    "CommentCount": "3",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "50892611",
                "ParentRepo": "https://github.com/carla-simulator/carla/issues/116",
                "StackOverflow_Post": {
                    "Id": "50892611",
                    "PostTypeId": "2",
                    "ParentId": "50892535",
                    "CreationDate": "2018-06-16T23:52:48.293",
                    "Score": "1",
                    "Body": "<p>You have to specify a gpu device with <code>with tf.device('gpu:N')</code> where <code>N</code> is the device index.  Read <a href=\"https://www.tensorflow.org/programmers_guide/using_gpu\" rel=\"nofollow noreferrer\">https://www.tensorflow.org/programmers_guide/using_gpu</a> and <a href=\"https://github.com/carla-simulator/carla/issues/116\" rel=\"nofollow noreferrer\">https://github.com/carla-simulator/carla/issues/116</a> first  </p>\n\n<p>I think you've confused running the same script multiple times on different GPUs and running one script using multiple GPUs. In the former case, read the \"Using a single GPU on a multi-GPU system\" section of the TensorFlow guide, for the latter \"Using multiple GPUs\".</p>\n",
                    "OwnerUserId": "4671908",
                    "LastEditorUserId": "4671908",
                    "LastEditDate": "2018-06-17T00:40:33.543",
                    "LastActivityDate": "2018-06-17T00:40:33.543",
                    "CommentCount": "6",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "51001583",
                "ParentRepo": "https://github.com/rosscdh/mkdocs-markdownextradata-plugin",
                "StackOverflow_Post": {
                    "Id": "51001583",
                    "PostTypeId": "2",
                    "ParentId": "48173267",
                    "CreationDate": "2018-06-23T13:23:12.717",
                    "Score": "1",
                    "Body": "<p>What you are describing, seems to be a primitive form of <a href=\"https://en.wikipedia.org/wiki/Interwiki_links\" rel=\"nofollow noreferrer\">interwiki links</a>. There is a plugin that you could use: <a href=\"https://github.com/rosscdh/mkdocs-markdownextradata-plugin\" rel=\"nofollow noreferrer\">markdown extra</a>.</p>\n\n<p>You could define your wikilinks, or wikilinks components in your <code>mkdocs.yaml</code>file, like so, e.g.:</p>\n\n<pre><code>extra:\n  interwiki:\n    stackoverflow: stackoverflow.com/questions/\n    google: https://www.google.com/search?q=\n</code></pre>\n\n<p>Then you would use the \"mustache\" notation:</p>\n\n<pre><code>Please refer to the [question on StackOverflow]({{ interwiki.stackoverflow }}48173267)\n</code></pre>\n\n<p>Which would be equivalent to:</p>\n\n<pre><code>Please refer to the [question on StackOverflow](stackoverflow.com/questions/48173267)\n</code></pre>\n\n<p>I haven't tried it, but that would be the gist. Let me know.</p>\n",
                    "OwnerUserId": "4334041",
                    "LastActivityDate": "2018-06-23T13:23:12.717",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "51012689",
                "ParentRepo": "https://github.com/fralau/mkdocs_macros_plugin",
                "StackOverflow_Post": {
                    "Id": "51012689",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "51015267",
                    "CreationDate": "2018-06-24T18:14:20.490",
                    "Score": "0",
                    "ViewCount": "587",
                    "Body": "<p>I would like to write a plugin for mkdocs that allows to add a file of custom python code.\nHere is an <a href=\"https://github.com/rosscdh/mkdocs-markdownextradata-plugin/blob/master/markdownextradata/plugin.py\" rel=\"nofollow noreferrer\">example of plugin</a>.</p>\n\n<p>I would like to put the module in the website's main dir, alongside the <code>mkdocs.yml</code> file, and declare that module in there, e.g.:</p>\n\n<pre><code>python_module=mycode.py\n</code></pre>\n\n<p>Then I would use in the code of the plugin, something like:</p>\n\n<pre><code>from mkdocs.plugins import BasePlugin\n\nfrom jinja2 import Template\nimport importlib\n\nclass MarkdownExtraDataPlugin(BasePlugin):\n    \"Execute piece of code\"\n\n    def on_page_markdown(self, markdown, page, config, site_navigation, **kwargs):\n\n        python_module = config.get('python_module')\n\n        if python_module:\n            # Add path, here is the question:\n            python_module = os.path.join(*?????*, python_module)\n\n            # do import here:\n            importlib.import_module(python_module)\n\n        ....\n        return result\n</code></pre>\n\n<p>The problem I am having at this point is I don't know how the code of the module could know the location of the yaml file, or the location of the markdown file. By any chance, would that be part of the <code>config</code> dictionary?</p>\n\n<h3>Update</h3>\n\n<p>I wrote the plugin and <a href=\"https://github.com/fralau/mkdocs_macros_plugin\" rel=\"nofollow noreferrer\">made it available on github</a>. Thanks a lot for your help.</p>\n",
                    "OwnerUserId": "4334041",
                    "LastEditorUserId": "4334041",
                    "LastEditDate": "2018-07-02T15:26:41.880",
                    "LastActivityDate": "2018-07-02T15:26:41.880",
                    "Title": "mkdocs: Using a custom python module to complement a plugin",
                    "Tags": "<python><mkdocs>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "51268997",
                "ParentRepo": "https://github.com/wejhink/django-phone-login",
                "StackOverflow_Post": {
                    "Id": "51268997",
                    "PostTypeId": "2",
                    "ParentId": "51268904",
                    "CreationDate": "2018-07-10T15:23:31.123",
                    "Score": "1",
                    "Body": "<p>I recommend using <a href=\"https://github.com/wejhink/django-phone-login\" rel=\"nofollow noreferrer\">Django Phone Login</a>, let me know if you need help with the setup.</p>\n",
                    "OwnerUserId": "3236484",
                    "LastActivityDate": "2018-07-10T15:23:31.123",
                    "CommentCount": "4",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "51367523",
                "ParentRepo": "https://github.com/telefonicaid/fiware-device-simulator",
                "StackOverflow_Post": {
                    "Id": "51367523",
                    "PostTypeId": "2",
                    "ParentId": "51362145",
                    "CreationDate": "2018-07-16T17:50:46.123",
                    "Score": "1",
                    "Body": "<p>In general, Orion Context Broker expects context producers to push data. </p>\n\n<p>The only case in which Orion pulls data is in <a href=\"https://fiware-orion.readthedocs.io/en/master/user/context_providers/index.html\" rel=\"nofollow noreferrer\">context provider scenarios</a> and does only in a transient way, i.e. it gets the data from the context provider and sends to the client in the response but the data is not stored in the context database managed by Orion.</p>\n\n<p>In addition, you could have a look to the <a href=\"https://github.com/telefonicaid/fiware-device-simulator\" rel=\"nofollow noreferrer\">FIWARE Device Simulator</a>. This is a powerful and flexible tool which allows to use <code>external</code> as a source of data, allow acting as a bridge between your source of data and Orion Context Broker. From <a href=\"https://fiware-device-simulator.readthedocs.io/en/latest/simulation-configuration-file/index.html\" rel=\"nofollow noreferrer\">its documentation</a>:</p>\n\n<blockquote>\n  <p>external: Information about an external source from which to load, to transform and to register data into a Context Broker instance.</p>\n</blockquote>\n",
                    "OwnerUserId": "1485926",
                    "LastActivityDate": "2018-07-16T17:50:46.123",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "51400847",
                "ParentRepo": "https://github.com/kubernetes-sigs/aws-alb-ingress-controller/blob/master/docs/walkthrough.md",
                "StackOverflow_Post": {
                    "Id": "51400847",
                    "PostTypeId": "1",
                    "CreationDate": "2018-07-18T11:25:53.330",
                    "Score": "0",
                    "ViewCount": "2142",
                    "Body": "<p>I am implementing an ingress controller with AWS and following <a href=\"https://github.com/kubernetes-sigs/aws-alb-ingress-controller/blob/master/docs/walkthrough.md\" rel=\"nofollow noreferrer\">this</a> tutorial. </p>\n\n<p>When creating an ingress as shown <a href=\"https://raw.githubusercontent.com/kubernetes-sigs/aws-alb-ingress-controller/master/examples/echoservice/echoserver-ingress.yaml\" rel=\"nofollow noreferrer\">here</a>, a  host name should be given.   </p>\n\n<pre><code>spec:\n  rules:\n  - host: echoserver.example.com #How to let kubernate assign ALB's DNS name and not give our own DNS name.\n    http:\n      paths:\n      - path: /\n        backend:\n          serviceName: echoserver\n          servicePort: 80\n</code></pre>\n\n<p>But I want to give the ALB's generated DNS name as I don't have my own DNS name. Is there any way to do it ? I tried ommiting the <strong>host</strong> attribute. But when I describe the ingress as mentioned in my tutorial mentioned above (section 13) running </p>\n\n<pre><code> kubectl describe ing -n echoserver echoserver  \n</code></pre>\n\n<p>The value of Address in the response of above command is empty, therefore no way to hit the ingress.   </p>\n\n<p><em>UPDATE</em>:  </p>\n\n<p>I created a ALB (through the aws UI, and allowed to forward requests to a target group which is created as default) and set its DNS name to the host name(in simple letters) in ingress yaml file. But I can't see it works. I follow the steps mentioned in above <a href=\"https://github.com/kubernetes-sigs/aws-alb-ingress-controller/blob/master/docs/walkthrough.md\" rel=\"nofollow noreferrer\">above tutorial</a>.  </p>\n\n<pre>\nkubectl logs -n kube-system \\\n    $(kubectl get po -n kube-system | \\\n    egrep -o alb-ingress[a-zA-Z0-9-]+) | \\\n    egrep -o '\\[ALB-INGRESS.*$'\n</pre>  \n\n<p>When the above log command executed only the following output returned:    </p>\n\n<pre>\n[ALB-INGRESS] [controller] [INFO]: Log level read as \"\", defaulting to INFO. To change, set LOG_LEVEL environment variable to WARN, ERROR, or DEBUG.\n[ALB-INGRESS] [controller] [INFO]: Ingress class set to alb\n[ALB-INGRESS] [controller] [INFO]: albNamePrefix undefined, defaulting to f0591ff6\n</pre>\n\n<p>As per step 12, when the log command executed,  </p>\n\n<pre>kubectl logs -n kube-system \\\n    $(kubectl get po -n kube-system | \\\n    egrep -o alb-ingress[a-zA-Z0-9-]+) | \\\n    egrep -o '\\[ALB-INGRESS.*$' | \\\n    grep 'echoserver\\/echoserver'\n</pre>\n\n<p>there is no any logs.   </p>\n\n<p>Also, when following command executed:<br>\nkubectl describe ing -n echoserver echoserver<br>\nThe response is:  </p>\n\n<p><pre>\nName:             echoserver\nNamespace:        echoserver\nAddress:\nDefault backend:  default-http-backend:80 (172.17.0.4:8080)\nRules:\n  Host                                                Path  Backends\n  ----                                                ----  --------\n  ingress-alb-3455057285.us-east-2.elb.amazonaws.com\n                                                      /   echoserver:80 ()\nAnnotations:\nEvents:  \n</pre></p>\n\n<p>Any idea please where things go wrong ?<br>\nI did not set any IAM roles here. If it is required, let me know how should I do it.</p>\n",
                    "OwnerUserId": "900081",
                    "LastEditorUserId": "900081",
                    "LastEditDate": "2018-07-22T16:00:58.303",
                    "LastActivityDate": "2018-07-22T16:00:58.303",
                    "Title": "Set ALB's DNS name for aws-alb-ingress-controller",
                    "Tags": "<amazon-web-services><kubernetes><kubernetes-ingress>",
                    "AnswerCount": "2",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "51555109",
                "ParentRepo": "https://github.com/rpclib/rpclib",
                "StackOverflow_Post": {
                    "Id": "51555109",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "51746642",
                    "CreationDate": "2018-07-27T09:39:27.860",
                    "Score": "1",
                    "ViewCount": "2823",
                    "Body": "<p>I was trying to compile statically <a href=\"https://cpp-netlib.org/\" rel=\"nofollow noreferrer\">cpp-netlib</a> and <a href=\"https://github.com/rpclib/rpclib\" rel=\"nofollow noreferrer\">rpclib</a> for ARM device.(Same as ZEDboard)</p>\n\n<p>Everything i did is changed the compiler and system settings in <strong>CMakeLists.txt</strong> file.</p>\n\n<pre><code>    set(CMAKE_SYSTEM_NAME Linux)\n    set(CMAKE_SYSTEM_PROCESSOR arm)\n\n    set(CMAKE_SYSROOT /home/a/buildroot-2018.05/output/host/arm-buildroot-linux-uclibcgnueabihf/sysroot/)\n    set(tools /home/a/buildroot-2018.05/output/host/bin/)\n    set(CMAKE_C_COMPILER ${tools}arm-buildroot-linux-uclibcgnueabihf-gcc)\n    set(CMAKE_CXX_COMPILER ${tools}arm-buildroot-linux-uclibcgnueabihf-g++)\n\n    set(CMAKE_FIND_ROOT_PATH_MODE_PROGRAM NEVER)\n    set(CMAKE_FIND_ROOT_PATH_MODE_LIBRARY ONLY)\n    set(CMAKE_FIND_ROOT_PATH_MODE_INCLUDE ONLY)\n    set(CMAKE_FIND_ROOT_PATH_MODE_PACKAGE ONLY)\n</code></pre>\n\n<p>After Makefile is created by cmake i ran make and no output has been produced. As i understand build directories should appear.</p>\n\n<p>For the rpclib things went better. It has compiled the librpc.a file but unftunately its not linking to my program.</p>\n\n<pre><code>arm-buildroot-linux-uclibcgnueabihf-g++ -I/home/a/rpclib/include/ -Xlinker -static /home/a/rpclib/librpc.a main.cpp\n</code></pre>\n\n<p>produces this output:</p>\n\n<pre><code>/home/a/buildroot-2018.05/output/host/lib/gcc/arm-buildroot-linux-uclibcgnueabihf/6.4.0/../../../../arm-buildroot-linux-uclibcgnueabihf/bin/ld: cannot find -lgcc_s\n/home/a/buildroot-2018.05/output/host/lib/gcc/arm-buildroot-linux-uclibcgnueabihf/6.4.0/../../../../arm-buildroot-linux-uclibcgnueabihf/bin/ld: cannot find -lgcc_s\ncollect2: error: ld returned 1 exit status\n</code></pre>\n\n<p>but there is gcc_s in the sysroot directory.</p>\n\n<pre><code>~/buildroot-2018.05/output/host/arm-buildroot-linux-uclibcgnueabihf$ find ./ -name *gcc_s*\n\n./sysroot/lib/libgcc_s.so\n./sysroot/lib/libgcc_s.so.1\n./sysroot/usr/include/boost/asio/detail/gcc_sync_fenced_block.hpp\n./sysroot/usr/include/boost/atomic/detail/caps_gcc_sync.hpp\n./sysroot/usr/include/boost/atomic/detail/ops_gcc_sync.hpp\n./sysroot/usr/include/boost/atomic/detail/ops_gcc_sparc.hpp\n./sysroot/usr/include/boost/atomic/detail/caps_gcc_sparc.hpp\n./sysroot/usr/include/boost/smart_ptr/detail/sp_counted_base_gcc_sparc.hpp\n./lib/libgcc_s.so\n./lib/libgcc_s.so.1\n</code></pre>\n\n<p>I guess i am missing something important about cross-compilation.\nSo basically i have 3 questions:</p>\n\n<ul>\n<li>Can you suggest some resources about cross-compilation for embdedd devices?</li>\n<li>How to compile cpp-netlib?</li>\n<li>How to link already compiled librpc?</li>\n</ul>\n",
                    "OwnerUserId": "4097755",
                    "LastActivityDate": "2019-01-15T14:35:43.643",
                    "Title": "How to build static library .a for ARM using cross compiler?",
                    "Tags": "<gcc><arm><cross-compiling><embedded-linux><cpp-netlib>",
                    "AnswerCount": "2",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "51669992",
                "ParentRepo": "https://github.com/jhfjhfj1/autokeras/issues/38",
                "StackOverflow_Post": {
                    "Id": "51669992",
                    "PostTypeId": "1",
                    "CreationDate": "2018-08-03T09:53:21.893",
                    "Score": "0",
                    "ViewCount": "884",
                    "Body": "<p>I tried to run <a href=\"https://github.com/jhfjhfj1/autokeras/issues/38\" rel=\"nofollow noreferrer\">auto-keras</a> in a demo, but it failed, the code as shown below:</p>\n\n<pre><code>from keras.datasets import mnist\nfrom autokeras.classifier import ImageClassifier\n\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\nx_train = x_train.reshape(x_train.shape + (1,))\nx_test = x_test.reshape(x_test.shape + (1,))\n\nclf = ImageClassifier(verbose=True)\nclf.fit(x_train, y_train, time_limit=12 * 60 * 60)\nclf.final_fit(x_train, y_train, x_test, y_test, retrain=True)\ny = clf.evaluate(x_test, y_test)\nprint(y)\n```\n</code></pre>\n\n<p>The error message as shown below:</p>\n\n<pre><code>```\nInitializing search.\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\n&lt;ipython-input-23-077a1b1d90e1&gt; in &lt;module&gt;()\n      1 clf = ImageClassifier(verbose=True)\n----&gt; 2 clf.fit(x_train, y_train, time_limit=12 * 60 * 60)\n      3 clf.final_fit(x_train, y_train, x_test, y_test, retrain=True)\n      4 y = clf.evaluate(x_test, y_test)\n      5 print(y)\n\n/Users/victor/virtualenvlist/mydlp2/lib/python2.7/site-packages/autokeras/classifier.pyc in fit(self, x_train, y_train, time_limit)\n    210         start_time = time.time()\n    211         while time.time() - start_time &lt;= time_limit:\n--&gt; 212             run_searcher_once(x_train, y_train, x_test, y_test, self.path)\n    213             if len(self.load_searcher().history) &gt;= constant.MAX_MODEL_NUM:\n    214                 break\n\n/Users/victor/virtualenvlist/mydlp2/lib/python2.7/site-packages/autokeras/classifier.pyc in run_searcher_once(x_train, y_train, x_test, y_test, path)\n     41         backend.set_session(sess)\n     42     searcher = pickle_from_file(os.path.join(path, 'searcher'))\n---&gt; 43     searcher.search(x_train, y_train, x_test, y_test)\n     44 \n     45 \n\n/Users/victor/virtualenvlist/mydlp2/lib/python2.7/site-packages/autokeras/search.pyc in search(self, x_train, y_train, x_test, y_test)\n    156     def search(self, x_train, y_train, x_test, y_test):\n    157         if not self.history:\n--&gt; 158             self.init_search()\n    159 \n    160         # Start the new process for training.\n\n/Users/victor/virtualenvlist/mydlp2/lib/python2.7/site-packages/autokeras/search.pyc in init_search(self)\n    142             print('Initializing search.')\n    143         graph = DefaultClassifierGenerator(self.n_classes,\n--&gt; 144                                            self.input_shape).generate(self.default_model_len,\n    145                                                                       self.default_model_width)\n    146         model_id = self.model_count\n\n/Users/victor/virtualenvlist/mydlp2/lib/python2.7/site-packages/autokeras/generator.pyc in __init__(self, n_classes, input_shape)\n     34 class DefaultClassifierGenerator(ClassifierGenerator):\n     35     def __init__(self, n_classes, input_shape):\n---&gt; 36         super().__init__(n_classes, input_shape)\n     37 \n     38     def generate(self, model_len=constant.MODEL_LEN, model_width=constant.MODEL_WIDTH):\n\nTypeError: super() takes at least 1 argument (0 given)\n```\n</code></pre>\n\n<p>From the log, I think the <code>fit()</code> function in class <code>ImageClassifier</code> got something wrong. Its init function in ImageClassifier didn't run well. </p>\n\n<p>Someone may encounter this problem and solve it. If could, please share it.</p>\n\n<p>Thanks in Advances.</p>\n",
                    "OwnerUserId": "6201599",
                    "LastEditorUserId": "458274",
                    "LastEditDate": "2018-10-22T02:16:41.207",
                    "LastActivityDate": "2018-10-22T02:16:41.207",
                    "Title": "The fit() function in class ImageClassifier in Auto-Keras didn't run well",
                    "Tags": "<keras><mnist><auto-keras>",
                    "AnswerCount": "2",
                    "CommentCount": "0",
                    "FavoriteCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "51724702",
                "ParentRepo": "https://github.com/ConsenSys/smart-contract-best-practices/blob/master/docs/known_attacks.md",
                "StackOverflow_Post": {
                    "Id": "51724702",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "51726028",
                    "CreationDate": "2018-08-07T10:36:22.747",
                    "Score": "2",
                    "ViewCount": "348",
                    "Body": "<p>I'm a rookie working with solidity and blockchain technologies and I was reading some good practices to improve my code. </p>\n\n<p>And I have a question about a code that I'm not quite understanding very well:</p>\n\n<p><em>Source</em>: <a href=\"https://github.com/ConsenSys/smart-contract-best-practices/blob/master/docs/known_attacks.md\" rel=\"nofollow noreferrer\">https://github.com/ConsenSys/smart-contract-best-practices/blob/master/docs/known_attacks.md</a></p>\n\n<pre><code>// INSECURE\nmapping (address =&gt; uint) private userBalances;\n\nfunction withdrawBalance() public {\n    uint amountToWithdraw = userBalances[msg.sender];\n    require(msg.sender.call.value(amountToWithdraw)()); // At this point, the caller's code is executed, and can call withdrawBalance again\n    userBalances[msg.sender] = 0;\n}\n</code></pre>\n\n<p>In the above code is said to be insecure because a malicious agent can call the step 2 require the amount of times we wants. My question regarding this is, how the malicious agent can call misuse this and call that line of code more than 1 time. I'm clearly missing something here.</p>\n",
                    "OwnerUserId": "9790056",
                    "LastEditorUserId": "1069068",
                    "LastEditDate": "2018-08-07T12:33:55.563",
                    "LastActivityDate": "2018-08-07T12:33:55.563",
                    "Title": "Smart contract good practice for reentrancy attacks",
                    "Tags": "<ethereum><solidity><reentrancy><remix><consensys-truffle>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "51770730",
                "ParentRepo": "https://github.com/materialdoc/materialdoc-web/blob/master/docs/components/snackbars-and-toasts.md",
                "StackOverflow_Post": {
                    "Id": "51770730",
                    "PostTypeId": "2",
                    "ParentId": "32425191",
                    "CreationDate": "2018-08-09T15:21:51.283",
                    "Score": "13",
                    "Body": "<p>Refer to this <a href=\"https://github.com/materialdoc/materialdoc-web/blob/master/docs/components/snackbars-and-toasts.md\" rel=\"nofollow noreferrer\">link</a> for more information:</p>\n\n<p>// create instance</p>\n\n<pre><code>Snackbar snackbar = Snackbar.make(view, text, duration);\n</code></pre>\n\n<p>// set action button color</p>\n\n<pre><code>snackbar.setActionTextColor(getResources().getColor(R.color.indigo));\n</code></pre>\n\n<p>// get snackbar view</p>\n\n<pre><code>View snackbarView = snackbar.getView();\n</code></pre>\n\n<p>// change snackbar text color</p>\n\n<pre><code>int snackbarTextId = android.support.design.R.id.snackbar_text;\nTextView textView = (TextView)snackbarView.findViewById(snackbarTextId);\ntextView.setTextColor(getResources().getColor(R.color.indigo));\n</code></pre>\n\n<p>// change snackbar background</p>\n\n<pre><code>snackbarView.setBackgroundColor(Color.MAGENTA);\n</code></pre>\n",
                    "OwnerUserId": "2448986",
                    "LastEditorUserId": "6782707",
                    "LastEditDate": "2020-06-03T04:09:54.787",
                    "LastActivityDate": "2020-06-03T04:09:54.787",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "51866574",
                "ParentRepo": "https://github.com/tathougies/beam",
                "StackOverflow_Post": {
                    "Id": "51866574",
                    "PostTypeId": "2",
                    "ParentId": "34231581",
                    "CreationDate": "2018-08-15T21:18:21.803",
                    "Score": "6",
                    "Body": "<p>I looked at the package mentioned. Some of these package are a dependency of another package (like opaleye-sqlite and sqlite-simple) depend on direct-sqlite.</p>\n<p>Therefore, let's first look at the package that provide the actual driver. Most of them are outdated. There seem to be 3 that still have recent updates:</p>\n<ul>\n<li><p><a href=\"https://hackage.haskell.org/package/simplest-sqlite\" rel=\"nofollow noreferrer\">https://hackage.haskell.org/package/simplest-sqlite</a> <a href=\"https://github.com/YoshikuniJujo/test_haskell/tree/master/features/ffi/sqlite3/simplest-sqlite\" rel=\"nofollow noreferrer\">https://github.com/YoshikuniJujo/test_haskell/tree/master/features/ffi/sqlite3/simplest-sqlite</a> i wouldn't use it because the repository says &quot;It's just my private Haskell learning/testing repository.&quot;</p>\n</li>\n<li><p><a href=\"https://hackage.haskell.org/package/persistent-sqlite\" rel=\"nofollow noreferrer\">https://hackage.haskell.org/package/persistent-sqlite</a> this one is based on direct-sqlite (seems like part of the direct-sqlite has been forked)</p>\n</li>\n<li><p>The last one being the direct-sqlite package. I used <a href=\"https://packdeps.haskellers.com/reverse/direct-sqlite\" rel=\"nofollow noreferrer\">this website</a> to find which package depend on direct-sqlite. Now leaving out package that don't have the purpose of working with sqlite (such as bake: Continuous integration system). And also leaving out packages that haven't seen updates in a long time.</p>\n</li>\n</ul>\n<p>That leaves us with the following package that provide extra functionality based on direct-sqlite. This list includes more levels of reverse lookup to see which other package make use of the package listed below.</p>\n<ul>\n<li><p><a href=\"https://github.com/yesodweb/persistent/tree/master/persistent-sqlite\" rel=\"nofollow noreferrer\">persistent-sqlite</a> as mentioned before</p>\n<ul>\n<li><a href=\"https://github.com/bitemyapp/esqueleto\" rel=\"nofollow noreferrer\">esqueleto\n</a></li>\n<li><a href=\"https://github.com/jdreaver/eventful\" rel=\"nofollow noreferrer\">eventful</a></li>\n</ul>\n</li>\n<li><p><a href=\"https://github.com/lykahb/groundhog\" rel=\"nofollow noreferrer\">groundhog-sqlite</a></p>\n</li>\n<li><p><a href=\"https://github.com/tomjaguarpaw/haskell-opaleye\" rel=\"nofollow noreferrer\">opaleye-sqlite</a></p>\n</li>\n<li><p><a href=\"https://github.com/valderman/selda\" rel=\"nofollow noreferrer\">selda-sqlite</a></p>\n</li>\n<li><p><a href=\"https://github.com/nurpax/sqlite-simple\" rel=\"nofollow noreferrer\">sqlite-simple</a></p>\n<ul>\n<li><a href=\"https://github.com/tathougies/beam\" rel=\"nofollow noreferrer\">beam-sqlite</a></li>\n</ul>\n</li>\n</ul>\n",
                    "OwnerUserId": "1833322",
                    "LastEditorUserId": "208273",
                    "LastEditDate": "2021-12-10T09:03:29.400",
                    "LastActivityDate": "2021-12-10T09:03:29.400",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "51866737",
                "ParentRepo": "https://github.com/allenai/allennlp-models",
                "StackOverflow_Post": {
                    "Id": "51866737",
                    "PostTypeId": "5",
                    "CreationDate": "2018-08-15T21:30:36.233",
                    "Score": "0",
                    "Body": "<p>An Apache 2.0 NLP research library, built on PyTorch, for developing state-of-the-art deep learning models on a wide variety of linguistic tasks.</p>\n\n<p>Quick Links</p>\n\n<ul>\n<li><a href=\"https://allennlp.org/\" rel=\"nofollow noreferrer\">Website</a></li>\n<li><a href=\"https://allennlp.org/tutorials\" rel=\"nofollow noreferrer\">Tutorial</a></li>\n<li><a href=\"https://discourse.allennlp.org/\" rel=\"nofollow noreferrer\">Forum</a></li>\n<li>Documentation ( <a href=\"https://docs.allennlp.org/latest/\" rel=\"nofollow noreferrer\">latest</a> | <a href=\"https://docs.allennlp.org/stable/\" rel=\"nofollow noreferrer\">stable</a> | <a href=\"https://docs.allennlp.org/master/\" rel=\"nofollow noreferrer\">master</a> )</li>\n<li><a href=\"https://github.com/allenai/allennlp/blob/master/CONTRIBUTING.md\" rel=\"nofollow noreferrer\">Contributing Guidelines</a></li>\n<li><a href=\"https://github.com/allenai/allennlp-hub/blob/master/allennlp_hub/pretrained/allennlp_pretrained.py\" rel=\"nofollow noreferrer\">Pretrained Models</a></li>\n<li><a href=\"https://github.com/allenai/allennlp/actions\" rel=\"nofollow noreferrer\">Continuous Build</a></li>\n<li><a href=\"https://pypi.org/project/allennlp/#history\" rel=\"nofollow noreferrer\">Nightly Releases</a></li>\n<li><a href=\"https://github.com/allenai/allennlp-models\" rel=\"nofollow noreferrer\">Officially Supported Models</a></li>\n</ul>\n",
                    "OwnerUserId": "6779252",
                    "LastEditorUserId": "6779252",
                    "LastEditDate": "2020-05-26T03:42:11.260",
                    "LastActivityDate": "2020-05-26T03:42:11.260",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "52174883",
                "ParentRepo": "https://github.com/MikeTheWatchGuy/PySimpleGUI/blob/master/Demo_Chat.py",
                "StackOverflow_Post": {
                    "Id": "52174883",
                    "PostTypeId": "2",
                    "ParentId": "52135974",
                    "CreationDate": "2018-09-04T22:46:00.277",
                    "Score": "1",
                    "Body": "<p>One potential solution is to use a simpler GUI package.  Perhaps the GUI package <a href=\"https://pysimplegui.readthedocs.io/en/latest/\" rel=\"nofollow noreferrer\">PySimpleGUI</a> would be a fit.  It could solve your GUI problem and free you up to work on the other portions of your project.</p>\n\n<p>Check out the <a href=\"https://github.com/MikeTheWatchGuy/PySimpleGUI/blob/master/Demo_Chat.py\" rel=\"nofollow noreferrer\">Chat Demo</a> that implements a Chat front-end. Therre's also a <a href=\"https://github.com/MikeTheWatchGuy/PySimpleGUI/blob/master/Demo_Chatterbot.py\" rel=\"nofollow noreferrer\">Chatterbot Demo</a> that implements a front-end to the Chatterbot project.</p>\n\n<p>You can start by copying that code and modifying it.</p>\n",
                    "OwnerUserId": "8743099",
                    "LastActivityDate": "2018-09-04T22:46:00.277",
                    "CommentCount": "6",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "52188413",
                "ParentRepo": "https://github.com/camunda/camunda-bpm-process-test-coverage",
                "StackOverflow_Post": {
                    "Id": "52188413",
                    "PostTypeId": "1",
                    "CreationDate": "2018-09-05T15:09:20.753",
                    "Score": "1",
                    "ViewCount": "1643",
                    "Body": "<p>I want to add test coverage to my JUnit tests for my BPMN files. I read <a href=\"https://github.com/camunda/camunda-bpm-process-test-coverage\" rel=\"nofollow noreferrer\">Camunda BPM Process Test Coverage</a> and tried the <a href=\"https://github.com/camunda/camunda-bpm-process-test-coverage/blob/master/test/src/test/java/org/camunda/bpm/extension/process_test_coverage/spring/SpringProcessWithCoverageTest.java\" rel=\"nofollow noreferrer\">Spring example</a> with the Camunda Spring Boot Starter test configuration, but I get an exception.</p>\n\n<p><strong>Code:</strong></p>\n\n<pre class=\"lang-java prettyprint-override\"><code>@RunWith(SpringRunner.class)\n@Deployment(resources = {\"test.bpmn\"})\n@ContextConfiguration(classes = {StandaloneInMemoryTestConfiguration.class})\npublic class MyTest {\n\n    @Autowired\n    private ProcessEngine processEngine;\n\n    @Rule\n    @ClassRule\n    public static ProcessEngineRule rule;\n\n    @PostConstruct\n    private void initRule() {\n        rule = TestCoverageProcessEngineRuleBuilder.create(processEngine).build();\n    }\n\n    @Test\n    public void test() {\n    }\n}\n</code></pre>\n\n<p><strong>Error:</strong></p>\n\n<pre><code>16:34:50.858 [main] ERROR o.s.test.context.TestContextManager - Caught exception while allowing TestExecutionListener [org.springframework.test.context.support.DependencyInjectionTestExecutionListener@1df82230] to prepare test instance [com.MyTest@58d75e99]\njava.lang.IllegalStateException: Failed to load ApplicationContext\n    at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:125)\n    at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:108)\n    at org.springframework.test.context.support.DependencyInjectionTestExecutionListener.injectDependencies(DependencyInjectionTestExecutionListener.java:117)\n    at org.springframework.test.context.support.DependencyInjectionTestExecutionListener.prepareTestInstance(DependencyInjectionTestExecutionListener.java:83)\n    at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:246)\n    at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.createTest(SpringJUnit4ClassRunner.java:227)\n    at org.springframework.test.context.junit4.SpringJUnit4ClassRunner$1.runReflectiveCall(SpringJUnit4ClassRunner.java:289)\n    at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)\n    at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.methodBlock(SpringJUnit4ClassRunner.java:291)\n    at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:246)\n    at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:97)\n    at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)\n    at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)\n    at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)\n    at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)\n    at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)\n    at org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61)\n    at org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:70)\n    at org.junit.runners.ParentRunner.run(ParentRunner.java:363)\n    at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:190)\n    at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:86)\n    at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)\n    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:538)\n    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:760)\n    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:460)\n    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:206)\nCaused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'standaloneInMemoryTestConfiguration': Instantiation of bean failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.camunda.bpm.spring.boot.starter.test.helper.StandaloneInMemoryTestConfiguration]: No default constructor found; nested exception is java.lang.NoSuchMethodException: org.camunda.bpm.spring.boot.starter.test.helper.StandaloneInMemoryTestConfiguration.&lt;init&gt;()\n    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateBean(AbstractAutowireCapableBeanFactory.java:1236)\n    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1135)\n    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:541)\n    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:501)\n    at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:317)\n    at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:228)\n    at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:315)\n    at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)\n    at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:760)\n    at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:869)\n    at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:550)\n    at org.springframework.test.context.support.AbstractGenericContextLoader.loadContext(AbstractGenericContextLoader.java:128)\n    at org.springframework.test.context.support.AbstractGenericContextLoader.loadContext(AbstractGenericContextLoader.java:60)\n    at org.springframework.test.context.support.AbstractDelegatingSmartContextLoader.delegateLoading(AbstractDelegatingSmartContextLoader.java:107)\n    at org.springframework.test.context.support.AbstractDelegatingSmartContextLoader.loadContext(AbstractDelegatingSmartContextLoader.java:243)\n    at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:99)\n    at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:117)\n    ... 25 common frames omitted\nCaused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.camunda.bpm.spring.boot.starter.test.helper.StandaloneInMemoryTestConfiguration]: No default constructor found; nested exception is java.lang.NoSuchMethodException: org.camunda.bpm.spring.boot.starter.test.helper.StandaloneInMemoryTestConfiguration.&lt;init&gt;()\n    at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:83)\n    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateBean(AbstractAutowireCapableBeanFactory.java:1228)\n    ... 41 common frames omitted\nCaused by: java.lang.NoSuchMethodException: org.camunda.bpm.spring.boot.starter.test.helper.StandaloneInMemoryTestConfiguration.&lt;init&gt;()\n    at java.lang.Class.getConstructor0(Unknown Source)\n    at java.lang.Class.getDeclaredConstructor(Unknown Source)\n    at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:78)\n    ... 42 common frames omitted\n</code></pre>\n\n<p>I also tried to build the process engine manually in the <code>initRule</code> method (removing autowired property <code>processEngine</code> and class annotation <code>@ContextConfiguration</code>):</p>\n\n<pre class=\"lang-java prettyprint-override\"><code>@PostConstruct\nprivate void initRule() {\n    ProcessEngine processEngine = new StandaloneInMemoryTestConfiguration().buildProcessEngine();\n    rule = TestCoverageProcessEngineRuleBuilder.create(processEngine).build();\n}\n</code></pre>\n\n<p>but I get still an exception:</p>\n\n<pre><code>java.lang.ClassCastException: org.camunda.bpm.engine.impl.history.handler.DbHistoryEventHandler cannot be cast to org.camunda.bpm.extension.process_test_coverage.listeners.FlowNodeHistoryEventHandler\n    at org.camunda.bpm.extension.process_test_coverage.junit.rules.TestCoverageProcessEngineRule.initializeListenerRunState(TestCoverageProcessEngineRule.java:259)\n    at org.camunda.bpm.extension.process_test_coverage.junit.rules.TestCoverageProcessEngineRule.initializeRunState(TestCoverageProcessEngineRule.java:240)\n    at org.camunda.bpm.extension.process_test_coverage.junit.rules.TestCoverageProcessEngineRule.starting(TestCoverageProcessEngineRule.java:134)\n    at org.junit.rules.TestWatcher.startingQuietly(TestWatcher.java:108)\n    at org.junit.rules.TestWatcher.access$000(TestWatcher.java:46)\n    at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:53)\n    at org.camunda.bpm.engine.test.ProcessEngineRule$1.evaluate(ProcessEngineRule.java:165)\n    at org.junit.rules.RunRules.evaluate(RunRules.java:20)\n    at org.springframework.test.context.junit4.statements.SpringRepeat.evaluate(SpringRepeat.java:84)\n    at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)\n    at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:251)\n    at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:97)\n    at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)\n    at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)\n    at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)\n    at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)\n    at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)\n    at org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61)\n    at org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:70)\n    at org.junit.runners.ParentRunner.run(ParentRunner.java:363)\n    at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:190)\n    at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:86)\n    at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)\n    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:538)\n    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:760)\n    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:460)\n    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:206)\n</code></pre>\n",
                    "OwnerUserId": "5277820",
                    "LastActivityDate": "2019-03-27T16:38:09.730",
                    "Title": "How to add test coverage to Camunda Spring Boot application?",
                    "Tags": "<spring-boot><code-coverage><junit4><camunda>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "FavoriteCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "52296370",
                "ParentRepo": "https://github.com/helmfile/helmfile",
                "StackOverflow_Post": {
                    "Id": "52296370",
                    "PostTypeId": "5",
                    "CreationDate": "2018-09-12T13:27:26.877",
                    "Score": "0",
                    "Body": "<p><a href=\"https://github.com/helmfile/helmfile\" rel=\"nofollow noreferrer\">Helmfile</a> is a tool for managing multiple <a href=\"/questions/tagged/kubernetes-helm\" class=\"post-tag\" title=\"show questions tagged &#39;kubernetes-helm&#39;\" aria-label=\"show questions tagged &#39;kubernetes-helm&#39;\" rel=\"tag\" aria-labelledby=\"kubernetes-helm-container\">kubernetes-helm</a> packages, to be installed together in the same <a href=\"/questions/tagged/kubernetes\" class=\"post-tag\" title=\"show questions tagged &#39;kubernetes&#39;\" aria-label=\"show questions tagged &#39;kubernetes&#39;\" rel=\"tag\" aria-labelledby=\"kubernetes-container\">kubernetes</a> cluster.  It allows declaring multiple Helm releases (chart installations) in a single YAML file.  It also supports multiple deployment environments, and uses the same templating language as Helm to supply Helm values and other configuration.</p>\n<p>Since Helmfile uses the <a href=\"/questions/tagged/go-templates\" class=\"post-tag\" title=\"show questions tagged &#39;go-templates&#39;\" aria-label=\"show questions tagged &#39;go-templates&#39;\" rel=\"tag\" aria-labelledby=\"go-templates-container\">go-templates</a> system, it is possible to write conditional logic within a Helmfile.  Helmfile also has multiple layers of templating, multiple ways to supply values to charts, and allows modifying chart content in various ways.  Questions should focus on the <code>helm file.yaml</code> and <code>*.yaml.gotmpl</code> files specific to Helmfile.</p>\n<p>Do not use this tag for general questions about Helm charts.  Questions that deal only with a Helm <code>Chart.yaml</code> file or the Helm <code>templates/*.yaml</code> files should be tagged with <a href=\"/questions/tagged/kubernetes-helm\" class=\"post-tag\" title=\"show questions tagged &#39;kubernetes-helm&#39;\" aria-label=\"show questions tagged &#39;kubernetes-helm&#39;\" rel=\"tag\" aria-labelledby=\"kubernetes-helm-container\">kubernetes-helm</a> but not <a href=\"/questions/tagged/helmfile\" class=\"post-tag\" title=\"show questions tagged &#39;helmfile&#39;\" aria-label=\"show questions tagged &#39;helmfile&#39;\" rel=\"tag\" aria-labelledby=\"helmfile-container\">helmfile</a>, unless there is something specific to their interaction with the separate Helmfile tool.</p>\n",
                    "OwnerUserId": "-1",
                    "LastEditorUserId": "10008173",
                    "LastEditDate": "2022-10-10T11:36:52.760",
                    "LastActivityDate": "2022-10-10T11:36:52.760",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "52386110",
                "ParentRepo": "https://github.com/SAP/vulnerability-assessment-tool",
                "StackOverflow_Post": {
                    "Id": "52386110",
                    "PostTypeId": "1",
                    "CreationDate": "2018-09-18T11:59:03.307",
                    "Score": "0",
                    "ViewCount": "201",
                    "Body": "<p>I am trying scan my projects in gradle using <a href=\"https://github.com/SAP/vulnerability-assessment-tool\" rel=\"nofollow noreferrer\">Vulas</a> and always get the same error:</p>\n\n<p>\"Application context is required to execute goal APP.\"</p>\n\n<p>Could you tell me what is missing or what exactly this error means? What exactly Vulas is trying to looking for?</p>\n\n<p>Thanks.</p>\n",
                    "OwnerUserId": "10380151",
                    "LastEditorUserId": "3482533",
                    "LastEditDate": "2018-10-15T19:22:26.640",
                    "LastActivityDate": "2018-10-15T19:22:26.640",
                    "Title": "Problem while using Vulas for scanning gradle projects",
                    "Tags": "<gradle><vulas>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "52407887",
                "ParentRepo": "https://github.com/PySimpleGUI/PySimpleGUI/blob/master/exemaker/readme.md",
                "StackOverflow_Post": {
                    "Id": "52407887",
                    "PostTypeId": "2",
                    "ParentId": "41570359",
                    "CreationDate": "2018-09-19T14:10:59.380",
                    "Score": "8",
                    "Body": "<p>I've been using Nuitka and PyInstaller with my package, PySimpleGUI.</p>\n\n<p><strong>Nuitka</strong>\nThere were issues getting tkinter to compile with Nuikta. One of the project contributors developed a script that fixed the problem.  </p>\n\n<p>If you're not using tkinter it may \"just work\" for you.  If you are using tkinter say so and I'll try to get the script and instructions published.</p>\n\n<p><strong>PyInstaller</strong>\nI'm running 3.6 and PyInstaller is working great!\nThe command I use to create my exe file is:</p>\n\n<blockquote>\n  <p>pyinstaller -wF myfile.py</p>\n</blockquote>\n\n<p>The -wF will create a single EXE file.  Because all of my programs have a GUI and I do not want to command window to show, the -w option will hide the command window.</p>\n\n<p>This is as close to getting what <em>looks like</em> a Winforms program to run that was written in Python.</p>\n\n<p>[Update 20-Jul-2019]</p>\n\n<p>There is PySimpleGUI GUI based solution that uses PyInstaller.  It uses PySimpleGUI.  It's called <a href=\"https://github.com/PySimpleGUI/PySimpleGUI/blob/master/exemaker/readme.md\" rel=\"noreferrer\">pysimplegui-exemaker</a> and can be pip installed.</p>\n\n<p><code>pip install PySimpleGUI-exemaker</code></p>\n\n<p>To run it after installing:</p>\n\n<p><code>python -m pysimplegui-exemaker.pysimplegui-exemaker</code></p>\n",
                    "OwnerUserId": "8743099",
                    "LastEditorUserId": "8743099",
                    "LastEditDate": "2019-07-20T15:51:26.753",
                    "LastActivityDate": "2019-07-20T15:51:26.753",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "52426205",
                "ParentRepo": "https://github.com/uglide/RedisDesktopManager/issues/3841",
                "StackOverflow_Post": {
                    "Id": "52426205",
                    "PostTypeId": "2",
                    "ParentId": "52412083",
                    "CreationDate": "2018-09-20T13:24:38.137",
                    "Score": "0",
                    "Body": "<p><a href=\"https://github.com/uglide/RedisDesktopManager/issues/3841\" rel=\"nofollow noreferrer\">https://github.com/uglide/RedisDesktopManager/issues/3841</a></p>\n\n<p>It's the appication issue, I don't know if the developer solved it yet, but right now I have to degrade the version from 0.9.3.817 to 0.8.8.384.</p>\n\n<p>Anyone who encounter <strong>Connection error: The proxy type is invalid for this operation</strong> can do the same, or you can tell me any other solution after you check this issue on GitHub.</p>\n\n<p>Thanks.</p>\n",
                    "OwnerUserId": "4849200",
                    "LastActivityDate": "2018-09-20T13:24:38.137",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "52431552",
                "ParentRepo": "https://github.com/dansiegel/Mobile.BuildTools",
                "StackOverflow_Post": {
                    "Id": "52431552",
                    "PostTypeId": "2",
                    "ParentId": "51621387",
                    "CreationDate": "2018-09-20T18:56:13.213",
                    "Score": "19",
                    "Body": "<p>So it turns out this is surprisingly easy by following these steps:</p>\n\n<p>Install the <a href=\"https://www.nuget.org/packages/Mobile.BuildTools/\" rel=\"noreferrer\">Mobile.BuildTools</a> NuGet package in your project.</p>\n\n<p>Add a secrets.json file in the root of your project (this should be excluded from source control using .gitignore).</p>\n\n<p>Add your secret to the secrets.json file, so in my case I'm going to add a SearchApiKey, obviously you can add as many secrets as you want: </p>\n\n<pre><code>{\n  \"SearchApiKey\": \"SUPERSECRETGOESHERE\"\n}\n</code></pre>\n\n<p>Build your project and this will generate a static class called Secrets with a property SearchApiKey, you can find it under the obj folder if you want to have a look at it.</p>\n\n<p>You can now access this class and it's properties in your code so I just do:</p>\n\n<pre><code>var secret = Secrets.SearchApiKey;\n</code></pre>\n\n<p>Finally to pass the secret into your build on AppCenter you need to add an Environment Variable that matches the property name prepended with Secret_ so in my case it's name is Secret_SearchApiKey and set it's value.</p>\n\n<p>You can check out the <a href=\"https://github.com/dansiegel/Mobile.BuildTools\" rel=\"noreferrer\">Mobile.BuildTools</a> GitHub repository for more information. </p>\n",
                    "OwnerUserId": "2529475",
                    "LastActivityDate": "2018-09-20T18:56:13.213",
                    "CommentCount": "11",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "52472604",
                "ParentRepo": "https://github.com/cgarciae/pypeln",
                "StackOverflow_Post": {
                    "Id": "52472604",
                    "PostTypeId": "2",
                    "ParentId": "8277715",
                    "CreationDate": "2018-09-24T04:11:21.443",
                    "Score": "0",
                    "Body": "<p><a href=\"https://github.com/cgarciae/pypeln\" rel=\"nofollow noreferrer\">Pypeline</a> does this for you. You can even choose between using Processes, Threads or async Tasks. What you want is just e.g. using Processes:</p>\n<pre><code>import pypeln as pl\n\ndata = some_iterable()\ndata = pl.process.map(f2, data, workers = 3)\ndata = list(data)\n</code></pre>\n<p>You can do more complex stuff</p>\n<pre><code>import pypeln as pl\n\ndata = some_iterable()\ndata = pl.process.map(f2, data, workers = 3)\ndata = pl.process.filter(f3, data, workers = 1)\ndata = pl.process.flat_map(f4, data, workers = 5)\ndata = list(data)\n</code></pre>\n",
                    "OwnerUserId": "2118130",
                    "LastEditorUserId": "2118130",
                    "LastEditDate": "2020-06-23T02:27:59.870",
                    "LastActivityDate": "2020-06-23T02:27:59.870",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "52652621",
                "ParentRepo": "https://github.com/overshard/timestrap",
                "StackOverflow_Post": {
                    "Id": "52652621",
                    "PostTypeId": "2",
                    "ParentId": "52560949",
                    "CreationDate": "2018-10-04T17:43:54.537",
                    "Score": "1",
                    "Body": "<p>Did you check - Timestrap Application ( <a href=\"https://github.com/overshard/timestrap\" rel=\"nofollow noreferrer\">https://github.com/overshard/timestrap</a>). They do have Heroku based demo instance: <a href=\"https://timestrap.herokuapp.com/\" rel=\"nofollow noreferrer\">https://timestrap.herokuapp.com/</a></p>\n\n<p>This Application is based on Vuejs and Django - it will give good idea on how to go about it. </p>\n\n<p>Enjoy</p>\n",
                    "OwnerUserId": "905670",
                    "LastActivityDate": "2018-10-04T17:43:54.537",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "52655008",
                "ParentRepo": "https://github.com/dalibo/temboard/commit/ff98d6740ae11345658508b02052294d6cffd448",
                "StackOverflow_Post": {
                    "Id": "52655008",
                    "PostTypeId": "2",
                    "ParentId": "51033689",
                    "CreationDate": "2018-10-04T20:55:11.297",
                    "Score": "26",
                    "Body": "<p>I had the same problem with my CI build, and I found a workaround creating the folders like @A. Scherbaum mentioned.</p>\n\n<pre><code>sudo mkdir -p /usr/share/man/man1\nsudo mkdir -p /usr/share/man/man7\nsudo apt-get update\nsudo apt-get install postgresql-client\n</code></pre>\n\n<p>I found this solution in this <a href=\"https://github.com/dalibo/temboard/commit/ff98d6740ae11345658508b02052294d6cffd448\" rel=\"noreferrer\">commit</a> through this <a href=\"https://github.com/dalibo/temboard/issues/211\" rel=\"noreferrer\">issue</a></p>\n\n<p>However I also did the test silencing the error like you said and It worked, but I don't know the consequences</p>\n\n<pre><code>sudo apt-get install postgresql-client || true\n</code></pre>\n\n<p>I found something similar in this <a href=\"https://circleci.com/docs/2.0/postgres-config/\" rel=\"noreferrer\">circleci article</a></p>\n",
                    "OwnerUserId": "4788966",
                    "LastActivityDate": "2018-10-04T20:55:11.297",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "52719324",
                "ParentRepo": "https://github.com/allegro/hermes/pull/749/files",
                "StackOverflow_Post": {
                    "Id": "52719324",
                    "PostTypeId": "2",
                    "ParentId": "33236284",
                    "CreationDate": "2018-10-09T10:54:01.950",
                    "Score": "1",
                    "Body": "<p>Check this project out: <a href=\"https://github.com/allegro/hermes/pull/749/files\" rel=\"nofollow noreferrer\">https://github.com/allegro/hermes/pull/749/files</a></p>\n\n<p>You are interested in the JsonAvroConverter. It de-serializes from json (without union types) to Avro generated objects (that have union types). Actually, it gets from the schema of types on the union and tries them one by one. It works excellent in our case.</p>\n\n<p>This is doing the job: <a href=\"https://github.com/allegro/json-avro-converter/blob/master/converter/src/main/java/tech/allegro/schema/json2avro/converter/JsonGenericRecordReader.java\" rel=\"nofollow noreferrer\">https://github.com/allegro/json-avro-converter/blob/master/converter/src/main/java/tech/allegro/schema/json2avro/converter/JsonGenericRecordReader.java</a></p>\n\n<p>Regards!</p>\n",
                    "OwnerUserId": "3794744",
                    "LastEditorUserId": "3794744",
                    "LastEditDate": "2018-10-09T11:00:14.020",
                    "LastActivityDate": "2018-10-09T11:00:14.020",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "52747084",
                "ParentRepo": "https://github.com/StarOfService/ingress-nginx/blob/7212d0081bd761477acb3b98ed4e7c44dd2fc5f8/test/e2e/settings/global_access_block.go#L69",
                "StackOverflow_Post": {
                    "Id": "52747084",
                    "PostTypeId": "2",
                    "ParentId": "52739929",
                    "CreationDate": "2018-10-10T19:00:23.340",
                    "Score": "0",
                    "Body": "<p>This is an <a href=\"https://www.cyberciti.biz/faq/unix-linux-appleosx-bsd-nginx-block-user-agent/\" rel=\"nofollow noreferrer\">example</a> of how to block user agents in the <code>nginx.conf</code>:</p>\n\n<pre><code>### make sure your 'if' statement is in the server block.\n### case sensitive http user agent blocking  ###\nif ($http_user_agent ~ (Catall Spider|AcoiRobot) ) {\n    return 403;\n}\n### case insensitive http user agent blocking  ###\nif ($http_user_agent ~* (foo|bar) ) {\n    return 403;\n}\n</code></pre>\n\n<p>You can add some configuration part in the ingress-controller's <code>nginx.conf</code> using the following  <a href=\"https://github.com/kubernetes/ingress-nginx/tree/master/docs/examples/customization/configuration-snippets\" rel=\"nofollow noreferrer\">example</a>. It adds a custom header to Nginx configuration that only applies to that specific Ingress:</p>\n\n<pre><code>---\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: nginx-configuration-snippet\n  annotations:\n    nginx.ingress.kubernetes.io/configuration-snippet: |\n      more_set_headers \"Request-Id: $req_id\";\nspec:\n  rules:\n  - host: custom.configuration.com\n    http:\n      paths:\n      - backend:\n          serviceName: http-svc\n          servicePort: 80\n        path: /\n</code></pre>\n\n<p>If you need to add some global settings to the ingress controller see the following <a href=\"https://github.com/kubernetes/ingress-nginx/tree/master/docs/examples/customization/custom-headers/\" rel=\"nofollow noreferrer\">examples</a>:</p>\n\n<pre><code>---\napiVersion: v1\ndata:\n  proxy-set-headers: \"ingress-nginx/custom-headers\"\nkind: ConfigMap\nmetadata:\n  name: nginx-configuration\n  namespace: ingress-nginx\n  labels:\n    app.kubernetes.io/name: ingress-nginx\n    app.kubernetes.io/part-of: ingress-nginx\n\n---\napiVersion: v1\ndata:\n  X-Different-Name: \"true\"\n  X-Request-Start: t=${msec}\n  X-Using-Nginx-Controller: \"true\"\nkind: ConfigMap\nmetadata:\n  name: custom-headers\n  namespace: ingress-nginx\n\n---\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: nginx-configuration\n  namespace: ingress-nginx\n  labels:\n    app.kubernetes.io/name: ingress-nginx\n    app.kubernetes.io/part-of: ingress-nginx\ndata:\n  proxy-connect-timeout: \"10\"\n  proxy-read-timeout: \"120\"\n  proxy-send-timeout: \"120\"\n</code></pre>\n\n<p>Create a YAML file using the previous examples and apply it to your cluster:</p>\n\n<pre><code>kubectl apply -f nginx-ingress-config.yaml\n</code></pre>\n\n<p>You can check if settings applied to the nginx.conf in the ingress controller using the following command:</p>\n\n<pre><code># Replace name of the ingress controller with the real name of the pod in the right namespace\n$ kubectl exec nginx-ingress-controller-6bdddddb-6dmnw -n kube-system cat /etc/nginx/nginx.conf\n\n# You can find the real name of your ingress controller and namespace using the next command\n$ kubectl get pods --all-namespaces | grep nginx-ingress-controller\n</code></pre>\n\n<hr>\n\n<p>Without information about your chart it's hard to guess which parameter you should set.</p>\n\n<p>If you are using  chart from the helm repository you can fetch it's content by running</p>\n\n<pre><code>$ helm fetch &lt;chart/name&gt;\n</code></pre>\n\n<p>After that you will get a compressed chart file in the current directory.\nYou may need to find the right value for you code snippet by reading the template files in the chart\u2019s template directory.</p>\n\n<p>If you are using chart written by you, you can use <code>stable/nginx-ingress</code> chart as a reference. It has a lot of configuration options.</p>\n\n<h2><strong>Update:</strong></h2>\n\n<p>Starting from version 0.20.0 new functionality was <a href=\"https://github.com/kubernetes/ingress-nginx/blob/master/Changelog.md\" rel=\"nofollow noreferrer\">introduced</a>:  </p>\n\n<blockquote>\n  <p><a href=\"https://github.com/kubernetes/ingress-nginx/pull/2997\" rel=\"nofollow noreferrer\">#2997</a> Provide possibility to block IPs, User-Agents and Referers\n  globally</p>\n</blockquote>\n\n<p>Usage of parameter is explained in <a href=\"http://nginx.org/en/docs/http/ngx_http_map_module.html#map\" rel=\"nofollow noreferrer\">Map section of the manual</a>.</p>\n\n<p>If you need an example of usage you can find it in <a href=\"https://github.com/StarOfService/ingress-nginx/blob/7212d0081bd761477acb3b98ed4e7c44dd2fc5f8/test/e2e/settings/global_access_block.go#L69\" rel=\"nofollow noreferrer\">test-case</a>.</p>\n\n<pre><code>It(\"should block User-Agents defined in the ConfigMap\", func() {\n    err := f.UpdateNginxConfigMapData(\"block-user-agents\", \"~*chrome\\\\/68\\\\.0\\\\.3440\\\\.106\\\\ safari\\\\/537\\\\.36,AlphaBot\")\n    Expect(err).NotTo(HaveOccurred())\n</code></pre>\n\n<p>...</p>\n\n<pre><code>    // Should be blocked\n    resp, _, errs := gorequest.New().\n        Get(f.IngressController.HTTPURL).\n        Set(\"Host\", host).\n        Set(\"User-Agent\", \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/68.0.3440.106 Safari/537.36\").\n        End()\n    Expect(errs).To(BeNil())\n    Expect(resp.StatusCode).Should(Equal(http.StatusForbidden))\n\n    resp, _, errs = gorequest.New().\n        Get(f.IngressController.HTTPURL).\n        Set(\"Host\", host).\n        Set(\"User-Agent\", \"AlphaBot\").\n        End()\n    Expect(errs).To(BeNil())\n    Expect(resp.StatusCode).Should(Equal(http.StatusForbidden))\n\n    // Shouldn't be blocked\n    resp, _, errs = gorequest.New().\n        Get(f.IngressController.HTTPURL).\n        Set(\"Host\", host).\n        Set(\"User-Agent\", \"Mozilla/5.0 (iPhone; CPU iPhone OS 11_4_1 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/11.0 Mobile/15E148 Safari/604.1\").\n        End()\n    Expect(errs).To(BeNil())\n    Expect(resp.StatusCode).Should(Equal(http.StatusOK))\n})\n</code></pre>\n",
                    "OwnerUserId": "9521610",
                    "LastEditorUserId": "9521610",
                    "LastEditDate": "2018-11-02T16:54:50.457",
                    "LastActivityDate": "2018-11-02T16:54:50.457",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "52815728",
                "ParentRepo": "https://github.com/igordejanovic/parglare/",
                "StackOverflow_Post": {
                    "Id": "52815728",
                    "PostTypeId": "2",
                    "ParentId": "52811498",
                    "CreationDate": "2018-10-15T11:26:56.463",
                    "Score": "3",
                    "Body": "<p>textX author here. In addition to Paul's excellent answer, there is <a href=\"https://github.com/igordejanovic/textX/blob/master/examples/expression/calc.py\" rel=\"nofollow noreferrer\">expression example</a> which should provide you a good start. </p>\n\n<p>Top-down parsers in general are not handling left-recursive rules without hacks like this. If your language is going to be complex and heavily expression oriented it might be better to try some bottom-up parser that allows for left recursion and provides declarative priority and associativity specification. If you liked textX then I suggest to take a look at <a href=\"https://github.com/igordejanovic/parglare/\" rel=\"nofollow noreferrer\">parglare</a> which has similar design goals but uses bottom-up parsing technique (specifically LR and GLR). Quick intro example is the exact language you are building.</p>\n\n<p>In <a href=\"http://www.igordejanovic.net/2017/08/09/parglare-python-parser.html\" rel=\"nofollow noreferrer\">this post</a> I blogged about rationale of starting parglare project and differences with textX/Arpeggio.</p>\n",
                    "OwnerUserId": "2024430",
                    "LastActivityDate": "2018-10-15T11:26:56.463",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "53172321",
                "ParentRepo": "https://github.com/ansible/ansible-lint",
                "StackOverflow_Post": {
                    "Id": "53172321",
                    "PostTypeId": "2",
                    "ParentId": "53164280",
                    "CreationDate": "2018-11-06T12:54:07.080",
                    "Score": "0",
                    "Body": "<p>Although it won't upgrade your playbooks for you (you have to do that yourself), you could use <a href=\"https://github.com/ansible/ansible-lint\" rel=\"nofollow noreferrer\">Ansible Lint</a>. Run it over your existing playbooks and address the issues that it finds. If you want to be even more sure, run the playbooks in check mode <code>ansible-playbook -C ...</code> to see if any module names or parameters need updating.</p>\n",
                    "OwnerUserId": "2707870",
                    "LastActivityDate": "2018-11-06T12:54:07.080",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "53183238",
                "ParentRepo": "https://github.com/agconti/cookiecutter-django-rest",
                "StackOverflow_Post": {
                    "Id": "53183238",
                    "PostTypeId": "2",
                    "ParentId": "52281123",
                    "CreationDate": "2018-11-07T03:34:39.577",
                    "Score": "4",
                    "Body": "<p>I ended up using</p>\n\n<ul>\n<li><a href=\"https://github.com/agconti/cookiecutter-django-rest\" rel=\"nofollow noreferrer\">https://github.com/agconti/cookiecutter-django-rest</a> a good DRF base with a docker file</li>\n<li><a href=\"https://github.com/RealmTeam/django-rest-framework-social-oauth2\" rel=\"nofollow noreferrer\">https://github.com/RealmTeam/django-rest-framework-social-oauth2</a> handles login with facebook</li>\n</ul>\n\n<p>also <a href=\"https://github.com/Tivix/django-rest-auth\" rel=\"nofollow noreferrer\">https://github.com/Tivix/django-rest-auth</a> promises fb login plus the reset password flows for an app.</p>\n\n<p>For a mobile+api blogpost read <a href=\"https://medium.com/@gabriel_gamil/react-native-expo-django-facebook-authentication-sign-in-83625c49da7\" rel=\"nofollow noreferrer\">https://medium.com/@gabriel_gamil/react-native-expo-django-facebook-authentication-sign-in-83625c49da7</a> (I was using react native and this was a helpful article)</p>\n",
                    "OwnerUserId": "630752",
                    "LastEditorUserId": "630752",
                    "LastEditDate": "2019-01-09T01:37:07.160",
                    "LastActivityDate": "2019-01-09T01:37:07.160",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "53368390",
                "ParentRepo": "https://github.com/http4k/http4k/blob/c7ada0c5127fd815903b1e8faf805ce2cbcdaffe/http4k-format-jackson/src/main/kotlin/org/http4k/format/Jackson.kt#L45",
                "StackOverflow_Post": {
                    "Id": "53368390",
                    "PostTypeId": "2",
                    "ParentId": "53361644",
                    "CreationDate": "2018-11-19T04:37:37.717",
                    "Score": "1",
                    "Body": "<p>Since the <code>ObjectMapper</code> instance is <a href=\"https://github.com/http4k/http4k/blob/c7ada0c5127fd815903b1e8faf805ce2cbcdaffe/http4k-format-jackson/src/main/kotlin/org/http4k/format/Jackson.kt#L45\" rel=\"nofollow noreferrer\">private within <code>ConfigurableJackson</code></a> you cannot get at it after construction to do any configuration.  </p>\n\n<p>So you either need to construct your own direct instance of <code>ConfigurableJackson</code> and pass in a customized <code>ObjectMapper</code> or you need to subclass <code>ConfigurableJackson</code> with your own class.  And then during the constructor, create an <code>ObjectMapper</code> (<em>see example below</em>) or intercept one being passed into your constructor and change its settings.</p>\n\n<p>Whatever you do, be sure you do not break the http4k framework or anything else that might be using the same instance.  You can see the defaults used by http4k <a href=\"https://github.com/http4k/http4k/blob/c7ada0c5127fd815903b1e8faf805ce2cbcdaffe/http4k-format-jackson/src/main/kotlin/org/http4k/format/Jackson.kt#L119-L126\" rel=\"nofollow noreferrer\">declared in their source code</a>:</p>\n\n<p></p>\n\n<pre><code>object Jackson : ConfigurableJackson(ObjectMapper()\n    .registerModule(defaultKotlinModuleWithHttp4kSerialisers)\n    .disableDefaultTyping()\n    .configure(FAIL_ON_UNKNOWN_PROPERTIES, false)\n    .configure(FAIL_ON_IGNORED_PROPERTIES, false)\n    .configure(USE_BIG_DECIMAL_FOR_FLOATS, true)\n    .configure(USE_BIG_INTEGER_FOR_INTS, true)\n)\n</code></pre>\n\n<p>You can use code similar to above to create your own instance.  </p>\n\n<p>See this thread for some conversation about this topic: <a href=\"https://github.com/http4k/http4k/issues/183\" rel=\"nofollow noreferrer\">https://github.com/http4k/http4k/issues/183</a></p>\n",
                    "OwnerUserId": "3679676",
                    "LastEditorUserId": "3679676",
                    "LastEditDate": "2018-11-19T05:34:58.137",
                    "LastActivityDate": "2018-11-19T05:34:58.137",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "53427376",
                "ParentRepo": "https://github.com/ericmjl/pyjanitor/blob/master/janitor/functions.py",
                "StackOverflow_Post": {
                    "Id": "53427376",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "53428663",
                    "CreationDate": "2018-11-22T09:12:49.733",
                    "Score": "-1",
                    "ViewCount": "234",
                    "Body": "<p>While renaming the dataframe, I need to preserve the original names. For e.g.</p>\n\n<pre><code>santandar_data = pd.read_csv(r\"train.csv\", nrows=40000)  \nsantandar_data.shape  \n\nsantandar_data.original_names=santandar_data.columns\n\nndf=santandar_data\n\nndf.original_names\n\nIndex(['ID', 'var3', 'var15', 'imp_ent_var16_ult1', 'imp_op_var39_comer_ult1',\n       'imp_op_var39_comer_ult3', 'imp_op_var40_comer_ult1',\n       'imp_op_var40_comer_ult3', 'imp_op_var40_efect_ult1',\n       'imp_op_var40_efect_ult3',\n       ...\n       'saldo_medio_var33_hace2', 'saldo_medio_var33_hace3',\n       'saldo_medio_var33_ult1', 'saldo_medio_var33_ult3',\n       'saldo_medio_var44_hace2', 'saldo_medio_var44_hace3',\n       'saldo_medio_var44_ult1', 'saldo_medio_var44_ult3', 'var38', 'TARGET'],\n      dtype='object', length=371)\n</code></pre>\n\n<p>The ndf dataframe object has a property original_names that works correctly. But when I use clean_names function, I do not get this functionality.</p>\n\n<pre><code>df=santandar_data.clean_names(case_type=\"upper\", remove_special=True).limit_column_characters(3)\ndf.original_names\n</code></pre>\n\n<blockquote>\n  <p>AttributeError: 'DataFrame' object has no attribute 'original_names'</p>\n</blockquote>\n\n<p>The clean_names function comes from:</p>\n\n<p><a href=\"https://github.com/ericmjl/pyjanitor/blob/master/janitor/functions.py\" rel=\"nofollow noreferrer\">https://github.com/ericmjl/pyjanitor/blob/master/janitor/functions.py</a></p>\n\n<p>What is the best way to change this function to include original column names as a property value?</p>\n",
                    "OwnerUserId": "139150",
                    "LastEditorUserId": "5178905",
                    "LastEditDate": "2018-11-22T09:34:34.147",
                    "LastActivityDate": "2018-11-22T10:17:42.373",
                    "Title": "Preserve original column names",
                    "Tags": "<python><pandas>",
                    "AnswerCount": "1",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "53556007",
                "ParentRepo": "https://github.com/encode/starlette",
                "StackOverflow_Post": {
                    "Id": "53556007",
                    "PostTypeId": "1",
                    "CreationDate": "2018-11-30T10:48:20.077",
                    "Score": "2",
                    "ViewCount": "1065",
                    "Body": "<p>Lately I've been playing around a little with the python 3 async features. Overal I'm quit happy with the 3.6 syntax and of course the performance boost you gain. One of the exciting projects evolving around the <code>ASGI</code> standard in my opinion is <a href=\"https://github.com/encode/starlette\" rel=\"nofollow noreferrer\">starlette</a>. I've got a sample app running where I'm reading data from a <code>hdf5</code> file. <code>h5py</code> does not support asynchronous I/O yet. Which leaves me with the question: does what I'm doing here make any sense at all? To my understanding this code runs synchronously after all. What is the recommended way to do I/O in async contexts?         </p>\n\n<pre><code>async def _flow(indexes):\n    print('received flow indexes %s ' %indexes)\n    # uses h5py under the hood\n    gr = GridH5ResultAdmin(gridadmin_f, results_f)\n    t = gr.nodes.timeseries(indexes=indexes)\n    data = t.only('s1').data\n    # data is a numpy array\n    return data['s1'].tolist()\n\n@app.route('/flow_velocity')\nasync def flow_results(request):\n\n    indexes_list = [[2,3,4,5], [6,7,8,9], [10,11,12,13]]\n\n    tasks = []\n    loop = asyncio.get_event_loop()\n    t0 = datetime.datetime.now()\n    for indexes in indexes_list:\n        print('Start getting indexes %s' % indexes)\n        # Launch a coroutine for each data fetch\n        task = loop.create_task(_flow(indexes))\n        tasks.append(task)\n\n    # Wait on, and then gather, all data\n    flow_data = await asyncio.gather(*tasks)\n    dt = (datetime.datetime.now() - t0).total_seconds()\n    print('elapsed time: {} [s]'.format(dt))\n\n    return JSONResponse({'flow_velocity': flow_data})\n</code></pre>\n\n<p>Logging:</p>\n\n<pre><code>INFO: Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\nStart getting indexes \"[2, 3, 4, 5]\"\nStart getting indexes \"[6, 7, 8, 9]\"\nStart getting indexes \"[10, 11, 12, 13]\"\nreceived flow indexes [2, 3, 4, 5] \nreceived flow indexes [6, 7, 8, 9] \nreceived flow indexes [10, 11, 12, 13]\nelapsed time: 1.49779 [s]\n</code></pre>\n",
                    "OwnerUserId": "1105929",
                    "LastActivityDate": "2019-08-01T03:16:05.490",
                    "Title": "How to read from (hdf5) file in async contexts?",
                    "Tags": "<python-3.x><python-asyncio><asgi><starlette>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "FavoriteCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "53642711",
                "ParentRepo": "https://github.com/sspkmnd/mkdocs-table-layout-problem",
                "StackOverflow_Post": {
                    "Id": "53642711",
                    "PostTypeId": "1",
                    "CreationDate": "2018-12-06T00:10:05.410",
                    "Score": "4",
                    "ViewCount": "738",
                    "Body": "<p>I am not really a html/css/js guy, but I am doing documentation for one project in <a href=\"https://www.mkdocs.org/\" rel=\"nofollow noreferrer\">MkDocs</a> with <a href=\"https://squidfunk.github.io/mkdocs-material/\" rel=\"nofollow noreferrer\">Material theme</a>. The problem here is that I have very wide tables and they are displayed differently in Chrome and Firefox, more concrete \u2013 they are completely unacceptable in Firefox.</p>\n\n<p>By default Chrome displays tables very nicely, it chooses column widths that look very nice and reasonable:</p>\n\n<p><a href=\"https://monosnap.com/file/LvtSxXhE5muFpz8aKhTPvbuoNkMOMN\" rel=\"nofollow noreferrer\">https://monosnap.com/file/LvtSxXhE5muFpz8aKhTPvbuoNkMOMN</a></p>\n\n<p>Unfortunately, in Firefox the table overflows the <em>container</em> which I suppose should not happen:</p>\n\n<p><a href=\"https://monosnap.com/file/u9bAq7pGarmGE5hhgawF84ah451HZz\" rel=\"nofollow noreferrer\">https://monosnap.com/file/u9bAq7pGarmGE5hhgawF84ah451HZz</a></p>\n\n<p>I tried different solutions to fix this, but in the end was not able to find the way to make it look in Firefox as in Chrome. It seems that Chrome uses some logic to display table in a <em>nice looking</em> way.</p>\n\n<p>The closest I can get to a Chrome version was to use the following css:</p>\n\n<pre class=\"lang-css prettyprint-override\"><code>table {\n  table-layout: fixed;\n  max-width: 100%;\n}\n\ntd {\n  word-wrap: break-word;\n}\n</code></pre>\n\n<p>It will force the table to stay inside the <em>container</em> and do not overflow, but how the table chooses widths for columns is not good:</p>\n\n<p><a href=\"https://monosnap.com/file/SJ6T20vIHpRTW5sy3RAa8RfY1Uchiq\" rel=\"nofollow noreferrer\">https://monosnap.com/file/SJ6T20vIHpRTW5sy3RAa8RfY1Uchiq</a></p>\n\n<p>I created a demo hosted on Github Pages: <a href=\"https://sspkmnd.github.io/mkdocs-table-layout-problem\" rel=\"nofollow noreferrer\">https://sspkmnd.github.io/mkdocs-table-layout-problem</a> (repo \u2013 <a href=\"https://github.com/sspkmnd/mkdocs-table-layout-problem\" rel=\"nofollow noreferrer\">https://github.com/sspkmnd/mkdocs-table-layout-problem</a>) Hope this will help to see the difference. Also, there is a <em>button</em> that changes the style for the table, so you can see the difference between <code>table-layout: fixed;</code> and <code>table-layout: auto;</code> \u2013 it is just above the table.</p>\n\n<p>The questions are:</p>\n\n<ol>\n<li>Is there a way to make it look in Firefox like in Chrome?</li>\n<li>Why it overflows the <em>container</em> in Firefox by default? I suppose this should not happen.</li>\n</ol>\n\n<p>PS: I suppose there is a way to set the width explicitly for columns in percent. I tried to achieve so, but I didn't find a way to assign a class to a table  <code>&lt;th&gt;</code> via Markdown (which is the source).</p>\n\n<p>Any ideas would be very much appreciated!</p>\n",
                    "OwnerUserId": "5282412",
                    "LastEditorUserId": "5282412",
                    "LastEditDate": "2018-12-06T17:52:17.067",
                    "LastActivityDate": "2018-12-06T19:10:14.523",
                    "Title": "Wide table differences in Chrome vs Firefox in mkdocs-material",
                    "Tags": "<html><css><mkdocs>",
                    "AnswerCount": "1",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "53983132",
                "ParentRepo": "https://github.com/besnik/tutorials/tree/master/docker-mediawiki",
                "StackOverflow_Post": {
                    "Id": "53983132",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "53983436",
                    "CreationDate": "2018-12-31T02:53:23.640",
                    "Score": "1",
                    "ViewCount": "482",
                    "Body": "<p>I want to run a MediaWiki inside a Docker container. I followed tutorial <a href=\"https://github.com/besnik/tutorials/tree/master/docker-mediawiki\" rel=\"nofollow noreferrer\">here</a>, using <a href=\"https://hub.docker.com/_/mediawiki/\" rel=\"nofollow noreferrer\">official mediawiki image</a>. I want to use sqlite instead of MySQL, to have less hassle with separate containers and its files. I've run the image, installed wiki and copied database and other directories from the container to local dir:</p>\n\n<pre><code>$ tree -d -L 2\n.\n\u2514\u2500\u2500 Social\n    \u251c\u2500\u2500 config\n    \u251c\u2500\u2500 data\n    \u251c\u2500\u2500 extensions\n    \u2514\u2500\u2500 images\n</code></pre>\n\n<p>Then I killed and removed docker image and run it again with:</p>\n\n<pre><code>docker run --name social-mediawiki -p 8080:80 \\\n    -v ~/Mediawiki/Social/config/LocalSettings.php:/var/www/html/LocalSettings.php \\\n    -v ~/Mediawiki/Social/images:/var/www/html/images \\\n    -v ~/Mediawiki/Social/extensions:/var/www/html/extensions \\\n    -v ~/Mediawiki/Social/data:/var/www/data \\\n    -d mediawiki\n</code></pre>\n\n<p>Unfortunately, it doesn't work as <a href=\"http://localhost:8080/index.php/Main_Page\" rel=\"nofollow noreferrer\">http://localhost:8080/index.php/Main_Page</a> page explodes with following exception</p>\n\n<pre><code>[847547d534f8a6acfbb81a43] /index.php/Main_Page Wikimedia\\Rdbms\\DBTransactionStateError from line 1312 of /var/www/html/includes/libs/rdbms/database/Database.php: Cannot execute query from MediaWiki\\Storage\\SqlBlobStore::fetchBlob while transaction status is ERROR.\n\nBacktrace:\n\n#0 /var/www/html/includes/libs/rdbms/database/Database.php(1095): Wikimedia\\Rdbms\\Database-&gt;assertTransactionStatus(string, string)\n#1 /var/www/html/includes/libs/rdbms/database/Database.php(1653): Wikimedia\\Rdbms\\Database-&gt;query(string, string)\n#2 /var/www/html/includes/libs/rdbms/database/Database.php(1730): Wikimedia\\Rdbms\\Database-&gt;select(string, array, array, string, array, array)\n#3 /var/www/html/includes/Storage/SqlBlobStore.php(329): Wikimedia\\Rdbms\\Database-&gt;selectRow(string, array, array, string, array)\n#4 /var/www/html/includes/Storage/SqlBlobStore.php(277): MediaWiki\\Storage\\SqlBlobStore-&gt;fetchBlob(string, integer)\n#5 /var/www/html/includes/libs/objectcache/WANObjectCache.php(1240): MediaWiki\\Storage\\SqlBlobStore-&gt;MediaWiki\\Storage\\{closure}(boolean, integer, array, NULL)\n#6 /var/www/html/includes/libs/objectcache/WANObjectCache.php(1114): WANObjectCache-&gt;doGetWithSetCallback(string, integer, Closure, array)\n#7 /var/www/html/includes/Storage/SqlBlobStore.php(279): WANObjectCache-&gt;getWithSetCallback(string, integer, Closure, array)\n#8 /var/www/html/includes/Storage/RevisionStore.php(921): MediaWiki\\Storage\\SqlBlobStore-&gt;getBlob(string, integer)\n#9 /var/www/html/includes/Storage/RevisionStore.php(865): MediaWiki\\Storage\\RevisionStore-&gt;loadSlotContent(MediaWiki\\Storage\\SlotRecord, NULL, NULL, NULL, integer)\n#10 [internal function]: MediaWiki\\Storage\\RevisionStore-&gt;MediaWiki\\Storage\\{closure}(MediaWiki\\Storage\\SlotRecord)\n#11 /var/www/html/includes/Storage/SlotRecord.php(308): call_user_func(Closure, MediaWiki\\Storage\\SlotRecord)\n#12 /var/www/html/includes/Storage/RevisionRecord.php(173): MediaWiki\\Storage\\SlotRecord-&gt;getContent()\n#13 /var/www/html/includes/Revision.php(937): MediaWiki\\Storage\\RevisionRecord-&gt;getContent(string, integer, User)\n#14 /var/www/html/includes/page/Article.php(368): Revision-&gt;getContent(integer, User)\n#15 /var/www/html/includes/page/Article.php(562): Article-&gt;fetchContentObject()\n#16 /var/www/html/includes/actions/ViewAction.php(68): Article-&gt;view()\n#17 /var/www/html/includes/MediaWiki.php(500): ViewAction-&gt;show()\n#18 /var/www/html/includes/MediaWiki.php(294): MediaWiki-&gt;performAction(Article, Title)\n#19 /var/www/html/includes/MediaWiki.php(861): MediaWiki-&gt;performRequest()\n#20 /var/www/html/includes/MediaWiki.php(524): MediaWiki-&gt;main()\n#21 /var/www/html/index.php(42): MediaWiki-&gt;run()\n#22 {main}\n</code></pre>\n\n<p>Sqlite file itself looks fine:</p>\n\n<pre><code>$ sudo sqlite3 my_wiki.sqlite \nsqlite&gt; PRAGMA integrity_check;\nok\nsqlite&gt; select * from page;\n1|0|Main_Page||0|1|0.468882297482|20181231020833||1|735|wikitext|\nsqlite&gt; \n</code></pre>\n\n<p>Dumping database into a new file (ad described <a href=\"https://stackoverflow.com/questions/18259692/how-to-recover-a-corrupt-sqlite3-database\">here</a>) didn't help. No change was made to <code>LocalSettings.php</code>, with except of debug information:</p>\n\n<pre><code>$wgShowExceptionDetails = true;\n$wgShowDBErrorBacktrace = true;\n$wgShowSQLErrors = true;\n</code></pre>\n\n<p>How can I make this work?</p>\n",
                    "OwnerUserId": "10850646",
                    "LastEditorUserId": "10850646",
                    "LastEditDate": "2018-12-31T03:56:43.290",
                    "LastActivityDate": "2018-12-31T03:56:43.290",
                    "Title": "MediaWiki raises DBTransactionStateError when it tries to read from sqlite db mounted to docker conainer",
                    "Tags": "<sqlite><docker><mediawiki>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "54007888",
                "ParentRepo": "https://github.com/testcontainers/testcontainer-go",
                "StackOverflow_Post": {
                    "Id": "54007888",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "54008959",
                    "CreationDate": "2019-01-02T14:14:07.940",
                    "Score": "0",
                    "ViewCount": "605",
                    "Body": "<p>I was trying out the sample of the page <a href=\"https://github.com/testcontainers/testcontainer-go\" rel=\"nofollow noreferrer\">https://github.com/testcontainers/testcontainer-go</a></p>\n\n<pre><code>package main\n\nimport (\n    \"context\"\n    \"fmt\"\n    \"net/http\"\n    \"testing\"\n\n    testcontainer \"github.com/testcontainers/testcontainer-go\"\n)\n\nfunc TestNginxLatestReturn(t *testing.T) {\n    ctx := context.Background()\n    req := testcontainer.ContainerRequest{\n        Image:        \"nginx\",\n        ExposedPorts: []string{\"80/tcp\"},\n    }\n...\n}\n</code></pre>\n\n<p>but when I put the code in the file <code>main.go</code> under <code>&lt;home&gt;/go/src/my-sample</code> and call <code>go get</code>, I just get this error:</p>\n\n<p>#</p>\n\n<pre><code> github.com/testcontainers/testcontainer-go\n../github.com/testcontainers/testcontainer-go/docker.go:116:32: cannot use inspect.NetworkSettings.NetworkSettingsBase.Ports (type \"github.com/docker/docker/vendor/github.com/docker/go-connections/nat\".PortMap) as type \"github.com/docker/go-connections/nat\".PortMap in return argument\n../github.com/testcontainers/testcontainer-go/docker.go:197:25: multiple-value uuid.NewV4() in single-value context\n../github.com/testcontainers/testcontainer-go/docker.go:219:3: cannot use exposedPortSet (type map[\"github.com/docker/go-connections/nat\".Port]struct {}) as type \"github.com/docker/docker/vendor/github.com/docker/go-connections/nat\".PortSet in field value\n../github.com/testcontainers/testcontainer-go/docker.go:261:3: cannot use exposedPortMap (type map[\"github.com/docker/go-connections/nat\".Port][]\"github.com/docker/go-connections/nat\".PortBinding) as type \"github.com/docker/docker/vendor/github.com/docker/go-connections/nat\".PortMap in field value\n</code></pre>\n\n<p>What am I doing wrong?</p>\n",
                    "OwnerUserId": "5247292",
                    "LastEditorUserId": "13860",
                    "LastEditDate": "2019-01-03T08:41:40.697",
                    "LastActivityDate": "2019-01-03T08:41:40.697",
                    "Title": "Go get problem when using testcontainer-go",
                    "Tags": "<go><testcontainers>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "54045147",
                "ParentRepo": "https://github.com/denysdovhan/spaceship-prompt",
                "StackOverflow_Post": {
                    "Id": "54045147",
                    "PostTypeId": "1",
                    "CreationDate": "2019-01-04T19:47:36.860",
                    "Score": "0",
                    "ViewCount": "678",
                    "Body": "<p><a href=\"https://i.stack.imgur.com/CVrWn.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/CVrWn.png\" alt=\"special characters on zsh prompt with oh-my-zsh\"></a></p>\n\n<p>I'm seeing some special characters after each command on zsh prompt (CentOS 6.10). I'm using oh-my-zsh and I've also installed Powerline fonts. </p>\n\n<p>I'm using <a href=\"https://github.com/denysdovhan/spaceship-prompt\" rel=\"nofollow noreferrer\">spaceship-prompt</a> installed using <a href=\"https://github.com/zplug/zplug\" rel=\"nofollow noreferrer\">zplug</a>.</p>\n",
                    "OwnerUserId": "454520",
                    "LastActivityDate": "2019-01-17T03:13:30.920",
                    "Title": "Special characters in zsh prompt with oh-my-zsh",
                    "Tags": "<zsh><centos6><oh-my-zsh>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "54654988",
                "ParentRepo": "https://github.com/wal-g/wal-g",
                "StackOverflow_Post": {
                    "Id": "54654988",
                    "PostTypeId": "1",
                    "CreationDate": "2019-02-12T16:51:38.650",
                    "Score": "2",
                    "ViewCount": "719",
                    "Body": "<p>I'm using AWS RDS and have a need to replicate \"database_a\" in an RDS instance to \"database_a\" in a different RDS instance.  The replication only needs to be once every 24 hours.</p>\n\n<p>I'm currently solving this with pg_dump and pg_restore but am wondering if there is a better (ie faster/more efficient) way I can go about things.  </p>\n\n<p>Using wal-e/g and RDS, is it at all possible for my use case to simply push the latest changes from the last say 24 hours?  The 2 RDS cannot speak to each other so all connection would be by S3.  I'm not clear what the docs mean by '<a href=\"https://github.com/wal-g/wal-g\" rel=\"nofollow noreferrer\">When uploading backups to S3, the user should pass in the path containing the backup started by Postgres</a>:' - does this mean i can create a pg backup to my EC2 and then point wal-g at this backup?</p>\n\n<p>Finally, is it at all possible to just use wal-e/g for complete backups (ie non incremental) just as i am doing now with pg_dump/pg_restore and in doing so would I see a speed improvement by switching?</p>\n\n<p>Thanks in advance,</p>\n",
                    "OwnerUserId": "1004781",
                    "LastActivityDate": "2019-12-03T13:29:05.283",
                    "Title": "wal-e/wal-g any benefit for simple backup and restore via S3",
                    "Tags": "<rds><wal><wal-e>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "54665459",
                "ParentRepo": "https://github.com/phalt/django-api-domains",
                "StackOverflow_Post": {
                    "Id": "54665459",
                    "PostTypeId": "2",
                    "ParentId": "42037633",
                    "CreationDate": "2019-02-13T08:19:19.750",
                    "Score": "17",
                    "Body": "<p>Paul Hallett put it all together in his beautiful and complete article: <a href=\"https://phalt.github.io/post/django-api-domains\" rel=\"noreferrer\">https://phalt.github.io/post/django-api-domains</a></p>\n<p>And the example here: <a href=\"https://github.com/phalt/django-api-domains\" rel=\"noreferrer\">https://github.com/phalt/django-api-domains</a></p>\n<p>In brief:</p>\n<blockquote>\n<h3>Django\u2019s style guide is old</h3>\n<p>The documentation, from the tutorials to the full docs, talk about a\nmodel-view-controller world in which Django renders HTML and delivers\nit to a web browser.</p>\n<p>Something about this struck me as odd - I have worked with Django\nsince 2012, and I only remember using it to render HTML once. Nearly\nall my time with Django, and all the time I have seen Django being\ntalked about at conferences has been to provide an API (usually with\nDjango REST Framework) to a frontend project. I would argue that this\nis actually the defacto standard for Django today. The documentation\nis out of date for the current popular use-cases. This is generally a\ntrend I am seeing with Django - the project is trying to modernise how\nit is run and even how to handle async properly. Maybe it is time\nDjango re-considered the design patterns it suggests for developers\ntoo?</p>\n<p>Back to my immediate problem: in order to help the team organise their\nsoftware better, I set out to find a good styleguide from the\ncommunity. I read about Domain Driven Resign, the benefits of bounded\ncontexts, and I found a nice styleguide by Hacksoft that we tried to\nuse. This was great! The documentation here was very sound, and\nperfect for smaller projects or small companies.</p>\n<p>But during our experimentation with it, we found it wasn\u2019t fit for\npurpose for a few reasons. Namely, the fact that is encouraged\nbusiness logic to live in the models. Django also recommends this and\nit is basically the active record pattern. In our experience with very\nlarge teams, keeping business logic tied to the models encouraged\ndevelopers to fill up models.py with tonnes of code. This makes it\nvery hard for developers to work on one file at the same time. Not to\nmention the fact that when a single file owns more than one problem in\na domain (presentation, data, controller, etc) it tends to suck all\nother problems into the file too.</p>\n</blockquote>\n",
                    "OwnerUserId": "4577565",
                    "LastEditorUserId": "-1",
                    "LastEditDate": "2020-06-20T09:12:55.060",
                    "LastActivityDate": "2019-02-13T08:40:02.903",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "55222081",
                "ParentRepo": "https://github.com/jatir/django-rest-framework-last-modified",
                "StackOverflow_Post": {
                    "Id": "55222081",
                    "PostTypeId": "2",
                    "ParentId": "55221394",
                    "CreationDate": "2019-03-18T13:04:25.400",
                    "Score": "-1",
                    "Body": "<p>@jozo,</p>\n\n<p>You can check the <a href=\"https://github.com/jatir/django-rest-framework-last-modified\" rel=\"nofollow noreferrer\">https://github.com/jatir/django-rest-framework-last-modified</a> django app to use the Last-Modified</p>\n\n<p>Edit:</p>\n\n<p>you can check the example in the test directory\n<a href=\"https://github.com/jatir/django-rest-framework-last-modified/blob/master/tests/views.py#L14\" rel=\"nofollow noreferrer\">https://github.com/jatir/django-rest-framework-last-modified/blob/master/tests/views.py#L14</a></p>\n",
                    "OwnerUserId": "7652827",
                    "LastEditorUserId": "7652827",
                    "LastEditDate": "2019-03-18T13:46:19.070",
                    "LastActivityDate": "2019-03-18T13:46:19.070",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "55261074",
                "ParentRepo": "https://github.com/turicas/rows",
                "StackOverflow_Post": {
                    "Id": "55261074",
                    "PostTypeId": "2",
                    "ParentId": "55261019",
                    "CreationDate": "2019-03-20T12:43:58.763",
                    "Score": "1",
                    "Body": "<p>It seems that you've over-indented the line that does the sum. It should be like this:</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>for row in CSVReader:\n    if CSVReader.line_num == 1:\n        continue \n    total += int(row[16])\n</code></pre>\n\n<p>Otherwise you'll only sum the values for the first row, which is exactly the one you want to skip.</p>\n\n<p><strong>EDIT:</strong>\nSince you said the previous change doesn't work, I'd suggest working with the excellent Python lib called <a href=\"https://github.com/turicas/rows\" rel=\"nofollow noreferrer\">rows</a>.</p>\n\n<p>With the following CSV (<code>fruits.csv</code>):</p>\n\n<pre><code>id,name,amount\n1,apple,3\n2,banana,6\n3,pineapple,2\n4,lemon,5\n</code></pre>\n\n<p>You can access columns directly by their name instead of their index:</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>import rows\ndata = rows.import_from_csv('fruits.csv')\nfor fruit_data in data: \n    print(fruit_data.name, fruit_data.amount)\n    # output:\n    # apple 3\n    # banana 6\n    # pineapple 2\n    # lemon 5\n</code></pre>\n\n<p><strong>NEW EDIT:</strong>\nAfter you've provided the data, I believe in your case you could do something like:</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>import rows\ndata = rows.import_from_csv('Data103.csv')\nprint(data.field_names[16])  # prints the field name\n\ntotal = 0\nfor row in data: \n    value = row.&lt;column_name&gt; \n    value = value.replace(',', '')  # remove commas\n    total += float(value)\nprint (total)\n</code></pre>\n",
                    "OwnerUserId": "1060162",
                    "LastEditorUserId": "1060162",
                    "LastEditDate": "2019-03-22T15:46:05.140",
                    "LastActivityDate": "2019-03-22T15:46:05.140",
                    "CommentCount": "15",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "55269153",
                "ParentRepo": "https://github.com/ibm-cloud-architecture/refarch-eda/blob/master/docs/kafka/monitoring.md",
                "StackOverflow_Post": {
                    "Id": "55269153",
                    "PostTypeId": "1",
                    "CreationDate": "2019-03-20T19:54:32.957",
                    "Score": "0",
                    "ViewCount": "440",
                    "Body": "<p>I am trying to do this without using Confluent Control Center, since I do not have a license.</p>\n\n<p>I am able to see the Kafka Broker metrics by using <code>dcos task metrics details &lt;broker-id&gt;</code> and see that all of these are already exposed on my DCOS Prometheus instance.</p>\n\n<p>However, I do not see any consumer/producer metrics available on Prometheus, despite having some producers/consumer tasks on dcos. </p>\n\n<p>Is there a process I can follow to expose kafka prodcuer/consumer metrics on dcos? I tried the following <a href=\"https://github.com/ibm-cloud-architecture/refarch-eda/blob/master/docs/kafka/monitoring.md\" rel=\"nofollow noreferrer\">https://github.com/ibm-cloud-architecture/refarch-eda/blob/master/docs/kafka/monitoring.md</a> . </p>\n\n<p>But from my understanding we cannot use JMX on a Kafka instance hosted on DCOS (yet) (soruce: <a href=\"https://jira.mesosphere.com/browse/DCOS_OSS-3632?page=com.atlassian.jira.plugin.system.issuetabpanels%3Achangehistory-tabpanel\" rel=\"nofollow noreferrer\">https://jira.mesosphere.com/browse/DCOS_OSS-3632?page=com.atlassian.jira.plugin.system.issuetabpanels%3Achangehistory-tabpanel</a>)</p>\n\n<p>Any ideas?</p>\n",
                    "OwnerUserId": "11126265",
                    "LastEditorUserId": "2308683",
                    "LastEditDate": "2019-03-21T18:47:03.670",
                    "LastActivityDate": "2019-03-21T18:47:03.670",
                    "Title": "Is it possible to monitor kafka producer/consumer metrics in DCOS?",
                    "Tags": "<apache-kafka><prometheus><confluent-platform><mesosphere><dcos>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "55337683",
                "ParentRepo": "https://github.com/ansible/molecule/blob/fc90dfd6c8a5fd3a3068b9cc8311dc176ab261cd/molecule/provisioner/ansible.py#L203-L208",
                "StackOverflow_Post": {
                    "Id": "55337683",
                    "PostTypeId": "2",
                    "ParentId": "55243571",
                    "CreationDate": "2019-03-25T12:21:24.967",
                    "Score": "1",
                    "Body": "<p>Molecule does this by setting some sensible defaults for ANSIBLE_ROLES_PATH:\n<a href=\"https://github.com/ansible/molecule/blob/fc90dfd6c8a5fd3a3068b9cc8311dc176ab261cd/molecule/provisioner/ansible.py#L203-L208\" rel=\"nofollow noreferrer\">Click me for source code</a></p>\n\n<p>There is also the concept of the <a href=\"https://github.com/ansible/molecule/blob/adb9fde29c05620be4b3b88e272339d9ec8b93bd/molecule/config.py#L133\" rel=\"nofollow noreferrer\">\"project directory\"</a> which is the directory that molecule is run from. This will be your role directory.</p>\n",
                    "OwnerUserId": "4834431",
                    "LastActivityDate": "2019-03-25T12:21:24.967",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "55409444",
                "ParentRepo": "https://github.com/liampauling/betfair",
                "StackOverflow_Post": {
                    "Id": "55409444",
                    "PostTypeId": "1",
                    "CreationDate": "2019-03-29T01:53:48.093",
                    "Score": "0",
                    "ViewCount": "544",
                    "Body": "<p>I have events  (matches i.e. Richmond vs Collingwood) and their respective IDs for a given competition, in my case AFL, however when trying to get the market IDs associated with these events, the API only gives the competition market ID as a response. How do I change my request so that this information is also given?</p>\n\n<p>The Python library I am using is: <a href=\"https://github.com/liampauling/betfair\" rel=\"nofollow noreferrer\">https://github.com/liampauling/betfair</a></p>\n\n<p>The following is the code I'm using to 1. get the competition ID for afl, 2. get the event IDs and names for all of the matches in that competition, and 3. get the market IDs for the events.</p>\n\n<p>In [1]:</p>\n\n<pre><code>competition_id = client.betting.list_competitions(filter=filters.market_filter(event_ids=event_ids))[-1].competition.id\n</code></pre>\n\n<p>Out [1]:\n<code>11897406</code></p>\n\n<p>In [2]:</p>\n\n<pre><code>events = client.betting.list_events(\n    filter=filters.market_filter(\n        competition_ids=[competition_id]))\n\nfor event_result in events:\n    print(event_result.event.name, event_result.event.id)\n\n</code></pre>\n\n<p>Out[2]:</p>\n\n<pre><code>AFL 28159788\nBrownlow Medal 2019 28927640\nHawthorn v Western Bulldogs 29182265\nNorth Melbourne v Brisbane 29182264\nGold Coast v Fremantle 29182266\nPort Adelaide v Carlton 29182261\nFavourites To Win 29203764\nGeelong v Melbourne 29182263\nWest Coast v GWS 29182262\nSydney v Adelaide 29182257\nWomen's AFL 28113600\nEssendon v St Kilda 29182258\nAFL Round 2 Multis 29195364\nAdelaide (W) v Carlton (W) 29199747\n</code></pre>\n\n<p>In [3]:</p>\n\n<pre><code>AFL_market_catalogue = client.betting.list_market_catalogue(filter=filters.market_filter(event_ids=event_ids),\n                                                           market_projection=['EVENT', 'COMPETITION'])[0]\n</code></pre>\n\n<p>Out [3]:</p>\n\n<pre><code>{\"marketId\":\"1.148783689\",\"marketName\":\"Premiers 2019\",\"totalMatched\":293415.056733,\"competition\":{\"id\":\"11897406\",\"name\":\"AFL\"},\"event\":{\"id\":\"28159788\",\"name\":\"AFL\",\"countryCode\":\"AU\",\"timezone\":\"GMT\",\"openDate\":\"2099-01-01T00:00:00.000Z\"}}\n</code></pre>\n\n<p>As shown in the output of 3, the only marketID returned is that of the premiers 2019 - when I need Hawthorn v Western Bulldogs, North Melbourne v Brisbane and so on.</p>\n",
                    "OwnerUserId": "11133970",
                    "LastEditorUserId": "472495",
                    "LastEditDate": "2019-03-30T14:57:51.940",
                    "LastActivityDate": "2019-04-04T13:56:40.053",
                    "Title": "Market IDs for events cannot be found through their event IDs - Betfair",
                    "Tags": "<python-3.x><betfair>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "55435292",
                "ParentRepo": "https://github.com/omu/nokul/blob/develop/lib/tasks/quality.rake",
                "StackOverflow_Post": {
                    "Id": "55435292",
                    "PostTypeId": "2",
                    "ParentId": "55433091",
                    "CreationDate": "2019-03-30T20:11:55.097",
                    "Score": "0",
                    "Body": "<p>Unfortunately, not possible.</p>\n\n<p>Rubocop is going to find issues, even if you bootstrap a new Rails project from scratch. For example some code lines will be detected as offense by the <code>Metrics/LineLength</code> cop.</p>\n\n<p>You may be wondering why Rails doesn't fix these issues beforehand, so people can get a fresh project without any offenses. The answer is, Rails, as a project is not accepting pull requests related to 'cosmetic' changes. Therefore, no one is fixing these issues. <a href=\"https://github.com/rails/rails/pull/13771#issuecomment-32746700\" rel=\"nofollow noreferrer\">Here is</a> the explanation of this decision. Same situation exists for tools like Devise, Simpleform etc.</p>\n\n<p>On the other hand, Rubocop is a great tool, but not all the developers agree with the default settings. That's why something called <code>.rubocop.yml</code> exists.</p>\n\n<p>I'm a big fan of code quality, so I really appreciate your intention. You can try to fix many of these offenses by calling rubocop with an <code>-a</code> flag (<code>rubocop -a</code>), and fix the rest manually. After this point you will not get similar offense messages.</p>\n\n<p>I'm using Rubocop to prevent ruby code smells, erblint as ERB linter and HTMLHint as HTML linter. I combined all these tools in a rake task called <code>quality</code>. When I run <code>quality:all</code>, I'm automatically checking my codebase against errors, typos and offenses. You can see the task <a href=\"https://github.com/omu/nokul/blob/develop/lib/tasks/quality.rake\" rel=\"nofollow noreferrer\">here</a>.</p>\n",
                    "OwnerUserId": "818033",
                    "LastActivityDate": "2019-03-30T20:11:55.097",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "55499852",
                "ParentRepo": "https://github.com/weaveworks/eksctl",
                "StackOverflow_Post": {
                    "Id": "55499852",
                    "PostTypeId": "2",
                    "ParentId": "52010459",
                    "CreationDate": "2019-04-03T16:19:24.067",
                    "Score": "1",
                    "Body": "<p>Just want to append to <a href=\"https://github.com/awslabs/amazon-eks-ami/issues/193\" rel=\"nofollow noreferrer\">this issue</a>:</p>\n\n<p>If you create EKS cluster by <a href=\"https://github.com/weaveworks/eksctl\" rel=\"nofollow noreferrer\">eksctl</a> then you can append to NodeGroup creation yaml:</p>\n\n<pre><code> preBootstrapCommand:\n      - \"sed -i -e 's/1024:4096/65536:65536/g' /etc/sysconfig/docker\"\n      - \"systemctl restart docker\"\n</code></pre>\n\n<p>This will solve the problem for newly created cluster by fixing docker daemon config.</p>\n",
                    "OwnerUserId": "1573395",
                    "LastActivityDate": "2019-04-03T16:19:24.067",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "55511659",
                "ParentRepo": "https://github.com/samuelcolvin/watchgod",
                "StackOverflow_Post": {
                    "Id": "55511659",
                    "PostTypeId": "2",
                    "ParentId": "55511553",
                    "CreationDate": "2019-04-04T08:50:19.440",
                    "Score": "1",
                    "Body": "<p>You can use <a href=\"https://github.com/samuelcolvin/watchgod\" rel=\"nofollow noreferrer\">watchgod</a> for this purpose. This may be a comment too, not sure if it deserves to be na answer.</p>\n",
                    "OwnerUserId": "1271185",
                    "LastEditorUserId": "426790",
                    "LastEditDate": "2021-09-16T19:15:26.033",
                    "LastActivityDate": "2021-09-16T19:15:26.033",
                    "CommentCount": "3",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "55520484",
                "ParentRepo": "https://github.com/zentralopensource/zentral",
                "StackOverflow_Post": {
                    "Id": "55520484",
                    "PostTypeId": "2",
                    "ParentId": "55520047",
                    "CreationDate": "2019-04-04T16:03:39.423",
                    "Score": "5",
                    "Body": "<p>When osquery is running in daemon mode, you can enable the <a href=\"https://osquery.readthedocs.io/en/stable/deployment/remote/\" rel=\"nofollow noreferrer\">distributed query facilities</a>. When this is enabled, osqueryd will periodically check in to a remote server to see whether there are queries for it to execute (typical intervals for this check range from 10 seconds to 1 minute).</p>\n\n<p>Note that due to the nature of the environments that osquery runs in, the osquery agent does not listen for incoming connections. It only ever makes outgoing connections to a remote server to check for queries to execute.</p>\n\n<p>To take advantage of this, you need a server implementing the osquery remote APIs. There are a handful of open-source options available:</p>\n\n<p><a href=\"https://github.com/kolide/fleet\" rel=\"nofollow noreferrer\">Fleet</a> (disclaimer: I build this)</p>\n\n<p><a href=\"https://github.com/zentralopensource/zentral\" rel=\"nofollow noreferrer\">Zentral</a></p>\n\n<p><a href=\"https://github.com/mwielgoszewski/doorman\" rel=\"nofollow noreferrer\">Doorman</a></p>\n\n<p><a href=\"https://github.com/OktaSecurityLabs/sgt\" rel=\"nofollow noreferrer\">SGT</a></p>\n\n<p><strong>Security note</strong>: providing remote execution on an osquery agent can be very dangerous since it can retrieve sensitive information on the device it runs on. If you plan to serve some sort of a web page allowing direct queries on your agent, be aware that since osquery provide an SQL abstraction of your system, it can be vulnerable to <a href=\"https://www.netsparker.com/blog/web-security/osquery-injection/\" rel=\"nofollow noreferrer\">injections</a>. </p>\n",
                    "OwnerUserId": "491710",
                    "LastEditorUserId": "2664350",
                    "LastEditDate": "2019-06-19T11:30:55.480",
                    "LastActivityDate": "2019-06-19T11:30:55.480",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "55818628",
                "ParentRepo": "https://github.com/arduino/arduino-cli",
                "StackOverflow_Post": {
                    "Id": "55818628",
                    "PostTypeId": "2",
                    "ParentId": "8189306",
                    "CreationDate": "2019-04-23T20:04:01.450",
                    "Score": "6",
                    "Body": "<h1>Official CLI tool</h1>\n\n<p>The arduino team is developing a <strong>cli</strong> client\n<a href=\"https://github.com/arduino/arduino-cli\" rel=\"noreferrer\">https://github.com/arduino/arduino-cli</a></p>\n\n<p><strong>Announcement</strong>: <a href=\"https://blog.arduino.cc/2018/08/24/announcing-the-arduino-command-line-interface-cli/\" rel=\"noreferrer\">https://blog.arduino.cc/2018/08/24/announcing-the-arduino-command-line-interface-cli/</a></p>\n\n<p>You can do almost everything with this, from downloading boards and libraries, to compile and upload scripts. What's missing is the monitoring part.</p>\n\n<p>To monitor in linux you can still use the commands <code>stty</code> to configure port and <code>cat</code> to read it.</p>\n\n<pre class=\"lang-sh prettyprint-override\"><code>stty -F /dev/ttyACM0 38400 # &lt;-- Baud rate. The number in Serial.begin()\ncat /dev/ttyACM0 # &lt;-- Port\n</code></pre>\n\n<p>You can find the port with <strong>arduino-cli</strong></p>\n\n<pre><code>arduino-cli board list\n</code></pre>\n\n<hr>\n\n<p>Full instructions in the <a href=\"https://github.com/arduino/Arduino-cli\" rel=\"noreferrer\">Github repo</a> and the man page:</p>\n\n<pre class=\"lang-sh prettyprint-override\"><code>    $ arduino-cli Arduino Command Line Interface (arduino-cli).\n\n    Usage:   arduino-cli [command]\n\n    Examples: arduino &lt;command&gt; [flags...]\n\n    Available Commands:\n      board         Arduino board commands.\n      compile       Compiles Arduino sketches.\n      config        Arduino Configuration Commands.\n      core          Arduino Core operations.\n      help          Help about any command\n      lib           Arduino commands about libraries.\n      sketch        Arduino CLI Sketch Commands.\n      upload        Upload Arduino sketches.\n      version       Shows version number of Arduino CLI.\n</code></pre>\n",
                    "OwnerUserId": "3163120",
                    "LastEditorUserId": "3163120",
                    "LastEditDate": "2019-11-13T22:58:01.987",
                    "LastActivityDate": "2019-11-13T22:58:01.987",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "55818628",
                "ParentRepo": "https://github.com/arduino/Arduino-cli",
                "StackOverflow_Post": {
                    "Id": "55818628",
                    "PostTypeId": "2",
                    "ParentId": "8189306",
                    "CreationDate": "2019-04-23T20:04:01.450",
                    "Score": "6",
                    "Body": "<h1>Official CLI tool</h1>\n\n<p>The arduino team is developing a <strong>cli</strong> client\n<a href=\"https://github.com/arduino/arduino-cli\" rel=\"noreferrer\">https://github.com/arduino/arduino-cli</a></p>\n\n<p><strong>Announcement</strong>: <a href=\"https://blog.arduino.cc/2018/08/24/announcing-the-arduino-command-line-interface-cli/\" rel=\"noreferrer\">https://blog.arduino.cc/2018/08/24/announcing-the-arduino-command-line-interface-cli/</a></p>\n\n<p>You can do almost everything with this, from downloading boards and libraries, to compile and upload scripts. What's missing is the monitoring part.</p>\n\n<p>To monitor in linux you can still use the commands <code>stty</code> to configure port and <code>cat</code> to read it.</p>\n\n<pre class=\"lang-sh prettyprint-override\"><code>stty -F /dev/ttyACM0 38400 # &lt;-- Baud rate. The number in Serial.begin()\ncat /dev/ttyACM0 # &lt;-- Port\n</code></pre>\n\n<p>You can find the port with <strong>arduino-cli</strong></p>\n\n<pre><code>arduino-cli board list\n</code></pre>\n\n<hr>\n\n<p>Full instructions in the <a href=\"https://github.com/arduino/Arduino-cli\" rel=\"noreferrer\">Github repo</a> and the man page:</p>\n\n<pre class=\"lang-sh prettyprint-override\"><code>    $ arduino-cli Arduino Command Line Interface (arduino-cli).\n\n    Usage:   arduino-cli [command]\n\n    Examples: arduino &lt;command&gt; [flags...]\n\n    Available Commands:\n      board         Arduino board commands.\n      compile       Compiles Arduino sketches.\n      config        Arduino Configuration Commands.\n      core          Arduino Core operations.\n      help          Help about any command\n      lib           Arduino commands about libraries.\n      sketch        Arduino CLI Sketch Commands.\n      upload        Upload Arduino sketches.\n      version       Shows version number of Arduino CLI.\n</code></pre>\n",
                    "OwnerUserId": "3163120",
                    "LastEditorUserId": "3163120",
                    "LastEditDate": "2019-11-13T22:58:01.987",
                    "LastActivityDate": "2019-11-13T22:58:01.987",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "55849209",
                "ParentRepo": "https://github.com/poseidon/typhoon",
                "StackOverflow_Post": {
                    "Id": "55849209",
                    "PostTypeId": "2",
                    "ParentId": "47203959",
                    "CreationDate": "2019-04-25T12:21:26.713",
                    "Score": "0",
                    "Body": "<p>You can use <a href=\"https://github.com/poseidon/typhoon\" rel=\"nofollow noreferrer\">typhoon</a> which can be used to provision an HA kubernetes cluster.</p>\n\n<p>Here is a sample configuration which I used to bring up my own <a href=\"https://github.com/tasdikrahman/infra/tree/master/aws/ap-south-1/homelab/poseidon\" rel=\"nofollow noreferrer\">home cluster</a>. </p>\n\n<p>A few advantages of typhoon are that you have the option of choosing your choice of a cloud provider for provisioning your infrastructure, which is done using terraform and the fact that it gives you upstream k8s is a big plus too. </p>\n\n<p>Internally, it uses <a href=\"https://github.com/kubernetes-incubator/bootkube\" rel=\"nofollow noreferrer\">bootkube</a> to bring up the temporary control plane, which would consist of </p>\n\n<ul>\n<li>api-server</li>\n<li>controller-manager</li>\n<li>scheduler</li>\n</ul>\n\n<p>and then when we have the temporary control plane object, we inject the objects to the API server to have our k8s cluster. </p>\n\n<p>Have a look at this <a href=\"https://www.youtube.com/watch?v=jIZ8NaR7msI\" rel=\"nofollow noreferrer\">kubecon talk given by CoreOS</a> which explains how this is working. </p>\n",
                    "OwnerUserId": "3834059",
                    "LastActivityDate": "2019-04-25T12:21:26.713",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "55888414",
                "ParentRepo": "https://github.com/square/workflow/issues/66",
                "StackOverflow_Post": {
                    "Id": "55888414",
                    "PostTypeId": "1",
                    "CreationDate": "2019-04-28T08:29:54.743",
                    "Score": "1",
                    "ViewCount": "34",
                    "Body": "<p>I'm trying to create an application that uses workflow (Square's Android library)</p>\n\n<p>I see on their Github project page that migration to AndroidX is currently blocked: <a href=\"https://github.com/square/workflow/issues/66\" rel=\"nofollow noreferrer\">https://github.com/square/workflow/issues/66</a></p>\n\n<p>Does that mean that I can't use it in my application if I'm using AndroidX libraries?</p>\n",
                    "OwnerUserId": "11422056",
                    "LastActivityDate": "2019-04-28T08:29:54.743",
                    "Title": "How can I use workflow library in application using AndroidX?",
                    "Tags": "<android><androidx>",
                    "AnswerCount": "0",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "55897653",
                "ParentRepo": "https://github.com/vapor/documentation/issues/395",
                "StackOverflow_Post": {
                    "Id": "55897653",
                    "PostTypeId": "2",
                    "ParentId": "55897286",
                    "CreationDate": "2019-04-29T05:50:43.400",
                    "Score": "2",
                    "Body": "<p>Indeed, at the time of this post, a <a href=\"https://www.google.com/search?as_q=ssl&amp;as_sitesearch=docs.vapor.codes%2F3.0&amp;safe=active\" rel=\"nofollow noreferrer\">Vapor 3 docs 'site:docs.vapor.codes/3.0' search did not find any information on how to setup SSL (or TLS) with Vapor 3</a>.</p>\n\n<p>Vapor <a href=\"https://github.com/vapor/documentation/issues/395\" rel=\"nofollow noreferrer\">issue #359 \"How to use certificate in vapor 3?\"</a> provides the guidance that:</p>\n\n<blockquote>\n  <p><em>Vapor 3 only supports plaintext HTTP.</em> You'll want to add something like NGINX in front for TLS. The docs from Vapor 2 should help: <a href=\"https://docs.vapor.codes/2.0/deploy/nginx/\" rel=\"nofollow noreferrer\">https://docs.vapor.codes/2.0/deploy/nginx/</a></p>\n  \n  <p>FWIW, Vapor 4 will include TLS support.</p>\n</blockquote>\n\n<p>For Vapor 3, SSL can be provided via a proxy such as NGINX: </p>\n\n<ol>\n<li><p>Proxy Vapor behind NGINX. See <a href=\"https://docs.vapor.codes/2.0/deploy/nginx/\" rel=\"nofollow noreferrer\">Vapor 2 docs \"Deploying with NGINX\"</a> or <a href=\"https://docs.vapor.codes/4.0/deploy/nginx/\" rel=\"nofollow noreferrer\">Vapor 4 docs \"Deploying with NGINX\"</a>. <em>The \"Deploying with NGINX\" pages are generally relevant to Vapor 3.</em></p></li>\n<li><p>Then, follow one of the more readily available tutorials about setting up Let\u2019s Encrypt SSL/TLS Certificates with NGINX. For example:</p>\n\n<ul>\n<li><a href=\"https://certbot.eff.org/lets-encrypt/ubuntubionic-nginx\" rel=\"nofollow noreferrer\">Certbot: \"Nginx on Ubuntu 18.04 LTS (bionic)\"</a></li>\n<li><a href=\"https://www.nginx.com/blog/using-free-ssltls-certificates-from-lets-encrypt-with-nginx/\" rel=\"nofollow noreferrer\">NGINX.com: \"Using Free Let\u2019s Encrypt SSL/TLS Certificates with NGINX\"</a> </li>\n<li><a href=\"https://www.digitalocean.com/community/tutorials/how-to-secure-nginx-with-let-s-encrypt-on-ubuntu-18-04\" rel=\"nofollow noreferrer\">Digital Ocean: How To Secure Nginx with Let's Encrypt on Ubuntu 18.04 </a></li>\n</ul></li>\n</ol>\n\n<p>Otherwise, the yet-to-be-released Vapor 4 (which will require Swift 5 and NIO 2.0) is expected to have support SSL/TLS without requiring an SSL/TLS enabled proxy.</p>\n",
                    "OwnerUserId": "3103448",
                    "LastEditorUserId": "3103448",
                    "LastEditDate": "2020-02-11T18:17:08.703",
                    "LastActivityDate": "2020-02-11T18:17:08.703",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "56025327",
                "ParentRepo": "https://github.com/20c/rdap/issues",
                "StackOverflow_Post": {
                    "Id": "56025327",
                    "PostTypeId": "2",
                    "ParentId": "56024070",
                    "CreationDate": "2019-05-07T14:53:10.293",
                    "Score": "1",
                    "Body": "<p>The archive <code>rdap-0.5.0.tar.gz</code> contains a subdirectory <code>rdap-0.5.0/Ctl/tmp/git@github.com:20c/</code>. The name is invalid because it contains <code>:</code> \u2014 a forbidden character in w32 (because of <code>C:</code>).</p>\n\n<p>This is a bug in the package. Please report it at <a href=\"https://github.com/20c/rdap/issues\" rel=\"nofollow noreferrer\">https://github.com/20c/rdap/issues</a>.</p>\n",
                    "OwnerUserId": "7976758",
                    "LastActivityDate": "2019-05-07T14:53:10.293",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "56072796",
                "ParentRepo": "https://github.com/sbischoff-ai/pygase",
                "StackOverflow_Post": {
                    "Id": "56072796",
                    "PostTypeId": "2",
                    "ParentId": "29440764",
                    "CreationDate": "2019-05-10T07:31:36.263",
                    "Score": "7",
                    "Body": "<p>This is a late answer, but it should give people looking for python networking libraries and guides for games a good overview.</p>\n\n<p><a href=\"https://github.com/sbischoff-ai/pygase\" rel=\"noreferrer\">pygase</a>\nThis is a library I wrote myself for various indie projects, because no other libraries met all my requirements. It's well documented and quite opinionated. It takes into account most learnings in terms of game networking that have been made in the past decades and the API is rather high-level. It's also actively developed and maintained by me. </p>\n\n<p><a href=\"https://github.com/chr15m/PodSixNet\" rel=\"noreferrer\">podsixnet</a>\nA really well-designed low-level game networking API that should work for any kind of game. You still have some decisions to make architecture-wise that require a deeper understanding of game networking.</p>\n\n<p><a href=\"https://github.com/Ganapati/Simple-Game-Server\" rel=\"noreferrer\">simple-game-server</a>\nNot really a library, more a ready-made server that organizes \"rooms\" of players, that can exchange messages directly. It's a simple concept that only really works for small games that are not too twitchy.</p>\n\n<p>If you want some deep and practical knowledge about game networking, look <a href=\"https://gafferongames.com/categories/game-networking/\" rel=\"noreferrer\">here</a>. Together with the docs for the <code>socket</code> and <code>SocketServer</code> packages this should enable anyone to write great networking code for games in python.</p>\n\n<p>Cheers, Silas</p>\n",
                    "OwnerUserId": "9926654",
                    "LastActivityDate": "2019-05-10T07:31:36.263",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "56103725",
                "ParentRepo": "https://github.com/browncoat-ninjas/nimoy",
                "StackOverflow_Post": {
                    "Id": "56103725",
                    "PostTypeId": "2",
                    "ParentId": "10993839",
                    "CreationDate": "2019-05-12T21:45:38.860",
                    "Score": "5",
                    "Body": "<p>I'm also big fan of Spock framework in Java/Groowy world. In search similar in Python. In my searching I found <a href=\"https://github.com/browncoat-ninjas/nimoy\" rel=\"noreferrer\">nimoy</a> which looks very promising.</p>\n\n<p>Example from official page:</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>from nimoy.specification import Specification\n\nclass MySpec(Specification):\n\n    def my_feature_method(self):\n        with given:\n            a = value_of_a\n            b = value_of_b\n\n        with expect:\n            (a * b) == expected_value\n\n        with where:\n            value_of_a | value_of_b | expected_value\n            1          | 10         | 10\n            2          | 20         | 40\n</code></pre>\n\n<p>And there also author <a href=\"https://medium.com/python-pandemonium/python-needs-a-fresh-testing-framework-19b41f3aa2d\" rel=\"noreferrer\">blog post</a> why it is born.</p>\n",
                    "OwnerUserId": "307525",
                    "LastActivityDate": "2019-05-12T21:45:38.860",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "56215933",
                "ParentRepo": "https://github.com/dansiegel/Prism.Container.Extensions",
                "StackOverflow_Post": {
                    "Id": "56215933",
                    "PostTypeId": "2",
                    "ParentId": "56214206",
                    "CreationDate": "2019-05-20T07:12:52.683",
                    "Score": "1",
                    "Body": "<p>By default Prism does not support Microsoft DI. However if this is a need you have you may want to try out the <a href=\"https://github.com/dansiegel/Prism.Container.Extensions\" rel=\"nofollow noreferrer\">Prism.Container.Extensions</a>. That project has several helpers available including the ability to handle working with <code>IServiceProvider</code> and <code>IServiceCollection</code> along with a package to make working with Shiny which uses Microsoft DI completely seamless. You can find the out more on the how to on GitHub.</p>\n",
                    "OwnerUserId": "5699454",
                    "LastActivityDate": "2019-05-20T07:12:52.683",
                    "CommentCount": "4",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "56229030",
                "ParentRepo": "https://github.com/greenape/mknotebooks",
                "StackOverflow_Post": {
                    "Id": "56229030",
                    "PostTypeId": "1",
                    "CreationDate": "2019-05-20T22:39:19.673",
                    "Score": "2",
                    "ViewCount": "885",
                    "Body": "<p>I am trying to use <a href=\"http://mkdocs.org/\" rel=\"nofollow noreferrer\">mkdocs</a> with <a href=\"https://github.com/greenape/mknotebooks\" rel=\"nofollow noreferrer\">mknotebooks</a> to build a website out of Jupyter Notebook and markdown files. All works well, except, the visual appearance of input and output cells in the resulting html pages is identical, making it hard to understand.</p>\n\n<p>For instance, in a notebook, input and output cells differently as shown below:\n<img src=\"https://user-images.githubusercontent.com/6750179/57325254-7b863180-70be-11e9-962e-e1bf852e4ea7.png\" alt=\"correct appearance\"></p>\n\n<p>However, when I export to markdown, then to html, they appear similar:\n<img src=\"https://user-images.githubusercontent.com/6750179/57325151-4548b200-70be-11e9-9cb0-6f3227d91c9a.png\" alt=\"current appearance\"></p>\n\n<p>I tried handling this with CSS. However, the <code>div</code>s of input and output cells are not of different classes, making it hard to define a different style.</p>\n\n<p>I am currently playing with <a href=\"https://github.com/jupyter/nbconvert/blob/master/nbconvert/templates/markdown.tpl\" rel=\"nofollow noreferrer\">nbconvert markdown templates</a>. However, I cannot figure out, what to modify so output cells appear differently. By default, they are indented by 1 tab space, which it appears is not sufficient to distinguish them when exported to HTML.</p>\n\n<p>My custom template file looks like below:</p>\n\n<pre class=\"lang-html prettyprint-override\"><code>{% extends 'markdown.tpl' %}\n\n&lt;!-- adds call number to input prompts --&gt;\n{% block in_prompt %}\n**In [{{ cell.execution_count }}]:**\n{% endblock in_prompt %}\n\n&lt;!-- need help - make outputs appear different, perhaps different background cell color? --&gt;\n{% block output %}\n    {{cell.source}}\n{% endblock output %}\n\n\n{% block markdowncell scoped %} \n{{ cell.source | wrap_text(80) }} \n{% endblock markdowncell %} \n...\n</code></pre>\n",
                    "OwnerUserId": "2471846",
                    "LastActivityDate": "2019-05-21T15:59:14.170",
                    "Title": "What markdown template do I need such that output cells in Jupyter notebooks look different from input cells when exporting using nbconvert",
                    "Tags": "<python><jupyter-notebook><markdown><nbconvert><mkdocs>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "56262627",
                "ParentRepo": "https://github.com/clementtsang/bottom",
                "StackOverflow_Post": {
                    "Id": "56262627",
                    "PostTypeId": "2",
                    "ParentId": "8334433",
                    "CreationDate": "2019-05-22T18:07:53.847",
                    "Score": "3",
                    "Body": "<p>if you are using ps, you can check the manual</p>\n<pre><code>man ps\n</code></pre>\n<p>there is a list of keywords allowing you to build what you need. for example to show, userid / processid / percent cpu / percent memory / work queue / command :</p>\n<pre><code>ps -e -o &quot;uid pid pcpu pmem wq comm&quot;\n</code></pre>\n<p>-e is similar to -A (all inclusive; your processes and others), and -o is to force a format.</p>\n<p>if you are looking for a specific uid, you can chain it using awk or grep such as :</p>\n<pre><code>ps -e -o &quot;uid pid pcpu pmem wq comm&quot; | grep 501\n</code></pre>\n<p>this should (almost) show only for userid 501. try it.</p>\n<p><strong>The slightly GUI way</strong></p>\n<p>if you are a cli (ui) fan. I recommend trying <a href=\"https://github.com/clementtsang/bottom\" rel=\"nofollow noreferrer\">https://github.com/clementtsang/bottom</a> which shows not only processes, but also temperature, disk usage and network. Screenshot is running from kitty (terminal) as an example, I use it on OSX default terminal and the color shows up a bit different, but still amazing.</p>\n<p><a href=\"https://i.stack.imgur.com/Da3UN.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/Da3UN.png\" alt=\"cli process monitor - bottom\" /></a></p>\n<p><strong>The tree way</strong></p>\n<p>As described here : <a href=\"https://en.wikipedia.org/wiki/Pstree\" rel=\"nofollow noreferrer\">https://en.wikipedia.org/wiki/Pstree</a> will give a better connection on the hierarchy of the processes</p>\n<pre><code>brew install pstree     # if you need to install it\npstree\npstree -u &lt;user&gt;        # show only processes by your user\npstree -s &lt;string&gt;      # show only processes with string\npstree -help            # show help\n</code></pre>\n",
                    "OwnerUserId": "154365",
                    "LastEditorUserId": "154365",
                    "LastEditDate": "2021-08-30T13:09:51.633",
                    "LastActivityDate": "2021-08-30T13:09:51.633",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "56558719",
                "ParentRepo": "https://github.com/instrumenta/kubeval",
                "StackOverflow_Post": {
                    "Id": "56558719",
                    "PostTypeId": "2",
                    "ParentId": "56557825",
                    "CreationDate": "2019-06-12T09:20:22.593",
                    "Score": "6",
                    "Body": "<p>You are using the wrong indentation and structure for Deployment objects. </p>\n\n<p>Both the <code>command</code> key and the <code>env</code> key are part of the <code>container</code> key.</p>\n\n<p>This is the right format</p>\n\n<pre><code>--- \napiVersion: apps/v1\nkind: Deployment\nmetadata: \n  labels: \n    app: test-d\n  name: test-deploy\nspec: \n  replicas: 1\n  selector: \n    matchLabels: \n      app: test-d\n  template: \n    metadata: \n      labels: \n        app: test-d\n    spec: \n      containers: \n        - image: busybox\n          name: test-d-container\n          command: \n            - sh\n            - \"-c\"\n            - \"echo Hello Kubernetes, I am $MY_DEPLOY_NAME in $MY_CLUSTER_NAME and $MY_NAMESPACE! &amp;&amp; sleep 3600\"\n          env: \n            - \n              name: MY_DEPLOY_NAME\n              valueFrom: \n                fieldRef: \n                  fieldPath: metadata.name\n            - \n              name: MY_NAMESPACE\n              valueFrom: \n                fieldRef: \n                  fieldPath: metadata.namespace\n            - \n              name: MY_CLUSTER_NAME\n              value: production\n</code></pre>\n\n<p>Remember that you can validate your Kubernetes manifests using <a href=\"https://kubeyaml.com/\" rel=\"nofollow noreferrer\">this online validator</a>, or locally <a href=\"https://github.com/instrumenta/kubeval\" rel=\"nofollow noreferrer\">using kubeval</a>.</p>\n\n<p>Referring to the main part of the question, <a href=\"https://stackoverflow.com/questions/42274229/kubernetes-deployment-name-from-within-a-pod\">you can get the object that created the Pod</a>, but most likely that will be the ReplicaSet, not the Deployment.</p>\n\n<p>The Pod name is normally generated by Kubernetes, you don't know it before hand, that's why there is a mechanism to get the name. But that is not the case for Deployments: you know the name of Deployments when creating them. I don't think there is a mechanism to get the Deployment name dynamically.</p>\n\n<p>Typically, labels are used in the PodSpec of the Deployment object to add metadata.</p>\n\n<p>You could also try to parse it, since the pod name (which you have) has always this format: deploymentName-replicaSetName-randomAlphanumericChars.</p>\n",
                    "OwnerUserId": "563072",
                    "LastEditorUserId": "563072",
                    "LastEditDate": "2019-06-12T10:29:53.670",
                    "LastActivityDate": "2019-06-12T10:29:53.670",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "56587690",
                "ParentRepo": "https://github.com/jpadilla/django-rest-framework-jwt/issues/482",
                "StackOverflow_Post": {
                    "Id": "56587690",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "57108110",
                    "CreationDate": "2019-06-13T19:51:30.390",
                    "Score": "22",
                    "ViewCount": "9780",
                    "Body": "<p>After using <a href=\"http://jpadilla.github.io/django-rest-framework-jwt/\" rel=\"noreferrer\">djangorestframework-jwt</a> in an unsafe way for over year I've finally decided that I would like to get it working in a safer fashion.</p>\n<p>I've read everywhere that is not good to save a JWT token in the local client (for example, local storage) and that the best solution is to use HttpOnly cookies instead.</p>\n<p>I understood that an HttpOnly cookie is a cookie indeed, that can be saved but not read by the browser. So I thought it could be used like the following:</p>\n<ul>\n<li>get_token: the client requests an authorization token to the server by sending user and password: if user and password are valid the server responds with an httpOnly cookie that can be stored but not read by the client.</li>\n<li>Every request the client does from now on are authorized because inside the HttpOnly cookie there is a valid authorization token.</li>\n<li>refresh_token: once the client needs to refresh the token, it only needs to request a refresh_token: if the sent cookie contains a valid token, the server will respond with an updated HttpOnly cookie with the new token.</li>\n</ul>\n<p>I'm now trying to use djangorestframework-jwt by using HttpOnly cookie and the JWT_AUTH_COOKIE configuration seems to be the most fitting one:</p>\n<blockquote>\n<p>You can set JWT_AUTH_COOKIE a string if you want to use http cookies in addition to the Authorization header as a valid transport for the token. The string you set here will be used as the cookie name that will be set in the response headers when requesting a token. The token validation procedure will also look into this cookie, if set. The 'Authorization' header takes precedence if both the header and the cookie are present in the request.</p>\n<p>Default is None and no cookie is set when creating tokens nor accepted when validating them.</p>\n</blockquote>\n<p>After giving a string value to JWT_AUTH_COOKIE I received an httpOnly cookie as expected.</p>\n<p>The problem:</p>\n<p>When I call refreshToken I get the following response:</p>\n<pre><code>{&quot;token&quot;:[&quot;This field is required.&quot;]}\n</code></pre>\n<p>True, I'm not sending any token in the request's HEADER and that is what I want since the client isn't supposed to keep it saved anywhere.</p>\n<p>And that is where I'm getting confused:</p>\n<p>If i'm not wrong from now on every request the client does to the server, the cookie should be added to the request.</p>\n<p>Shouldn't the server check the cookie after it sees that no token has been passed in the Header? How is it supposed to work if not like this?</p>\n<p>Also posted a Github issue here if anyone wants to contribute for improvements: <a href=\"https://github.com/jpadilla/django-rest-framework-jwt/issues/482\" rel=\"noreferrer\">https://github.com/jpadilla/django-rest-framework-jwt/issues/482</a></p>\n",
                    "OwnerUserId": "7754093",
                    "LastEditorUserId": "-1",
                    "LastEditDate": "2020-06-20T09:12:55.060",
                    "LastActivityDate": "2021-08-11T15:36:37.827",
                    "Title": "django-rest-framework using HttpOnly Cookie",
                    "Tags": "<django-rest-framework><jwt>",
                    "AnswerCount": "2",
                    "CommentCount": "6",
                    "FavoriteCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "56655948",
                "ParentRepo": "https://github.com/damiafuentes/DJITelloPy/blob/master/example.py",
                "StackOverflow_Post": {
                    "Id": "56655948",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "56672567",
                    "CreationDate": "2019-06-18T19:38:11.977",
                    "Score": "3",
                    "ViewCount": "1226",
                    "Body": "<p>I'm using the djitellopy module (running on Win10/Python3.6) to connect to my Ryze TELLO-drone. That module uses cv2, the drone provides the current the videostream in h264 codec. While running my script (based on <a href=\"https://github.com/damiafuentes/DJITelloPy/blob/master/example.py\" rel=\"nofollow noreferrer\">the docs</a>), not all pictures are getting transmitted e. g. because my wlan connection is too weak. That's not the actual problem, as I don't need all 60fps. But it's quite annoying, that every time I miss a frame, I get errors like</p>\n\n<pre><code>[h264 @ 0000019ab6699b40] non-existing PPS 0 referenced\n[h264 @ 0000019ab6699b40] decode_slice_header error\n[h264 @ 0000019ab6699b40] no frame!\n[h264 @ 0000019ab8394b00] non-existing PPS 0 referenced\n[h264 @ 0000019ab66ab040] non-existing PPS 0 referenced\n[h264 @ 0000019ab8394b00] decode_slice_header error\n[h264 @ 0000019ab8394b00] no frame!\n[h264 @ 0000019ab8394b00] error while decoding MB 31 40, bytestream -10\n</code></pre>\n\n<p>and so on. Is there any neat way to turn off/suppress these errors in cv2? The script itself is running on without problems.</p>\n\n<p>Thanks in advance!</p>\n",
                    "OwnerUserId": "9145525",
                    "LastActivityDate": "2019-06-19T16:53:58.427",
                    "Title": "Remove [h264 @ xxx] error cosole output while using cv2",
                    "Tags": "<python><python-3.x><opencv><h.264><dji-sdk>",
                    "AnswerCount": "1",
                    "CommentCount": "2",
                    "FavoriteCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "56663463",
                "ParentRepo": "https://github.com/instrumenta/conftest",
                "StackOverflow_Post": {
                    "Id": "56663463",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "57526982",
                    "CreationDate": "2019-06-19T08:39:40.823",
                    "Score": "1",
                    "ViewCount": "4802",
                    "Body": "<p>We are using <a href=\"https://github.com/instrumenta/conftest\" rel=\"nofollow noreferrer\">conftest</a> to validate if our terraform changeset applies to certain rules &amp; compliances. One thing we want to validate is wether our AWS resources are tagged according to the AWS tagging convention, which specifies certain tags to use (e.g. Owner, ApplicationRole, Project) and specifies that all tags and values are in CamelCase.</p>\n\n<p>in terraform the changeset is portrayed in the following (simplified) json output:</p>\n\n<pre><code>{\n   \"resource_changes\":{\n      \"provider_name\":\"aws\",\n      \"change\":{\n         \"before\":{\n\n         },\n         \"after\":{\n            \"tags\":{\n               \"ApplicationRole\":\"SomeValue\",\n               \"Owner\":\"SomeValue\",\n               \"Project\":\"SomeValue\"\n            }\n         }\n      }\n   }\n}\n</code></pre>\n\n<p>What I am now trying to do is to validate the following:</p>\n\n<ol>\n<li>Check wether tags are set.</li>\n<li>Validate if the keys and values are all camelcase.</li>\n<li>Check that the keys include the set (ApplicationRole, Owner, Project) in the minimum.</li>\n</ol>\n\n<p>However, I am having trouble defining that in Rego (I am quite new to OPA).</p>\n\n<p>Is there a way to \"loop\" over the keys and values of an object, and validate if they are formatted correctly?</p>\n\n<p>in pseudo code:</p>\n\n<pre><code>for key, value in tags {\n  re_match(`([A-Z][a-z0-9]+)+`, key)\n  re_match(`([A-Z][a-z0-9]+)+`, value)\n}\n</code></pre>\n\n<p>I have tried the following:</p>\n\n<pre><code>tags_camel_case(tags) {\n    some key\n    val := tags[key]\n    re_match(`^([A-Z][a-z0-9]+)+`, key) # why is key not evaluated?\n    re_match(`^([A-Z][a-z0-9]+)+`, val)\n}\n</code></pre>\n\n<p>However, when evaluating against the following test json:</p>\n\n<pre><code>{\n  \"AppRole\": \"SomeValue\",\n  \"appRole\": \"SomeValue\"\n}\n</code></pre>\n\n<p>the rule returns true, even though I am checking both key and value vs the regex</p>\n",
                    "OwnerUserId": "9741769",
                    "LastEditorUserId": "9741769",
                    "LastEditDate": "2019-06-19T10:00:04.060",
                    "LastActivityDate": "2019-08-16T15:05:16.710",
                    "Title": "Can I loop over keys and values of an object in OPA to validate if they adhere to a certain format (CamelCase)",
                    "Tags": "<terraform><open-policy-agent>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "FavoriteCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "56702148",
                "ParentRepo": "https://github.com/shopsys/shopsys/blob/master/docs/installation/installation-using-docker-linux.md",
                "StackOverflow_Post": {
                    "Id": "56702148",
                    "PostTypeId": "1",
                    "CreationDate": "2019-06-21T11:01:03.307",
                    "Score": "0",
                    "ViewCount": "737",
                    "Body": "<p>I wanna install shopsys via composer and docker, as is recommended.</p>\n\n<p><a href=\"https://github.com/shopsys/shopsys/blob/master/docs/installation/installation-using-docker-linux.md\" rel=\"nofollow noreferrer\">https://github.com/shopsys/shopsys/blob/master/docs/installation/installation-using-docker-linux.md</a></p>\n\n<p>I installed git, php-fpm (configured), postgres (configured), composer, docker, docker-compose.</p>\n\n<pre><code>sudo apt install git\nsudo apt install php7.2-fpm\nsudo apt install postgresql\nsudo apt install composer\nsudo apt install docker-ce\nsudo apt install docker-compose\n</code></pre>\n\n<p>Everything ok.</p>\n\n<p>I added my user to docker group.</p>\n\n<pre><code>sudo usermod -a -G docker $(whoami)\n</code></pre>\n\n<p>Ok.</p>\n\n<p>Next I made folder <strong>/var/www/html/shopsys</strong>, created project shopsys via composer.</p>\n\n<pre><code>composer create-project shopsys/project-base --no-install --keep-vcs\ncd project-base/\n</code></pre>\n\n<p>Then I run this in <strong>/var/www/html/shopsys/project-base</strong>.</p>\n\n<pre><code>./scripts/install.sh\n</code></pre>\n\n<p>Everything seems to be ok, until this.</p>\n\n<pre><code>[RuntimeException]                                             \n/var/www/html/vendor does not exist and could not be created.\n</code></pre>\n\n<p>I set rights to 777 for folder <strong>/var/www/html</strong>, and run it again, but same problem.</p>\n\n<p>The I run this.</p>\n\n<pre><code>sudo composer install\n</code></pre>\n\n<p>It shows me this error.</p>\n\n<pre><code>....Exception\\InvalidConfigurationException]\nInvalid configuration for path \"monolog.handlers.main\": You can only use ex    \ncluded_http_codes/excluded_404s with a FingersCrossedHandler definition\n\nIn ScriptHandler.php line 294:\n\nAn error occurred when executing the \"'shopsys:domains-urls:configure'\" command:\nIn BaseNode.php line 319:\n\n...\\Exception\\InvalidConfigurationException]\nInvalid configuration for path \"monolog.handlers.main\": You can only use ex                                                                                                                                     \ncluded_http_codes/excluded_404s with a FingersCrossedHandler definition\n...\n</code></pre>\n\n<p>etc., error is quite ugly.</p>\n\n<p>Last error when i run script <strong>install.sh</strong>.</p>\n\n<pre><code>file_put_contents(/var/www/html/vendor/composer/installed.json): failed to open stream: Permission denied\n</code></pre>\n\n<p>But this folder does not exist.</p>\n\n<pre><code>ls: cannot access '/var/www/html/vendor/': No such file or directory\n</code></pre>\n\n<p>Just question, where could be the problem?</p>\n\n<p><strong>Is possible to download sources from some link, extract it, configure and display in web browser with easy way, for example as wordpress?</strong></p>\n\n<p>Thanks.</p>\n",
                    "OwnerUserId": "6440367",
                    "LastEditorUserId": "6440367",
                    "LastEditDate": "2019-06-21T11:15:51.350",
                    "LastActivityDate": "2019-06-21T12:30:15.030",
                    "Title": "Ubuntu, shopsys install via composer, docker, still crashing",
                    "Tags": "<docker><ubuntu><composer-php>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "56951860",
                "ParentRepo": "https://github.com/jmfayard/buildSrcVersions",
                "StackOverflow_Post": {
                    "Id": "56951860",
                    "PostTypeId": "1",
                    "CreationDate": "2019-07-09T11:46:14.170",
                    "Score": "15",
                    "ViewCount": "2884",
                    "Body": "<p>There has been a myriad of articles written about how migrating from using groovy scripts to using Kotlin DSL for Gradle dependency management is an ideal way to manage build scripts among other mentioned advantages.</p>\n\n<p>However, the limitation that I have found is the lack of this Gradle management way or process in highlighting when new versions of the current dependencies are available as was done previously using groovy scripts. The current solutions that I have found include the use of plugins or utilities that scan through your buildSrc folder and provide the updates as comments to the current versions of the libraries. Some of which include the following:</p>\n\n<p><a href=\"https://github.com/jmfayard/buildSrcVersions\" rel=\"noreferrer\">buildSrcVersions</a></p>\n\n<p><a href=\"https://github.com/ben-manes/gradle-versions-plugin\" rel=\"noreferrer\">Gradle-versions-plugin</a></p>\n\n<p>Apart from the few plugins that I have mentioned is there any other efficient methods of checking for dependency updates?</p>\n",
                    "OwnerUserId": "4319835",
                    "LastEditorUserId": "4319835",
                    "LastEditDate": "2019-07-09T19:40:41.523",
                    "LastActivityDate": "2020-09-22T19:40:40.417",
                    "Title": "Kotlin DSL build scripts dependency updates",
                    "Tags": "<android><android-studio><android-gradle-plugin><gradle-kotlin-dsl>",
                    "AnswerCount": "2",
                    "CommentCount": "4",
                    "FavoriteCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "57005560",
                "ParentRepo": "https://github.com/weaveworks/ignite",
                "StackOverflow_Post": {
                    "Id": "57005560",
                    "PostTypeId": "2",
                    "ParentId": "56996602",
                    "CreationDate": "2019-07-12T10:55:17.937",
                    "Score": "16",
                    "Body": "<p>Both <a href=\"https://aws.amazon.com/about-aws/whats-new/2018/11/firecracker-lightweight-virtualization-for-serverless-computing/\" rel=\"noreferrer\">Firecracker</a> and <a href=\"https://github.com/google/gvisor\" rel=\"noreferrer\">gVisor</a> are technologies which provide sandboxing / isolation but in a different way.</p>\n<ul>\n<li>Firecracker (orange box) is a Virtual Machine Manager.</li>\n<li>gVisor (green box) has an architecture which controls/filters the system calls that reach the actual host.</li>\n</ul>\n<p><a href=\"https://github.com/weaveworks/ignite\" rel=\"noreferrer\">Weave Ignite</a> is a <strong>tool</strong> that helps you use Firecracker in order to run containers inside lightweight VMs and also do that with a nice UX, similar to using Docker.</p>\n<p>This is also mentioned in the <em>Scope</em> section of <a href=\"https://github.com/weaveworks/ignite\" rel=\"noreferrer\">github.com/weaveworks/ignite</a></p>\n<blockquote>\n<h3>Scope</h3>\n<p>Ignite is different from Kata Containers or gVisor. They don't let you run real VMs, but only wrap a container in new layer providing some kind of security boundary (or sandbox).</p>\n<p>Ignite on the other hand lets you run a full-blown VM, easily and super-fast, but with the familiar container UX. This means you can &quot;move down one layer&quot; and start managing your fleet of VMs powering e.g. a Kubernetes cluster, but still package your VMs like containers.</p>\n</blockquote>\n<p>Regarding the <em>use-case</em> part of your question, it's my feeling that because of the stronger isolation VMs offer, Ignite can be more production-ready. Also, the approach of gVisor seems to have a significant performance cost, as it is mentioned at <a href=\"https://www.usenix.org/system/files/hotcloud19-paper-young.pdf\" rel=\"noreferrer\">The True Cost of Containing: A gVisor Case Study</a>:</p>\n<blockquote>\n<h3>Conclusion</h3>\n<ul>\n<li>gVisor is arguably more secure than <code>runc</code></li>\n<li>Unfortunately, our analysis shows that the true costs of effectively containing are high: system calls are 2.2\u00d7 slower, memory allocations are 2.5\u00d7 slower, large downloads are 2.8\u00d7 slower, and file opens are 216\u00d7 slower</li>\n</ul>\n</blockquote>\n<hr />\n<blockquote>\n<h2>Current Sandboxing Methods</h2>\n<p><a href=\"https://i.stack.imgur.com/v4qPx.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/v4qPx.png\" alt=\"enter image description here\" /></a></p>\n<br>\n<h2>Sandboxing with gVisor</h2>\n<p><a href=\"https://i.stack.imgur.com/NrxvQ.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/NrxvQ.png\" alt=\"Sandboxing with gVisor\" /></a></p>\n<br>\n<h2>Do I Need gVisor?</h2>\n<p>No. If you're running production workloads, don't even think about it! Right now, this is a metaphorical science experiment. That's not to say you may not want to use it as it matures. I don't have any problem with the way it's trying to solve process isolation and I think it's a good idea. There are also alternatives you should take the time to explore before adopting this technology in the future.</p>\n<h2>Where might I want to use it?</h2>\n<p>As an operator, you'll want to <strong>use gVisor to isolate application containers that aren't entirely trusted</strong>. This could be a new version of an open source project your organization has trusted in the past. It could be a new project your team has yet to completely vet or anything else you aren't entirely sure can be trusted in your cluster. After all, if you're running an open source project you didn't write (all of us), your team certainly didn't write it so it would be good security and good engineering to properly isolate and protect your environment in case there may be a yet unknown vulnerability.</p>\n</blockquote>\n<hr />\n<p><a href=\"https://i.stack.imgur.com/3dkPj.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/3dkPj.png\" alt=\"enter image description here\" /></a></p>\n<hr />\n<h2>Further reading</h2>\n<p>My answer has information from the following sources which are in <em>quote</em> sections when taken &quot;as-is&quot; and I recommend them for further reading:</p>\n<ul>\n<li><a href=\"https://rancher.com/blog/2018/2018-05-24-what-is-gvisor/\" rel=\"noreferrer\">What is gVisor?</a> from Rancher Blog</li>\n<li><a href=\"https://unit42.paloaltonetworks.com/making-containers-more-isolated-an-overview-of-sandboxed-container-technologies/\" rel=\"noreferrer\">Making Containers More Isolated: An Overview of Sandboxed Container Technologies</a></li>\n<li><a href=\"https://blog.jessfraz.com/post/containers-security-and-echo-chambers/\" rel=\"noreferrer\">Containers, Security, and Echo Chambers</a> blog by Jessie Frazelle</li>\n<li><a href=\"https://www.usenix.org/system/files/hotcloud19-paper-young.pdf\" rel=\"noreferrer\">The True Cost of Containing: A gVisor Case Study</a></li>\n<li><a href=\"https://stackoverflow.com/questions/50143367/kata-containers-vs-gvisor\">Kata Containers vs gVisor?</a></li>\n<li><a href=\"https://www.usenix.org/system/files/nsdi20-paper-agache.pdf\" rel=\"noreferrer\">Firecracker: Lightweight Virtualization  for Serverless Applications</a> paper from AWS</li>\n<li><a href=\"https://gvisor.dev/blog/2019/11/18/gvisor-security-basics-part-1/\" rel=\"noreferrer\">gVisor Security Basics - Part 1</a> from gVisor blog</li>\n</ul>\n",
                    "OwnerUserId": "1561148",
                    "LastEditorUserId": "1561148",
                    "LastEditDate": "2020-09-16T07:45:26.110",
                    "LastActivityDate": "2020-09-16T07:45:26.110",
                    "CommentCount": "3",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "57056156",
                "ParentRepo": "https://github.com/omadson/fuzzy-c-means",
                "StackOverflow_Post": {
                    "Id": "57056156",
                    "PostTypeId": "1",
                    "CreationDate": "2019-07-16T11:24:31.820",
                    "Score": "0",
                    "ViewCount": "2261",
                    "Body": "<p>I use the  <a href=\"https://github.com/omadson/fuzzy-c-means\" rel=\"nofollow noreferrer\">fuzzy-c-means</a> clustering implementation and I would like the data X to form the number of clusters i define in the algorithm(I beleive that is how it works). But the behavior is confusing.</p>\n\n<pre><code>cm = FCM(n_clusters=6)\ncm.fit(X)\n</code></pre>\n\n<p>This code generates a plot with 4 labels - [0,2,4,6]</p>\n\n<pre><code>cm = FCM(n_clusters=4)\ncm.fit(X)\n</code></pre>\n\n<p>This code generates a plot with 4 labels - [0,1,2,3]</p>\n\n<p>I expect labels [0,1,2,3,4,5] when i initialize the cluster number to be 6.</p>\n\n<p>code:</p>\n\n<pre><code>from fcmeans import FCM\nfrom matplotlib import pyplot as plt\nfrom seaborn import scatterplot as scatter\n\n# fit the fuzzy-c-means\nfcm = FCM(n_clusters=6)\nfcm.fit(X)\n\n# outputs\nfcm_centers = fcm.centers\nfcm_labels  = fcm.u.argmax(axis=1)\n\n# plot result\n%matplotlib inline\nf, axes = plt.subplots(1, 2, figsize=(11,5))\nscatter(X[:,0], X[:,1], ax=axes[0])\nscatter(X[:,0], X[:,1], ax=axes[1], hue=fcm_labels)\nscatter(fcm_centers[:,0], fcm_centers[:,1], ax=axes[1],marker=\"s\",s=200)\nplt.show()\n</code></pre>\n",
                    "OwnerUserId": "8627309",
                    "LastEditorUserId": "4685471",
                    "LastEditDate": "2019-07-16T11:51:45.543",
                    "LastActivityDate": "2019-07-17T20:16:51.877",
                    "Title": "fuzzy-c-means - setting initial number of clusters=6, but only 4 cluster labels generated",
                    "Tags": "<python><machine-learning><cluster-analysis><fuzzy-c-means>",
                    "AnswerCount": "2",
                    "CommentCount": "7",
                    "FavoriteCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "57139791",
                "ParentRepo": "https://github.com/bpesquet/thejsway",
                "StackOverflow_Post": {
                    "Id": "57139791",
                    "PostTypeId": "2",
                    "ParentId": "57137866",
                    "CreationDate": "2019-07-22T05:44:59.170",
                    "Score": "1",
                    "Body": "<p>You never answered my question about what \"\"dominantDirection()\" is supposed to do.</p>\n\n<p>I found the answer here:</p>\n\n<blockquote>\n  <p><a href=\"https://www.freecodecamp.org/forum/t/reading-eloquent-javascript-can-i-ever-get-this-good/181511\" rel=\"nofollow noreferrer\">https://www.freecodecamp.org/forum/t/reading-eloquent-javascript-can-i-ever-get-this-good/181511</a></p>\n  \n  <p>... a program to take a string and identify what percentage of\n  whatever Unicode scripts are present in it out of the total. the\n  program also accounts for Unicode characters which take up more than\n  one code unit</p>\n</blockquote>\n\n<p>Here's some very useful advice from the same thread:</p>\n\n<blockquote>\n  <p>That book (<a href=\"https://rads.stackoverflow.com/amzn/click/com/1593272820\" rel=\"nofollow noreferrer\" rel=\"nofollow noreferrer\">Eloquent Javascript</a>) is not for everyone, including me :wink: and many others too\n  don\u2019t like it\u2026</p>\n  \n  <p>A Better and Practical alternative for Eloquent Javascript is <a href=\"https://github.com/bpesquet/thejsway\" rel=\"nofollow noreferrer\">The\n  Javascript Way</a> followed by\n  <a href=\"https://www.edx.org/course/programming-web-javascript-pennx-sd4x\" rel=\"nofollow noreferrer\">Programming for the Web with\n  JavaScript</a>.</p>\n</blockquote>\n\n<p>Regarding your initial question, I hope lipusal's most excellent post gave you the answer you were looking for.  In particular, these two snippets are basically equivalent:</p>\n\n<pre><code>// \"Classic\" JS syntax:\ncountBy(text, function(char) {\n      var script = characterScript(char.codePointAt(0));\n      return script ? script.direction : \"none\";\n});\n</code></pre>\n\n<p>vs.</p>\n\n<pre><code>// ES6 syntax:\ncountBy(text, char =&gt; {\n      let script = characterScript(char.codePointAt(0));\n      return script ? script.direction : \"none\";\n});\n</code></pre>\n\n<p>PS: </p>\n\n<p>From Amazon.com:</p>\n\n<p><a href=\"https://www.amazon.com/gp/customer-reviews/R1ZCGRCI42K17S/ref=cm_cr_dp_d_rvw_ttl?ie=UTF8&amp;ASIN=1593275846\" rel=\"nofollow noreferrer\">Alright, but NOT a good book if you're just starting to learn JavaScript</a></p>\n\n<p>and </p>\n\n<p><a href=\"https://www.amazon.com/gp/customer-reviews/R32UODHNA76JZT/ref=cm_cr_getr_d_rvw_ttl?ie=UTF8&amp;ASIN=1593279507\" rel=\"nofollow noreferrer\">not for beginners</a></p>\n",
                    "OwnerUserId": "421195",
                    "LastEditorUserId": "421195",
                    "LastEditDate": "2019-07-22T06:04:08.210",
                    "LastActivityDate": "2019-07-22T06:04:08.210",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "57274389",
                "ParentRepo": "https://github.com/squidfunk/mkdocs-material/issues/693#issuecomment-411885426",
                "StackOverflow_Post": {
                    "Id": "57274389",
                    "PostTypeId": "2",
                    "ParentId": "49535327",
                    "CreationDate": "2019-07-30T14:45:51.330",
                    "Score": "3",
                    "Body": "<p>Don't know what you use to produce output from your Markdown -- I use <a href=\"https://www.mkdocs.org/\" rel=\"nofollow noreferrer\">MkDocs</a> with <a href=\"https://squidfunk.github.io/mkdocs-material/\" rel=\"nofollow noreferrer\">Material</a>, and added Mermaid support like explained <a href=\"https://github.com/squidfunk/mkdocs-material/issues/693#issuecomment-411885426\" rel=\"nofollow noreferrer\">here</a>.</p>\n\n<p>After some trial-and-error configurations I found out that using Cloudflare's CDN, you can include an older version of MermaidJS with another CSS. This way, I was able to render the diagram using the neutral style:</p>\n\n<pre><code>markdown_extensions:\n  - pymdownx.superfences:\n      custom_fences:\n        - name: mermaid\n          class: mermaid\n          format: !!python/name:pymdownx.superfences.fence_div_format\n\nextra_css:\n  - https://cdnjs.cloudflare.com/ajax/libs/mermaid/7.0.9/mermaid.neutral.css\nextra_javascript:\n  - https://cdnjs.cloudflare.com/ajax/libs/mermaid/7.0.9/mermaid.min.js\n</code></pre>\n",
                    "OwnerUserId": "11858390",
                    "LastActivityDate": "2019-07-30T14:45:51.330",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "57291664",
                "ParentRepo": "https://github.com/osquery/osquery/blob/master/tools/deployment/make_windows_package.ps1",
                "StackOverflow_Post": {
                    "Id": "57291664",
                    "PostTypeId": "1",
                    "CreationDate": "2019-07-31T13:15:08.053",
                    "Score": "1",
                    "ViewCount": "576",
                    "Body": "<p>After installing osquery with an MSI made with WiXToolSet (Using the script provided by osquery), I tried uninstalling it which failed.\nAlso it didn't show as a program in the appwiz.\n(Link to the script - <a href=\"https://github.com/osquery/osquery/blob/master/tools/deployment/make_windows_package.ps1\" rel=\"nofollow noreferrer\">https://github.com/osquery/osquery/blob/master/tools/deployment/make_windows_package.ps1</a>)</p>\n\n<p>I've tried using both the MSI itself - <code>osquery.msi /uninstall</code> and the unsintall string - <code>msiexec /I{'uninstallstring'}</code>.\nI also tried repairing using the <code>/fv</code> option. </p>\n\n<p>The code the script used with WiX to create the MSI:</p>\n\n<pre><code>@'\n&lt;?xml version='1.0' encoding='windows-1252'?&gt;\n&lt;?define OsqueryVersion = 'OSQUERY_VERSION'?&gt;\n&lt;?define OsqueryUpgradeCode = 'ea6c7327-461e-4033-847c-acdf2b85dede'?&gt;\n&lt;Wix xmlns=\"http://schemas.microsoft.com/wix/2006/wi\" xmlns:util=\"http://schemas.microsoft.com/wix/UtilExtension\"&gt;\n  &lt;Product\n    Name='osquery'\n    Manufacturer='Facebook'\n'@\n$wix += \"`n    Id='$(New-Guid)'`n\"\n$wix +=\n@'\n    UpgradeCode='$(var.OsqueryUpgradeCode)'\n    Language='1033'\n    Codepage='1252'\n    Version='$(var.OsqueryVersion)'&gt;\n    &lt;Package Id='*'\n      Keywords='Installer'\n      Description='osquery standalone installer'\n      Comments='Facebooks opensource host intrusion detection agent'\n      Manufacturer='Facebook'\n      InstallerVersion='200'\n      Platform='x64'\n      Languages='1033'\n      Compressed='yes'\n      SummaryCodepage='1252' /&gt;\n    &lt;MediaTemplate EmbedCab=\"yes\" /&gt;\n    &lt;MajorUpgrade\n      DowngradeErrorMessage=\"A later version of osquery is already installed. Setup will now exit.\" /&gt;\n    &lt;Condition Message='A newer version of osquery is already installed.'&gt;\n      NOT NEWERVERSIONDETECTED\n    &lt;/Condition&gt;\n    &lt;Condition Message=\"You need to be an administrator to install this product.\"&gt;\n        Privileged\n    &lt;/Condition&gt;\n    &lt;Property Id='SOURCEDIRECTORY' Value='packs'/&gt;\n    &lt;PropertyRef Id=\"WIX_ACCOUNT_LOCALSYSTEM\" /&gt;\n    &lt;PropertyRef Id=\"WIX_ACCOUNT_USERS\" /&gt;\n    &lt;PropertyRef Id=\"WIX_ACCOUNT_ADMINISTRATORS\" /&gt;\n    &lt;Directory Id='TARGETDIR' Name='SourceDir'&gt;\n      &lt;Directory Id='ProgramFiles64Folder'&gt;\n        &lt;Directory Id='INSTALLFOLDER' Name='osquery'&gt;\n          &lt;Directory Id='DaemonFolder' Name='osqueryd'&gt;\n            &lt;Component Id='osqueryd'\n                Guid='41c9910d-bded-45dc-8f82-3cd00a24fa2f'&gt;\n                &lt;CreateFolder&gt;\n                &lt;Permission User=\"[WIX_ACCOUNT_USERS]\" Read=\"yes\"\n                  ReadExtendedAttributes=\"yes\" Traverse=\"yes\"\n                  ReadAttributes=\"yes\" ReadPermission=\"yes\" Synchronize=\"yes\"\n                  GenericWrite=\"no\" WriteAttributes=\"no\"/&gt;\n                &lt;Permission User=\"[WIX_ACCOUNT_ADMINISTRATORS]\" GenericAll=\"yes\"/&gt;\n                &lt;Permission User=\"[WIX_ACCOUNT_LOCALSYSTEM]\" GenericAll=\"yes\"/&gt;\n              &lt;/CreateFolder&gt;\n              &lt;File Id='osqueryd'\n                Name='osqueryd.exe'\n                Source='OSQUERY_DAEMON_PATH'\n                KeyPath='yes'/&gt;\n              &lt;ServiceInstall Id='osqueryd'\n                Name='osqueryd'\n                Account='NT AUTHORITY\\SYSTEM'\n                Arguments='--flagfile=\"C:\\Program Files\\osquery\\osquery.flags\"'\n                Start='auto'\n                Type='ownProcess'\n                Vital='yes'\n                ErrorControl='normal'/&gt;\n              &lt;ServiceControl Id='osqueryd'\n                Name='osqueryd'\n                Stop='both'\n                Start='install'\n                Remove='uninstall'\n                Wait='no'/&gt;\n            &lt;/Component&gt;\n          &lt;/Directory&gt;\n          &lt;Component Id='osqueryi' Guid='6a49524e-52b0-4e99-876f-ec50c0082a04'&gt;\n            &lt;File Id='osqueryi'\n              Name='osqueryi.exe'\n              Source='OSQUERY_SHELL_PATH'\n              KeyPath='yes'/&gt;\n          &lt;/Component&gt;\n          &lt;Component Id='extras' Guid='3f435561-8fe7-4725-975a-95930c44d063'&gt;\n            &lt;File Id='osquery.conf'\n              Name='osquery.conf'\n              Source='OSQUERY_CONF_PATH'\n              KeyPath='yes'/&gt;\n            &lt;File Id='osquery.flags'\n              Name='osquery.flags'\n              Source='OSQUERY_FLAGS_PATH'/&gt;\n            &lt;File Id='osquery.man'\n              Name='osquery.man'\n              Source='OSQUERY_MAN_PATH'/&gt;\n            &lt;File Id='osquery_utils.ps1'\n              Name='osquery_utils.ps1'\n              Source='OSQUERY_UTILS_PATH'/&gt;\n            &lt;File Id='manage_osqueryd.ps1'\n              Name='manage-osqueryd.ps1'\n              Source='OSQUERY_MGMT_PATH'/&gt;\n'@\n</code></pre>\n\n<p>When trying to use the MSI to uninstall I saw the following message :\n<code>This patch package could not be opened. Verify that the patch package exists and that you can access it, or contact the application vendor to verify that this is a valid Windows Installer patch package</code>\nWhen trying to use the uninstall string I see this message:\n<code>This action is only valid for products that are currently installed</code></p>\n",
                    "OwnerUserId": "10203725",
                    "LastActivityDate": "2019-08-04T01:47:18.687",
                    "Title": "Unable to uninstall program from WiX created MSI",
                    "Tags": "<wix><windows-installer><osquery>",
                    "AnswerCount": "1",
                    "CommentCount": "3",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "57452302",
                "ParentRepo": "https://github.com/FORTH-ICS-INSPIRE/artemis/blob/master/artemis-chart/templates/ingresses.yaml",
                "StackOverflow_Post": {
                    "Id": "57452302",
                    "PostTypeId": "2",
                    "ParentId": "57451382",
                    "CreationDate": "2019-08-11T17:54:41.467",
                    "Score": "1",
                    "Body": "<p>I had the same issue with a bit more complicated rewrite (it was only for one different path).</p>\n\n<p>Making multiple Ingresses for each path worked for me but might not be the cleanest solution.</p>\n\n<p>My ingress definition:\n<a href=\"https://github.com/FORTH-ICS-INSPIRE/artemis/blob/master/artemis-chart/templates/ingresses.yaml\" rel=\"nofollow noreferrer\">https://github.com/FORTH-ICS-INSPIRE/artemis/blob/master/artemis-chart/templates/ingresses.yaml</a></p>\n",
                    "OwnerUserId": "9558219",
                    "LastActivityDate": "2019-08-11T17:54:41.467",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "57523390",
                "ParentRepo": "https://github.com/rancher/k3d",
                "StackOverflow_Post": {
                    "Id": "57523390",
                    "PostTypeId": "2",
                    "ParentId": "57497040",
                    "CreationDate": "2019-08-16T10:55:13.007",
                    "Score": "1",
                    "Body": "<p>As you may know there are a lot of projects that offer K8S solution, Minikube is the closest to an official mini distribution for local testing and development, but if you wanna try lightweight options you can check:</p>\n\n<ul>\n<li><p><strong><a href=\"https://github.com/kubernetes-sigs/kind\" rel=\"nofollow noreferrer\">Kind</a></strong> runs Kubernetes clusters in Docker containers. It supports multi-node clusters as well as HA clusters. Because it runs K8s in Docker, kind can run on Windows, Mac, and Linux. Kind may not have developer-friendly features.</p></li>\n<li><p><strong><a href=\"https://github.com/rancher/k3s\" rel=\"nofollow noreferrer\">K3s</a></strong> is ma project by Rancher as a lightweight Kubernetes offering suitable for edge environments, IoT devices, CI pipelines, and even ARM devices, like Raspberry Pi's. It runs on any Linux distribution without any additional external dependencies or tools. K3s provides lightweight by replacing docker with containerd, and using sqlite3 as the default DB (instead of etcd). This solution consumes 512 MB of RAM and 200 MB of disk space.</p></li>\n<li><p><strong><a href=\"https://github.com/rancher/k3d\" rel=\"nofollow noreferrer\">K3d</a></strong>\nIt is based on a k3s which is a lightweight kubernetes distribution (similar to kind).</p></li>\n<li><p><strong><a href=\"https://microk8s.io/\" rel=\"nofollow noreferrer\">Microk8s</a></strong> runs upstream Kubernetes as native services on Linux systems supporting snap. A good option if you are running Ubuntu on your Laptop. There is a very good <a href=\"https://tutorials.ubuntu.com/tutorial/install-a-local-kubernetes-with-microk8s#0\" rel=\"nofollow noreferrer\">installation tutorial</a>: </p></li>\n</ul>\n\n<p>And there are plenty more. You can check what solution suits you best.</p>\n",
                    "OwnerUserId": "7090016",
                    "LastActivityDate": "2019-08-16T10:55:13.007",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "57653669",
                "ParentRepo": "https://github.com/networktocode/ntc-templates",
                "StackOverflow_Post": {
                    "Id": "57653669",
                    "PostTypeId": "2",
                    "ParentId": "32126460",
                    "CreationDate": "2019-08-26T07:42:37.490",
                    "Score": "3",
                    "Body": "<p><a href=\"https://github.com/networktocode/ntc-templates\" rel=\"nofollow noreferrer\">NTC Templates</a> provides a set of templates to parse various Cisco IOS command outputs (and other network devices). The templates work with <a href=\"https://github.com/google/textfsm\" rel=\"nofollow noreferrer\">TextFSM</a> to do the actual parsing.</p>\n\n<p>For example:</p>\n\n<pre><code>&gt;&gt;&gt; from ntc_templates.parse import parse_output\n&gt;&gt;&gt; vlan_output = (\n        \"VLAN Name                             Status    Ports\\n\"\n        \"---- -------------------------------- --------- -------------------------------\\n\"\n        \"1    default                          active    Gi0/1\\n\"\n        \"10   Management                       active    \\n\"\n        \"50   VLan50                           active    Fa0/1, Fa0/2, Fa0/3, Fa0/4, Fa0/5,\\n\"\n        \"                                                Fa0/6, Fa0/7, Fa0/8\\n\"\n    )\n&gt;&gt;&gt; vlan_parsed = parse_output(platform=\"cisco_ios\", command=\"show vlan\", data=vlan_output)\n&gt;&gt;&gt; vlan_parsed\n[\n    {\n        'vlan_id': '1',\n        'name': 'default',\n        'status': 'active',\n        'interfaces': ['Gi0/1']\n    },\n    {\n        'vlan_id': '10',\n        'name': 'Management',\n        'status': 'active',\n        'interfaces': []\n    },\n    {\n        'vlan_id': '50',\n        'name': 'VLan50', 'status': 'active',\n        'interfaces': ['Fa0/1', 'Fa0/2', 'Fa0/3', 'Fa0/4', 'Fa0/5', 'Fa0/6', 'Fa0/7', 'Fa0/8']\n    }\n]\n&gt;&gt;&gt; \n</code></pre>\n",
                    "OwnerUserId": "6170798",
                    "LastActivityDate": "2019-08-26T07:42:37.490",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "57665285",
                "ParentRepo": "https://github.com/tfeldmann/organize/blob/master/manage.py",
                "StackOverflow_Post": {
                    "Id": "57665285",
                    "PostTypeId": "2",
                    "ParentId": "57628064",
                    "CreationDate": "2019-08-26T21:39:45.297",
                    "Score": "5",
                    "Body": "<p>I automated this for one of my open-source tools.\nIt\u2018s all in the file manage.py:\n<a href=\"https://github.com/tfeldmann/organize/blob/master/manage.py\" rel=\"nofollow noreferrer\">https://github.com/tfeldmann/organize/blob/master/manage.py</a></p>\n\n<p>My project uses poetry for uploading to pypi, so this looks a bit different but should be a good starting point. It also manages the changelog and creates all releases.</p>\n\n<p><code>python manage.py version</code> steps:</p>\n\n<ul>\n<li>prompts for version number and checks validity</li>\n<li>updates the __version__.py file</li>\n<li>updates the pyproject.toml file used by poetry</li>\n<li>searches for a section <code>## WIP</code> in changelog.md and replaces it with current version and todays date.</li>\n</ul>\n\n<p><code>python manage.py publish</code> steps:</p>\n\n<ul>\n<li>reads the current version</li>\n<li>reads the changes listed for this version from the changelog</li>\n<li>creates a git tag</li>\n<li>pushes to github (with tags)</li>\n<li>builds and publishes to pypi</li>\n<li>creates a github release with the version number as name and the changes from the changelog as description</li>\n</ul>\n\n<p>The scripts asks for confirmation for each step so things don't get out of hand and prompts for your github and pypi passwords as soon as they are needed.</p>\n",
                    "OwnerUserId": "300783",
                    "LastEditorUserId": "300783",
                    "LastEditDate": "2019-08-27T09:24:23.253",
                    "LastActivityDate": "2019-08-27T09:24:23.253",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "57694290",
                "ParentRepo": "https://github.com/teamhephy/workflow",
                "StackOverflow_Post": {
                    "Id": "57694290",
                    "PostTypeId": "2",
                    "ParentId": "57258740",
                    "CreationDate": "2019-08-28T14:04:00.540",
                    "Score": "0",
                    "Body": "<p>Reading your requirements it looks to me, like you require more a type of own PaaS on top of Kubernetes, rather than kind of Scaling service. There are couple of existing solutions out there, e.g. check '<a href=\"https://github.com/teamhephy/workflow\" rel=\"nofollow noreferrer\">Deis Workflow</a>'. <br><br>If you really intend to create such a solution from scratch I would use as a proof of concept for (1 &amp; 2), a package manager tool for Kubernetes, called <a href=\"https://helm.sh/docs/\" rel=\"nofollow noreferrer\">helm</a>, which works on higher level abstraction - bundles in single 'release' a Kubernetes resources that make up the whole working application: Pod, Service, Persistence Volume, etc. . <br><br>You could literally treat 'release' equally with an 'id'.  No releases created in K8S cluster = your service is scaled to zero. Beside 'helm' client tool gives you an easy way to find out application URLs (target route for specific user id). The same information would be accessible from Kubernetes API using <a href=\"https://kubernetes.io/docs/reference/using-api/client-libraries/\" rel=\"nofollow noreferrer\">Kubernetes API client libraries </a> or directly by <a href=\"https://kubernetes.io/docs/reference/using-api/api-overview/\" rel=\"nofollow noreferrer\">Kubernetes REST API</a>, that your frontend would use (3).</p>\n",
                    "OwnerUserId": "10347794",
                    "LastActivityDate": "2019-08-28T14:04:00.540",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "57717912",
                "ParentRepo": "https://github.com/codalab/codalab-worksheets/commit/6e92da072e17ad7a25c287325d0795233fd2d168",
                "StackOverflow_Post": {
                    "Id": "57717912",
                    "PostTypeId": "2",
                    "ParentId": "57712418",
                    "CreationDate": "2019-08-29T21:26:53.467",
                    "Score": "0",
                    "Body": "<p>You may need to fix the <code>codalabworker/setup.py</code> file.</p>\n\n<p>Check this: <a href=\"https://github.com/codalab/codalab-worksheets/commit/6e92da072e17ad7a25c287325d0795233fd2d168\" rel=\"nofollow noreferrer\">https://github.com/codalab/codalab-worksheets/commit/6e92da072e17ad7a25c287325d0795233fd2d168</a></p>\n\n<p>Or change <code>package_data={'': 'requirements.txt'}</code> to\n<code>package_data={'': ['requirements.txt'\\]</code>.</p>\n",
                    "OwnerUserId": "11996682",
                    "LastActivityDate": "2019-08-29T21:26:53.467",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "57744375",
                "ParentRepo": "https://github.com/BetterThanTomorrow/calva/issues/296#issuecomment-526898449",
                "StackOverflow_Post": {
                    "Id": "57744375",
                    "PostTypeId": "2",
                    "ParentId": "57744104",
                    "CreationDate": "2019-09-01T08:25:53.907",
                    "Score": "1",
                    "Body": "<p>Issue resolved, steps to connect:</p>\n\n<p><a href=\"https://github.com/BetterThanTomorrow/calva/issues/296#issuecomment-526898449\" rel=\"nofollow noreferrer\">https://github.com/BetterThanTomorrow/calva/issues/296#issuecomment-526898449</a></p>\n",
                    "OwnerUserId": "10589291",
                    "LastActivityDate": "2019-09-01T08:25:53.907",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "57744915",
                "ParentRepo": "https://github.com/tencent/pocketflow",
                "StackOverflow_Post": {
                    "Id": "57744915",
                    "PostTypeId": "2",
                    "ParentId": "55585236",
                    "CreationDate": "2019-09-01T09:48:26.110",
                    "Score": "0",
                    "Body": "<p>For 4-bit quantization on tensorflow, you can try to use pocketflow <a href=\"https://github.com/tencent/pocketflow\" rel=\"nofollow noreferrer\">https://github.com/tencent/pocketflow</a> to do your experiments.</p>\n",
                    "OwnerUserId": "1314209",
                    "LastActivityDate": "2019-09-01T09:48:26.110",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "57756096",
                "ParentRepo": "https://github.com/testcontainers/testcontainers-go",
                "StackOverflow_Post": {
                    "Id": "57756096",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "57760234",
                    "CreationDate": "2019-09-02T11:24:01.777",
                    "Score": "0",
                    "ViewCount": "420",
                    "Body": "<p>I am the current maintainer for the testcontainers-go project\n<a href=\"https://github.com/testcontainers/testcontainers-go\" rel=\"nofollow noreferrer\">https://github.com/testcontainers/testcontainers-go</a> .</p>\n\n<p>This project is a library. It does not produce any binary or docker image. I would still like to use goreleaser and the GitHub Action to automate the release process.</p>\n\n<p>I had a look around but I am not able to find the right configuration to only run goreleaser to generate the changelog. </p>\n\n<p>Do you have any suggestion?\nThanks a lot</p>\n",
                    "OwnerUserId": "1894196",
                    "LastEditorUserId": "405013",
                    "LastEditDate": "2019-09-02T16:30:47.250",
                    "LastActivityDate": "2019-09-03T06:34:56.833",
                    "Title": "goreleaser to only generate the changelog on GitHub",
                    "Tags": "<go><release><goreleaser>",
                    "AnswerCount": "2",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "57811501",
                "ParentRepo": "https://github.com/DocNow/twarc",
                "StackOverflow_Post": {
                    "Id": "57811501",
                    "PostTypeId": "2",
                    "ParentId": "2693553",
                    "CreationDate": "2019-09-05T18:55:00.473",
                    "Score": "4",
                    "Body": "<p>You can use <a href=\"https://github.com/DocNow/twarc\" rel=\"nofollow noreferrer\">twarc</a> package in python to collect all the replies to a tweet.</p>\n\n<p><code>twarc replies 824077910927691778 &gt; replies.jsonl</code></p>\n\n<p>Also, it is possible to collect all the reply chains (replies to the replies) to a tweet using command below:</p>\n\n<p><code>twarc replies 824077910927691778 --recursive</code></p>\n",
                    "OwnerUserId": "7789594",
                    "LastActivityDate": "2019-09-05T18:55:00.473",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "57908380",
                "ParentRepo": "https://github.com/containrrr/watchtower",
                "StackOverflow_Post": {
                    "Id": "57908380",
                    "PostTypeId": "2",
                    "ParentId": "35413173",
                    "CreationDate": "2019-09-12T13:58:35.313",
                    "Score": "1",
                    "Body": "<p>There's a so-called watchtower docker image. Github: <a href=\"https://github.com/containrrr/watchtower\" rel=\"nofollow noreferrer\">https://github.com/containrrr/watchtower</a>, docker hub: <a href=\"https://hub.docker.com/r/containrrr/watchtower\" rel=\"nofollow noreferrer\">https://hub.docker.com/r/containrrr/watchtower</a>.</p>\n\n<p>You use it as a side-car to the containers you want to update. Watchtower runs alongside your app, watches for pushes to the specified tags and updates your app if there is a push.</p>\n\n<p>You give up control over downtime though. Containers usually don't start instantly.</p>\n",
                    "OwnerUserId": "67774",
                    "LastActivityDate": "2019-09-12T13:58:35.313",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "58026695",
                "ParentRepo": "https://github.com/encode/httpx",
                "StackOverflow_Post": {
                    "Id": "58026695",
                    "PostTypeId": "2",
                    "ParentId": "57261619",
                    "CreationDate": "2019-09-20T10:35:45.127",
                    "Score": "2",
                    "Body": "<p>This have support for brotli requests <a href=\"https://github.com/encode/httpx\" rel=\"nofollow noreferrer\">https://github.com/encode/httpx</a>.</p>\n\n<p>Example from unit tests:</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>import brotli\nimport httpx\n\nbody = b\"test 123\"\ncompressed_body = brotli.compress(body)\n\nheaders = [(b\"Content-Encoding\", b\"br\")]\nresponse = httpx.Response(200, headers=headers, content=compressed_body)\n</code></pre>\n",
                    "OwnerUserId": "1643541",
                    "LastActivityDate": "2019-09-20T10:35:45.127",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "58029246",
                "ParentRepo": "https://github.com/abdullahselek/HerePy/commit/7c913541961dfebf6673b5e0ba1456e0d382ef10",
                "StackOverflow_Post": {
                    "Id": "58029246",
                    "PostTypeId": "2",
                    "ParentId": "58015913",
                    "CreationDate": "2019-09-20T13:22:53.060",
                    "Score": "1",
                    "Body": "<p>It looks like this function <a href=\"https://github.com/abdullahselek/HerePy/commit/7c913541961dfebf6673b5e0ba1456e0d382ef10\" rel=\"nofollow noreferrer\">was just added recently</a>, try installing the latest version from source, i.e.:</p>\n\n<ol>\n<li>Clone <a href=\"https://github.com/abdullahselek/HerePy\" rel=\"nofollow noreferrer\">the repo</a></li>\n<li>Run <code>python setup.py install</code></li>\n</ol>\n",
                    "OwnerUserId": "5012099",
                    "LastActivityDate": "2019-09-20T13:22:53.060",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "58241252",
                "ParentRepo": "https://github.com/hynek/doc2dash/issues/93#issuecomment-441318128",
                "StackOverflow_Post": {
                    "Id": "58241252",
                    "PostTypeId": "2",
                    "ParentId": "53402747",
                    "CreationDate": "2019-10-04T18:01:32.167",
                    "Score": "2",
                    "Body": "<p>looks like lxml&lt;4.0 just doesn't support python 3.7. sorry for the bad news. <a href=\"https://pypi.org/project/lxml/3.8.0/\" rel=\"nofollow noreferrer\">https://pypi.org/project/lxml/3.8.0/</a> (the latest &lt;4.0 version) only says it supports up to python 3.6; <a href=\"https://github.com/hynek/doc2dash/issues/93#issuecomment-441318128\" rel=\"nofollow noreferrer\">https://github.com/hynek/doc2dash/issues/93#issuecomment-441318128</a> confirms.</p>\n\n<p>aha, from <a href=\"https://pypi.org/project/lxml/4.0.0/#bugs-fixed\" rel=\"nofollow noreferrer\">https://pypi.org/project/lxml/4.0.0/#bugs-fixed</a> :</p>\n\n<blockquote>\n  <p>Compilation under Py3.7-pre failed due to a modified function signature.</p>\n</blockquote>\n",
                    "OwnerUserId": "186123",
                    "LastActivityDate": "2019-10-04T18:01:32.167",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "58373243",
                "ParentRepo": "https://github.com/testcontainers/testcontainers-node",
                "StackOverflow_Post": {
                    "Id": "58373243",
                    "PostTypeId": "2",
                    "ParentId": "58356178",
                    "CreationDate": "2019-10-14T08:55:53.167",
                    "Score": "1",
                    "Body": "<p><a href=\"https://github.com/testcontainers/testcontainers-node\" rel=\"nofollow noreferrer\">Testcontainers</a> is a library for running databases in docker containers during integration, it works very well with the official <a href=\"https://hub.docker.com/_/neo4j\" rel=\"nofollow noreferrer\">Neo4j docker image</a></p>\n",
                    "OwnerUserId": "951609",
                    "LastActivityDate": "2019-10-14T08:55:53.167",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "58395664",
                "ParentRepo": "https://github.com/pyrates/roll",
                "StackOverflow_Post": {
                    "Id": "58395664",
                    "PostTypeId": "2",
                    "ParentId": "56203367",
                    "CreationDate": "2019-10-15T13:16:09.083",
                    "Score": "0",
                    "Body": "<p>I used JWT with <a href=\"https://github.com/pyrates/roll\" rel=\"nofollow noreferrer\">Roll</a> and was facing a similar issue.</p>\n\n<p>It might be that your JWT secret is resetting each time your server restarts.\nIn which case the token you send cannot be validated anymore as the secret is different and you need to regenerate a token.</p>\n\n<p>However, to fix this issue you can hard code your secret for development in a settings or somewhere else.</p>\n",
                    "OwnerUserId": "328117",
                    "LastActivityDate": "2019-10-15T13:16:09.083",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "58406386",
                "ParentRepo": "https://github.com/florimondmanca/djangorestframework-api-key/blob/master/rest_framework_api_key/crypto.py",
                "StackOverflow_Post": {
                    "Id": "58406386",
                    "PostTypeId": "2",
                    "ParentId": "58406078",
                    "CreationDate": "2019-10-16T05:39:07.993",
                    "Score": "0",
                    "Body": "<p>Looking \u00e0 <a href=\"https://github.com/florimondmanca/djangorestframework-api-key/blob/master/rest_framework_api_key/crypto.py\" rel=\"nofollow noreferrer\">KeyGenerator</a> source, you might want to override your <code>KeyGenerator</code> class.</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>class CustomKeyGenerator(KeyGenerator):\n    def get_prefix(self) -&gt; str:\n        return 'your_prefix'\n\n    def get_secret_key(self) -&gt; str:\n        return 'your_secret_key'\n\n    # Below, you can modify the way your \"hasher\" works, \n    # but I wouldn't play with that as it's native django's auth' hasher.\n\n    def hash(self, key: str) -&gt; str:\n        #your hashing algorithm\n        return 'your_hashed_key'\n\n    def verify(self, key: str, hashed_key: str) -&gt; bool:\n        #checking given key\n        return bool()\n\n</code></pre>\n\n<p>Then, within your code, use <code>CustomKeyGenerator</code>instead of <code>KeyGenerator</code></p>\n\n<p><strong>Important note:</strong> Instead of overriding <code>hash</code> and <code>verify</code> function's, I'd recomend you setup your own wanted <a href=\"https://docs.djangoproject.com/en/2.2/topics/auth/passwords/\" rel=\"nofollow noreferrer\">PASSWORD_HASHERS</a></p>\n",
                    "OwnerUserId": "5681565",
                    "LastActivityDate": "2019-10-16T05:39:07.993",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "58499906",
                "ParentRepo": "https://github.com/deepmind/kapitan",
                "StackOverflow_Post": {
                    "Id": "58499906",
                    "PostTypeId": "2",
                    "ParentId": "58494159",
                    "CreationDate": "2019-10-22T08:20:22.830",
                    "Score": "0",
                    "Body": "<p>As already mentioned, that's precisely what <a href=\"https://github.com/kubernetes-sigs/kustomize\" rel=\"nofollow noreferrer\">kustomize</a> was made for.</p>\n\n<p>Other templating solutions include <a href=\"https://github.com/deepmind/kapitan\" rel=\"nofollow noreferrer\">Kapitan</a>, <a href=\"https://ksonnet.io/\" rel=\"nofollow noreferrer\">ksonnet</a>, <a href=\"https://github.com/bitnami/kubecfg\" rel=\"nofollow noreferrer\">kubecfg</a>, <a href=\"https://github.com/k14s/ytt\" rel=\"nofollow noreferrer\">ytt</a>, <a href=\"http://mikefarah.github.io/yq/\" rel=\"nofollow noreferrer\">yq</a>, and <a href=\"https://helm.sh/\" rel=\"nofollow noreferrer\">Helm</a> (more than just templating, it's also a \"package manager\").</p>\n",
                    "OwnerUserId": "4747193",
                    "LastActivityDate": "2019-10-22T08:20:22.830",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "58672022",
                "ParentRepo": "https://github.com/encode/databases/blob/f916dbbedceb0740c3708251c90a4f84108c3757/databases/core.py#L242-L247",
                "StackOverflow_Post": {
                    "Id": "58672022",
                    "PostTypeId": "2",
                    "ParentId": "58668615",
                    "CreationDate": "2019-11-02T14:30:52.107",
                    "Score": "5",
                    "Body": "<p><code>Database.execute_many()</code> calls <code>Connection.execute_many()</code> which breaks your query up into separate individual queries (one per element in <code>values</code>), here's the method (<a href=\"https://github.com/encode/databases/blob/f916dbbedceb0740c3708251c90a4f84108c3757/databases/core.py#L242-L247\" rel=\"noreferrer\">source</a>):</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>    async def execute_many(\n        self, query: typing.Union[ClauseElement, str], values: list\n    ) -&gt; None:\n        queries = [self._build_query(query, values_set) for values_set in values]\n        async with self._query_lock:\n            await self._connection.execute_many(queries)\n</code></pre>\n\n<p>Note that it calls the <code>_build_query()</code> method (<a href=\"https://github.com/encode/databases/blob/f916dbbedceb0740c3708251c90a4f84108c3757/databases/core.py#L266-L277\" rel=\"noreferrer\">source</a>):</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>    @staticmethod\n    def _build_query(\n        query: typing.Union[ClauseElement, str], values: dict = None\n    ) -&gt; ClauseElement:\n        if isinstance(query, str):\n            query = text(query)\n\n            return query.bindparams(**values) if values is not None else query\n        elif values:\n            return query.values(**values)\n\n        return query\n</code></pre>\n\n<p>As you aren't passing a <code>str</code> query and you are passing values, control enters the <code>elif values:</code> condition handling where the individual dict of values is unpacked into the <code>.values()</code> method on your query (which is <a href=\"https://docs.sqlalchemy.org/en/13/core/dml.html#sqlalchemy.sql.expression.Update.values\" rel=\"noreferrer\"><code>Update.values()</code></a>). That essentially makes the query it's trying to compile this:</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>query = (\n    User.update()\n    .where(User.c.id == bindparam(\"_id\"))\n    .values(score=bindparam(\"score\"))\n    .values(score=2, _id=1)\n)\n</code></pre>\n\n<p>That second values clause results in a new Update with new bind params that are trying to set values for both <code>score</code> and <code>_id</code>. This causes compilation of the query to fail as there is no <code>_id</code> column on the table.</p>\n\n<p>So the MCVE to reproduce the error is really this:</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>from sqlalchemy.dialects import postgresql\n\nUser.update().values(score=2, _id=1).compile(dialect=postgresql.dialect())\n</code></pre>\n\n<p>Which raises:</p>\n\n<pre><code>Traceback (most recent call last):\n  File \".\\main.py\", line 31, in &lt;module&gt;\n    User.update().values(score=2, _id=1).compile(dialect=postgresql.dialect())\n  File \"&lt;string&gt;\", line 1, in &lt;lambda&gt;\n  File \"C:\\Users\\peter\\Documents\\git\\stackoverflow\\58668615-sqalchemy-update-bindparam-primary-key\\.venv\\lib\\site-packages\\sqlalchemy\\sql\\elements.py\", line 462, in compile\n    return self._compiler(dialect, bind=bind, **kw)\n  File \"C:\\Users\\peter\\Documents\\git\\stackoverflow\\58668615-sqalchemy-update-bindparam-primary-key\\.venv\\lib\\site-packages\\sqlalchemy\\sql\\elements.py\", line 468, in _compiler\n    return dialect.statement_compiler(dialect, self, **kw)\n  File \"C:\\Users\\peter\\Documents\\git\\stackoverflow\\58668615-sqalchemy-update-bindparam-primary-key\\.venv\\lib\\site-packages\\sqlalchemy\\sql\\compiler.py\", line 571, in __init__\n    Compiled.__init__(self, dialect, statement, **kwargs)\n  File \"C:\\Users\\peter\\Documents\\git\\stackoverflow\\58668615-sqalchemy-update-bindparam-primary-key\\.venv\\lib\\site-packages\\sqlalchemy\\sql\\compiler.py\", line 319, in __init__\n    self.string = self.process(self.statement, **compile_kwargs)\n  File \"C:\\Users\\peter\\Documents\\git\\stackoverflow\\58668615-sqalchemy-update-bindparam-primary-key\\.venv\\lib\\site-packages\\sqlalchemy\\sql\\compiler.py\", line 350, in process\n    return obj._compiler_dispatch(self, **kwargs)\n  File \"C:\\Users\\peter\\Documents\\git\\stackoverflow\\58668615-sqalchemy-update-bindparam-primary-key\\.venv\\lib\\site-packages\\sqlalchemy\\sql\\visitors.py\", line 92, in _compiler_dispatch\n    return meth(self, **kw)\n  File \"C:\\Users\\peter\\Documents\\git\\stackoverflow\\58668615-sqalchemy-update-bindparam-primary-key\\.venv\\lib\\site-packages\\sqlalchemy\\sql\\compiler.py\", line 2569, in visit_update\n    self, update_stmt, crud.ISUPDATE, **kw\n  File \"C:\\Users\\peter\\Documents\\git\\stackoverflow\\58668615-sqalchemy-update-bindparam-primary-key\\.venv\\lib\\site-packages\\sqlalchemy\\sql\\crud.py\", line 62, in _setup_crud_params\n    return _get_crud_params(compiler, stmt, **kw)\n  File \"C:\\Users\\peter\\Documents\\git\\stackoverflow\\58668615-sqalchemy-update-bindparam-primary-key\\.venv\\lib\\site-packages\\sqlalchemy\\sql\\crud.py\", line 177, in _get_crud_params\n    % (\", \".join(\"%s\" % c for c in check))\nsqlalchemy.exc.CompileError: Unconsumed column names: _id\n</code></pre>\n\n<p>To summarise the issue, you build a query with bind params passed to both <code>Update.where()</code> and <code>Update.values()</code>. You then pass that query and your values to <code>Database.execute_many()</code> where they unpack the individual elements of your values list into a second call of <code>Update.values()</code> on your query which replaces your query with one that tries to set a value for an <code>_id</code> column which doesn't exist.</p>\n\n<blockquote>\n  <p>Is there any solution other than updating each row individullay?</p>\n</blockquote>\n\n<p>Well the query works just fine when using sqlalchemy engine as well as query:</p>\n\n<pre class=\"lang-py prettyprint-override\"><code># using a sqlalchemy engine\nengine.execute(query, values)\n</code></pre>\n\n<p>Otherwise, what should work is sending the query in as a string to <code>Database.execute_many()</code> as that will mean the query gets handled in the <code>if isinstance(query, str):</code> part of the <code>_build_query()</code> method which will avoid the second <code>.values()</code> call being made on the query:</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>db.execute_many(str(query), values)\n</code></pre>\n",
                    "OwnerUserId": "6560549",
                    "LastActivityDate": "2019-11-02T14:30:52.107",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "58674323",
                "ParentRepo": "https://github.com/dry-python/dry-python.github.io/tree/develop/slides",
                "StackOverflow_Post": {
                    "Id": "58674323",
                    "PostTypeId": "2",
                    "ParentId": "42037633",
                    "CreationDate": "2019-11-02T19:00:35.337",
                    "Score": "5",
                    "Body": "<p>If you need some examples regarding DDD and Django then this <a href=\"https://github.com/dry-python/dry-python.github.io/tree/develop/slides\" rel=\"nofollow noreferrer\">https://github.com/dry-python/dry-python.github.io/tree/develop/slides</a> slides using dry python tools could be useful.</p>\n<p>Also, check the example project <a href=\"https://github.com/dry-python/bookshelf\" rel=\"nofollow noreferrer\">https://github.com/dry-python/bookshelf</a></p>\n",
                    "OwnerUserId": "3544931",
                    "LastEditorUserId": "3544931",
                    "LastEditDate": "2022-12-04T16:04:11.970",
                    "LastActivityDate": "2022-12-04T16:04:11.970",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "58711657",
                "ParentRepo": "https://github.com/cashapp/sqldelight",
                "StackOverflow_Post": {
                    "Id": "58711657",
                    "PostTypeId": "2",
                    "ParentId": "58695086",
                    "CreationDate": "2019-11-05T12:44:28.167",
                    "Score": "4",
                    "Body": "<p>try <a href=\"https://github.com/icerockdev/moko-template/\" rel=\"nofollow noreferrer\">https://github.com/icerockdev/moko-template/</a> - here sample with network, serialization, shared business logic, storage.<br>\nfor database use <a href=\"https://github.com/cashapp/sqldelight\" rel=\"nofollow noreferrer\">https://github.com/cashapp/sqldelight</a><br>\nmultithreading can be done with <a href=\"https://github.com/Autodesk/coroutineworker\" rel=\"nofollow noreferrer\">https://github.com/Autodesk/coroutineworker</a> (if you want coroutines) or <a href=\"https://github.com/badoo/Reaktive\" rel=\"nofollow noreferrer\">https://github.com/badoo/Reaktive</a> (if you want Rx)</p>\n",
                    "OwnerUserId": "9931244",
                    "LastActivityDate": "2019-11-05T12:44:28.167",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "58767164",
                "ParentRepo": "https://github.com/rsinger86/django-lifecycle",
                "StackOverflow_Post": {
                    "Id": "58767164",
                    "PostTypeId": "2",
                    "ParentId": "58766787",
                    "CreationDate": "2019-11-08T13:04:46.517",
                    "Score": "0",
                    "Body": "<p>I advise you <a href=\"https://github.com/rsinger86/django-lifecycle\" rel=\"nofollow noreferrer\">django-lifecycle</a> library. Use before_create hook for the validation</p>\n",
                    "OwnerUserId": "11993534",
                    "LastActivityDate": "2019-11-08T13:04:46.517",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "58984476",
                "ParentRepo": "https://github.com/doorstop-dev/doorstop/issues/293",
                "StackOverflow_Post": {
                    "Id": "58984476",
                    "PostTypeId": "1",
                    "CreationDate": "2019-11-21T22:06:35.877",
                    "Score": "0",
                    "ViewCount": "646",
                    "Body": "<p>I am trying to delete documents which are created by doorstop and getting error as \"Multiple Root documents\" Please refer to below link for more information </p>\n\n<p><a href=\"https://github.com/doorstop-dev/doorstop/issues/293\" rel=\"nofollow noreferrer\">https://github.com/doorstop-dev/doorstop/issues/293</a></p>\n\n<p>Solution for that is to run \"mvn clean\" command but I am getting below error for \"mvn clean\" command. Any possible solutions regarding this.</p>\n\n<pre><code>(base) MANOJs-MacBook-Air:~ manojdeshpande$ mvn clean\n[INFO] Scanning for projects...\n[INFO] ------------------------------------------------------------------------\n[INFO] BUILD FAILURE\n[INFO] ------------------------------------------------------------------------\n[INFO] Total time:  0.090 s\n[INFO] Finished at: 2019-11-21T23:01:40+01:00\n[INFO] ------------------------------------------------------------------------\n[ERROR] The goal you specified requires a project to execute but there is no POM in this directory (/Users/manojdeshpande). Please verify you invoked Maven from the correct directory. -&gt; [Help 1]\n[ERROR] \n[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.\n[ERROR] Re-run Maven using the -X switch to enable full debug logging.\n[ERROR] \n[ERROR] For more information about the errors and possible solutions, please read the following articles:\n[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MissingProjectException\n</code></pre>\n",
                    "OwnerUserId": "3248113",
                    "LastActivityDate": "2019-11-22T07:45:06.857",
                    "Title": "mvn clean command on my Mac OS throws me error",
                    "Tags": "<maven><maven-plugin><osx-mavericks>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "59251954",
                "ParentRepo": "https://github.com/erayerdin/django-persistent-settings/tree/perma/1",
                "StackOverflow_Post": {
                    "Id": "59251954",
                    "PostTypeId": "1",
                    "CreationDate": "2019-12-09T15:27:55.170",
                    "Score": "1",
                    "ViewCount": "203",
                    "Body": "<p>Well, I haven't been getting some answers or commentary partly because the codes in the original content below is so restricted to their own small contexts, so instead of that, I wanted to share the whole codebase with you (don't worry, I will permalink the selected lines) because I intend to open the source anyway so that you can review as much as you'd like to.</p>\n\n<p>The whole codebase is <a href=\"https://github.com/erayerdin/django-persistent-settings/tree/perma/1\" rel=\"nofollow noreferrer\">here</a>. It's <code>perma/1</code> branch of the repository.</p>\n\n<h1>Original Content</h1>\n\n<p>I have a custom template tag as below:</p>\n\n<pre class=\"lang-py prettyprint-override\"><code># other imports\nfrom django.conf import settings\n\nDPS_TEMPLATE_TRUE_DEFAULT = getattr(settings, \"DPS_TEMPLATE_TRUE_DEFAULT\", \"True\")\n\n\n@register.simple_tag(name=\"var\")\ndef get_var(name, rit=DPS_TEMPLATE_TRUE_DEFAULT, rif=\"False\", rin=\"\"):\n    \"\"\"\n    A template tag to render value of a variable.\n    \"\"\"\n\n    _LOGGER.debug(\"Rendering value for `%s`...\", name)\n\n    variable = models.Variable.objects.get(name=name)\n    value = variable.value\n\n    if value is None:\n        return rin\n\n    if isinstance(value, bool):\n        if value:\n            return rit\n        else:\n            return rif\n\n    return variable.value\n</code></pre>\n\n<p>As you can see, I would like to set <code>rit</code> by <code>DPS_TEMPLATE_TRUE_DEFAULT</code>. I test this behavior as below:</p>\n\n<pre class=\"lang-py prettyprint-override\"><code># `template_factory` and `context_factory` creates Template and Context instances accordingly.\n# i use them in other tests. they work.\n\n    @pytest.mark.it(\"Render if True by settings\")\n    def test_render_if_true_settings(\n        self, template_factory, context_factory, variable_factory, settings\n    ):\n        settings.DPS_TEMPLATE_TRUE_DEFAULT = \"this is true by settings\"\n        variable_factory(True)\n        template = template_factory(\"FOO\", tag_name=self.tag_name).render(\n            context_factory()\n        )\n        assert \"&lt;p&gt;this is true by settings&lt;/p&gt;\" in template\n</code></pre>\n\n<p>I use <code>pytest-django</code> and, as <a href=\"https://pytest-django.readthedocs.io/en/latest/helpers.html#settings\" rel=\"nofollow noreferrer\">the docs put</a>, I can <em>kinda</em> mock the settings. However, when I run the test, it does not see <code>DPS_TEMPLATE_TRUE_DEFAULT</code> and uses <code>\"True\"</code>. I debugged this behavior by removing <code>\"True\"</code> on <code>getattr</code>.</p>\n\n<p>Why does it not see <code>DPS_TEMPLATE_TRUE_DEFAULT</code> even if I set it in tests?</p>\n\n<h1>Addition / New Content</h1>\n\n<p><a href=\"https://github.com/erayerdin/django-persistent-settings/blob/perma/1/persistent_settings/templatetags/persistent_settings.py#L10\" rel=\"nofollow noreferrer\">In the custom template tag</a>, you can see that I'd like to grab <code>DPS_TEMPLATE_TRUE_DEFAULT</code> from <code>django.conf.settings</code> and use it as <code>rit</code> kwarg in my <code>var</code> tag.</p>\n\n<p><a href=\"https://github.com/erayerdin/django-persistent-settings/blob/perma/1/project/tests/test_templatetags.py#L43-L52\" rel=\"nofollow noreferrer\">This</a> is where I test this behavior by mutating the related setting with <code>settings</code> fixture of <code>pytest-django</code> and <a href=\"https://github.com/erayerdin/django-persistent-settings/runs/344509377#step:5:28\" rel=\"nofollow noreferrer\">it fails</a>.</p>\n\n<p>As the troubleshooting section states I have also tried the other and possibly official ways to do this, they produce the same behavior. As to why it does that, I have no clue.</p>\n\n<h1>Troubleshooting</h1>\n\n<h2>Using Standard Solutions</h2>\n\n<p>The odd thing is I have also tried good-old <code>django.test.utils.override_settings</code> and <code>modify_settings</code>, which show the same behavior.</p>\n\n<h2>Eager Initialization</h2>\n\n<p>I thought, maybe, the problem was I was using <code>getattr</code> outside the scope of <code>get_var</code> function, which would load it before it executes, which means before the tests and <em>somehow</em> does not let me set it again. So I moved <code>getattr</code> inside <code>get_var</code> function but the behavior was the same. It behaves like <code>DPS_TEMPLATE_TRUE_DEFAULT</code> does not exist in settings.</p>\n\n<h2>Hardcoding into Settings File</h2>\n\n<p>So I have hardcoded the \"failing to see\" setting in the <code>settings.py</code> file as below:</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>DPS_TEMPLATE_TRUE_DEFAULT = \"this is true by settings\"\n</code></pre>\n\n<p>Still it behaves like <code>DPS_TEMPLATE_TRUE_DEFAULT</code> does not exist.</p>\n\n<p>This is also proven by removing the default value <code>\"True\"</code> from <code>getattr</code> <a href=\"https://github.com/erayerdin/django-persistent-settings/blob/perma/1/persistent_settings/templatetags/persistent_settings.py#L10\" rel=\"nofollow noreferrer\">in this line</a>.</p>\n\n<hr>\n\n<h1>Environment</h1>\n\n<ul>\n<li>Django 2.2.8</li>\n<li>Pytest Django 3.7.0</li>\n</ul>\n",
                    "OwnerUserId": "2926992",
                    "LastEditorUserId": "2926992",
                    "LastEditDate": "2019-12-11T20:31:17.403",
                    "LastActivityDate": "2019-12-11T20:31:17.403",
                    "Title": "Django does not Override Settings in Template Tag Testing",
                    "Tags": "<python><django><pytest><pytest-django>",
                    "AnswerCount": "0",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "59267393",
                "ParentRepo": "https://github.com/jmfayard/gradle-dependencies-plugins",
                "StackOverflow_Post": {
                    "Id": "59267393",
                    "PostTypeId": "2",
                    "ParentId": "59216701",
                    "CreationDate": "2019-12-10T12:36:27.277",
                    "Score": "2",
                    "Body": "<p>In my environment inspection is broken also. So I used from third-party plugin and run it task in some interval for checking available update and manage it.</p>\n\n<p>More details: <a href=\"https://github.com/jmfayard/gradle-dependencies-plugins\" rel=\"nofollow noreferrer\">https://github.com/jmfayard/gradle-dependencies-plugins</a></p>\n",
                    "OwnerUserId": "3032347",
                    "LastActivityDate": "2019-12-10T12:36:27.277",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "59277154",
                "ParentRepo": "https://github.com/erm/mangum",
                "StackOverflow_Post": {
                    "Id": "59277154",
                    "PostTypeId": "2",
                    "ParentId": "59276760",
                    "CreationDate": "2019-12-11T00:11:47.067",
                    "Score": "1",
                    "Body": "<p>From <a href=\"https://github.com/pgjones/quart/issues/68\" rel=\"nofollow noreferrer\">https://github.com/pgjones/quart/issues/68</a>:</p>\n\n<blockquote>\n  <p>Quart is an ASGI framework, rather than a WSGI framework, which means that it cannot work with serverless. It can work with <a href=\"https://github.com/erm/mangum\" rel=\"nofollow noreferrer\">Mangum</a>, which is an ASGI alternative to serverless.</p>\n</blockquote>\n\n<p>This also means that Quart will not be compatible with App Engine, Cloud Functions, etc.</p>\n\n<p>However, it would work well with <a href=\"https://cloud.google.com/run/\" rel=\"nofollow noreferrer\">Cloud Run</a> via a HTTP server that supports ASGI such as <a href=\"https://www.uvicorn.org/\" rel=\"nofollow noreferrer\">Uvicorn</a>.</p>\n",
                    "OwnerUserId": "328036",
                    "LastActivityDate": "2019-12-11T00:11:47.067",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "59364138",
                "ParentRepo": "https://github.com/pwwang/python-varname",
                "StackOverflow_Post": {
                    "Id": "59364138",
                    "PostTypeId": "2",
                    "ParentId": "18425225",
                    "CreationDate": "2019-12-16T20:52:48.173",
                    "Score": "85",
                    "Body": "<h2>TL;DR</h2>\n<p>Use the <code>Wrapper</code> helper from <a href=\"https://github.com/pwwang/python-varname\" rel=\"noreferrer\"><code>python-varname</code></a>:</p>\n<pre class=\"lang-py prettyprint-override\"><code>from varname.helpers import Wrapper\n\nfoo = Wrapper(dict())\n\n# foo.name == 'foo'\n# foo.value == {}\nfoo.value['bar'] = 2\n</code></pre>\n<p>For list comprehension part, you can do:</p>\n<pre class=\"lang-py prettyprint-override\"><code>n_jobs = Wrapper(&lt;original_value&gt;) \nusers = Wrapper(&lt;original_value&gt;) \nqueues = Wrapper(&lt;original_value&gt;) \npriorities = Wrapper(&lt;original_value&gt;) \n\nlist_of_dicts = [n_jobs, users, queues, priorities]\ncolumns = [d.name for d in list_of_dicts]\n# ['n_jobs', 'users', 'queues', 'priorities']\n# REMEMBER that you have to access the &lt;original_value&gt; by d.value\n</code></pre>\n<p>I am the author of the <a href=\"https://github.com/pwwang/python-varname\" rel=\"noreferrer\"><code>python-varname</code></a> package. Please let me know if you have any questions or you can submit issues on Github.</p>\n<h2>The long answer</h2>\n<h3>Is it even possible?</h3>\n<p>Yes and No.</p>\n<p>We are retrieving the variable names at runtime, so we need a function to be called to enable us to access the previous frames to retrieve the variable names. That's why we need a <code>Wrapper</code> there. In that function, at runtime, we are parsing the source code/AST nodes in the previous frames to get the exact variable name.</p>\n<p>However, the source code/AST nodes in the previous frames are not always available, or they could be modified by other environments (e.g: <code>pytest</code>'s <code>assert</code> statement). One simple example is that the codes run via <code>exec()</code>.  Even though we are still able to retrieve some information from the bytecode, it needs too much effort and it is also error-prone.</p>\n<h3>How to do it?</h3>\n<p>First of all, we need to identify which frame the variable is given. It's not always simply the direct previous frame. For example, we may have another wrapper for the function:</p>\n<pre class=\"lang-py prettyprint-override\"><code>from varname import varname\n\ndef func():\n  return varname()\n\ndef wrapped():\n  return func()\n\nx = wrapped()\n</code></pre>\n<p>In the above example, we have to skip the frame inside <code>wrapped</code> to get to the right frame <code>x = wrapped()</code> so that we are able to locate <code>x</code>. The arguments <code>frame</code> and <code>ignore</code> of <code>varname</code> allow us to skip some of these intermediate frames. See more details in the README file and the API docs of the package.</p>\n<p>Then we need to parse the AST node to locate where the variable is assigned value (function call) to. It's not always just a simple assignment. Sometimes there could be complex AST nodes, for example, <code>x = [wrapped()]</code>. We need to identify the correct assignment by traversing the AST tree.</p>\n<h3>How reliable is it?</h3>\n<p>Once we identify the assignment node, it is reliable.</p>\n<p><code>varname</code> is all depending on <a href=\"https://github.com/alexmojaki/executing\" rel=\"noreferrer\"><code>executing</code></a> package to look for the node. The node executing detects is ensured to be the correct one (see also <a href=\"https://github.com/alexmojaki/executing#is-it-reliable\" rel=\"noreferrer\">this</a>).</p>\n<p>It partially works with environments where other AST magics apply, including pytest, ipython, macropy, birdseye, reticulate with R, etc. Neither executing nor varname is 100% working with those environments.</p>\n<h3>Do we need a package to do it?</h3>\n<p>Well, yes and no, again.</p>\n<p>If your scenario is simple, the code provided by @juan Isaza or @scohe001 probably is enough for you to work with the case where a variable is defined at the direct previous frame and the AST node is a simple assignment. You just need to go one frame back and retrieve the information there.</p>\n<p>However, if the scenario becomes complicated, or we need to adopt different application scenarios, you probably need a package like <a href=\"https://github.com/pwwang/python-varname\" rel=\"noreferrer\"><code>python-varname</code></a>, to handle them. These scenarios may include to:</p>\n<ol>\n<li>present more friendly messages when the source code is not available or AST nodes are not accessible</li>\n<li>skip intermediate frames (allows the function to be wrapped or called in other intermediate frames)</li>\n<li>automatically ignores calls from built-in functions or libraries. For example: <code>x = str(func())</code></li>\n<li>retrieve multiple variable names on the left-hand side of the assignment</li>\n<li>etc.</li>\n</ol>\n<p>How about the <code>f-string</code>?</p>\n<p>Like the answer provided by @Aivar Paalberg. It's definitely fast and reliable. However, it's not at runtime, meaning that you have to know it's <code>foo</code> before you print the name out. But with <code>varname</code>, you don't have to know that variable is coming:</p>\n<pre class=\"lang-py prettyprint-override\"><code>from varname import varname\n\ndef func():\n  return varname()\n\n# In external uses\nx = func() # 'x'\ny = func() # 'y'\n</code></pre>\n<h3>Finally</h3>\n<p><code>python-varname</code> is not only able to detect the variable name from an assignment, but also:</p>\n<ul>\n<li>Retrieve variable names directly, using <code>nameof</code></li>\n<li>Detect next immediate attribute name, using <code>will</code></li>\n<li>Fetch argument names/sources passed to a function using <code>argname</code></li>\n</ul>\n<p>Read more from its documentation.</p>\n<p>However, the final word I want to say is that, <strong>try to avoid using it whenever you can.</strong></p>\n<p>Because you can't make sure that the client code will run in an environment where the source node is available or AST node is accessible. And of course, it costs resources to parse the source code, identify the environment, retrieve the AST nodes and evaluate them when needed.</p>\n",
                    "OwnerUserId": "5088165",
                    "LastEditorUserId": "5088165",
                    "LastEditDate": "2021-12-14T16:56:07.550",
                    "LastActivityDate": "2021-12-14T16:56:07.550",
                    "CommentCount": "17",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "59428821",
                "ParentRepo": "https://github.com/smallrye/smallrye-reactive-messaging/blob/master/api/src/main/java/io/smallrye/reactive/messaging/annotations/Stream.java",
                "StackOverflow_Post": {
                    "Id": "59428821",
                    "PostTypeId": "2",
                    "ParentId": "56218161",
                    "CreationDate": "2019-12-20T16:53:02.653",
                    "Score": "3",
                    "Body": "<blockquote>\n  <p>Since <a href=\"https://stackoverflow.com/a/56220264/7773032\">Clement's answer</a> the <a href=\"https://github.com/smallrye/smallrye-reactive-messaging/blob/master/api/src/main/java/io/smallrye/reactive/messaging/annotations/Stream.java\" rel=\"nofollow noreferrer\"><code>@Stream</code></a> annotation has been deprecated. The <a href=\"https://github.com/smallrye/smallrye-reactive-messaging/blob/master/api/src/main/java/io/smallrye/reactive/messaging/annotations/Channel.java\" rel=\"nofollow noreferrer\"><code>@Channel</code></a> annotation\n  must be used instead.</p>\n</blockquote>\n\n<p>You can use an <code>Emitter</code> provided by the <code>quarkus-smallrye-reactive-messaging-kafka</code> dependency to produce message to a Kafka topic. </p>\n\n<p>A simple Kafka producer implementation:</p>\n\n<pre class=\"lang-java prettyprint-override\"><code>public class MyKafkaProducer {\n\n    @Inject\n    @Channel(\"my-topic\")\n    Emitter&lt;String&gt; myEmitter;\n\n    public void produce(String message) {\n      myEmitter.send(message);\n    }\n}\n</code></pre>\n\n<p>And the following configuration must be added to the application.properties file:</p>\n\n<pre><code>mp.messaging.outgoing.my-topic.connector=smallrye-kafka\nmp.messaging.outgoing.my-topic.bootstrap.servers=localhost:9092\nmp.messaging.outgoing.my-topic.value.serializer=org.apache.kafka.common.serialization.StringSerializer\n</code></pre>\n\n<p>This will produce string serialized messages to a kafka topic named <code>my-topic</code>.</p>\n\n<p>Note that by default the name of the channel is also the name of the kafka topic in which the data will be produced. This behavior can be changed through the configuration. The supported configuration attributes are described in the reactive Messaging <a href=\"https://smallrye.io/smallrye-reactive-messaging/#_forwarding_messages_to_kafka\" rel=\"nofollow noreferrer\">documentation</a></p>\n",
                    "OwnerUserId": "7773032",
                    "LastEditorUserId": "7773032",
                    "LastEditDate": "2019-12-24T14:57:53.840",
                    "LastActivityDate": "2019-12-24T14:57:53.840",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "59432914",
                "ParentRepo": "https://github.com/aPureBase/KGraphQL/issues/10",
                "StackOverflow_Post": {
                    "Id": "59432914",
                    "PostTypeId": "2",
                    "ParentId": "58328920",
                    "CreationDate": "2019-12-21T01:34:35.410",
                    "Score": "0",
                    "Body": "<p>The closest GraphQL equivalent of a streaming response is probably a subscription: <a href=\"https://graphql.org/blog/subscriptions-in-graphql-and-relay/\" rel=\"nofollow noreferrer\">https://graphql.org/blog/subscriptions-in-graphql-and-relay/</a> .  Implementing what you're doing as a subscription to DB row \"events\" seems reasonable to me.</p>\n\n<p>It looks like that's not currently implemented in KGraphQL: <a href=\"https://github.com/aPureBase/KGraphQL/issues/10\" rel=\"nofollow noreferrer\">https://github.com/aPureBase/KGraphQL/issues/10</a></p>\n\n<p>The graphql-kotlin project (<a href=\"https://github.com/ExpediaGroup/graphql-kotlin\" rel=\"nofollow noreferrer\">https://github.com/ExpediaGroup/graphql-kotlin</a>) however, has subscriptions implemented on top of a spring-boot base: <a href=\"https://expediagroup.github.io/graphql-kotlin/docs/server/subscriptions\" rel=\"nofollow noreferrer\">https://expediagroup.github.io/graphql-kotlin/docs/server/subscriptions</a> .  </p>\n\n<p>If you're used to jersey and would prefer to stick with that, we've put together a separate implementation leveraging graphql-kotlin's base libraries to implement subscriptions on a dropwizard (jersey, etc) base: <a href=\"https://github.com/trib3/leakycauldron/tree/master/graphql\" rel=\"nofollow noreferrer\">https://github.com/trib3/leakycauldron/tree/master/graphql</a></p>\n",
                    "OwnerUserId": "10997589",
                    "LastActivityDate": "2019-12-21T01:34:35.410",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "59494725",
                "ParentRepo": "https://github.com/keras-team/autokeras",
                "StackOverflow_Post": {
                    "Id": "59494725",
                    "PostTypeId": "2",
                    "ParentId": "54238519",
                    "CreationDate": "2019-12-27T00:19:19.587",
                    "Score": "3",
                    "Body": "<p>I have Windows 10, Anaconda 2019.10 and Python 3.7.5. In my case, I get the error <code>ERROR: No matching distribution found for torch==1.0.1.post2 (from autokeras)</code> on Windows 10 when trying to <code>pip install autokeras</code> as indicated by the official documentation.</p>\n\n<p>Then I try to get the source code from <a href=\"https://github.com/keras-team/autokeras\" rel=\"nofollow noreferrer\">https://github.com/keras-team/autokeras</a> and run <code>python setup.py install</code>. It successfully installs autokeras for me.</p>\n",
                    "OwnerUserId": "7978903",
                    "LastActivityDate": "2019-12-27T00:19:19.587",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "59543667",
                "ParentRepo": "https://github.com/koxudaxi/local-data-api/",
                "StackOverflow_Post": {
                    "Id": "59543667",
                    "PostTypeId": "2",
                    "ParentId": "57650408",
                    "CreationDate": "2019-12-31T11:41:10.290",
                    "Score": "8",
                    "Body": "<p>Have a look at <a href=\"https://github.com/koxudaxi/local-data-api/\" rel=\"noreferrer\">local-data-api</a>, it looks like what you're asking for. </p>\n\n<p>It is a Docker image that hosts a Data API proxy and either a Postgres or MySQL instance; you can find pull it for DockerHub, image info is here: <a href=\"https://hub.docker.com/r/koxudaxi/local-data-api\" rel=\"noreferrer\">https://hub.docker.com/r/koxudaxi/local-data-api</a>, including instructions how to run it.</p>\n",
                    "OwnerUserId": "26391",
                    "LastActivityDate": "2019-12-31T11:41:10.290",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "59545228",
                "ParentRepo": "https://github.com/wso2/docs-is/pull/1007",
                "StackOverflow_Post": {
                    "Id": "59545228",
                    "PostTypeId": "2",
                    "ParentId": "59528744",
                    "CreationDate": "2019-12-31T14:17:38.807",
                    "Score": "1",
                    "Body": "<p>There is an issue with the toml configuration in the mentioned documentation. Please use the following corrected deployment.toml in the 4th step.</p>\n\n<pre><code># Google reCAPTCHA settings\n\n# Enable Google reCAPTCHA\n[recaptcha] \nenabled= true\n\n# reCaptcha API URL\napi_url=\"https://www.google.com/recaptcha/api.jssss\"\n\n# reCaptcha verification URL\nverify_url=\"https://www.google.com/recaptcha/api/siteverify\"\n\n# reCaptcha site key\nsite_key=\"6Lc8THgUAAAAAPekxT991FGFXRrsiPCMNv5PwZHB\"\n\n# reCaptcha secret key\nsecret_key=\"6Lc8THgUAAAAAEu83iOwSin_CSt6gqe97aa7EGFd\"\n</code></pre>\n\n<p>The documentation issue will be fixed with this <a href=\"https://github.com/wso2/docs-is/pull/1007\" rel=\"nofollow noreferrer\">PR</a>. Thank you for reporting. </p>\n\n<hr>\n\n<p>[Update]</p>\n\n<p>About your use-case, the current implementation of the doesn't have the ability to cover this use case. The implementation needs the username, from this only the tenant name can be retrieved and specific tenant configurations(the Max failed attempts you configured in the resident idp \n) can be used for the ReCaptcha.</p>\n",
                    "OwnerUserId": "9624430",
                    "LastEditorUserId": "9624430",
                    "LastEditDate": "2019-12-31T16:11:16.523",
                    "LastActivityDate": "2019-12-31T16:11:16.523",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "59558252",
                "ParentRepo": "https://github.com/TailorDev/Watson",
                "StackOverflow_Post": {
                    "Id": "59558252",
                    "PostTypeId": "1",
                    "CreationDate": "2020-01-02T04:23:35.760",
                    "Score": "5",
                    "ViewCount": "2606",
                    "Body": "<h1>TLDR;</h1>\n\n<p>I need a way for <code>.zshrc</code> to automatically be sourced each time a command is executed. <code>PROMPT</code> needs to be updated each time a command is executed in order to show relevant information in the prompt.</p>\n\n<h1>Reason</h1>\n\n<p>I use <a href=\"https://github.com/TailorDev/Watson\" rel=\"noreferrer\">Watson cli</a> for tracking time. On my previous bash setup, I prepended my prompt (<code>$PS1</code>) with a symbol that indicates whether the timer is running or not (red/green). I have mimicked this functionality with Oh My Zsh, as follows (in the theme file):</p>\n\n<pre><code>WATSON_DIR=\"$HOME/Library/Application Support/watson\"\nwatson_status() {\n    local txtred=\"${fg_bold[red]}\"\n    local txtgrn=\"${fg_bold[green]}\"\n    local txtrst=\"${reset_color}\"\n\n    # Started\n    local status_color=\"$txtgrn\"\n\n    # Stopped\n    if [[ $(cat \"$WATSON_DIR/state\") == '{}' ]]; then\n        status_color=\"$txtred\"\n    fi\n    echo -e \"$status_color\"\"\u25c9\"\"$txtrst\"\n}\n\nPROMPT=\"\u256d\u2500\u2500 %{$(watson_status) $fg_bold[green]%}%~%{$reset_color%}$(git_prompt_info) \u231a %{$FG[130]%}%*%{$reset_color%}\n\u2570\u2500\u27a4 $ \"\n</code></pre>\n\n<h1>Current issue</h1>\n\n<p>The icon will indicate the color of the state at the time that .zshrc was executed. For example, if the timer is running and the icon is properly indicating green, stopping the timer will not cause the icon to turn red. In order to see the icon change color, I have to source .zshrc. </p>\n\n<p>This indicates that the function <code>watson_status()</code> needs to be run each time a command is executed, to give the latest status at the time of the command</p>\n",
                    "OwnerUserId": "1170429",
                    "LastActivityDate": "2020-12-10T04:52:35.777",
                    "Title": "make zsh prompt update each time a command is executed",
                    "Tags": "<zsh><oh-my-zsh>",
                    "AnswerCount": "1",
                    "CommentCount": "6",
                    "FavoriteCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "59610025",
                "ParentRepo": "https://github.com/alexanderankin/pyfpdf",
                "StackOverflow_Post": {
                    "Id": "59610025",
                    "PostTypeId": "2",
                    "ParentId": "59609882",
                    "CreationDate": "2020-01-06T10:00:18.197",
                    "Score": "1",
                    "Body": "<p>Most probably you are using Python 3.x where x >= 5 . </p>\n\n<p>On the pypi it says that the module has only experimental support for python 3.y where y &lt;= 4 .</p>\n\n<p>Try it with python 2.7 and it might work.</p>\n\n<p>PS: Better try <a href=\"https://pypi.org/project/fpdf2/\" rel=\"nofollow noreferrer\">https://pypi.org/project/fpdf2/</a>, the updated version. For bugs or issues see <a href=\"https://github.com/alexanderankin/pyfpdf\" rel=\"nofollow noreferrer\">https://github.com/alexanderankin/pyfpdf</a> .</p>\n\n<p>If you really want to use the old version, you can install whatever version you want from the original repo like this </p>\n\n<pre><code>pip install git+https://github.com/reingart/pyfpdf@&lt;branchname of tag or commit&gt; \n</code></pre>\n",
                    "OwnerUserId": "3725896",
                    "LastEditorUserId": "3725896",
                    "LastEditDate": "2020-01-06T11:11:57.707",
                    "LastActivityDate": "2020-01-06T11:11:57.707",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "59815441",
                "ParentRepo": "https://github.com/prefecthq/prefect",
                "StackOverflow_Post": {
                    "Id": "59815441",
                    "PostTypeId": "2",
                    "ParentId": "58419203",
                    "CreationDate": "2020-01-19T23:44:42.900",
                    "Score": "4",
                    "Body": "<p>From the knowledge I gained in my attempt to answer this question, I've come to the conclusion that <strong>Airflow is just not the tool for the job.</strong></p>\n\n<p>Airflow is designed for <em>scheduled</em>, idempotent DAGs. A DagRun must also have a unique <code>execution_date</code>; this means running the same DAG at the exact same start time (in the case that we receive two documents at the same time is quite literally impossible. Of course, we can schedule the next DagRun immediately in succession, but this limitation should demonstrate that any attempt to use Airflow in this fashion will always be, to an extent, a hack.</p>\n\n<p>The most viable solution I've found is to instead use <a href=\"https://github.com/prefecthq/prefect\" rel=\"nofollow noreferrer\">Prefect</a>, which was developed with the intention of overcoming some of the limitations of Airflow:</p>\n\n<p>\"Prefect assumes that flows can be run at any time, for any reason.\"</p>\n\n<p>Prefect's equivalent of a DAG is a Flow; one key advantage of a flow that we may take advantage of is the ease of parametriziation. Then, with some threads, we're able to have a Flow run for each element in a stream. Here is an example streaming ETL pipeline:</p>\n\n<pre><code>import time\nfrom prefect import task, Flow, Parameter\nfrom threading import Thread\n\u200b\n\u200b\ndef stream():\n    for x in range(10):\n        yield x\n        time.sleep(1)\n\u200b\n\u200b\n@task\ndef extract(x):\n    # If 'x' referenced a document, in this step we could load that document\n    return x\n\u200b\n\u200b\n@task\ndef transform(x):\n    return x * 2\n\u200b\n\u200b\n@task\ndef load(y):\n    print(\"Received y: {}\".format(y))\n\u200b\n\u200b\nwith Flow(\"ETL\") as flow:\n    x_param = Parameter('x')\n    e = extract(x_param)\n    t = transform(e)\n    l = load(t)\n\u200b\nfor x in stream():\n    thread = Thread(target=flow.run, kwargs={\"x\": x})\n    thread.start()\n</code></pre>\n",
                    "OwnerUserId": "4418475",
                    "LastEditorUserId": "4418475",
                    "LastEditDate": "2020-01-19T23:55:49.883",
                    "LastActivityDate": "2020-01-19T23:55:49.883",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "59820407",
                "ParentRepo": "https://github.com/mingw-w64/mingw-w64.github.io/",
                "StackOverflow_Post": {
                    "Id": "59820407",
                    "PostTypeId": "2",
                    "ParentId": "59820244",
                    "CreationDate": "2020-01-20T09:35:01.693",
                    "Score": "8",
                    "Body": "<p>Strangely enough it doesn't come with a C compiler, we need to install one,  <a href=\"https://github.com/mingw-w64/mingw-w64.github.io/\" rel=\"nofollow noreferrer\">Mingw-w64</a> is allways my  choice, you will need to <a href=\"http://www.codebind.com/cprogramming/install-mingw-windows-10-gcc/\" rel=\"nofollow noreferrer\">add the path in environment variables</a> (step 12), if you want to use it anywhere. You can then use the <code>gcc</code> command where it's more convenient like in Linux, don't forget to open a new cmd after the changes for them to take effect.</p>\n<p>Unfortunately, Windows doesn't have the command line tools for installing/removing stuff and the great repository infrastructure we know and love from Linux.</p>\n",
                    "OwnerUserId": "6865932",
                    "LastEditorUserId": "6865932",
                    "LastEditDate": "2022-05-17T11:50:18.087",
                    "LastActivityDate": "2022-05-17T11:50:18.087",
                    "CommentCount": "4",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "59894833",
                "ParentRepo": "https://github.com/INCATools/ontology-development-kit/blob/master/Dockerfile",
                "StackOverflow_Post": {
                    "Id": "59894833",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "59897268",
                    "CreationDate": "2020-01-24T10:42:02.263",
                    "Score": "2",
                    "ViewCount": "178",
                    "Body": "<p>I am using the exact same section in two different Dockerfiles (base is ubuntu:18.04 in both cases) that downloads two files from a remote location using wget. </p>\n\n<pre><code>ENV ROBOT v1.5.0\nENV ROBOT_JAR=https://github.com/ontodev/robot/releases/download/$ROBOT/robot.jar\nRUN wget $ROBOT_JAR -O /tools/robot.jar &amp;&amp; \\\n    wget https://raw.githubusercontent.com/ontodev/robot/$ROBOT/bin/robot -O /tools/robot &amp;&amp; \\\n    chmod +x /tools/*\n</code></pre>\n\n<p><code>docker history --no-trunc [...]</code></p>\n\n<p>tells me that in the one Dockerfile, the layer created by this command, is 114 MB:</p>\n\n<pre><code>... /bin/sh -c wget $ROBOT_JAR -O /tools/robot.jar &amp;&amp;     wget https://raw.githubusercontent.com/ontodev/robot/$ROBOT/bin/robot -O /tools/robot &amp;&amp;     chmod +x /tools/* 114MB   \n</code></pre>\n\n<p>and in the other only 44.9MB:</p>\n\n<pre><code>... /bin/sh -c wget $ROBOT_JAR -O /tools/robot.jar &amp;&amp;     wget https://raw.githubusercontent.com/ontodev/robot/$ROBOT/bin/robot -O /tools/robot &amp;&amp;     chmod +x /tools/* 44.9MB              \n</code></pre>\n\n<p>Apart from being the same base, the Dockerfiles are of course very different (the 114MB one is huge, for example, while the 45MB one has only two defined layers); I am curious: What could cause the difference in size? Can this be mitigated somehow?</p>\n\n<p>EDIT 1:</p>\n\n<p>Here is the 114 MB case: <a href=\"https://github.com/INCATools/ontology-development-kit/blob/master/Dockerfile\" rel=\"nofollow noreferrer\">https://github.com/INCATools/ontology-development-kit/blob/master/Dockerfile</a></p>\n\n<p>Here is the other: <a href=\"https://github.com/INCATools/ontology-development-kit/blob/master/docker/testdocker/Dockerfile\" rel=\"nofollow noreferrer\">https://github.com/INCATools/ontology-development-kit/blob/master/docker/testdocker/Dockerfile</a></p>\n",
                    "OwnerUserId": "2451542",
                    "LastEditorUserId": "2451542",
                    "LastEditDate": "2020-01-24T11:31:03.180",
                    "LastActivityDate": "2020-01-24T13:19:27.923",
                    "Title": "Why does the same RUN command in a Dockerfile lead to different layer sizes across images?",
                    "Tags": "<docker><dockerfile>",
                    "AnswerCount": "1",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "59956029",
                "ParentRepo": "https://github.com/PrefectHQ/prefect",
                "StackOverflow_Post": {
                    "Id": "59956029",
                    "PostTypeId": "2",
                    "ParentId": "59164875",
                    "CreationDate": "2020-01-28T19:50:01.850",
                    "Score": "3",
                    "Body": "<p>This is now possible on the <a href=\"https://github.com/PrefectHQ/prefect\" rel=\"nofollow noreferrer\">master branch</a> of Prefect and will be released with 0.9.2 next week: the <a href=\"https://docs.prefect.io/core/concepts/schedules.html#clocks\" rel=\"nofollow noreferrer\">Clocks API</a> now allows for providing parameters to each clock that will be passed to each flow run generated from that clock.  In your case, you can do:</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>from prefect import task, Flow, Task, Parameter\nfrom prefect.schedules import clocks, Schedule\n\ndiurnal   = ['rooster', 'dog']\nnocturnal = ['owl', 'hampster']\n\n# Clocks\ndiurnal_clock   = clocks.CronClock(\"50 7 * * mon,wed\", parameter_defaults={\"animals\": diurnal})\nnocturnal_clock = clocks.CronClock(\"15 12 * * tue,thu\", parameter_defaults={\"animals\": nocturnal})\n\n# the full schedule\nschedule = Schedule(clocks=[diurnal_clock, nocturnal_clock])\n\n# Flow is common to both types, though with different schedules.\nwith Flow(name=\"wakuptime\", schedule=schedule) as this_flow:\n    animals = Parameter(\"animals\", default=[])\n    wakeup(animals)\n\n# will run on the schedule with varying parameter values\nthis_flow.run()\n</code></pre>\n",
                    "OwnerUserId": "1617887",
                    "LastActivityDate": "2020-01-28T19:50:01.850",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "59974398",
                "ParentRepo": "https://github.com/wso2/docs-apim/issues/498",
                "StackOverflow_Post": {
                    "Id": "59974398",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "59979023",
                    "CreationDate": "2020-01-29T19:37:59.947",
                    "Score": "1",
                    "ViewCount": "243",
                    "Body": "<p>I have newly added <strong>messageFormatter</strong> and <strong>messageBuilder</strong> similar to:</p>\n\n<pre><code>&lt;messageFormatter contentType=\"application/hal+json\" class=\"org.apache.synapse.commons.json.JsonStreamFormatter\"/&gt;\n\n&lt;messageBuilder contentType=\"application/hal+json\" class=\"org.apache.synapse.commons.json.JsonStreamBuilder\"/&gt;\n</code></pre>\n\n<p>In this two files:</p>\n\n<ul>\n<li>[API-HOME]/repository/conf/axis/<strong>axis2.xml</strong></li>\n<li>[API-HOME]/repository/conf/axis/<strong>axis2_blocking_client.xml</strong></li>\n</ul>\n\n<p>in API Manager version 3.0.0.</p>\n\n<p>But in the APIM version 3.0.0 all changes in this files discards because any server configuration is: [API-HOME]/repository/conf/<strong>deployment.toml</strong>, reference: <a href=\"https://github.com/wso2/docs-apim/issues/498\" rel=\"nofollow noreferrer\">https://github.com/wso2/docs-apim/issues/498</a></p>\n\n<p>What is the correct way of adding these lines ?</p>\n\n<p>Thanks!</p>\n",
                    "OwnerUserId": "12642641",
                    "LastEditorUserId": "2674285",
                    "LastEditDate": "2020-01-30T08:16:49.057",
                    "LastActivityDate": "2020-04-10T18:04:53.237",
                    "Title": "WSO2 API Manager Add hal+json",
                    "Tags": "<wso2><wso2-api-manager>",
                    "AnswerCount": "2",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "60040977",
                "ParentRepo": "https://github.com/PedroBern/django-graphql-auth/blob/f596826a02188e5f1acb75d62246c840d609ff79/graphql_auth/schema.py#L10",
                "StackOverflow_Post": {
                    "Id": "60040977",
                    "PostTypeId": "2",
                    "ParentId": "60039959",
                    "CreationDate": "2020-02-03T14:13:24.280",
                    "Score": "5",
                    "Body": "<p>You can define a custom field for pk, here is an example with user.</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>from django.contrib.auth import get_user_model\nimport graphene\nfrom graphene_django.types import DjangoObjectType\nfrom graphene_django.filter.fields import DjangoFilterConnectionField\n\n\nclass UserNode(DjangoObjectType):\n    class Meta:\n        model = get_user_model()\n        interfaces = (graphene.relay.Node,)\n\n    pk = graphene.Int()\n\n    def resolve_pk(self, info):\n        return self.pk\n\nclass UserQuery(graphene.ObjectType):\n    user = graphene.relay.Node.Field(UserNode)\n    users = DjangoFilterConnectionField(UserNode)\n\nclass Query(UserQuery, graphene.ObjectType):\n    pass\n\nschema = graphene.Schema(query=Query)\n</code></pre>\n\n<p>Then you can query like:</p>\n\n<pre><code>query {\n  users{\n    edges {\n      node {\n        pk\n      }\n    }\n  }\n}\n</code></pre>\n\n<p>You can check other examples <a href=\"https://github.com/PedroBern/django-graphql-auth/blob/f596826a02188e5f1acb75d62246c840d609ff79/graphql_auth/schema.py#L10\" rel=\"noreferrer\">here</a>.</p>\n",
                    "OwnerUserId": "10645790",
                    "LastActivityDate": "2020-02-03T14:13:24.280",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "60047398",
                "ParentRepo": "https://github.com/dvershinin/lastversion/blob/v0.2.4/setup.py#L43",
                "StackOverflow_Post": {
                    "Id": "60047398",
                    "PostTypeId": "2",
                    "ParentId": "60045473",
                    "CreationDate": "2020-02-03T21:26:27.940",
                    "Score": "0",
                    "Body": "<p>Just my two cents, rather than a complete answer. Will mostly touch on RPM packaging.</p>\n\n<p>The <code>bdist_rpm</code> option seems easy, but you have little control of the logic of the <code>.spec</code> file it generates/uses and cannot do fancy stuff like scriplets, etc.</p>\n\n<p>That is, unless you take the approach of having it generate the <code>.spec</code> file and quit (instead of building final RPM). From the <a href=\"https://docs.python.org/2/distutils/builtdist.html#creating-rpm-packages\" rel=\"nofollow noreferrer\">docs</a>:</p>\n\n<blockquote>\n  <p>If you wish, you can separate these three steps. You can use the --spec-only option to make bdist_rpm just create the .spec file and exit; in this case, the .spec file will be written to the \u201cdistribution directory\u201d\u2014normally dist/, but customizable with the --dist-dir option. (Normally, the .spec file winds up deep in the \u201cbuild tree,\u201d in a temporary directory created by bdist_rpm.)</p>\n</blockquote>\n\n<p>But as a matter of preference and consistency, I would advise on following distro-specific guidelines for packaging Python apps.</p>\n\n<p>In that way, you will be more in line with the distro's you are building for.</p>\n\n<p>It is not the easiest way though. You will have to shift through some <a href=\"https://docs.fedoraproject.org/en-US/packaging-guidelines/Python/\" rel=\"nofollow noreferrer\">docs</a>. Basically, if you're building for anything CentOS/RHEL, Fedora guidelines for packaging should be observed.</p>\n\n<p>You can find the extra reference <a href=\"https://docs.fedoraproject.org/en-US/packaging-guidelines/Python_Appendix/\" rel=\"nofollow noreferrer\">here</a>, with the example <code>.spec</code> file for building both Python 2 and 3 versions of the same app.</p>\n\n<p>For this whole 'build like a distro' thing, you would definitely want to look into using <code>mock</code> for the job, to build your package in a chroot.</p>\n\n<p>As for the \"shortcut\" issue, you have to have your <code>setup.py</code> declare some console scripts for it to create one when you install your package.  E.g. from <a href=\"https://github.com/dvershinin/lastversion/blob/v0.2.4/setup.py#L43\" rel=\"nofollow noreferrer\">lastversion's setup.py</a>:</p>\n\n<pre><code>entry_points={\"console_scripts\": [\"lastversion = lastversion:main\"]},\n</code></pre>\n\n<p>This entry will result in a \"binary\" <code>lastversion</code> created/installed (which runs the defined function) when you install your Python package.</p>\n\n<p>Subsequently, in the spec files, the macro <code>%py2_install</code> will make use of <code>setup.py</code> to create the same launcher program.</p>\n\n<p>And you will then be able to ensure that launcher is packaged by placing it in the files section of the spec file:</p>\n\n<pre><code>%files -n python3-myapp\n%license COPYING\n%doc README.rst\n%{python3_sitelib}/%{srcname}/\n%{python3_sitelib}/%{srcname}-*.egg-info/\n%{_bindir}/myapp\n</code></pre>\n",
                    "OwnerUserId": "285069",
                    "LastActivityDate": "2020-02-03T21:26:27.940",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "60065918",
                "ParentRepo": "https://github.com/pedrobern/django-graphql-auth/",
                "StackOverflow_Post": {
                    "Id": "60065918",
                    "PostTypeId": "2",
                    "ParentId": "58236345",
                    "CreationDate": "2020-02-04T21:39:49.263",
                    "Score": "0",
                    "Body": "<p>To register a user from a react app, you can use <a href=\"https://github.com/pedrobern/django-graphql-auth/\" rel=\"nofollow noreferrer\">django-graphql-auth</a>.</p>\n\n<p>It is great with react because if you want to use <a href=\"https://relay.dev/\" rel=\"nofollow noreferrer\">relay</a>, it is fully compatible.</p>\n\n<p>The registration process is made by sending the following graphql mutation to the server:</p>\n\n<pre><code>mutation {\n  register(\n    email:\"someemail@email.com\",\n    username:\"someusername\",\n    password1: \"somepassword\",\n    password2:\"somepassword\"\n  ) {\n    success,\n    errors,\n    token,\n    refreshToken\n  }\n}\n</code></pre>\n\n<p>You don't need to clean the password, as the it will be handled by django, for example, on a bad request would return something like:</p>\n\n<pre><code>{\n  \"data\": {\n    \"register\": {\n      \"success\": false,\n      \"errors\": {\n        \"password2\": [\n          {\n            \"message\": \"This password is too short. It must contain at least 8 characters.\",\n            \"code\": \"password_too_short\"\n          },\n          {\n            \"message\": \"This password is too common.\",\n            \"code\": \"password_too_common\"\n          },\n          {\n            \"message\": \"This password is entirely numeric.\",\n            \"code\": \"password_entirely_numeric\"\n          }\n        ]\n      },\n      \"token\": null,\n      \"refreshToken\": null\n    }\n  }\n}\n</code></pre>\n\n<p>The <a href=\"https://django-graphql-auth.readthedocs.io/en/latest/\" rel=\"nofollow noreferrer\">docs</a> have more examples.</p>\n\n<p>(I'm the author)</p>\n",
                    "OwnerUserId": "10645790",
                    "LastActivityDate": "2020-02-04T21:39:49.263",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "60111016",
                "ParentRepo": "https://github.com/camunda/camunda-rest-client-spring-boot",
                "StackOverflow_Post": {
                    "Id": "60111016",
                    "PostTypeId": "1",
                    "CreationDate": "2020-02-07T09:54:48.793",
                    "Score": "0",
                    "ViewCount": "863",
                    "Body": "<p>I use a <a href=\"https://github.com/camunda/camunda-rest-client-spring-boot\" rel=\"nofollow noreferrer\">library</a> that defines some OpenFeign clients using spring-cloud-openfeign. I need to add an interceptor to these clients to add an authorization header without changing the library code.</p>\n\n<p>So far I just defined the interceptor as a Spring bean and everything worked. But now I added another OpenFeign client that needs a different interceptor, which I defined using the <code>configuration</code> attribute of the <code>@FeignClient</code> annotation. My problem is that the new client now gets both interceptors.</p>\n\n<p>I tried configuring the first interceptor using application properties instead, but the interceptor needs to get another bean injected, which seems to require defining it as a bean, which would add it to the second client again.</p>\n\n<p>I also tried to find an equivalent to CDI's <code>@Typed</code> annotation so that the interceptor would only be found when looking for it's concrete class but not when looking for the <code>RequestInterceptor</code> interface, but couldn't find any.</p>\n\n<p>Is there any way to add a configuration to an OpenFeign client defined in a library such that it does not affect any other clients?</p>\n",
                    "OwnerUserId": "2764119",
                    "LastEditorUserId": "2764119",
                    "LastEditDate": "2020-02-07T11:59:22.823",
                    "LastActivityDate": "2020-02-10T23:04:44.143",
                    "Title": "How to add specific configuration to a Spring Cloud OpenFeign client defined in a library?",
                    "Tags": "<spring-cloud><spring-cloud-feign><openfeign>",
                    "AnswerCount": "1",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "60164203",
                "ParentRepo": "https://github.com/splewis/get5/wiki/Stats-system",
                "StackOverflow_Post": {
                    "Id": "60164203",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "60165194",
                    "CreationDate": "2020-02-11T07:53:49.200",
                    "Score": "-1",
                    "ViewCount": "118",
                    "Body": "<p>I've been developing a discord bot for the game Counter Strike Global Offensive and upon me trying to widen its features i've come across something i've never seen before. I have been looking for the past 4 hours and can't find anything related close enough for me to make a connection.\nI am using this plugin for the game that places a text file in my servers directory that I will be FTPing to gain access to (I got that part down pretty easily). \n<a href=\"https://github.com/splewis/get5/wiki/Stats-system\" rel=\"nofollow noreferrer\">https://github.com/splewis/get5/wiki/Stats-system</a></p>\n\n<p>I do have my users stats and soon to be settings that are stored on a json file, but thats with a format that I know of, this file is generated by the game server whenever I run a command (ill be doing it with another plugin at the end of each game automatically) so I have no control of changing the format.</p>\n\n<p><strong>What i'm trying to do:</strong>\nRead specific lines of data from a unknown structured text file and turn those into strings after each game.</p>\n\n<p>My code (just reading the text file)</p>\n\n<pre><code>   with open('get5_matchstats.cfg', 'r') as file:\n   data = file.read()\nprint(data)\n</code></pre>\n\n<p>Output (exact same as text file): </p>\n\n<pre><code>\"Stats\"\n{\n    \"series_type\"       \"bo1\"\n    \"map0\"\n    {\n        \"team1\"\n        {\n            \"76561628991367478\"\n            {\n                \"roundsplayed\"      \"7\"\n                \"name\"      \"CoC Legende\"\n                \"deaths\"        \"3\"\n                \"damage\"        \"415\"\n                \"kills\"     \"4\"\n                \"headshot_kills\"        \"2\"\n                \"1kill_rounds\"      \"4\"\n                \"firstdeath_ct\"     \"2\"\n                \"firstkill_ct\"      \"1\"\n            }\n            \"7655212110096592\"\n            {\n                \"roundsplayed\"      \"7\"\n                \"name\"      \"payperview\"\n                \"deaths\"        \"2\"\n                \"firstdeath_ct\"     \"1\"\n                \"damage\"        \"672\"\n                \"kills\"     \"6\"\n                \"1kill_rounds\"      \"1\"\n                \"headshot_kills\"        \"3\"\n                \"3kill_rounds\"      \"1\"\n                \"firstkill_ct\"      \"1\"\n                \"assists\"       \"1\"\n                \"2kill_rounds\"      \"1\"\n            }\n            \"76561198821291593\"\n            {\n                \"roundsplayed\"      \"7\"\n                \"name\"      \"dog\"\n                \"damage\"        \"458\"\n                \"deaths\"        \"3\"\n                \"assists\"       \"1\"\n                \"firstdeath_ct\"     \"1\"\n                \"firstkill_ct\"      \"2\"\n                \"kills\"     \"4\"\n                \"1kill_rounds\"      \"1\"\n                \"headshot_kills\"        \"2\"\n                \"3kill_rounds\"      \"1\"\n            }\n            \"76561668131605879\"\n            {\n                \"roundsplayed\"      \"7\"\n                \"name\"      \"Cat\"\n                \"damage\"        \"640\"\n                \"firstkill_ct\"      \"1\"\n                \"kills\"     \"7\"\n                \"2kill_rounds\"      \"1\"\n                \"bomb_defuses\"      \"1\"\n                \"1kill_rounds\"      \"5\"\n                \"tradekill\"     \"1\"\n                \"headshot_kills\"        \"1\"\n            }\n            \"76566648819479703\"\n            {\n                \"roundsplayed\"      \"7\"\n                \"name\"      \"BackAndImBetter\"\n                \"damage\"        \"801\"\n                \"kills\"     \"9\"\n                \"3kill_rounds\"      \"2\"\n                \"firstkill_ct\"      \"1\"\n                \"headshot_kills\"        \"3\"\n                \"assists\"       \"1\"\n                \"2kill_rounds\"      \"1\"\n                \"deaths\"        \"1\"\n                \"bomb_defuses\"      \"1\"\n                \"1kill_rounds\"      \"1\"\n            }\n            \"score\"     \"6\"\n        }\n        \"team2\"\n        {\n            \"76561198120865213\"\n            {\n                \"roundsplayed\"      \"7\"\n                \"name\"      \"Squid\"\n                \"damage\"        \"231\"\n                \"deaths\"        \"6\"\n                \"firstdeath_t\"      \"2\"\n                \"kills\"     \"1\"\n                \"headshot_kills\"        \"1\"\n                \"1kill_rounds\"      \"1\"\n            }\n            \"76561198355321210\"\n            {\n                \"roundsplayed\"      \"7\"\n                \"name\"      \"Chub vc_0\"\n                \"damage\"        \"106\"\n                \"kills\"     \"1\"\n                \"deaths\"        \"6\"\n                \"1kill_rounds\"      \"1\"\n                \"firstdeath_t\"      \"1\"\n            }\n            \"76561197963353523\"\n            {\n                \"roundsplayed\"      \"7\"\n                \"name\"      \"Bravo\"\n                \"damage\"        \"630\"\n                \"assists\"       \"1\"\n                \"deaths\"        \"6\"\n                \"firstdeath_t\"      \"1\"\n                \"bomb_plants\"       \"2\"\n                \"kills\"     \"3\"\n                \"1kill_rounds\"      \"1\"\n                \"firstkill_t\"       \"1\"\n                \"2kill_rounds\"      \"1\"\n            }\n            \"76561198111573735\"\n            {\n                \"roundsplayed\"      \"7\"\n                \"name\"      \"Manager\"\n                \"damage\"        \"255\"\n                \"firstkill_t\"       \"2\"\n                \"kills\"     \"3\"\n                \"headshot_kills\"        \"1\"\n                \"deaths\"        \"6\"\n                \"2kill_rounds\"      \"1\"\n                \"1kill_rounds\"      \"1\"\n                \"firstdeath_t\"      \"2\"\n            }\n            \"76561198853686342\"\n            {\n                \"roundsplayed\"      \"7\"\n                \"name\"      \"Compliment\"\n                \"damage\"        \"282\"\n                \"deaths\"        \"6\"\n                \"assists\"       \"1\"\n                \"firstkill_t\"       \"1\"\n                \"kills\"     \"1\"\n                \"headshot_kills\"        \"1\"\n                \"1kill_rounds\"      \"1\"\n            }\n            \"score\"     \"0\"\n        }\n        \"mapname\"       \"de_season\"\n    }\n}\n\n\nProcess finished with exit code 0\n</code></pre>\n\n<p>Before needing this information I will have their steam64ID (the large set of numbers) which I will use to create a link between their discord account and game stats.</p>\n\n<p>The only thing I believe I need help with is figuring how specifically to get things like team score, user kills, deaths, damage etc.</p>\n\n<p>Thanks a lot for your guys' time, having this bit of knowledge will help me progress my bot significantly.</p>\n",
                    "OwnerUserId": "12876582",
                    "LastActivityDate": "2020-02-11T09:06:39.730",
                    "Title": "How to read specific data in this oddly structured text file? Python",
                    "Tags": "<python><discord.py><read-data>",
                    "AnswerCount": "1",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "60257690",
                "ParentRepo": "https://github.com/xaratustrah/iqtools",
                "StackOverflow_Post": {
                    "Id": "60257690",
                    "PostTypeId": "2",
                    "ParentId": "60170170",
                    "CreationDate": "2020-02-17T07:26:39.853",
                    "Score": "1",
                    "Body": "<p>Should be possible with <a href=\"https://github.com/xaratustrah/iqtools\" rel=\"nofollow noreferrer\">iqtools</a> library. I regularly use it to jump to a certain position of very large files (tested around 5GB) using <code>seek</code> and read a portion only, not the whole file. Generally you should consider the TDMS file containing a huge string of data points with a bit of complex data format inside, <strong>length of frames</strong>, <strong>number of frames</strong> are basically numbers for your analysis convenience. \"Jumping\" is done using the <strong>starting frame</strong> argument.</p>\n\n<pre><code>from iqtools import *\nfilename ='blah.tdms'\nmyiq=TDMSData(filename)\nmyiq.read(nframes=100, lframes=1024, sframes=400)\n</code></pre>\n\n<p>Which means reading 100 frames each 1024 samples long starting from sample 400.</p>\n\n<p>For very small files, there is also another <code>read_complete_file</code> function. In the library there are many other tools for spectral analysis such as 1D and 2D spectrograms, <strong>multi taper</strong> etc. There are some examples in the repository.</p>\n\n<p>btw. <a href=\"https://github.com/xaratustrah/iqtools\" rel=\"nofollow noreferrer\">iqtools</a> library has also a GUI front end called <a href=\"https://github.com/xaratustrah/iqgui\" rel=\"nofollow noreferrer\">IQGUI</a>, which, although not as versatile as the library interface, can be used to \"traverse\" through the time file using a visual slider.</p>\n\n<p>maybe this can help.</p>\n",
                    "OwnerUserId": "5177935",
                    "LastActivityDate": "2020-02-17T07:26:39.853",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "60339862",
                "ParentRepo": "https://github.com/blockchaintp/daml-on-sawtooth",
                "StackOverflow_Post": {
                    "Id": "60339862",
                    "PostTypeId": "2",
                    "ParentId": "60339357",
                    "CreationDate": "2020-02-21T13:43:15.837",
                    "Score": "3",
                    "Body": "<p>The open source DAML on Sawtooth and DAML on Fabric integrations built by partners BTP and HACERA can be found here in github, and instructions on how to run the respective network locally for the purposes of development and evaluation are included in the readmes</p>\n\n<p>Hyperledger Sawtooth\n<a href=\"https://github.com/blockchaintp/daml-on-sawtooth\" rel=\"nofollow noreferrer\">https://github.com/blockchaintp/daml-on-sawtooth</a></p>\n\n<p>Hyperledger Fabric\n<a href=\"https://github.com/hacera/daml-on-fabric\" rel=\"nofollow noreferrer\">https://github.com/hacera/daml-on-fabric</a></p>\n\n<p>For a fully supported production usage of DAML on Sawtooth, please see the BTP Sextant offering via AWS Marketplace\n<a href=\"https://aws.amazon.com/marketplace/pp/B07Z8HPN96\" rel=\"nofollow noreferrer\">https://aws.amazon.com/marketplace/pp/B07Z8HPN96</a></p>\n\n<p>Once you have spun up the network, you can allocate parties and upload your DAR files using the DAML assistant tool that is part of the DAML SDK, which I assume you have already installed if you have already built smart contracts in DAML\n<a href=\"https://docs.daml.com/getting-started/installation.html\" rel=\"nofollow noreferrer\">https://docs.daml.com/getting-started/installation.html</a></p>\n\n<p>The daml ledger upload-dar and daml ledger allocate-parties commands will be the ones you want to use to initialize the ledger with the specific of your application, and ensure you specific the correct --host and --port for the running ledger.</p>\n",
                    "OwnerUserId": "11062698",
                    "LastActivityDate": "2020-02-21T13:43:15.837",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "60421794",
                "ParentRepo": "https://github.com/NaturalHistoryMuseum/ckanext-userdatasets",
                "StackOverflow_Post": {
                    "Id": "60421794",
                    "PostTypeId": "2",
                    "ParentId": "60292145",
                    "CreationDate": "2020-02-26T20:09:43.377",
                    "Score": "1",
                    "Body": "<p>For a vanilla CKAN implementation permissions are managed via the organizations that own each dataset as you noted. The default permission system can be modified via an extension and there are quite a few that exist although I am unsure if any match your request. You could check these out as potential solutions or an example from which to build your own:</p>\n\n<p><a href=\"https://github.com/NaturalHistoryMuseum/ckanext-userdatasets\" rel=\"nofollow noreferrer\">https://github.com/NaturalHistoryMuseum/ckanext-userdatasets</a></p>\n\n<p><a href=\"https://github.com/okfn/ckanext-collaborators\" rel=\"nofollow noreferrer\">https://github.com/okfn/ckanext-collaborators</a></p>\n\n<p><a href=\"https://github.com/conwetlab/ckanext-privatedatasets\" rel=\"nofollow noreferrer\">https://github.com/conwetlab/ckanext-privatedatasets</a></p>\n",
                    "OwnerUserId": "11985151",
                    "LastActivityDate": "2020-02-26T20:09:43.377",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "60563166",
                "ParentRepo": "https://github.com/stuebersystems/mkdocs-img2fig-plugin",
                "StackOverflow_Post": {
                    "Id": "60563166",
                    "PostTypeId": "2",
                    "ParentId": "39616519",
                    "CreationDate": "2020-03-06T11:27:13.687",
                    "Score": "0",
                    "Body": "<p>Rather than tweaking the CSS, it might be easier to try a different plugin, such as <a href=\"https://github.com/stuebersystems/mkdocs-img2fig-plugin\" rel=\"nofollow noreferrer\">img2fig</a></p>\n",
                    "OwnerUserId": "342327",
                    "LastActivityDate": "2020-03-06T11:27:13.687",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "60569493",
                "ParentRepo": "https://github.com/MathieuB1/KOREK-backend/commit/ff6a4b542cda583a1d5abbf200a5d57ef328cae0#diff-95e545fb374a9ed7e8af8c31087a3f29",
                "StackOverflow_Post": {
                    "Id": "60569493",
                    "PostTypeId": "2",
                    "ParentId": "59632125",
                    "CreationDate": "2020-03-06T18:09:53.220",
                    "Score": "5",
                    "Body": "<p>Fixed by using @database_sync_to_async decorator:</p>\n\n<p>(see <a href=\"https://github.com/MathieuB1/KOREK-backend/commit/ff6a4b542cda583a1d5abbf200a5d57ef328cae0#diff-95e545fb374a9ed7e8af8c31087a3f29\" rel=\"noreferrer\">https://github.com/MathieuB1/KOREK-backend/commit/ff6a4b542cda583a1d5abbf200a5d57ef328cae0#diff-95e545fb374a9ed7e8af8c31087a3f29</a>)</p>\n\n\n\n<pre><code>import jwt, re\nimport traceback\nfrom channels.auth import AuthMiddlewareStack\nfrom channels.db import database_sync_to_async\nfrom django.contrib.auth.models import AnonymousUser\nfrom django.conf import LazySettings\nfrom jwt import InvalidSignatureError, ExpiredSignatureError, DecodeError\nfrom django.contrib.auth.models import User\nfrom django.contrib.sessions.models import Session\n\nsettings = LazySettings()\n\nfrom django.db import close_old_connections\n\n@database_sync_to_async\ndef close_connections():\n    close_old_connections()\n\n@database_sync_to_async\ndef get_user(user_jwt):\n    try:\n        return User.objects.get(id=user_jwt)\n    except User.DoesNotExist:\n        return AnonymousUser()\n\n\nclass TokenAuthMiddleware:\n    \"\"\"\n    Token authorization middleware for Django Channels 2\n    \"\"\"\n    def __init__(self, inner):\n        self.inner = inner\n\n    def __call__(self, scope):\n        # Close old database connections to prevent usage of timed out connections\n        close_connections()\n\n        # Login with JWT\n        try:\n            if scope['subprotocols'][0] != 'None':\n\n                token = scope['subprotocols'][0]\n\n                try:\n                    user_jwt = jwt.decode(\n                        token,\n                        settings.SECRET_KEY,\n                    )\n                    scope['user'] = get_user(user_jwt['user_id'])\n                    return self.inner(scope)\n\n                except (InvalidSignatureError, KeyError, ExpiredSignatureError, DecodeError):\n                    traceback.print_exc()\n                    pass\n                except Exception as e:\n                    traceback.print_exc()\n            else:\n                raise\n</code></pre>\n",
                    "OwnerUserId": "10707666",
                    "LastEditorUserId": "5675325",
                    "LastEditDate": "2020-03-06T18:31:41.827",
                    "LastActivityDate": "2020-03-06T18:31:41.827",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "60776764",
                "ParentRepo": "https://github.com/ansible-community/molecule/blob/master/molecule/provisioner/ansible/playbooks/docker/create.yml",
                "StackOverflow_Post": {
                    "Id": "60776764",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "60810144",
                    "CreationDate": "2020-03-20T15:09:15.500",
                    "Score": "3",
                    "ViewCount": "1041",
                    "Body": "<p>I have a molecule test which spins up 2 Docker containers, for testing 2 application versions at once.</p>\n\n<pre><code>dependency:\n  name: galaxy\ndriver:\n  name: docker\nlint:\n  name: yamllint\nplatforms:\n  - name: molecule1\n    hostname: molecule1\n    image: \"geerlingguy/docker-${MOLECULE_DISTRO:-centos7}-ansible:latest\"\n    command: ${MOLECULE_DOCKER_COMMAND:-\"\"}\n    volumes:\n      - /sys/fs/cgroup:/sys/fs/cgroup:ro\n    privileged: true\n    pre_build_image: true\n  - name: molecule2\n    hostname: molecule2\n    image: \"geerlingguy/docker-${MOLECULE_DISTRO:-centos7}-ansible:latest\"\n    command: ${MOLECULE_DOCKER_COMMAND:-\"\"}\n    volumes:\n      - /sys/fs/cgroup:/sys/fs/cgroup:ro\n    privileged: true\n    pre_build_image: true\nprovisioner:\n  name: ansible\n  inventory:\n    host_vars:\n      molecule1:\n        app_version: \"v1\"\n      molecule2:\n        app_version: \"v2\"\n  lint:\n    name: ansible-lint\nscenario:\n  name: default\n  converge_sequence:\n    - syntax\n    - lint\n    - create\n    - prepare\n    - converge\n    - idempotence\n    - verify\nverifier:\n  name: goss\n  lint:\n    name: yamllint\n</code></pre>\n\n<p>I am looking for a way to specify the memory like <code>-m</code> or <code>--memory=</code> as described <a href=\"https://docs.docker.com/config/containers/resource_constraints/\" rel=\"nofollow noreferrer\">here</a>.</p>\n\n<p>I understand that <code>molecule</code> makes use of the <code>docker_container</code> ansible module, which support the <a href=\"https://docs.ansible.com/ansible/latest/modules/docker_container_module.html#parameter-memory\" rel=\"nofollow noreferrer\">memory</a> parameter, but somehow I cannot find a way to make this work in <code>molecule</code>.</p>\n\n<p>Any ideas how to accomplish this?</p>\n\n<p>PS: My guess is that this parameter is not yet implemented in molecule, if my assumption is correct that <a href=\"https://github.com/ansible-community/molecule/blob/master/molecule/provisioner/ansible/playbooks/docker/create.yml\" rel=\"nofollow noreferrer\">this</a> is the implementation.</p>\n\n<p>Thanks in advance.</p>\n",
                    "OwnerUserId": "10637968",
                    "LastActivityDate": "2020-03-31T16:28:35.507",
                    "Title": "Ansible molecule using docker - how to specify memory limit",
                    "Tags": "<docker><ansible><molecule>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "60820172",
                "ParentRepo": "https://github.com/microsoft/coyote",
                "StackOverflow_Post": {
                    "Id": "60820172",
                    "PostTypeId": "5",
                    "CreationDate": "2020-03-23T19:15:31.270",
                    "Score": "0",
                    "Body": "<p><strong>Coyote: making it easier for developers to build reliable asynchronous software</strong></p>\n\n<p>Coyote, an <a href=\"https://github.com/microsoft/coyote\" rel=\"nofollow noreferrer\">open-source .NET</a> framework from Microsoft Research that guides developers toward designing, implementing, and testing code in a way that embraces non-determinism and asynchrony and helps them create asynchronous systems quickly and confidently.</p>\n\n<p>This advanced testing tool can control every source of non-determinism defined, including the exact order of every asynchronous operation, which allows it to systematically explore all the possibilities. The tool runs very quickly and reaches unheard-of levels of coverage of all non-deterministic choices in code, enabling it to find most of the tricky bugs in a way that\u2019s also trivial to reproduce and debug.</p>\n\n<p><strong>Coyote programming models</strong></p>\n\n<p>Coyote, which evolved from a previous Microsoft Research project called P#, is a combination of a programming model, a lightweight runtime, and a testing infrastructure all packaged as a portable library with minimal dependencies. The framework supports two main programming models: an asynchronous tasks programming model (in preview) and an asynchronous actors programming model.</p>\n\n<p>If you\u2019re happy developing your code using C# async/await construct for asynchronous tasks, then Coyote can add value on top of that. If you switch to the <a href=\"https://microsoft.github.io/coyote/learn/programming-models/async/overview\" rel=\"nofollow noreferrer\">Coyote task library</a>, the Coyote testing tool will look for bugs by systematically exploring the concurrency between your tasks. However, while the C# async/await feature is wonderful, it sometimes yields code that is too parallel, resulting in a lot of complexity. For example, when performing two or more concurrent tasks, you may need to guard private data with locks, and then you have to worry about deadlocks. Coyote offers an alternative that solves this with the more advanced <a href=\"https://microsoft.github.io/coyote/learn/programming-models/actors/overview\" rel=\"nofollow noreferrer\">asynchronous actors programming model</a>.\nActors constrain your parallelism so that a given actor receives messages in a serialized order via an inbox. Actor models have gained a lot of popularity, especially in the area of distributed systems, precisely because they help manage the complexity of a system. Actors essentially embrace asynchrony by making every message between actors an async operation. Coyote fully understands the semantics of actors and can do a world-class job of testing them and finding even the most subtle bugs. The framework goes one step further, providing a type of actor called a <a href=\"https://microsoft.github.io/coyote/learn/programming-models/actors/state-machines\" rel=\"nofollow noreferrer\">state machine</a>, which it knows how to fully test, ensuring every state is covered and every state transition is tested.</p>\n\n<p><strong>Building blocks of Coyote applications</strong></p>\n\n<p>The Coyote programming models are easy to use, so even with minimal investment, you get the huge upside of a powerful testing tool that automatically finds bugs in your code. And the more time and resources you invest in Coyote, the greater the benefits. Coyote provides the following building blocks for more reliable software:</p>\n\n<ul>\n<li><a href=\"https://microsoft.github.io/coyote/learn/ref/Microsoft.Coyote.Tasks/TaskType\" rel=\"nofollow noreferrer\">Task</a>: a wrapper on .NET tasks that allows the Coyote testing tool\nto take control of scheduling </li>\n<li><a href=\"https://microsoft.github.io/coyote/learn/ref/Microsoft.Coyote.Actors/ActorType\" rel=\"nofollow noreferrer\">Actor</a>, <a href=\"https://microsoft.github.io/coyote/learn/ref/Microsoft.Coyote.Actors/StateMachineType\" rel=\"nofollow noreferrer\">StateMachine</a>, and Event: base classes for the Coyote actors programming model</li>\n<li><a href=\"https://microsoft.github.io/coyote/learn/ref/Microsoft.Coyote.Specifications/SpecificationType\" rel=\"nofollow noreferrer\">Specification</a> and <a href=\"https://microsoft.github.io/coyote/learn/ref/Microsoft.Coyote.Specifications/MonitorType\" rel=\"nofollow noreferrer\">Monitor</a>: ways to embed checks into code that can be verified at test time; this also includes easy ways of monitoring liveness, ensuring that code doesn\u2019t get stuck spinning its wheels</li>\n<li><a href=\"https://microsoft.github.io/coyote/learn/programming-models/actors/timers\" rel=\"nofollow noreferrer\">Timers</a>: a way to model timing activities in a system, which is especially useful in the design of mocks that model external systems </li>\n<li><a href=\"https://microsoft.github.io/coyote/learn/core/logging\" rel=\"nofollow noreferrer\">Logging</a>: a feature that allows you to see debug messages in context with decisions being made during a Coyote test run, including nice ways to visualize what\u2019s happening</li>\n</ul>\n\n<p>In addition to the above constructs, Coyote allows you to use the full power of the C# programming language. To get the best test performance, it is recommended to mock all the systems outside your control. This allows the Coyote testing tool to test code locally on a laptop. The following example\u2014a shopping cart system with all external services written as Coyote mock actors\u2014shows a typical test setup:</p>\n\n<p><a href=\"https://i.stack.imgur.com/eYS7Q.jpg\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/eYS7Q.jpg\" alt=\"enter image description here\"></a></p>\n\n<p>To get the best test performance from the Coyote framework, it\u2019s recommended that developers mock all the systems outside their control. Above is a typical test setup, a shopping cart system with all external services written as Coyote mock actors using the asynchronous actors programming model.</p>\n\n<p>Larger teams can share their Coyote mocks for improved code reuse in testing. In fact, you can publish your Coyote mocks as a precise protocol definition of your public services. The Coyote testing tool can then be used to fully certify that new customer code is working properly with the mock model of the service before customers even attempt to use your production APIs.</p>\n\n<p>Coyote mocks can be more sophisticated than normal mocks. They not only specify the asynchronous API required to talk to a service, but they can also serve as a rich model of how the service is expected to behave. Most teams are already building mocks, so switching that over to work with Coyote usually requires minimal effort.</p>\n\n<p><strong>Learn more and contribute</strong></p>\n\n<p>The Coyote package is available on <a href=\"https://www.nuget.org/packages/Microsoft.Coyote/\" rel=\"nofollow noreferrer\">NuGet</a>, so <a href=\"https://microsoft.github.io/coyote/learn/get-started/install\" rel=\"nofollow noreferrer\">getting started</a> with Coyote is very simple. Coyote is also <a href=\"http://github.com/microsoft/coyote\" rel=\"nofollow noreferrer\">open source on GitHub</a> and available to all who want to provide feedback and suggestions. Submit your pull requests if you have specific ideas on how to improve Coyote. You can also learn more about the <a href=\"https://microsoft.github.io/coyote/learn/resources/publications\" rel=\"nofollow noreferrer\">research behind Coyote</a>.</p>\n\n<hr>\n\n<p><strong>Related tags</strong></p>\n\n<ul>\n<li><a href=\"https://stackoverflow.com/questions/tagged/async-await\"> [async-await]</a></li>\n<li><a href=\"https://stackoverflow.com/questions/tagged/asynchronous\">[asynchronous]</a></li>\n<li><a href=\"https://stackoverflow.com/questions/tagged/actor\">[actor]</a></li>\n<li><a href=\"https://stackoverflow.com/questions/tagged/state-machine\">[state-machine]</a></li>\n<li><a href=\"https://stackoverflow.com/questions/tagged/task\">[task]</a></li>\n<li><a href=\"https://stackoverflow.com/questions/tagged/task-parallel-library\">[task-parallel-library]</a></li>\n</ul>\n",
                    "OwnerUserId": "36305",
                    "LastEditorUserId": "36305",
                    "LastEditDate": "2020-03-24T16:22:38.550",
                    "LastActivityDate": "2020-03-24T16:22:38.550",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "61138925",
                "ParentRepo": "https://github.com/loonghao/photoshop_python_api",
                "StackOverflow_Post": {
                    "Id": "61138925",
                    "PostTypeId": "2",
                    "ParentId": "56469651",
                    "CreationDate": "2020-04-10T11:01:03.943",
                    "Score": "2",
                    "Body": "<p>You can try to use the package <code>photoshop_python_api</code>.</p>\n\n<p><a href=\"https://github.com/loonghao/photoshop_python_api\" rel=\"nofollow noreferrer\">https://github.com/loonghao/photoshop_python_api</a></p>\n\n<p><code>Hello World</code> for this package.</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>import photoshop as ps\n\n\ndef hello_world():\n    app = ps.Application()\n    doc = app.documents.add()\n    text_color = ps.SolidColor()\n    text_color.rgb.green = 255\n    new_text_layer = doc.artLayers.add()\n    new_text_layer.kind = ps.LayerKind.TextLayer\n    new_text_layer.textItem.contents = 'Hello, World!'\n    new_text_layer.textItem.position = [160, 167]\n    new_text_layer.textItem.size = 40\n    new_text_layer.textItem.color = text_color\n    options = ps.JPEGSaveOptions(quality=5)\n    jpg = 'd:/hello_world.jpg'\n    doc.saveAs(jpg, options, asCopy=True)\n    app.doJavaScript(f'alert(\"save to jpg: {jpg}\")')\n\n\nif __name__ == '__main__':\n    hello_world()\n</code></pre>\n\n<p>More examples:</p>\n\n<p><a href=\"https://photoshop-python-api.readthedocs.io/en/master/examples.html\" rel=\"nofollow noreferrer\">https://photoshop-python-api.readthedocs.io/en/master/examples.html</a></p>\n",
                    "OwnerUserId": "6796060",
                    "LastEditorUserId": "6796060",
                    "LastEditDate": "2020-04-10T17:08:02.720",
                    "LastActivityDate": "2020-04-10T17:08:02.720",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "61219910",
                "ParentRepo": "https://github.com/blurg/sauron-engine",
                "StackOverflow_Post": {
                    "Id": "61219910",
                    "PostTypeId": "2",
                    "ParentId": "61030617",
                    "CreationDate": "2020-04-15T01:34:44.203",
                    "Score": "1",
                    "Body": "<p>You provided a simple case. However if your logic is getting more complicated, you may need a <a href=\"https://en.wikipedia.org/wiki/Business_rules_engine\" rel=\"nofollow noreferrer\">rules engine</a> to handle the chaos.</p>\n\n<p>You can try <a href=\"https://github.com/blurg/sauron-engine\" rel=\"nofollow noreferrer\">Sauron Rule engine</a> or find some Python rules engines from PYPI.</p>\n",
                    "OwnerUserId": "3619192",
                    "LastActivityDate": "2020-04-15T01:34:44.203",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "61346652",
                "ParentRepo": "https://github.com/loonghao/photoshop-python-api",
                "StackOverflow_Post": {
                    "Id": "61346652",
                    "PostTypeId": "2",
                    "ParentId": "29109677",
                    "CreationDate": "2020-04-21T15:01:58.080",
                    "Score": "0",
                    "Body": "<p>you can try to use <code>photoshop-python-api</code></p>\n\n<pre><code>from photoshop import Session\n\nwith Session() as ps:\n    print(ps.app.currentTool)\n</code></pre>\n\n<p><a href=\"https://github.com/loonghao/photoshop-python-api\" rel=\"nofollow noreferrer\">https://github.com/loonghao/photoshop-python-api</a></p>\n",
                    "OwnerUserId": "6796060",
                    "LastActivityDate": "2020-04-21T15:01:58.080",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "61808042",
                "ParentRepo": "https://github.com/giswqs/geemap/blob/master/examples/notebooks/10_shapefiles.ipynb",
                "StackOverflow_Post": {
                    "Id": "61808042",
                    "PostTypeId": "2",
                    "ParentId": "48148800",
                    "CreationDate": "2020-05-14T21:50:58.420",
                    "Score": "0",
                    "Body": "<p>This is possible with the geemap package from Dr. Quisheng Wu from University of Tennessee Knoxville.</p>\n\n<p>There's an example notebook for the geemap.shp_to_ee() function here: <a href=\"https://github.com/giswqs/geemap/blob/master/examples/notebooks/10_shapefiles.ipynb\" rel=\"nofollow noreferrer\">https://github.com/giswqs/geemap/blob/master/examples/notebooks/10_shapefiles.ipynb</a></p>\n",
                    "OwnerUserId": "13544610",
                    "LastActivityDate": "2020-05-14T21:50:58.420",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "61849680",
                "ParentRepo": "https://github.com/Coderx7/SimpleNet_Pytorch",
                "StackOverflow_Post": {
                    "Id": "61849680",
                    "PostTypeId": "2",
                    "ParentId": "61841938",
                    "CreationDate": "2020-05-17T09:33:02.727",
                    "Score": "0",
                    "Body": "<p>Architecture is just one side of the story and the way you optimize it is the other side which is as important.<br>\nTry better hyper parameters and you'll definitely get higher accuracy.  </p>\n\n<p>What you can do is to use an already proven settings from other architectures that also have been trained on <code>CIFAR10</code> (preferably <code>ResNet</code>, but any other models will do and will give you a good starting point). Here is an example for a former <a href=\"https://github.com/Coderx7/SimpleNet_Pytorch\" rel=\"nofollow noreferrer\">CIFAR10 sota</a>.  </p>\n\n<p>A side note:<br>\nBased on my experience in classification tasks (such as <code>CIFAR10</code>) <code>Adam</code> optimizer wont give you good accuracy unless you really try hard. I had much better luck with <code>Adadelta</code>, <code>SGD</code> and <code>RMSProp</code>.<br>\nAdam seems to be working fine when it comes to <code>GAN</code>s though, but in other scenarios I find it to always perform inferior compared to others.</p>\n\n<p>Side note 2:<br>\nTry to use lower batch sizes, in practice you may fine batch sizes as small as 64 can give you pretty good results. Also nearly always try to start with a large learning rate and then gradually decrease it. </p>\n",
                    "OwnerUserId": "2736559",
                    "LastActivityDate": "2020-05-17T09:33:02.727",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "61855034",
                "ParentRepo": "https://github.com/man-group/arctic/issues/17",
                "StackOverflow_Post": {
                    "Id": "61855034",
                    "PostTypeId": "1",
                    "CreationDate": "2020-05-17T16:21:56.197",
                    "Score": "0",
                    "ViewCount": "83",
                    "Body": "<p>I'm trying to use a work-around for the problems described in <a href=\"https://github.com/python/mypy/issues/5485\" rel=\"nofollow noreferrer\">this</a> GitHub issue (<em>\"Class with function fields incorrectly thinks the first argument is self\"</em>). </p>\n\n<pre><code>from dataclasses import dataclass\nfrom typing import TypeVar, Generic, Any, Iterable, List\n\nT = TypeVar(\"T\")\n\n# See https://github.com/python/mypy/issues/5485\n\n\n@dataclass\nclass Box(Generic[T]):\n    inner: T\n\n    @property\n    def unboxed(self) -&gt; T:\n        return self.inner\n\n</code></pre>\n\n<p>I run into a traceback like this, though:</p>\n\n<p>However, upon <strong><em>importing</em></strong>  (only(!) ) the code above from another module I run into a traceback like this:</p>\n\n<pre><code>(py) sugarline:~/src/oss/ormsnack write-compile-eval\nTraceback (most recent call last):\n[.....]\n  File \"/Users/jacob/src/oss/ormsnack/ormsnack/ng_desc.py\", line 8, in &lt;module&gt;\n    from kingston.kind import Box  # type: ignore\n  File \"kingston/kind.py\", line 12, in &lt;module&gt;\nAttributeError: attribute '__dict__' of 'type' objects is not writable\n</code></pre>\n\n<p>Googling only lands me in old bugs that seem to have gone stale, though (<a href=\"https://bugs.python.org/issue38099\" rel=\"nofollow noreferrer\">https://bugs.python.org/issue38099</a>, <a href=\"https://github.com/man-group/arctic/issues/17\" rel=\"nofollow noreferrer\">https://github.com/man-group/arctic/issues/17</a>), etc.</p>\n\n<p>Is anyone able to figure out a work-around?</p>\n",
                    "OwnerUserId": "288672",
                    "LastEditorUserId": "288672",
                    "LastEditDate": "2020-05-17T18:39:46.400",
                    "LastActivityDate": "2020-05-17T18:39:46.400",
                    "Title": "mypy typing leeds to unexpected traceback",
                    "Tags": "<python><mypy>",
                    "AnswerCount": "0",
                    "CommentCount": "5",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "61987837",
                "ParentRepo": "https://github.com/lyft/amundsen",
                "StackOverflow_Post": {
                    "Id": "61987837",
                    "PostTypeId": "2",
                    "ParentId": "58488628",
                    "CreationDate": "2020-05-24T15:01:54.930",
                    "Score": "1",
                    "Body": "<p>Have you looked at Lyft's open source data catalog and discovery tool called \"Amundsen\"?</p>\n\n<p><a href=\"https://github.com/lyft/amundsen\" rel=\"nofollow noreferrer\">https://github.com/lyft/amundsen</a></p>\n\n<p><a href=\"https://eng.lyft.com/open-sourcing-amundsen-a-data-discovery-and-metadata-platform-2282bb436234\" rel=\"nofollow noreferrer\">https://eng.lyft.com/open-sourcing-amundsen-a-data-discovery-and-metadata-platform-2282bb436234</a></p>\n",
                    "OwnerUserId": "8060056",
                    "LastActivityDate": "2020-05-24T15:01:54.930",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "62009124",
                "ParentRepo": "https://github.com/dockersamples/101-tutorial/blob/master/docs_en/tutorial/using-docker-compose/index.md#running-our-application-stack",
                "StackOverflow_Post": {
                    "Id": "62009124",
                    "PostTypeId": "2",
                    "ParentId": "61925112",
                    "CreationDate": "2020-05-25T19:10:57.657",
                    "Score": "10",
                    "Body": "<h3>TL;DR;</h3>\n\n<p>Run the command</p>\n\n<pre><code>docker-compose down --volumes\n</code></pre>\n\n<p>to remove any problematic volume created during the tutorial early phases, then, resume your tutorial at the step <a href=\"https://github.com/dockersamples/101-tutorial/blob/master/docs_en/tutorial/using-docker-compose/index.md#running-our-application-stack\" rel=\"noreferrer\">Running our Application Stack</a>.</p>\n\n<hr>\n\n<p>I suppose that the tutorial you are following is <a href=\"https://github.com/dockersamples/101-tutorial/blob/master/docs_en/tutorial/using-docker-compose/index.md\" rel=\"noreferrer\">this one</a>.</p>\n\n<p>If you did follow it piece by piece and tried some <code>docker-compose up -d</code> in the step 1 or 2, then you've probably created a <a href=\"https://docs.docker.com/storage/volumes/\" rel=\"noreferrer\">volume</a> without your <code>todos</code> database. </p>\n\n<p>Just going <code>docker-compose down</code> with your existing <em>docker-compose.yml</em> won't suffice because volumes is exactly made for this, the volume is the permanent storage layer of Docker. </p>\n\n<blockquote>\n  <p>By default all files created inside a container are stored on a writable container layer. This means that:</p>\n  \n  <ul>\n  <li>The data doesn\u2019t persist when that container no longer exists, and it can be difficult to get the data out of the container if another process needs it.</li>\n  <li>A container\u2019s writable layer is tightly coupled to the host machine where the container is running. You can\u2019t easily move the data somewhere else.</li>\n  <li>Writing into a container\u2019s writable layer requires a storage driver to manage the filesystem. The storage driver provides a union filesystem, using the Linux kernel. This extra abstraction reduces performance as compared to using data volumes, which write directly to the host filesystem.</li>\n  </ul>\n  \n  <p>Docker has two options for containers to store files in the host machine, so that the files are persisted even after the container stops: volumes, and bind mounts. If you\u2019re running Docker on Linux you can also use a tmpfs mount. If you\u2019re running Docker on Windows you can also use a named pipe.</p>\n</blockquote>\n\n<p><em>Source: <a href=\"https://docs.docker.com/storage/\" rel=\"noreferrer\">https://docs.docker.com/storage/</a></em></p>\n\n<p>In order to remove that volume, you probably created without your database there is an extra flag you can add to <code>docker-compose down</code>: the flag <code>--volumes</code> or, in short <code>-v</code></p>\n\n<pre><code>-v, --volumes           Remove named volumes declared in the `volumes`\n                            section of the Compose file and anonymous volumes\n                            attached to containers.\n</code></pre>\n\n<p><em>Source: <a href=\"https://docs.docker.com/compose/reference/down/\" rel=\"noreferrer\">https://docs.docker.com/compose/reference/down/</a></em></p>\n\n<p>So your fix should be as simple as:</p>\n\n<ol>\n<li><code>docker-compose down --volumes</code></li>\n<li><code>docker-compose up -d</code>, so back in your tutorial at the step <a href=\"https://github.com/dockersamples/101-tutorial/blob/master/docs_en/tutorial/using-docker-compose/index.md#running-our-application-stack\" rel=\"noreferrer\">Running our Application Stack</a></li>\n<li><code>docker-compose logs -f</code> as prompted in the rest of the tutorial</li>\n</ol>\n",
                    "OwnerUserId": "2123530",
                    "LastEditorUserId": "2123530",
                    "LastEditDate": "2020-05-25T20:12:54.607",
                    "LastActivityDate": "2020-05-25T20:12:54.607",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "62036451",
                "ParentRepo": "https://github.com/awslabs/cdk8s/tree/master/examples",
                "StackOverflow_Post": {
                    "Id": "62036451",
                    "PostTypeId": "2",
                    "ParentId": "61878907",
                    "CreationDate": "2020-05-27T06:03:33.120",
                    "Score": "0",
                    "Body": "<p>You can use cdk8s.io. Here's some examples: <a href=\"https://github.com/awslabs/cdk8s/tree/master/examples\" rel=\"nofollow noreferrer\">https://github.com/awslabs/cdk8s/tree/master/examples</a></p>\n",
                    "OwnerUserId": "1832617",
                    "LastActivityDate": "2020-05-27T06:03:33.120",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "62145444",
                "ParentRepo": "https://github.com/RammusXu/toolkit/tree/master/k8s/echoserver",
                "StackOverflow_Post": {
                    "Id": "62145444",
                    "PostTypeId": "2",
                    "ParentId": "62137132",
                    "CreationDate": "2020-06-02T05:26:53.613",
                    "Score": "0",
                    "Body": "<p>ref: <a href=\"https://github.com/RammusXu/toolkit/tree/master/k8s/echoserver\" rel=\"nofollow noreferrer\">https://github.com/RammusXu/toolkit/tree/master/k8s/echoserver</a></p>\n\n<p>Here's a example to mount nginx.conf from ConfigMap</p>\n\n<p>And make sure you <code>kubectl rollout restart deployment echoserver</code> after update ConfigMap. Pod only clone ConfigMap when it created. It don't sync or auto-updated.</p>\n\n<pre class=\"lang-yaml prettyprint-override\"><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: echoserver\n  namespace: default\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: echoserver\n  template:\n    metadata:\n      labels:\n        app: echoserver\n    spec:\n      volumes:\n      - name: config\n        configMap:\n          name: nginx-config\n\n      containers:\n      - name: echoserver\n        # image: gcr.io/google_containers/echoserver:1.10\n        image: openresty/openresty:1.15.8.2-1-alpine\n        ports:\n        - containerPort: 8080\n          name: http\n\n        # nginx.conf override\n        volumeMounts:\n        - name: config\n          subPath: nginx.conf\n          # mountPath: /etc/nginx/nginx.conf\n          mountPath: /usr/local/openresty/nginx/conf/nginx.conf\n          readOnly: true\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: echoserver\n  namespace: default\nspec:\n  type: NodePort\n  ports:\n  - port: 80\n    targetPort: http\n    protocol: TCP\n    name: http\n  selector:\n    app: echoserver\n---\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: nginx-config\n  namespace: default\ndata:\n  nginx.conf: |-\n    events {\n      worker_connections 1024;\n    }\n\n    env HOSTNAME;\n    env NODE_NAME;\n    env POD_NAME;\n    env POD_NAMESPACE;\n    env POD_IP;\n\n    http {\n      default_type 'text/plain';\n      # maximum allowed size of the client request body. By default this is 1m.\n      # Request with bigger bodies nginx will return error code 413.\n      # http://nginx.org/en/docs/http/ngx_http_core_module.html#client_max_body_size\n      client_max_body_size 10m;\n\n      # https://blog.percy.io/tuning-nginx-behind-google-cloud-platform-http-s-load-balancer-305982ddb340\n      keepalive_timeout         650;\n      keepalive_requests        10000;\n\n      # GZIP support\n      gzip                      on;\n      gzip_min_length           128;\n      gzip_proxied              any;\n      gzip_comp_level           6;\n\n      gzip_types                text/css\n                                text/plain\n                                text/javascript\n                                application/javascript\n                                application/json\n                                application/x-javascript\n                                application/xml\n                                application/xml+rss\n                                application/xhtml+xml\n                                application/x-font-ttf\n                                application/x-font-opentype\n                                application/vnd.ms-fontobject\n                                image/svg+xml\n                                image/x-icon\n                                application/rss+xml\n                                application/atom_xml\n                                application/vnd.apple.mpegURL\n                                application/x-mpegurl\n                                vnd.apple.mpegURL\n                                application/dash+xml;\n\n      init_by_lua_block {\n        local template = require(\"template\")\n        -- template syntax documented here:\n        -- https://github.com/bungle/lua-resty-template/blob/master/README.md\n        tmpl = template.compile([[\n\n\n    Hostname: {{os.getenv(\"HOSTNAME\") or \"N/A\"}}\n\n    Pod Information:\n    {% if os.getenv(\"POD_NAME\") then %}\n      node name:    {{os.getenv(\"NODE_NAME\") or \"N/A\"}}\n      pod name: {{os.getenv(\"POD_NAME\") or \"N/A\"}}\n      pod namespace:    {{os.getenv(\"POD_NAMESPACE\") or \"N/A\"}}\n      pod IP:   {{os.getenv(\"POD_IP\") or \"N/A\"}}\n    {% else %}\n      -no pod information available-\n    {% end %}\n\n    Server values:\n      server_version=nginx: {{ngx.var.nginx_version}} - lua: {{ngx.config.ngx_lua_version}}\n\n    Request Information:\n      client_address={{ngx.var.remote_addr}}\n      method={{ngx.req.get_method()}}\n      real path={{ngx.var.request_uri}}\n      query={{ngx.var.query_string or \"\"}}\n      request_version={{ngx.req.http_version()}}\n      request_scheme={{ngx.var.scheme}}\n      request_uri={{ngx.var.scheme..\"://\"..ngx.var.host..\":\"..ngx.var.server_port..ngx.var.request_uri}}\n\n    Request Headers:\n    {% for i, key in ipairs(keys) do %}\n      {{key}}={{headers[key]}}\n    {% end %}\n\n    Request Body:\n    {{ngx.var.request_body or \" -no body in request-\"}}\n    ]])\n      }\n\n      server {\n        # please check the benefits of reuseport https://www.nginx.com/blog/socket-sharding-nginx-release-1-9-1\n        # basically instructs to create an individual listening socket for each worker process (using the SO_REUSEPORT\n        # socket option), allowing a kernel to distribute incoming connections between worker processes.\n        listen 8080 default_server reuseport;\n        listen 8443 default_server ssl http2 reuseport;\n\n        ssl_certificate /certs/certificate.crt;\n        ssl_certificate_key /certs/privateKey.key;\n\n        # Replace '_' with your hostname.\n        server_name _;\n\n        location / {\n          lua_need_request_body on;\n          content_by_lua_block {\n            ngx.header[\"Server\"] = \"echoserver\"\n\n            local headers = ngx.req.get_headers()\n            local keys = {}\n            for key, val in pairs(headers) do\n              table.insert(keys, key)\n            end\n            table.sort(keys)\n\n            ngx.say(tmpl({os=os, ngx=ngx, keys=keys, headers=headers}))\n          }\n        }\n      }\n    }\n</code></pre>\n",
                    "OwnerUserId": "3854890",
                    "LastActivityDate": "2020-06-02T05:26:53.613",
                    "CommentCount": "3",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "62192641",
                "ParentRepo": "https://github.com/IBM/dataset-lifecycle-framework",
                "StackOverflow_Post": {
                    "Id": "62192641",
                    "PostTypeId": "2",
                    "ParentId": "51673011",
                    "CreationDate": "2020-06-04T10:40:05.740",
                    "Score": "14",
                    "Body": "<p>We recently opensourced a project that looks to automate this steps for you: <a href=\"https://github.com/IBM/dataset-lifecycle-framework\" rel=\"noreferrer\">https://github.com/IBM/dataset-lifecycle-framework</a></p>\n<p>Basically you can create a dataset:</p>\n<pre><code>apiVersion: com.ie.ibm.hpsys/v1alpha1\nkind: Dataset\nmetadata:\n  name: example-dataset\nspec:\n  local:\n    type: &quot;COS&quot;\n    accessKeyID: &quot;iQkv3FABR0eywcEeyJAQ&quot;\n    secretAccessKey: &quot;MIK3FPER+YQgb2ug26osxP/c8htr/05TVNJYuwmy&quot;\n    endpoint: &quot;http://192.168.39.245:31772&quot;\n    bucket: &quot;my-bucket-d4078283-dc35-4f12-a1a3-6f32571b0d62&quot;\n    region: &quot;&quot; #it can be empty\n</code></pre>\n<p>And then you will get a pvc you can mount in your pods</p>\n",
                    "OwnerUserId": "277693",
                    "LastEditorUserId": "277693",
                    "LastEditDate": "2020-08-18T07:04:46.930",
                    "LastActivityDate": "2020-08-18T07:04:46.930",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "62269264",
                "ParentRepo": "https://github.com/koxudaxi/datamodel-code-generator",
                "StackOverflow_Post": {
                    "Id": "62269264",
                    "PostTypeId": "2",
                    "ParentId": "62267544",
                    "CreationDate": "2020-06-08T18:52:29.840",
                    "Score": "5",
                    "Body": "<p>There's no method for exactly that, but you can use <a href=\"https://pydantic-docs.helpmanual.io/usage/models/#dynamic-model-creation\" rel=\"noreferrer\"><code>create_model()</code></a> to create a model if you know the field types.</p>\n\n<p>Or there's <a href=\"https://github.com/koxudaxi/datamodel-code-generator\" rel=\"noreferrer\">datamodel-code-generator</a> (separate package) which allows you to generate models from schema definitions.</p>\n",
                    "OwnerUserId": "949890",
                    "LastActivityDate": "2020-06-08T18:52:29.840",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "62297536",
                "ParentRepo": "https://github.com/dsoftwareinc/fakeredis-py",
                "StackOverflow_Post": {
                    "Id": "62297536",
                    "PostTypeId": "2",
                    "ParentId": "62292568",
                    "CreationDate": "2020-06-10T06:54:28.703",
                    "Score": "1",
                    "Body": "<p>my solution involved using unittest.mock.patch:</p>\n<pre><code>import fakeredis\nfake_redis = fakeredis.FakeRedis()\n\n@patch(&quot;app_name1.views.redis_connection&quot;, fake_redis)\n@patch(&quot;app_name2.views.redis_connection&quot;, fake_redis)\n@patch(&quot;app_name3.views.redis_connection&quot;, fake_redis)\nclass TestSomethingWithRedis(TestCase):\n    pass\n</code></pre>\n<p>if you want to check query inside your test(s)\nuse <a href=\"https://github.com/dsoftwareinc/fakeredis-py\" rel=\"nofollow noreferrer\">fake_redis</a></p>\n",
                    "OwnerUserId": "412137",
                    "LastEditorUserId": "1056460",
                    "LastEditDate": "2022-05-07T20:38:10.577",
                    "LastActivityDate": "2022-05-07T20:38:10.577",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "62336659",
                "ParentRepo": "https://github.com/vapor/docs/blob/fluent-gm/4.0/docs/fluen",
                "StackOverflow_Post": {
                    "Id": "62336659",
                    "PostTypeId": "2",
                    "ParentId": "62274453",
                    "CreationDate": "2020-06-12T02:41:58.100",
                    "Score": "3",
                    "Body": "<p>0xTim helped me out on Discord. And I managed to make it work after reading <a href=\"https://github.com/vapor/docs/blob/fluent-gm/4.0/docs/fluent/relations.md#nested-eager-load\" rel=\"nofollow noreferrer\">This doc</a></p>\n<p>Here's working solution:</p>\n<pre class=\"lang-swift prettyprint-override\"><code>func create(req: Request) throws -&gt; EventLoopFuture&lt;Chat&gt; {\n  \n  let currentUser = try req.auth.require(User.self)\n  \n  guard\n    let userID = req.parameters.get(&quot;userID&quot;),\n    let userUUID = UUID(userID)\n    else { throw Abort(.badRequest) }\n  \n  return User\n    .query(on: req.db)\n    .filter(\\.$id == userUUID)\n    .with(\\.$chats, { chats in\n      chats.with(\\.$users)\n    })\n    .first()\n    .unwrap(or: Abort(.internalServerError))\n    .flatMap({ chatUser -&gt; EventLoopFuture&lt;Chat&gt; in\n      \n      let chat = chatUser\n        .chats\n        .filter({\n          $0.users.contains(where: { $0.id! == currentUser.id! })\n        })\n        .first\n      \n      if let chat = chat {\n        \n        return req.eventLoop.makeSucceededFuture(chat)\n        \n      } else {\n        \n        let newChat = Chat()\n        return newChat\n          .save(on: req.db)\n          .flatMap({\n            \n            newChat\n              .$users\n              .attach([chatUser, currentUser], on: req.db)\n              .flatMap({\n                \n                return req.eventLoop.makeSucceededFuture(newChat)\n              })\n          })\n      }\n    })\n}\n</code></pre>\n",
                    "OwnerUserId": "7234482",
                    "LastEditorUserId": "406677",
                    "LastEditDate": "2021-01-10T11:53:32.227",
                    "LastActivityDate": "2021-01-10T11:53:32.227",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "62388943",
                "ParentRepo": "https://github.com/bees-hive/elegant-git/",
                "StackOverflow_Post": {
                    "Id": "62388943",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "62410132",
                    "CreationDate": "2020-06-15T13:12:08.067",
                    "Score": "1",
                    "ViewCount": "341",
                    "Body": "<p>I'm developing a wrapper around Git called <a href=\"https://github.com/bees-hive/elegant-git/\" rel=\"nofollow noreferrer\">Elegant Git</a> and want to have tests running on multiple Git versions. As the project uses Docker containers for testing, I've prepared a Dockerfile that installs Git from sources and got strange results:</p>\n\n<ul>\n<li>Apline image with Git installed from sources <strong>> 200Mb</strong></li>\n<li>Apline image with Git installed via <code>apk add git</code> ~ <strong>28Mb</strong></li>\n</ul>\n\n<p>It reflects the size of each created binary file</p>\n\n<pre><code>Build version: \n18.6M   /git/usr/libexec/git-core/git\napk version: \n2.4M    /usr/libexec/git-core/git\n</code></pre>\n\n<p><strong>Is there a way to decrease binaries' size while building Git from sources?</strong></p>\n\n<p>The following <em>Dockerfile</em> reproduces the behavior:</p>\n\n<pre><code>ARG bashversion=3.2.57\nFROM bash:${bashversion}\nARG gitversion=2.26.2\nWORKDIR /git\n\nRUN apk add --no-cache curl &amp;&amp; \\\n    curl --output git-${gitversion}.tar.gz \\\n         https://mirrors.edge.kernel.org/pub/software/scm/git/git-${gitversion}.tar.gz &amp;&amp; \\\n    tar -xvzf git-${gitversion}.tar.gz &amp;&amp; \\\n    mkdir -p /git\n\nRUN apk add --no-cache \\\n        zlib-dev \\\n        openssl-dev \\\n        curl-dev \\\n        expat-dev \\\n        perl-dev \\\n        python3-dev \\\n        pcre2-dev \\\n        asciidoc \\\n        xmlto \\\n        perl-error tcl tk make gcc g++ \n\nRUN cd git-${gitversion} &amp;&amp; \\\n    make prefix=/usr DESTDIR=/git NO_GETTEXT=YesPlease NO_REGEX=YesPlease ICONV_OMITS_BOM=Yes &amp;&amp; \\ \n    make prefix=/usr DESTDIR=/git NO_GETTEXT=YesPlease NO_REGEX=YesPlease ICONV_OMITS_BOM=Yes install\n\nRUN apk add --no-cache git &amp;&amp; \\\n    echo \"Build version: \" &amp;&amp; \\\n    du -ha /git/usr/libexec/git-core/git | sort &amp;&amp; \\\n    echo \"apk version: \" &amp;&amp; \\\n    du -ha /usr/libexec/git-core/git | sort \n</code></pre>\n",
                    "OwnerUserId": "10418734",
                    "LastActivityDate": "2020-06-16T13:50:42.727",
                    "Title": "How to decrease Git binaries size while building Git on Docker Alpine?",
                    "Tags": "<git><docker><alpine-linux>",
                    "AnswerCount": "1",
                    "CommentCount": "6",
                    "FavoriteCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "62408827",
                "ParentRepo": "https://github.com/open-policy-agent/conftest",
                "StackOverflow_Post": {
                    "Id": "62408827",
                    "PostTypeId": "2",
                    "ParentId": "62407203",
                    "CreationDate": "2020-06-16T12:45:11.457",
                    "Score": "2",
                    "Body": "<p>Perhaps your master thesis project is already implemented by <a href=\"https://github.com/open-policy-agent/conftest\" rel=\"nofollow noreferrer\">conftest</a> - a tool which helps you write tests against structured configuration data.</p>\n\n<p>For example, the following rule will prevent running containers as root</p>\n\n<pre><code>deny[msg] {\n  input.kind = \"Deployment\"\n  not input.spec.template.spec.securityContext.runAsNonRoot = true\n  msg = \"Containers must not run as root\"\n}\n</code></pre>\n\n<p>Check some other <a href=\"https://github.com/open-policy-agent/conftest/tree/master/examples/kubernetes\" rel=\"nofollow noreferrer\">kubernetes examples</a>.</p>\n",
                    "OwnerUserId": "7568391",
                    "LastActivityDate": "2020-06-16T12:45:11.457",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "62602972",
                "ParentRepo": "https://github.com/marshmallow-code/django-rest-marshmallow",
                "StackOverflow_Post": {
                    "Id": "62602972",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "62603335",
                    "CreationDate": "2020-06-26T21:18:16.563",
                    "Score": "0",
                    "ViewCount": "560",
                    "Body": "<p>I tried all the ways and when I validate the serializer by calling is_valid(), I always get an error.</p>\n<pre><code>class KVSFileMapSerializer(Schema):\n    kv_map = fields.Dict()\n\nkvs_result = {\n    'trial': 'Config',\n    'trial_1': 'Congig',\n}\n\nkvs_serializer = KVSFileMapSerializer(data=kvs_result)\nkvs_serializer.is_valid()\n</code></pre>\n<p>The last line always returns 'False', I tried raising an exception and this is what I get,</p>\n<blockquote>\n<p>{'trial': [ErrorDetail(string='Unknown field.', code='invalid')],\n'trial_1': [ErrorDetail(string='Unknown field.', code='invalid')]}</p>\n</blockquote>\n<p>This is the package that I use - <a href=\"https://github.com/marshmallow-code/django-rest-marshmallow\" rel=\"nofollow noreferrer\">django-marshmallow</a></p>\n",
                    "OwnerUserId": "10982755",
                    "LastActivityDate": "2020-06-26T21:55:47.733",
                    "Title": "How to serialize a simple Dict using django-marshmallow?",
                    "Tags": "<python><python-3.x><django><django-rest-framework><marshmallow>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "62645796",
                "ParentRepo": "https://github.com/iver56/audiomentations",
                "StackOverflow_Post": {
                    "Id": "62645796",
                    "PostTypeId": "2",
                    "ParentId": "62645577",
                    "CreationDate": "2020-06-29T19:57:36.313",
                    "Score": "1",
                    "Body": "<p>Converting from MP3 to Linear PCM alone won't remove encoding artifacts which may be &quot;learned&quot; by your neural network. Since MP3 is the lossy format in question, the natural approach would be to apply the same codec to your WAVE 16-bit Linear PCM files and work with both classes encoded-decoded in MP3.</p>\n<p>However, the codec alone might not be the only unintended discriminator of your classes. Aside from double-checking the audio capture implementation from jotform, you could also apply data augmentation techniques like ones available in the <a href=\"https://github.com/iver56/audiomentations\" rel=\"nofollow noreferrer\">audiomentations</a> project.</p>\n",
                    "OwnerUserId": "13806326",
                    "LastEditorUserId": "13806326",
                    "LastEditDate": "2020-06-29T20:02:45.987",
                    "LastActivityDate": "2020-06-29T20:02:45.987",
                    "CommentCount": "3",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "62774486",
                "ParentRepo": "https://github.com/Arksine/moonraker",
                "StackOverflow_Post": {
                    "Id": "62774486",
                    "PostTypeId": "1",
                    "CreationDate": "2020-07-07T11:42:25.467",
                    "Score": "0",
                    "ViewCount": "92",
                    "Body": "<p>I'm trying to connect to a server called <a href=\"https://github.com/Arksine/moonraker\" rel=\"nofollow noreferrer\">Moonraker</a> and communicate to it with json-rpc. I think I have solved that task with Tornado, but I also want to create a web UI on port 8080 also with Tornado but in another instance.</p>\n<p>What is the best way to do this?:</p>\n<ol>\n<li><p>Start a Tornado Io-loop that connects to port localhost:7125, keeps the connection open and send diffrent json-rpc commands to it.</p>\n</li>\n<li><p>Start another Tornado instance that serves a webpage on port 8080. This page will I use for a UI to send and receive the json-rpc commands that coming from the first Tornado instance.</p>\n</li>\n</ol>\n<p>I hope you can understand what I want to create.</p>\n",
                    "OwnerUserId": "13884323",
                    "LastActivityDate": "2020-07-07T11:55:46.277",
                    "Title": "Can I use Tornado for parsing json-rpc to web-frontend?",
                    "Tags": "<python-3.x><tornado><json-rpc>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "62791628",
                "ParentRepo": "https://github.com/dmontagu/fastapi-utils",
                "StackOverflow_Post": {
                    "Id": "62791628",
                    "PostTypeId": "1",
                    "CreationDate": "2020-07-08T09:25:38.280",
                    "Score": "5",
                    "ViewCount": "6501",
                    "Body": "<p>We are using <a href=\"https://github.com/dmontagu/fastapi-utils\" rel=\"noreferrer\">fastapi-utils</a> to have a scheduled task in the background. We check all 5 seconds if new data is available in the DB, if yes we process it (takes up to 5 minutes)</p>\n<p>During this time, the couroutine should be blocking so that its only triggered once.</p>\n<p>We noticed that our data is sometimes processed 3x, we assume that the scheduler continues to run, even though the function has been triggered.</p>\n<p>Therefore we tried  to circumvent it with the <code>IsRunningQuery</code> variable.</p>\n<p>We tried a solution with a while True loop without <code>@repeat_every</code> to make it run once at startup, but Azure Webapps does not allow running this.</p>\n<pre><code>@app.on_event(&quot;startup&quot;) \n@repeat_every(wait_first=True,seconds=int(10))\ndef scheduled_task() -&gt; None:\n    global IsRunningQuery\n    global LastCheck\n    if IsRunningQuery == False:\n        IsRunningQuery = True\n        gunicorn_logger.info(&quot;status='checkforleads'&quot;)\n        OurProccessingClass.processDataBaseData() # can take up 5 minutes\n        LastCheck=Utils.datetime()\n        IsRunningQuery = False\n\n</code></pre>\n<p>This variante works in our DEV environment, but not on Azure</p>\n<pre><code>@app.on_event(&quot;startup&quot;) \nasync def scheduled_task() -&gt; None:\n    while True:\n        gunicorn_logger.info(&quot;status='checkforleads'&quot;)\n        OurProccessingClass.processDataBaseData() # can take up 5 minutes\n        time.sleep(int(os.environ[&quot;CRM_SLEEP&quot;]))\n</code></pre>\n",
                    "OwnerUserId": "670186",
                    "LastEditorUserId": "670186",
                    "LastEditDate": "2020-07-08T09:34:03.837",
                    "LastActivityDate": "2022-01-11T02:19:11.823",
                    "Title": "FastAPI @repeat_every how to prevent parallel def scheduled_task() instances",
                    "Tags": "<fastapi>",
                    "AnswerCount": "2",
                    "CommentCount": "0",
                    "FavoriteCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "62908965",
                "ParentRepo": "https://github.com/Tencent/PocketFlow/blob/master/requirement.txt",
                "StackOverflow_Post": {
                    "Id": "62908965",
                    "PostTypeId": "2",
                    "ParentId": "62907741",
                    "CreationDate": "2020-07-15T06:40:47.737",
                    "Score": "0",
                    "Body": "<p><strong>TensorFlow Version</strong></p>\n<p>From the <a href=\"https://github.com/Tencent/PocketFlow/blob/master/requirement.txt\" rel=\"nofollow noreferrer\">requirement.txt</a> file of PocketFlow, it seems requires at least 1.10.0, it would work fine with anything above (except some warnings and deprecated notices).</p>\n<p><strong>Where to Run?</strong></p>\n<p>You should already know it. If you have a GPU cluster, run it there. Otherwise, you can use free GPU options like <a href=\"https://www.kaggle.com/dansbecker/running-kaggle-kernels-with-a-gpu\" rel=\"nofollow noreferrer\">Kaggle</a> and <a href=\"https://research.google.com/colaboratory/faq.html\" rel=\"nofollow noreferrer\">Colab</a>: <a href=\"https://colab.research.google.com/notebooks/gpu.ipynb\" rel=\"nofollow noreferrer\">Example</a>. In Colab you can define which TensorFlow version to use, <a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" rel=\"nofollow noreferrer\">official example</a>. If you choose anyone between Kaggel and Colab, you may need to modify the original codes you have to use PocketFlow.</p>\n<p>If you have your own GPU cluster and I assume you'll have Linux system installed. You have two option to choose from</p>\n<p><strong>Use Python Virtual Environments</strong></p>\n<ol>\n<li>Create it: <code>python3 -m venv pocketflow-env</code></li>\n<li>Activate it: <code>source pocketflow-env/bin/activate</code></li>\n<li>Install required packages with version: <code>pip install -r requirements.txt</code></li>\n</ol>\n<p><strong>Use Docker</strong></p>\n<ol>\n<li>Check if it's already installed by running <code>docker version</code> if returns appropriate messages, which means <a href=\"https://docs.docker.com/engine/reference/commandline/version/#default-output\" rel=\"nofollow noreferrer\">default output</a>, then it means Docker is already installed. Otherwise, install Docker by following the official documentation: <a href=\"https://docs.docker.com/engine/install/\" rel=\"nofollow noreferrer\">Install Docker on Linux</a>.\nThen, you just need to run the next two commands as the <a href=\"https://pocketflow.github.io/installation/#prepare-for-the-docker-mode\" rel=\"nofollow noreferrer\">official documentation of PocketFlow</a> describes</li>\n<li><code>docker pull uber/horovod</code> it pulls <a href=\"https://hub.docker.com/r/uber/horovod\" rel=\"nofollow noreferrer\">this image</a> from Dockerhub and stores in your system to use it for next command</li>\n<li><code>./scripts/run_docker.sh nets/resnet_at_cifar10_run.py</code></li>\n</ol>\n",
                    "OwnerUserId": "8840245",
                    "LastActivityDate": "2020-07-15T06:40:47.737",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "62909774",
                "ParentRepo": "https://github.com/sciann/sciann",
                "StackOverflow_Post": {
                    "Id": "62909774",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "62922847",
                    "CreationDate": "2020-07-15T07:35:40.393",
                    "Score": "0",
                    "ViewCount": "2986",
                    "Body": "<p>I'm trying to install a python package directly from github. In my case that's <a href=\"https://github.com/sciann/sciann\" rel=\"nofollow noreferrer\">SciANN</a>. When I selected my environment in conda using <code>conda activate myenv</code> and afterwards install this package as explained in <a href=\"https://stackoverflow.com/a/50141879\">this</a> post using the following lines of code:</p>\n<pre><code>conda install git pip\npip install git+git://github.com/sciann/sciann.git\n</code></pre>\n<p>it is successfully installed and I get the message &quot;Successfully built SciANN&quot; in the end of the insatllation procedure. When I then open spyder and type <code>import sciann</code> I get the error <code>ModuleNotFoundError: No module named 'sciann'</code>. I also tried to use <code>pip3</code> instead of <code>pip</code> but this did not change something.</p>\n<p>Have I missed something? Is this package now installed correctly into my environment <code>myenv</code>?</p>\n",
                    "OwnerUserId": "12823540",
                    "LastActivityDate": "2020-07-15T19:56:50.637",
                    "Title": "Installing a package from git in Anaconda environment which is afterwards not recognized in Python",
                    "Tags": "<python><git><pip><package>",
                    "AnswerCount": "1",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "62957754",
                "ParentRepo": "https://github.com/mitodl/mitx-grading-library",
                "StackOverflow_Post": {
                    "Id": "62957754",
                    "PostTypeId": "1",
                    "CreationDate": "2020-07-17T16:05:09.757",
                    "Score": "2",
                    "ViewCount": "55",
                    "Body": "<p>I am trying to use the MITxGraders library from <a href=\"https://github.com/mitodl/mitx-grading-library\" rel=\"nofollow noreferrer\">https://github.com/mitodl/mitx-grading-library</a>.</p>\n<p>I have clones it, run pip install -r requirements3.txt in the Command Line like they told me to, run Pytest to see that it is working, and now I have no idea how to use it.</p>\n<p>I tried to pip install the library in Jupyter Notebook and I tried to import it in the same notebook, and in both cases the code said the module didn't exist. I tried to import the file location of <strong>&quot;C:\\Users\\nolan\\Desktopmitx-grading-library&quot;</strong>, and it spit back a Syntax Error of</p>\n<pre><code>&quot;SyntaxError: (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape&quot;\n</code></pre>\n<p>I'm really annoyed that my Data Science bootcamp never bothered teaching me how this works, but I'm really hoping someone on here can help me out.</p>\n",
                    "OwnerUserId": "12068677",
                    "LastEditorUserId": "7189370",
                    "LastEditDate": "2020-07-17T16:13:21.497",
                    "LastActivityDate": "2020-07-17T16:13:21.497",
                    "Title": "How Do You Use New Packages Installed Via GitHub?",
                    "Tags": "<python><python-3.x>",
                    "AnswerCount": "1",
                    "CommentCount": "5",
                    "ClosedDate": "2020-07-17T17:18:22.460",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "62965074",
                "ParentRepo": "https://github.com/mattbrictson/tomo",
                "StackOverflow_Post": {
                    "Id": "62965074",
                    "PostTypeId": "1",
                    "CreationDate": "2020-07-18T05:39:04.893",
                    "Score": "1",
                    "ViewCount": "43",
                    "Body": "<p>I'm trying to install a Rails app (Spree E-commerce) on a Digital Ocean droplet using the <a href=\"https://github.com/mattbrictson/tomo\" rel=\"nofollow noreferrer\">Tomo CLI</a> tool. You run it on your local machine, give it the login credentials for the server, and it will deploy your Rails app for you. At least in theory.</p>\n<p>I've had problem after problem with Tomo, most of which I've managed to fix. However, I'm at a loss for the current problem, which Tomo encounters when it tries to create the database with <code>bundle exec rake db:create</code>. I tried creating the database first, as Tomo seems to skip steps if they are already completed on the server, but that didn't fix anything.</p>\n<p>Here is the error message provided by Tomo. Googling has brought me zilch so far. Any help would be great!</p>\n<pre><code>\u2022 rails:db_create\ncd /tmp/tomo/20200718051237 &amp;&amp; bundle exec rake db:version\ncd /tmp/tomo/20200718051237 &amp;&amp; bundle exec rake db:create\nDEPRECATION WARNING: Including LoggerSilence is deprecated and will be removed in Rails 6.1. Please use `ActiveSupport::LoggerSilence` instead (called from block (2 levels) in require at /home/deployer/.rbenv/versions/2.6.5/lib/ruby/gems/2.6.0/gems/bundler-2.1.4/lib/bundler/runtime.rb:74)\nrake aborted!\nLoadError: Could not load the 'http' Active Record adapter. Ensure that the adapter is spelled correctly in config/database.yml and that you've added the necessary adapter gem to your Gemfile.\n/var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/bootsnap-1.4.6/lib/bootsnap/load_path_cache/core_ext/kernel_require.rb:34:in `require'\n/var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/polyglot-0.3.5/lib/polyglot.rb:65:in `require'\n/var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/zeitwerk-2.3.0/lib/zeitwerk/kernel.rb:23:in `require'\n/var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/activesupport-6.0.3.2/lib/active_support/dependencies.rb:324:in `block in require'\n/var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/activesupport-6.0.3.2/lib/active_support/dependencies.rb:291:in `load_dependency'\n/var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/activesupport-6.0.3.2/lib/active_support/dependencies.rb:324:in `require'\n/var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/activerecord-6.0.3.2/lib/active_record/connection_adapters/connection_specification.rb:169:in `spec'\n/var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/activerecord-6.0.3.2/lib/active_record/connection_adapters/abstract/connection_pool.rb:1052:in `establish_connection'\n/var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/activerecord-6.0.3.2/lib/active_record/connection_handling.rb:51:in `establish_connection'\n/var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/activerecord-6.0.3.2/lib/active_record/railtie.rb:201:in `block (2 levels) in &lt;class:Railtie&gt;'\n/var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/activesupport-6.0.3.2/lib/active_support/lazy_load_hooks.rb:71:in `class_eval'\n/var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/activesupport-6.0.3.2/lib/active_support/lazy_load_hooks.rb:71:in `block in execute_hook'\n/var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/activesupport-6.0.3.2/lib/active_support/lazy_load_hooks.rb:61:in `with_execution_control'\n/var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/activesupport-6.0.3.2/lib/active_support/lazy_load_hooks.rb:66:in `execute_hook'\n/var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/activesupport-6.0.3.2/lib/active_support/lazy_load_hooks.rb:43:in `block in on_load'\n/var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/activesupport-6.0.3.2/lib/active_support/lazy_load_hooks.rb:42:in `each'\n/var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/activesupport-6.0.3.2/lib/active_support/lazy_load_hooks.rb:42:in `on_load'\n/var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/activerecord-6.0.3.2/lib/active_record/railtie.rb:198:in `block in &lt;class:Railtie&gt;'\n/var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/railties-6.0.3.2/lib/rails/initializable.rb:32:in `instance_exec'\n/var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/railties-6.0.3.2/lib/rails/initializable.rb:32:in `run'\n/var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/railties-6.0.3.2/lib/rails/initializable.rb:61:in `block in run_initializers'\n/var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/railties-6.0.3.2/lib/rails/initializable.rb:60:in `run_initializers'\n/var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/railties-6.0.3.2/lib/rails/application.rb:363:in `initialize!'\n/tmp/tomo/20200718051237/config/environment.rb:5:in `&lt;main&gt;'\n/var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/bootsnap-1.4.6/lib/bootsnap/load_path_cache/core_ext/kernel_require.rb:23:in `require'\n/var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/bootsnap-1.4.6/lib/bootsnap/load_path_cache/core_ext/kernel_require.rb:23:in `block in require_with_bootsnap_lfi'\n/var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/bootsnap-1.4.6/lib/bootsnap/load_path_cache/loaded_features_index.rb:92:in `register'\n/var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/bootsnap-1.4.6/lib/bootsnap/load_path_cache/core_ext/kernel_require.rb:22:in `require_with_bootsnap_lfi'\n/var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/bootsnap-1.4.6/lib/bootsnap/load_path_cache/core_ext/kernel_require.rb:31:in `require'\n/var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/polyglot-0.3.5/lib/polyglot.rb:65:in `require'\n/var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/zeitwerk-2.3.0/lib/zeitwerk/kernel.rb:23:in `require'\n/var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/activesupport-6.0.3.2/lib/active_support/dependencies.rb:324:in `block in require'\n/var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/activesupport-6.0.3.2/lib/active_support/dependencies.rb:291:in `load_dependency'\n/var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/activesupport-6.0.3.2/lib/active_support/dependencies.rb:324:in `require'\n/var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/railties-6.0.3.2/lib/rails/application.rb:339:in `require_environment!'\n/var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/railties-6.0.3.2/lib/rails/application.rb:523:in `block in run_tasks_blocks'\n/var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/rake-13.0.1/exe/rake:27:in `&lt;top (required)&gt;'\n/home/deployer/.rbenv/versions/2.6.5/bin/bundle:23:in `load'\n/home/deployer/.rbenv/versions/2.6.5/bin/bundle:23:in `&lt;main&gt;'\n\nCaused by:\nLoadError: cannot load such file -- active_record/connection_adapters/http_adapter\n/var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/bootsnap-1.4.6/lib/bootsnap/load_path_cache/core_ext/kernel_require.rb:34:in `require'\n/var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/polyglot-0.3.5/lib/polyglot.rb:65:in `require'\n/var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/zeitwerk-2.3.0/lib/zeitwerk/kernel.rb:23:in `require'\n/var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/activesupport-6.0.3.2/lib/active_support/dependencies.rb:324:in `block in require'\n/var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/activesupport-6.0.3.2/lib/active_support/dependencies.rb:291:in `load_dependency'\n/var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/activesupport-6.0.3.2/lib/active_support/dependencies.rb:324:in `require'\n/var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/activerecord-6.0.3.2/lib/active_record/connection_adapters/connection_specification.rb:169:in `spec'\n/var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/activerecord-6.0.3.2/lib/active_record/connection_adapters/abstract/connection_pool.rb:1052:in `establish_connection'\n/var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/activerecord-6.0.3.2/lib/active_record/connection_handling.rb:51:in `establish_connection'\n/var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/activerecord-6.0.3.2/lib/active_record/railtie.rb:201:in `block (2 levels) in &lt;class:Railtie&gt;'\n/var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/activesupport-6.0.3.2/lib/active_support/lazy_load_hooks.rb:71:in `class_eval'\n/var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/activesupport-6.0.3.2/lib/active_support/lazy_load_hooks.rb:71:in `block in execute_hook'\n/var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/activesupport-6.0.3.2/lib/active_support/lazy_load_hooks.rb:61:in `with_execution_control'\n/var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/activesupport-6.0.3.2/lib/active_support/lazy_load_hooks.rb:66:in `execute_hook'\n/var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/activesupport-6.0.3.2/lib/active_support/lazy_load_hooks.rb:43:in `block in on_load'\n/var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/activesupport-6.0.3.2/lib/active_support/lazy_load_hooks.rb:42:in `each'\n/var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/activesupport-6.0.3.2/lib/active_support/lazy_load_hooks.rb:42:in `on_load'\n/var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/activerecord-6.0.3.2/lib/active_record/railtie.rb:198:in `block in &lt;class:Railtie&gt;'\n/var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/railties-6.0.3.2/lib/rails/initializable.rb:32:in `instance_exec'\n/var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/railties-6.0.3.2/lib/rails/initializable.rb:32:in `run'\n/var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/railties-6.0.3.2/lib/rails/initializable.rb:61:in `block in run_initializers'\n/var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/railties-6.0.3.2/lib/rails/initializable.rb:60:in `run_initializers'\n/var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/railties-6.0.3.2/lib/rails/application.rb:363:in `initialize!'\n/tmp/tomo/20200718051237/config/environment.rb:5:in `&lt;main&gt;'\n/var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/bootsnap-1.4.6/lib/bootsnap/load_path_cache/core_ext/kernel_require.rb:23:in `require'\n/var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/bootsnap-1.4.6/lib/bootsnap/load_path_cache/core_ext/kernel_require.rb:23:in `block in require_with_bootsnap_lfi'\n/var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/bootsnap-1.4.6/lib/bootsnap/load_path_cache/loaded_features_index.rb:92:in `register'\n/var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/bootsnap-1.4.6/lib/bootsnap/load_path_cache/core_ext/kernel_require.rb:22:in `require_with_bootsnap_lfi'\n/var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/bootsnap-1.4.6/lib/bootsnap/load_path_cache/core_ext/kernel_require.rb:31:in `require'\n/var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/polyglot-0.3.5/lib/polyglot.rb:65:in `require'\n/var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/zeitwerk-2.3.0/lib/zeitwerk/kernel.rb:23:in `require'\n/var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/activesupport-6.0.3.2/lib/active_support/dependencies.rb:324:in `block in require'\n/var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/activesupport-6.0.3.2/lib/active_support/dependencies.rb:291:in `load_dependency'\n/var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/activesupport-6.0.3.2/lib/active_support/dependencies.rb:324:in `require'\n/var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/railties-6.0.3.2/lib/rails/application.rb:339:in `require_environment!'\n/var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/railties-6.0.3.2/lib/rails/application.rb:523:in `block in run_tasks_blocks'\n/var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/rake-13.0.1/exe/rake:27:in `&lt;top (required)&gt;'\n/home/deployer/.rbenv/versions/2.6.5/bin/bundle:23:in `load'\n/home/deployer/.rbenv/versions/2.6.5/bin/bundle:23:in `&lt;main&gt;'\nTasks: TOP =&gt; db:create =&gt; db:load_config =&gt; environment\n(See full trace by running task with --trace)\n\n  ERROR: The following script failed on deployer@134.209.110.34 (exit status 1).\n\n    cd /tmp/tomo/20200718051237 &amp;&amp; bundle exec rake db:create\n\n  You can manually re-execute the script via SSH as follows:\n\n    ssh -o LogLevel\\=ERROR -A -o ConnectTimeout\\=5 -o StrictHostKeyChecking\\=accept-new -o ControlMaster\\=auto -o ControlPath\\=/var/folders/b1/mqpmy8jj4h74xl88g_wdxr3h0000gn/T/tomo_ssh_91c26631d427a22d -o ControlPersist\\=30s -o PasswordAuthentication\\=no deployer@134.209.110.34 -- cd\\ /tmp/tomo/20200718051237\\ \\&amp;\\&amp;\\ bundle\\ exec\\ rake\\ db:create\n\n  For more troubleshooting info, run tomo again using the --debug option.\n\n  DEPRECATION WARNING: Including LoggerSilence is deprecated and will be removed in Rails 6.1. Please use `ActiveSupport::LoggerSilence` instead (called from block (2 levels) in require at /home/deployer/.rbenv/versions/2.6.5/lib/ruby/gems/2.6.0/gems/bundler-2.1.4/lib/bundler/runtime.rb:74)\n  rake aborted!\n  LoadError: Could not load the 'http' Active Record adapter. Ensure that the adapter is spelled correctly in config/database.yml and that you've added the necessary adapter gem to your Gemfile.\n  /var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/bootsnap-1.4.6/lib/bootsnap/load_path_cache/core_ext/kernel_require.rb:34:in `require'\n  /var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/polyglot-0.3.5/lib/polyglot.rb:65:in `require'\n  /var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/zeitwerk-2.3.0/lib/zeitwerk/kernel.rb:23:in `require'\n  /var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/activesupport-6.0.3.2/lib/active_support/dependencies.rb:324:in `block in require'\n  /var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/activesupport-6.0.3.2/lib/active_support/dependencies.rb:291:in `load_dependency'\n  /var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/activesupport-6.0.3.2/lib/active_support/dependencies.rb:324:in `require'\n  /var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/activerecord-6.0.3.2/lib/active_record/connection_adapters/connection_specification.rb:169:in `spec'\n  /var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/activerecord-6.0.3.2/lib/active_record/connection_adapters/abstract/connection_pool.rb:1052:in `establish_connection'\n  /var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/activerecord-6.0.3.2/lib/active_record/connection_handling.rb:51:in `establish_connection'\n  /var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/activerecord-6.0.3.2/lib/active_record/railtie.rb:201:in `block (2 levels) in &lt;class:Railtie&gt;'\n  /var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/activesupport-6.0.3.2/lib/active_support/lazy_load_hooks.rb:71:in `class_eval'\n  /var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/activesupport-6.0.3.2/lib/active_support/lazy_load_hooks.rb:71:in `block in execute_hook'\n  /var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/activesupport-6.0.3.2/lib/active_support/lazy_load_hooks.rb:61:in `with_execution_control'\n  /var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/activesupport-6.0.3.2/lib/active_support/lazy_load_hooks.rb:66:in `execute_hook'\n  /var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/activesupport-6.0.3.2/lib/active_support/lazy_load_hooks.rb:43:in `block in on_load'\n  /var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/activesupport-6.0.3.2/lib/active_support/lazy_load_hooks.rb:42:in `each'\n  /var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/activesupport-6.0.3.2/lib/active_support/lazy_load_hooks.rb:42:in `on_load'\n  /var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/activerecord-6.0.3.2/lib/active_record/railtie.rb:198:in `block in &lt;class:Railtie&gt;'\n  /var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/railties-6.0.3.2/lib/rails/initializable.rb:32:in `instance_exec'\n  /var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/railties-6.0.3.2/lib/rails/initializable.rb:32:in `run'\n  /var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/railties-6.0.3.2/lib/rails/initializable.rb:61:in `block in run_initializers'\n  /var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/railties-6.0.3.2/lib/rails/initializable.rb:60:in `run_initializers'\n  /var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/railties-6.0.3.2/lib/rails/application.rb:363:in `initialize!'\n  /tmp/tomo/20200718051237/config/environment.rb:5:in `&lt;main&gt;'\n  /var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/bootsnap-1.4.6/lib/bootsnap/load_path_cache/core_ext/kernel_require.rb:23:in `require'\n  /var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/bootsnap-1.4.6/lib/bootsnap/load_path_cache/core_ext/kernel_require.rb:23:in `block in require_with_bootsnap_lfi'\n  /var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/bootsnap-1.4.6/lib/bootsnap/load_path_cache/loaded_features_index.rb:92:in `register'\n  /var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/bootsnap-1.4.6/lib/bootsnap/load_path_cache/core_ext/kernel_require.rb:22:in `require_with_bootsnap_lfi'\n  /var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/bootsnap-1.4.6/lib/bootsnap/load_path_cache/core_ext/kernel_require.rb:31:in `require'\n  /var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/polyglot-0.3.5/lib/polyglot.rb:65:in `require'\n  /var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/zeitwerk-2.3.0/lib/zeitwerk/kernel.rb:23:in `require'\n  /var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/activesupport-6.0.3.2/lib/active_support/dependencies.rb:324:in `block in require'\n  /var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/activesupport-6.0.3.2/lib/active_support/dependencies.rb:291:in `load_dependency'\n  /var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/activesupport-6.0.3.2/lib/active_support/dependencies.rb:324:in `require'\n  /var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/railties-6.0.3.2/lib/rails/application.rb:339:in `require_environment!'\n  /var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/railties-6.0.3.2/lib/rails/application.rb:523:in `block in run_tasks_blocks'\n  /var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/rake-13.0.1/exe/rake:27:in `&lt;top (required)&gt;'\n  /home/deployer/.rbenv/versions/2.6.5/bin/bundle:23:in `load'\n  /home/deployer/.rbenv/versions/2.6.5/bin/bundle:23:in `&lt;main&gt;'\n\n  Caused by:\n  LoadError: cannot load such file -- active_record/connection_adapters/http_adapter\n  /var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/bootsnap-1.4.6/lib/bootsnap/load_path_cache/core_ext/kernel_require.rb:34:in `require'\n  /var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/polyglot-0.3.5/lib/polyglot.rb:65:in `require'\n  /var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/zeitwerk-2.3.0/lib/zeitwerk/kernel.rb:23:in `require'\n  /var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/activesupport-6.0.3.2/lib/active_support/dependencies.rb:324:in `block in require'\n  /var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/activesupport-6.0.3.2/lib/active_support/dependencies.rb:291:in `load_dependency'\n  /var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/activesupport-6.0.3.2/lib/active_support/dependencies.rb:324:in `require'\n  /var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/activerecord-6.0.3.2/lib/active_record/connection_adapters/connection_specification.rb:169:in `spec'\n  /var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/activerecord-6.0.3.2/lib/active_record/connection_adapters/abstract/connection_pool.rb:1052:in `establish_connection'\n  /var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/activerecord-6.0.3.2/lib/active_record/connection_handling.rb:51:in `establish_connection'\n  /var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/activerecord-6.0.3.2/lib/active_record/railtie.rb:201:in `block (2 levels) in &lt;class:Railtie&gt;'\n  /var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/activesupport-6.0.3.2/lib/active_support/lazy_load_hooks.rb:71:in `class_eval'\n  /var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/activesupport-6.0.3.2/lib/active_support/lazy_load_hooks.rb:71:in `block in execute_hook'\n  /var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/activesupport-6.0.3.2/lib/active_support/lazy_load_hooks.rb:61:in `with_execution_control'\n  /var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/activesupport-6.0.3.2/lib/active_support/lazy_load_hooks.rb:66:in `execute_hook'\n  /var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/activesupport-6.0.3.2/lib/active_support/lazy_load_hooks.rb:43:in `block in on_load'\n  /var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/activesupport-6.0.3.2/lib/active_support/lazy_load_hooks.rb:42:in `each'\n  /var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/activesupport-6.0.3.2/lib/active_support/lazy_load_hooks.rb:42:in `on_load'\n  /var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/activerecord-6.0.3.2/lib/active_record/railtie.rb:198:in `block in &lt;class:Railtie&gt;'\n  /var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/railties-6.0.3.2/lib/rails/initializable.rb:32:in `instance_exec'\n  /var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/railties-6.0.3.2/lib/rails/initializable.rb:32:in `run'\n  /var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/railties-6.0.3.2/lib/rails/initializable.rb:61:in `block in run_initializers'\n  /var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/railties-6.0.3.2/lib/rails/initializable.rb:60:in `run_initializers'\n  /var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/railties-6.0.3.2/lib/rails/application.rb:363:in `initialize!'\n  /tmp/tomo/20200718051237/config/environment.rb:5:in `&lt;main&gt;'\n  /var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/bootsnap-1.4.6/lib/bootsnap/load_path_cache/core_ext/kernel_require.rb:23:in `require'\n  /var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/bootsnap-1.4.6/lib/bootsnap/load_path_cache/core_ext/kernel_require.rb:23:in `block in require_with_bootsnap_lfi'\n  /var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/bootsnap-1.4.6/lib/bootsnap/load_path_cache/loaded_features_index.rb:92:in `register'\n  /var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/bootsnap-1.4.6/lib/bootsnap/load_path_cache/core_ext/kernel_require.rb:22:in `require_with_bootsnap_lfi'\n  /var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/bootsnap-1.4.6/lib/bootsnap/load_path_cache/core_ext/kernel_require.rb:31:in `require'\n  /var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/polyglot-0.3.5/lib/polyglot.rb:65:in `require'\n  /var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/zeitwerk-2.3.0/lib/zeitwerk/kernel.rb:23:in `require'\n  /var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/activesupport-6.0.3.2/lib/active_support/dependencies.rb:324:in `block in require'\n  /var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/activesupport-6.0.3.2/lib/active_support/dependencies.rb:291:in `load_dependency'\n  /var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/activesupport-6.0.3.2/lib/active_support/dependencies.rb:324:in `require'\n  /var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/railties-6.0.3.2/lib/rails/application.rb:339:in `require_environment!'\n  /var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/railties-6.0.3.2/lib/rails/application.rb:523:in `block in run_tasks_blocks'\n  /var/www/ncode-bkk-spree/shared/bundle/ruby/2.6.0/gems/rake-13.0.1/exe/rake:27:in `&lt;top (required)&gt;'\n  /home/deployer/.rbenv/versions/2.6.5/bin/bundle:23:in `load'\n  /home/deployer/.rbenv/versions/2.6.5/bin/bundle:23:in `&lt;main&gt;'\n  Tasks: TOP =&gt; db:create =&gt; db:load_config =&gt; environment\n  (See full trace by running task with --trace)\n</code></pre>\n<p>\u200b</p>\n<p>Here is my database.yml file:</p>\n<pre><code>\ndefault: &amp;default\n  adapter: postgresql\n  encoding: unicode\n\n  pool: &lt;%= ENV.fetch(&quot;RAILS_MAX_THREADS&quot;) { 5 } %&gt;\n\ndevelopment:\n  &lt;&lt;: *default\n  database: development_db\n  username: my-user\n  password: Rails.application.credentials.db[:dpassword]\n\ntest:\n  &lt;&lt;: *default\n  database: test_db\n\nproduction:\n  &lt;&lt;: *default\n  host: localhost\n  database: production_db\n  encoding: utf8\n  username: my-user\n  password: Rails.application.credentials.db[:ppassword]\n\n</code></pre>\n",
                    "OwnerUserId": "4914224",
                    "LastEditorUserId": "4914224",
                    "LastEditDate": "2020-07-18T08:12:09.340",
                    "LastActivityDate": "2020-07-18T08:12:09.340",
                    "Title": "Rails - deployment problem with HTTP Active Record Adapter",
                    "Tags": "<ruby-on-rails><ruby><ubuntu><activerecord><ruby-on-rails-6>",
                    "AnswerCount": "0",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "63058448",
                "ParentRepo": "https://github.com/andyoakley/mkdocs-blog",
                "StackOverflow_Post": {
                    "Id": "63058448",
                    "PostTypeId": "1",
                    "CreationDate": "2020-07-23T16:01:25.703",
                    "Score": "0",
                    "ViewCount": "423",
                    "Body": "<p>My goal is to be able to create content that get's automatically added to the html page(s) created with mkdocs. One example usage for this could be a blog.</p>\n<p>The solution may require placing <code>.md</code> files into</p>\n<ol>\n<li>Same folder</li>\n<li>Subfolders by year, month and day</li>\n<li>Subfolder by year and month</li>\n</ol>\n<p>and <em>it should add every .md file</em> inside the folder (and possibly subfolders) <em><strong>automatically</strong></em> to the generated html. For me, the best solution would add following contents automatically to the navigation menu (option 3. above):</p>\n<pre><code>mkdocs.yml\ndocs/\n  blog/\n    2020/\n      01/\n        05.md\n        22.md\n        30.md\n      03/\n        01.md\n        08.md\n</code></pre>\n<p>Desired output would be a tree-like presentation of titles (2020/01/05, 2020/01/22, ..etc) in a html page with links to the pages, or a navigation menu entry which follow similar tree-like structure. Other suggestions are also welcome. The main point is to have this automated; without having a need to create entry to some other page or <code>mkdocs.yml</code> each time a .md file is added.</p>\n<p>I checked <a href=\"https://github.com/andyoakley/mkdocs-blog\" rel=\"nofollow noreferrer\">mkdocs-blog</a>, but it lacks documentation, and <a href=\"https://pypi.org/project/mkdocs-blog-plugin/\" rel=\"nofollow noreferrer\">mkdocs-blog-plugin</a>, but after configuration nothing showed up in the nav panel and it uses suboptimal file structure (option 2).</p>\n<p>I am looking for clear instructions that would offer the easiest/best way to accomplish the goal defined above.</p>\n",
                    "OwnerUserId": "3015186",
                    "LastEditorUserId": "3015186",
                    "LastEditDate": "2020-07-23T16:11:51.637",
                    "LastActivityDate": "2020-07-24T11:20:28.747",
                    "Title": "How to add .md files automatically to the output html file(s) with mkdocs?",
                    "Tags": "<python><mkdocs>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "63288886",
                "ParentRepo": "https://github.com/awslabs/aws-lambda-powertools-python/blob/f5d14e3279276192c6fed0907b84b1dfa23c7b3c/aws_lambda_powertools/tracing/tracer.py",
                "StackOverflow_Post": {
                    "Id": "63288886",
                    "PostTypeId": "1",
                    "CreationDate": "2020-08-06T17:30:56.050",
                    "Score": "-1",
                    "ViewCount": "1229",
                    "Body": "<p>I have a lambda function and I am using aws_lambda_powertools in it. Lambda function project structure is like below-</p>\n<pre><code>source-&gt;Folder\n   - handler.py\nlibs\n   - aws-lambda-powertools\n   - aws-xray-sdk\n   - other libs which aws-lambda-powertools need\n\nhandler.py\nfrom libs.aws_lambda_powertools import Logger, Tracer\n</code></pre>\n<p>When I run the lambda, it gives me an error &quot;No Module found aws_xray_sdk&quot; even though the module(used by aws-powertools) is there under the libs folder.</p>\n<p>Source of Tracer which I am using in my lambda.\n<a href=\"https://github.com/awslabs/aws-lambda-powertools-python/blob/f5d14e3279276192c6fed0907b84b1dfa23c7b3c/aws_lambda_powertools/tracing/tracer.py\" rel=\"nofollow noreferrer\">https://github.com/awslabs/aws-lambda-powertools-python/blob/f5d14e3279276192c6fed0907b84b1dfa23c7b3c/aws_lambda_powertools/tracing/tracer.py</a></p>\n",
                    "OwnerUserId": "11740470",
                    "LastEditorUserId": "11740470",
                    "LastEditDate": "2020-08-06T18:07:26.397",
                    "LastActivityDate": "2020-08-08T10:38:26.810",
                    "Title": "Python not able to find modules",
                    "Tags": "<python><aws-lambda><python-3.6><aws-xray>",
                    "AnswerCount": "2",
                    "CommentCount": "4",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "63413087",
                "ParentRepo": "https://github.com/fralau/mkdocs-mermaid2-plugin",
                "StackOverflow_Post": {
                    "Id": "63413087",
                    "PostTypeId": "2",
                    "ParentId": "62333023",
                    "CreationDate": "2020-08-14T12:48:30.423",
                    "Score": "2",
                    "Body": "<p>For a prepackaged solution to integrate mermaid diagrams into mkdocs, there is now the <a href=\"https://github.com/fralau/mkdocs-mermaid2-plugin\" rel=\"nofollow noreferrer\">mkdocs-mermaid2</a> plugin, which I'm maintaining.</p>\n<p>For code highlighting, it also contains an example of how to make it work with the <a href=\"https://facelessuser.github.io/pymdown-extensions/extensions/superfences/\" rel=\"nofollow noreferrer\">superfences</a> plugin.</p>\n<p>It may be especially useful if one needs to <a href=\"https://mermaid-js.github.io/mermaid/#/Setup?id=mermaidapi-configuration-defaults\" rel=\"nofollow noreferrer\">pass arguments</a> to the <code>initialize()</code> method of the mermaid renderer, to tweak the look of diagrams.</p>\n",
                    "OwnerUserId": "4334041",
                    "LastActivityDate": "2020-08-14T12:48:30.423",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "63564640",
                "ParentRepo": "https://github.com/raynigon/unit-api/tree/master/jpa-starter/src/main/java/com/raynigon/unit_api/jpa",
                "StackOverflow_Post": {
                    "Id": "63564640",
                    "PostTypeId": "1",
                    "CreationDate": "2020-08-24T16:03:24.130",
                    "Score": "2",
                    "ViewCount": "192",
                    "Body": "<p>How can i register a global available <code>DynamicParameterizedType</code> in hibernate?</p>\n<p>I wrote the following type:</p>\n<pre class=\"lang-java prettyprint-override\"><code>public class QuantityType extends AbstractSingleColumnStandardBasicType&lt;Quantity&lt;?&gt;&gt; implements DynamicParameterizedType {\n\n    public static final QuantityType INSTANCE = new QuantityType();\n\n    public QuantityType() {\n        super(DoubleTypeDescriptor.INSTANCE, new QuantityJavaDescriptor(AbstractUnit.ONE));\n    }\n\n    @Override\n    public String getName() {\n        return QuantityType.class.getSimpleName();\n    }\n\n    @Override\n    public void setParameterValues(Properties parameters) {\n        ParameterType reader = (ParameterType) parameters.get(PARAMETER_TYPE);\n        if (reader == null) throw new RuntimeException(&quot;Not Implemented&quot;);\n        Unit&lt;?&gt; resolvedUnit = resolveUnit(reader);\n        setJavaTypeDescriptor(new QuantityJavaDescriptor(resolvedUnit));\n    }\n\n    private Unit&lt;?&gt; resolveUnit(ParameterType reader) {...}\n}\n</code></pre>\n<p>and registered it with a service registration in hibernate:</p>\n<pre class=\"lang-java prettyprint-override\"><code>public class QuantityTypeRegistration implements TypeContributor {\n\n    @Override\n    public void contribute(TypeContributions typeContributions, ServiceRegistry serviceRegistry) {\n        typeContributions.contributeType(QuantityType.INSTANCE);\n    }\n}\n</code></pre>\n<p>If i use the type in an entity, the wrap/unwrap method of the JavaTypeDescriptor gets called,\nbut instead of the parameterized JavaTypeDescriptor, the default JavaTypeDescriptor gets called. For some reason the <code>setParameterValues</code> method was not called.</p>\n<p>Code: <a href=\"https://github.com/raynigon/unit-api/tree/master/jpa-starter/src/main/java/com/raynigon/unit_api/jpa\" rel=\"nofollow noreferrer\">https://github.com/raynigon/unit-api/tree/master/jpa-starter/src/main/java/com/raynigon/unit_api/jpa</a></p>\n",
                    "OwnerUserId": "8720110",
                    "LastEditorUserId": "8720110",
                    "LastEditDate": "2020-08-24T16:16:13.613",
                    "LastActivityDate": "2020-08-24T16:16:13.613",
                    "Title": "Register DynamicParameterizedType global",
                    "Tags": "<spring-boot><hibernate><jpa>",
                    "AnswerCount": "0",
                    "CommentCount": "3",
                    "FavoriteCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "63662555",
                "ParentRepo": "https://github.com/summer/mojang",
                "StackOverflow_Post": {
                    "Id": "63662555",
                    "PostTypeId": "2",
                    "ParentId": "63096451",
                    "CreationDate": "2020-08-30T22:00:36.520",
                    "Score": "0",
                    "Body": "<p>The documentation is relatively straightforward.</p>\n<p>You want to send a <code>GET</code> request with their username:</p>\n<pre class=\"lang-py prettyprint-override\"><code>import requests\n\nusername = &quot;Bob&quot;\n\nresp = requests.get(f&quot;https://api.mojang.com/users/profiles/minecraft/{username}&quot;)\nuuid = resp.json()[&quot;id&quot;]\n\nprint(f&quot;Bob's current UUID is {uuid}&quot;)\n</code></pre>\n<p>Optionally, you can include a UNIX timestamp to get the username's UUID at a specific point in time:</p>\n<pre class=\"lang-py prettyprint-override\"><code>username = &quot;Alice&quot;\n# UNIX timestamp that equates to 01/01/2018\ntimestamp = 1514764800\n\nresp = requests.get(f&quot;https://api.mojang.com/users/profiles/minecraft/{username}?at={timestamp}&quot;)\n\nuuid = resp.json()[&quot;id&quot;]\n\nprint(f&quot;Alice's UUID on 01/01/2018 was {uuid}&quot;)\n</code></pre>\n<h1></h1>\n<h2>Other Solution (third party library)</h2>\n<p>Alternatively, you can use my newly released <a href=\"https://github.com/summer/mojang\" rel=\"nofollow noreferrer\">Mojang package</a>, if you don't want to deal with the HTTP requests, JSON, and other web junk in your code.</p>\n<p>Install it with pip by running the following console command:</p>\n<pre><code>python -m pip install mojang\n</code></pre>\n<p>Usage:</p>\n<pre class=\"lang-py prettyprint-override\"><code>from mojang import API\n\napi = API()\n\nuuid = api.get_uuid(&quot;Alice&quot;)\nprint(f&quot;Alice's UUID is {uuid}&quot;)\n\n# or with a timestamp\nuuid = api.get_uuid(&quot;Alice&quot;, timestamp=1514764800)\nprint(f&quot;Alice's UUID on 01/01/2018 was {uuid}&quot;)\n</code></pre>\n",
                    "OwnerUserId": "11216896",
                    "LastEditorUserId": "11216896",
                    "LastEditDate": "2022-11-04T23:23:45.857",
                    "LastActivityDate": "2022-11-04T23:23:45.857",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "63710044",
                "ParentRepo": "https://github.com/jordaneremieff/mangum/issues/126",
                "StackOverflow_Post": {
                    "Id": "63710044",
                    "PostTypeId": "1",
                    "CreationDate": "2020-09-02T16:47:46.183",
                    "Score": "1",
                    "ViewCount": "2646",
                    "Body": "<p>I am trying to use Serverless Framework to deploy a Python Fast API WebApp.\nIs is related to issue:</p>\n<p><a href=\"https://github.com/jordaneremieff/mangum/issues/126\" rel=\"nofollow noreferrer\">https://github.com/jordaneremieff/mangum/issues/126</a></p>\n<p>When I deploy it using serverless, sls depoy and Invoke the function I am getting the following error:</p>\n<pre><code>[ERROR] KeyError: 'requestContext'\nTraceback (most recent call last):\n  File &quot;/var/task/mangum/adapter.py&quot;, line 110, in __call__\n    return self.handler(event, context)\n  File &quot;/var/task/mangum/adapter.py&quot;, line 130, in handler\n    if &quot;eventType&quot; in event[&quot;requestContext&quot;]:\n</code></pre>\n<p>I have tried with python 3.8 and 3.7.\nNot able to find a resolution on the web for the same.\nAlso tried using the parameters spec_version=2(which is not required I feel).</p>\n<p>I feel something is missing here, the issue is somewhere around:</p>\n<pre><code>Adapter requires the information in the event and request context to form the ASGI connection scope.\n</code></pre>\n<p>Wondering if anyone has got FastAPI working on AWS Lambda using serverless Framework.</p>\n<p>My handler:</p>\n<pre><code>from fastapi import FastAPI\nfrom mangum import Mangum\n\n\napp = FastAPI()\nhandler = Mangum(app)\n\n@app.get(&quot;/ping&quot;)\ndef ping():\n    return {'response': 'pong'}\n\n</code></pre>\n<p>serverless.yml:</p>\n<pre><code>provider:\n  name: aws\n  runtime: python3.8\n  stage: dev\n  region: ap-southeast-1\n  memorySize: 256\n\nfunctions:\n  ping:\n    handler: ping.handler\n    events:\n      - http:\n          path: ping\n          method: get\n          cors: true\n</code></pre>\n<p>My requirements.txt</p>\n<pre><code>appnope==0.1.0\nbackcall==0.2.0\ncertifi==2020.6.20\nchardet==3.0.4\nclick==7.1.2\ndecorator==4.4.2\nfastapi==0.61.1\nh11==0.9.0\nhttpcore==0.10.2\nhttptools==0.1.1\nhttpx==0.14.1\nidna==2.10\nipython==7.17.0\nipython-genutils==0.2.0\njedi==0.17.2\nmangum==0.9.2\nparso==0.7.1\npexpect==4.8.0\npickleshare==0.7.5\nprompt-toolkit==3.0.6\nptyprocess==0.6.0\npydantic==1.6.1\nPygments==2.6.1\nrequests==2.24.0\nrfc3986==1.4.0\nsix==1.15.0\nsniffio==1.1.0\nstarlette==0.13.6\ntraitlets==4.3.3\ntyping-extensions==3.7.4.2\nurllib3==1.25.10\nuvicorn==0.11.8\nuvloop==0.14.0\nwcwidth==0.2.5\nwebsockets==8.1\n</code></pre>\n",
                    "OwnerUserId": "1694699",
                    "LastActivityDate": "2022-04-11T23:32:26.983",
                    "Title": "KeyError: 'requestContext', FastAPI, Mangum, Serverless",
                    "Tags": "<python><aws-lambda><serverless-framework><fastapi>",
                    "AnswerCount": "2",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "63832506",
                "ParentRepo": "https://github.com/mfesiem/msiempy",
                "StackOverflow_Post": {
                    "Id": "63832506",
                    "PostTypeId": "2",
                    "ParentId": "48898955",
                    "CreationDate": "2020-09-10T15:02:59.080",
                    "Score": "0",
                    "Body": "<p>The <a href=\"https://github.com/mfesiem/msiempy\" rel=\"nofollow noreferrer\">McAfee SIEM API Python wrapper</a> can handle of the boring stuff like login, get results rows, etc for you.</p>\n<p>It's really simple to query events and perform other actions like managing Datasources.</p>\n<p>Exemple of simple event query with filters :</p>\n<pre><code>from  msiempy.event import EventManager, FieldFilter\n\nprint('Simple event query sorted by AlertID')\nevents = EventManager(\n        time_range='CURRENT_YEAR',\n        fields=['SrcIP', 'AlertID'], # SrcIP and AlertID are not queried by default\n        filters=[\n                FieldFilter('DstIP', ['0.0.0.0/0',]),\n                FieldFilter('HostID', ['mail'], operator='CONTAINS')], # Please replace &quot;mail&quot; by a test hostname\n        order=(('ASCENDING', 'AlertID')),\n        limit=10)\n\nevents.load_data()\nprint(events)\nprint(events.get_text(fields=['AlertID','LastTime','SrcIP', 'Rule.msg']))\n</code></pre>\n",
                    "OwnerUserId": "14255302",
                    "LastActivityDate": "2020-09-10T15:02:59.080",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "63843254",
                "ParentRepo": "https://github.com/NervanaSystems/distiller/blob/master/distiller/knowledge_distillation.py#L105",
                "StackOverflow_Post": {
                    "Id": "63843254",
                    "PostTypeId": "1",
                    "CreationDate": "2020-09-11T08:13:06.683",
                    "Score": "0",
                    "ViewCount": "538",
                    "Body": "<p>I am implementing fast DNN model training using knowledge distillation, as illustrated in the figure below, to run the teacher and student models in parallel.</p>\n<p>I checked some popular repos like <a href=\"https://github.com/NervanaSystems/distiller/blob/master/distiller/knowledge_distillation.py#L105\" rel=\"nofollow noreferrer\">NervanaSystems/distiller</a> and <a href=\"https://github.com/peterliht/knowledge-distillation-pytorch/blob/e4c40132fed5a45e39a6ef7a77b15e5d389186f8/train.py#L277\" rel=\"nofollow noreferrer\">peterliht/knowledge-distillation-pytorch</a>. They execute the forward operations of the student and teacher models step by step, i.e., not in parallel on different devices (GPU or CPU).</p>\n<p>I am trying to speed up this training process to run the 2 models at the same time using multiple devices (e.g., loading one model on CPU and not interrupting the GPU training of the other model).</p>\n<p>What is the proper way to run 2 models in parallel? Can I use Python <code>multiprocessing</code> library to start 2 processes for the 2 models, i.e., loading 2 model instances and running <code>forward()</code>? I am using MXNet but this is a general question for all ML frameworks.</p>\n<p>Edit:<br />\nMy plan is to put a light-weight pre-trained teacher model on CPU which only runs forward pass with frozen parameters.<br />\nThe student model is a large model to be trained on GPU (distributedly).\nThis task is not for model compression.\nI suppose moving a light task (teacher's forward pass) to CPU can increase the overlap and make this pipeline faster.<br />\nThe idea is from a workshop paper: <a href=\"http://learningsys.org/nips18/assets/papers/24CameraReadySubmissionInfer2Train.pdf\" rel=\"nofollow noreferrer\">Infer2Train: leveraging inference for better training of deep networks</a>.</p>\n<p><a href=\"https://i.stack.imgur.com/uOrit.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/uOrit.png\" alt=\"knowledge distillation illustration\" /></a></p>\n",
                    "OwnerUserId": "7975433",
                    "LastEditorUserId": "7975433",
                    "LastEditDate": "2020-09-11T10:36:54.820",
                    "LastActivityDate": "2020-09-11T10:36:54.820",
                    "Title": "In knowledge distillation, how to run the student and the teacher models in parallel?",
                    "Tags": "<tensorflow><machine-learning><neural-network><pytorch><mxnet>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "FavoriteCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "63932678",
                "ParentRepo": "https://github.com/traefik/traefik/issues/3745",
                "StackOverflow_Post": {
                    "Id": "63932678",
                    "PostTypeId": "2",
                    "ParentId": "63847763",
                    "CreationDate": "2020-09-17T06:49:59.913",
                    "Score": "0",
                    "Body": "<p>Seems to be a feature request to add more configuration options to DRR load balancing - <a href=\"https://github.com/traefik/traefik/issues/3745\" rel=\"nofollow noreferrer\">https://github.com/traefik/traefik/issues/3745</a></p>\n",
                    "OwnerUserId": "961152",
                    "LastActivityDate": "2020-09-17T06:49:59.913",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "63959436",
                "ParentRepo": "https://github.com/carlspring/s3fs-nio/",
                "StackOverflow_Post": {
                    "Id": "63959436",
                    "PostTypeId": "5",
                    "CreationDate": "2020-09-18T16:23:33.717",
                    "Score": "0",
                    "Body": "<p>This is an implementation of an Amazon AWS S3 FileSystem provider using <a href=\"https://jcp.org/en/jsr/detail?id=203\" rel=\"nofollow noreferrer\">JSR-203</a> (a.k.a. NIO2) for Java 8.</p>\n<p>This project provides a complete API implementation for managing files and folders directly in Amazon S3 and it also supports AWS SDK v.2, as well as JDK8 and 11.</p>\n<p>You can find more details here:</p>\n<ul>\n<li><p><a href=\"https://s3fs-nio.carlspring.org/\" rel=\"nofollow noreferrer\">Project wiki</a></p>\n</li>\n<li><p><a href=\"https://github.com/carlspring/s3fs-nio/\" rel=\"nofollow noreferrer\">Github project</a></p>\n</li>\n<li><p><a href=\"https://github.com/carlspring/s3fs-nio/issues/\" rel=\"nofollow noreferrer\">Issue tracker</a></p>\n</li>\n<li><p><a href=\"https://chat.carlspring.org/channel/s3fs-nio-community\" rel=\"nofollow noreferrer\">Chat channel</a></p>\n</li>\n</ul>\n",
                    "OwnerUserId": "774183",
                    "LastEditorUserId": "774183",
                    "LastEditDate": "2020-11-09T17:51:55.743",
                    "LastActivityDate": "2020-11-09T17:51:55.743",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "64168180",
                "ParentRepo": "https://github.com/microsoft/presidio/blob/master/presidio-analyzer/presidio_analyzer/recognizer_registry/recognizer_registry.py#L151",
                "StackOverflow_Post": {
                    "Id": "64168180",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "64168240",
                    "CreationDate": "2020-10-02T08:08:24.763",
                    "Score": "1",
                    "ViewCount": "101",
                    "Body": "<p>One of Microsoft's <code>presidio-analyzer</code> <a href=\"https://github.com/microsoft/presidio/blob/master/presidio-analyzer/presidio_analyzer/recognizer_registry/recognizer_registry.py#L151\" rel=\"nofollow noreferrer\">modules</a> logs with the root logger:</p>\n<pre class=\"lang-py prettyprint-override\"><code>        logging.info(\n            &quot;Returning a total of %d recognizers (predefined + custom)&quot;, len(to_return)\n        )\n</code></pre>\n<p>This particular line will be written millions of times.</p>\n<p>I created an <a href=\"https://github.com/microsoft/presidio/issues/372\" rel=\"nofollow noreferrer\">issue</a> on GitHub, but in the meantime, is there a way to suppress these logs? I can't access the logger by name, and I can't set the root logger to <code>WARN</code> either because it propagates to all my loggers.</p>\n",
                    "OwnerUserId": "5276797",
                    "LastActivityDate": "2020-10-02T08:26:03.000",
                    "Title": "Disable logs from imported module using the root logger",
                    "Tags": "<python><logging><python-import>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "64236507",
                "ParentRepo": "https://github.com/lensapp/lens/",
                "StackOverflow_Post": {
                    "Id": "64236507",
                    "PostTypeId": "2",
                    "ParentId": "61630205",
                    "CreationDate": "2020-10-07T02:50:34.270",
                    "Score": "0",
                    "Body": "<ul>\n<li>Lens is the best IDE for kubernetes that I have used upto now.</li>\n<li>It serves everything in a plate , as there is no need to mug up the commands of kubectl,\nyou can make changes in any of kubernetes yaml file from lens and it will apply changes in to your cluster.</li>\n<li>install lens for your OS: <a href=\"https://github.com/lensapp/lens/releases/\" rel=\"nofollow noreferrer\">https://github.com/lensapp/lens/releases/</a></li>\n<li>you can know more about lens from this link : <a href=\"https://github.com/lensapp/lens/\" rel=\"nofollow noreferrer\">https://github.com/lensapp/lens/</a></li>\n</ul>\n",
                    "OwnerUserId": "8214877",
                    "LastActivityDate": "2020-10-07T02:50:34.270",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "64342640",
                "ParentRepo": "https://github.com/docker/getting-started",
                "StackOverflow_Post": {
                    "Id": "64342640",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "64342666",
                    "CreationDate": "2020-10-13T20:21:52.133",
                    "Score": "-1",
                    "ViewCount": "120",
                    "Body": "<p>I am following <a href=\"https://github.com/docker/getting-started\" rel=\"nofollow noreferrer\">Docker Labs</a> tutorial &amp; have made it to the 7th step. Where I need to Attach MySQL DB container to my app network container. Upon entering the following command on windows 10 CMD:</p>\n<pre><code>docker run -d \\\n--network todo-app --network-alias mysql \\\n-v todo-mysql-data:/var/lib/mysql \\\n-e MYSQL_ROOT_PASSWORD=secret \\\n-e MYSQL_DATABASE=todos \\\nmysql:5.7\n</code></pre>\n<p>I get this error:</p>\n<pre><code>C:\\Users\\Ajmal .M\\getting-started&gt;docker run -d \\\ndocker: invalid reference format.\nSee 'docker run --help'.\n\nC:\\Users\\Ajmal .M\\getting-started&gt;    --network todo-app --network-alias mysql \\\n'--network' is not recognized as an internal or external command,\noperable program or batch file.\n\nC:\\Users\\Ajmal .M\\getting-started&gt;    -v todo-mysql-data:/var/lib/mysql \\\n'-v' is not recognized as an internal or external command,\noperable program or batch file.\n\nC:\\Users\\Ajmal .M\\getting-started&gt;    -e MYSQL_ROOT_PASSWORD=secret \\\n'-e' is not recognized as an internal or external command,\noperable program or batch file.\n\nC:\\Users\\Ajmal .M\\getting-started&gt;    -e MYSQL_DATABASE=todos \\\n'-e' is not recognized as an internal or external command,\noperable program or batch file.\n\nC:\\Users\\Ajmal .M\\getting-started&gt;    mysql:5.7\nThe filename, directory name, or volume label syntax is incorrect.\n</code></pre>\n<p><a href=\"https://i.stack.imgur.com/sYaoy.png\" rel=\"nofollow noreferrer\">CMD Snapshot</a></p>\n",
                    "OwnerUserId": "10788573",
                    "LastActivityDate": "2020-10-13T20:24:25.053",
                    "Title": "Unable to start a MySQL Container & attach it to the Docker network",
                    "Tags": "<mysql><docker>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "64542275",
                "ParentRepo": "https://github.com/kubernetes-sigs/aws-load-balancer-controller/blob/main/docs/guide/ingress/annotations.md",
                "StackOverflow_Post": {
                    "Id": "64542275",
                    "PostTypeId": "2",
                    "ParentId": "50448620",
                    "CreationDate": "2020-10-26T17:43:11.080",
                    "Score": "0",
                    "Body": "<p>I'll first give some background regarding annotations.</p>\n<h3>Annotations Vs Labels</h3>\n<p>Annotations are quiet different then labels.</p>\n<p><em>Labels</em>:<br>\nYou use labels to group resources that you want to refer as a whole. <br>\nFor example pods with the <code>app=run, env=staging</code> could be exposed by a service with a label selector that matches those labels or managed by a deployment or a daemon set.</p>\n<p><em>Annotations</em>:<br>\nAnnotations have a few different usages like providing description and adding support for fields that are not part of the K8S API. <br>\nWhile labels should be short, annotations can contain much larger sets of data and <a href=\"https://github.com/kubernetes/kubernetes/pull/16068\" rel=\"nofollow noreferrer\">can reach up to 256KB</a>.</p>\n<h3>Annotations use cases examples</h3>\n<p>You can see below a few examples of how annotations are being used by the various providers / tools that interacts with your cluster.</p>\n<p>1 ) Used internally by K8S - below are the annotations that are added to the API-server pod:</p>\n<pre><code>kubernetes.io/config.hash: 7c3646d2bcee38ee7dfb851711571ba3\nkubernetes.io/config.mirror: 7c3646d2bcee38ee7dfb851711571ba3\nkubernetes.io/config.seen: &quot;2020-10-22T01:26:12.671011852+03:00&quot;\nkubernetes.io/config.source: file\n</code></pre>\n<p>2 ) If you provision a cluster with <a href=\"/questions/tagged/kubeadm\" class=\"post-tag\" title=\"show questions tagged &#39;kubeadm&#39;\" rel=\"tag\">kubeadm</a> - this will be added to the API-server pod:</p>\n<pre><code>annotations: \n    kubeadm.kubernetes.io/kube-apiserver.advertise-address.endpoint: 10.246.38.137:6443\n</code></pre>\n<p>3 ) If you run on <a href=\"/questions/tagged/amazon-eks\" class=\"post-tag\" title=\"show questions tagged &#39;amazon-eks&#39;\" rel=\"tag\">amazon-eks</a> you can see that the following annotation is added to your workloads - this is for backward compatibility - read more in <a href=\"https://docs.aws.amazon.com/eks/latest/userguide/pod-security-policy.html#default-psp\" rel=\"nofollow noreferrer\">here</a>):</p>\n<pre><code>  annotations:\n    kubernetes.io/psp: eks.privileged\n</code></pre>\n<p>4 ) There are cases when 3rd party tools like <a href=\"https://github.com/kubernetes-sigs/aws-load-balancer-controller/blob/main/docs/guide/ingress/annotations.md\" rel=\"nofollow noreferrer\">aws-alb-ingress-controller</a> that requires you to pass (mandatory) configuration via annotations (because those fields are not supported by the K8S api):</p>\n<pre><code>apiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: aws-alb-ingress\n  namespace: default\n  annotations:\n    kubernetes.io/ingress.class: alb\n    alb.ingress.kubernetes.io/scheme: internet-facing\n    alb.ingress.kubernetes.io/tags: Role=Backend , Environment=prod , Name=eros-ingress-alb\n    alb.ingress.kubernetes.io/listen-ports: '[{&quot;HTTP&quot;: 80},{&quot;HTTPS&quot;: 443}]'\n    alb.ingress.kubernetes.io/security-groups : sg-0e3455g455        \n    alb.ingress.kubernetes.io/backend-protocol : HTTP\n    alb.ingress.kubernetes.io/target-type: instance \n    alb.ingress.kubernetes.io/healthcheck-path: \n    alb.ingress.kubernetes.io/success-codes: &quot;200&quot; \n    alb.ingress.kubernetes.io/certificate-arn: \n</code></pre>\n<h3>In your case</h3>\n<p>Ask yourself what is the reason for adding the annotations. <br>\nThen make sure you use a unique prefix for your key in order to avoid collusions.</p>\n<p>If you're not sure how to add an annotation to a yaml you can add it manually:</p>\n<pre><code>$kubectl annotate pod &lt;pod-name&gt; unique.prefix/for-my-key=&quot;value&quot;\n</code></pre>\n<p>And then run <code>$kubectl get po &lt;pod-name&gt; -o yaml</code> to view the annotation that you added manually and copy the yaml to your VCS.</p>\n",
                    "OwnerUserId": "1103953",
                    "LastActivityDate": "2020-10-26T17:43:11.080",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "64720717",
                "ParentRepo": "https://github.com/uriyyo/fastapi-pagination/blob/main/examples/pagination_sqlalchemy.py",
                "StackOverflow_Post": {
                    "Id": "64720717",
                    "PostTypeId": "2",
                    "ParentId": "60152442",
                    "CreationDate": "2020-11-06T19:42:46.540",
                    "Score": "11",
                    "Body": "<p>You can use <code>fastapi-pagination</code> module, it currently has integration with <code>sqlalchemy</code> and <code>gino</code>.</p>\n<p>The usage will look like:</p>\n<pre class=\"lang-py prettyprint-override\"><code>from fastapi_pagination import Page, PaginationParams\nfrom fastapi_pagination.ext.sqlalchemy import paginate\n\n\nclass User(Base):\n    __tablename__ = &quot;users&quot;\n\n    id = Column(Integer, primary_key=True, autoincrement=True)\n    name = Column(String, nullable=False)\n    email = Column(String, nullable=False)\n\n\nclass UserModel(BaseModel):\n    id: int\n    name: str\n    email: str\n\n    class Config:\n        orm_mode = True\n\n\napp = FastAPI()\n\n@app.get('/users', response_model=Page[UserModel])\ndef get_users(db: Session = Depends(get_db), params: PaginationParams = Depends()):\n    return paginate(db.query(User), params)\n</code></pre>\n<p>Please notice, the purpose of this code is to show <code>fastapi-pagination</code> API.\nYou can find a fully working example here: <a href=\"https://github.com/uriyyo/fastapi-pagination/blob/main/examples/pagination_sqlalchemy.py\" rel=\"noreferrer\">https://github.com/uriyyo/fastapi-pagination/blob/main/examples/pagination_sqlalchemy.py</a></p>\n",
                    "OwnerUserId": "12243670",
                    "LastEditorUserId": "12243670",
                    "LastEditDate": "2021-11-12T14:05:38.093",
                    "LastActivityDate": "2021-11-12T14:05:38.093",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "64769646",
                "ParentRepo": "https://github.com/PyCQA/isort/blob/5.6.4/isort/place.py#L63-L95",
                "StackOverflow_Post": {
                    "Id": "64769646",
                    "PostTypeId": "2",
                    "ParentId": "63583880",
                    "CreationDate": "2020-11-10T13:14:33.377",
                    "Score": "4",
                    "Body": "<p>You can use <code>src_paths</code> option to specify the project folder. You are do not need to maintain <code>known_first_party</code> list. Related source code (<a href=\"https://github.com/PyCQA/isort/blob/5.6.4/isort/place.py#L63-L95\" rel=\"nofollow noreferrer\">https://github.com/PyCQA/isort/blob/5.6.4/isort/place.py#L63-L95</a>) :</p>\n<pre><code>if (\n    _is_module(module_path)\n    or _is_package(module_path)\n    or _src_path_is_module(src_path, root_module_name)\n):\n    return (sections.FIRSTPARTY, f&quot;Found in one of the configured src_paths: {src_path}.&quot;)\n</code></pre>\n",
                    "OwnerUserId": "3096304",
                    "LastActivityDate": "2020-11-10T13:14:33.377",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "64936701",
                "ParentRepo": "https://github.com/aeternity/aepp-aeproject-js",
                "StackOverflow_Post": {
                    "Id": "64936701",
                    "PostTypeId": "2",
                    "ParentId": "60637652",
                    "CreationDate": "2020-11-20T20:48:45.363",
                    "Score": "2",
                    "Body": "<p>This post is pretty old but thought on responding anyway.</p>\n<p>Did you tried this by using aeproject?</p>\n<p><a href=\"https://github.com/aeternity/aepp-aeproject-js\" rel=\"noreferrer\">https://github.com/aeternity/aepp-aeproject-js</a></p>\n<p>Try to put your contract code under the file structure and use the deploy script so you can work it out locally first and the deploy to testnet or mainnet.</p>\n",
                    "OwnerUserId": "2465044",
                    "LastActivityDate": "2020-11-20T20:48:45.363",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "64954575",
                "ParentRepo": "https://github.com/wandb/client",
                "StackOverflow_Post": {
                    "Id": "64954575",
                    "PostTypeId": "2",
                    "ParentId": "53356846",
                    "CreationDate": "2020-11-22T13:16:04.263",
                    "Score": "0",
                    "Body": "<p>Recently found this <a href=\"https://github.com/wandb/client\" rel=\"nofollow noreferrer\">Weights and Biases</a> framework that seems to nail the job. It's a more comprehensive solution, and they've got a nicer dashboard.</p>\n",
                    "OwnerUserId": "5989906",
                    "LastActivityDate": "2020-11-22T13:16:04.263",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "65054229",
                "ParentRepo": "https://github.com/oprypin/mkdocs-section-index",
                "StackOverflow_Post": {
                    "Id": "65054229",
                    "PostTypeId": "2",
                    "ParentId": "54596774",
                    "CreationDate": "2020-11-28T20:39:01.090",
                    "Score": "1",
                    "Body": "<p>I have implemented a plugin for this functionality, &quot;<strong><a href=\"https://github.com/oprypin/mkdocs-section-index\" rel=\"nofollow noreferrer\">mkdocs-section-index</a></strong>&quot;, and it works similarly to <a href=\"https://stackoverflow.com/a/54598748\">what @Waylan describes</a> -- or actually more similar to <a href=\"https://github.com/mkdocs/mkdocs/pull/1042\" rel=\"nofollow noreferrer\">the dropped pull request #1042</a>, because most of the logic is <em>outside</em> of the theme/template. The special sections with a link are explicitly put into the nav and presented as such to the theme, so it doesn't need to find and exclude this &quot;first child&quot; itself.</p>\n<p><em>mkdocs.yml</em>:</p>\n<pre class=\"lang-yaml prettyprint-override\"><code>plugins:\n  - section-index\nnav:\n  - Frob: index.md\n  - Baz: baz.md\n  - Borgs:\n    - borgs/index.md\n    - Bar: borgs/bar.md\n    - Foo: borgs/foo.md\n</code></pre>\n<p>That gives you a nav like this:</p>\n<blockquote>\n<ul>\n<li><a href=\"https://example.org/index.html\" rel=\"nofollow noreferrer\">Frob</a></li>\n<li><a href=\"https://example.org/baz.html\" rel=\"nofollow noreferrer\">Baz</a></li>\n<li><a href=\"https://example.org/borgs/index.html\" rel=\"nofollow noreferrer\">Borgs</a>\n<ul>\n<li><a href=\"https://example.org/borgs/bar.html\" rel=\"nofollow noreferrer\">Bar</a></li>\n<li><a href=\"https://example.org/borgs/foo.html\" rel=\"nofollow noreferrer\">Foo</a></li>\n</ul>\n</li>\n</ul>\n</blockquote>\n<p>It makes sense to me that this functionality couldn't be included by default, but a plugin as a way to opt in seems perfectly fine.</p>\n",
                    "OwnerUserId": "241039",
                    "LastActivityDate": "2020-11-28T20:39:01.090",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "65100564",
                "ParentRepo": "https://github.com/smallrye/smallrye-config/blob/master/sources/yaml/src/test/java/io/smallrye/config/source/yaml/YamlConfigSourceTest.java#L141-L153",
                "StackOverflow_Post": {
                    "Id": "65100564",
                    "PostTypeId": "2",
                    "ParentId": "65094647",
                    "CreationDate": "2020-12-02T00:30:46.767",
                    "Score": "0",
                    "Body": "<p>You need to provide a Config Converter class that can read the configuration value and convert it to your object.</p>\n<p>Please check here for an example:\n<a href=\"https://github.com/smallrye/smallrye-config/blob/master/sources/yaml/src/test/java/io/smallrye/config/source/yaml/YamlConfigSourceTest.java#L141-L153\" rel=\"nofollow noreferrer\">https://github.com/smallrye/smallrye-config/blob/master/sources/yaml/src/test/java/io/smallrye/config/source/yaml/YamlConfigSourceTest.java#L141-L153</a></p>\n<p>And how to use Converters:\n<a href=\"https://quarkus.io/guides/config#custom-configuration-converters\" rel=\"nofollow noreferrer\">https://quarkus.io/guides/config#custom-configuration-converters</a></p>\n",
                    "OwnerUserId": "1757919",
                    "LastActivityDate": "2020-12-02T00:30:46.767",
                    "CommentCount": "4",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "65361940",
                "ParentRepo": "https://github.com/carla-simulator/scenario_runner/blob/master/srunner/examples/catalogs/EnvironmentCatalog.xosc",
                "StackOverflow_Post": {
                    "Id": "65361940",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "65362406",
                    "CreationDate": "2020-12-18T18:09:51.407",
                    "Score": "2",
                    "ViewCount": "197",
                    "Body": "<p>I would like to copy a list of files from a given directory in a repository <em>A</em> to repository <em>B</em> with its commit history.</p>\n<p>The internet is full with solutions for copying a full directory with all its content:\n<a href=\"https://stackoverflow.com/questions/44777043/git-copy-history-of-file-from-one-repository-to-another\">Git: Copy history of file from one repository to another</a>\nor\n<a href=\"https://mattsch.com/2015/06/19/move-directory-from-one-repository-to-another-preserving-history/\" rel=\"nofollow noreferrer\">https://mattsch.com/2015/06/19/move-directory-from-one-repository-to-another-preserving-history/</a></p>\n<p>Those solution assumed I would like to copy all files in a subdirectory, which is not my case. I would like to copy a subset of files from a directory with its commit history from one repository to another.</p>\n<p>For example:\nI would like to copy <a href=\"https://github.com/carla-simulator/scenario_runner/blob/master/srunner/examples/catalogs/EnvironmentCatalog.xosc\" rel=\"nofollow noreferrer\">https://github.com/carla-simulator/scenario_runner/blob/master/srunner/examples/catalogs/EnvironmentCatalog.xosc</a> to another repository <em>B</em> and to place it there at root (<code>./</code>).</p>\n<p>The suggested solution from @jingx solved almost this problem.</p>\n<p>Using</p>\n<pre><code>git am &lt;the-patch-files&gt;\n</code></pre>\n<p>the file will be placed in repository <em>B</em> at <code>B/examples/catalogs/EnvironmentCatalog.xosc</code> instead of <code>B/EnvironmentCatalog.xosc</code></p>\n<p>After moving the files to the &quot;right&quot; place, an additional commit is needed due to this directory change.</p>\n<p>Unfortunately I was unable to do this using this method above.</p>\n<p>How can I solve this problem?</p>\n",
                    "OwnerUserId": "230270",
                    "LastEditorUserId": "230270",
                    "LastEditDate": "2020-12-20T08:36:31.317",
                    "LastActivityDate": "2020-12-20T22:18:44.287",
                    "Title": "Copy a file from one repository to another with its history",
                    "Tags": "<git>",
                    "AnswerCount": "1",
                    "CommentCount": "3",
                    "FavoriteCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "65491442",
                "ParentRepo": "https://github.com/laurentS/slowapi",
                "StackOverflow_Post": {
                    "Id": "65491442",
                    "PostTypeId": "2",
                    "ParentId": "65491184",
                    "CreationDate": "2020-12-29T11:31:42.747",
                    "Score": "25",
                    "Body": "<p>Best option is using a library since FastAPI does not provide this functionality out-of-box.</p>\n<p><a href=\"https://github.com/laurentS/slowapi\" rel=\"noreferrer\">slowapi</a> is great, and easy to use.</p>\n<p>You can use ut like this.</p>\n<pre><code>from fastapi import FastAPI\nfrom slowapi.errors import RateLimitExceeded\nfrom slowapi import Limiter, _rate_limit_exceeded_handler\nfrom slowapi.util import get_remote_address\n\n\nlimiter = Limiter(key_func=get_remote_address)\napp = FastAPI()\napp.state.limiter = limiter\napp.add_exception_handler(RateLimitExceeded, _rate_limit_exceeded_handler)\n\n@app.get(&quot;/home&quot;)\n@limiter.limit(&quot;5/minute&quot;)\nasync def homepage(request: Request):\n    return PlainTextResponse(&quot;test&quot;)\n\n@app.get(&quot;/mars&quot;)\n@limiter.limit(&quot;5/minute&quot;)\nasync def homepage(request: Request, response: Response):\n    return {&quot;key&quot;: &quot;value&quot;}\n</code></pre>\n",
                    "OwnerUserId": "13161155",
                    "LastEditorUserId": "13161155",
                    "LastEditDate": "2022-04-09T11:56:56.427",
                    "LastActivityDate": "2022-04-09T11:56:56.427",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "65641751",
                "ParentRepo": "https://github.com/kubernetes-sigs/service-apis",
                "StackOverflow_Post": {
                    "Id": "65641751",
                    "PostTypeId": "2",
                    "ParentId": "65598713",
                    "CreationDate": "2021-01-09T10:48:36.983",
                    "Score": "0",
                    "Body": "<p>Perhaps you should consider implementing <a href=\"https://github.com/kubernetes-sigs/service-apis\" rel=\"nofollow noreferrer\">Kubernetes Service APIs </a></p>\n",
                    "OwnerUserId": "1753098",
                    "LastActivityDate": "2021-01-09T10:48:36.983",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "65745304",
                "ParentRepo": "https://github.com/Flank/flank",
                "StackOverflow_Post": {
                    "Id": "65745304",
                    "PostTypeId": "2",
                    "ParentId": "65711821",
                    "CreationDate": "2021-01-16T00:28:24.920",
                    "Score": "0",
                    "Body": "<p>The specific REST API you want to invoke is\n<a href=\"https://firebase.google.com/docs/test-lab/reference/testing/rest/v1/projects.testMatrices/create\" rel=\"nofollow noreferrer\">https://firebase.google.com/docs/test-lab/reference/testing/rest/v1/projects.testMatrices/create</a>.</p>\n<p>You can use the &quot;Try it!&quot; button to play with the API and see the http request body and response.</p>\n<p>Google publishes client libraries for many specific APIs in several languages. I have not used this specific library, but here's the link to the client library that should be usable for .NET development:\n<a href=\"https://developers.google.com/api-client-library/dotnet/apis/testing/v1\" rel=\"nofollow noreferrer\">https://developers.google.com/api-client-library/dotnet/apis/testing/v1</a></p>\n<p>It is a somewhat complex API. You might want to study the Cloud SDK (gcloud) Python source code for ideas on how to use it. But that would require you to install the Cloud SDK first, which you say you cannot do.</p>\n<p>You could also study the <a href=\"https://github.com/Flank/flank\" rel=\"nofollow noreferrer\">Flank</a> kotlin code for examples of how to use the Cloud Testing API (and also the Cloud Tool Results API).</p>\n",
                    "OwnerUserId": "8297396",
                    "LastActivityDate": "2021-01-16T00:28:24.920",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "65831813",
                "ParentRepo": "https://github.com/FIWARE/data-models/blob/master/tools/normalized2LD.py",
                "StackOverflow_Post": {
                    "Id": "65831813",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "65835685",
                    "CreationDate": "2021-01-21T16:37:06.113",
                    "Score": "2",
                    "ViewCount": "213",
                    "Body": "<p>I already found <a href=\"https://github.com/FIWARE/data-models/blob/master/tools/normalized2LD.py\" rel=\"nofollow noreferrer\">this script</a>  by the FIWARE-Community, which converts an NGSI-v2 normalized representation into an NGSI-LD representation.</p>\n<p>Is there something similar for the opposite direction? I am aware that most of the steps can be done backwards. However, I am not sure about the usual procedure for converting back the <code>&quot;type&quot;: &quot;Property&quot;</code> nodes.</p>\n<p>E.g given an NGSI-v2 entity representation:</p>\n<pre><code>{\n    &quot;id&quot;: &quot;Store:001&quot;,\n    &quot;type&quot;: &quot;Store&quot;,\n    &quot;name&quot;: {\n        &quot;type&quot;: &quot;Text&quot;,\n        &quot;value&quot;: &quot;Checkpoint Markt&quot;\n    }\n}\n</code></pre>\n<p>Running the script on this will lead to:</p>\n<pre><code>{\n    &quot;@context&quot;: [\n        https://uri.etsi.org/ngsi-ld/v1/ngsi-ld-core-context.jsonld&quot;\n    ],\n    &quot;id&quot;: &quot;urn:ngsi-ld:Store:Store:001&quot;,\n    &quot;type&quot;: &quot;Store&quot;,\n    &quot;name&quot;: {\n        &quot;type&quot;: &quot;Property,\n        &quot;value&quot;: &quot;Checkpoint Markt&quot;\n    }\n}\n</code></pre>\n<p>So in this case it is quite difficult to convert the <code>&quot;type&quot;: &quot;Property&quot;</code> node back to <code>&quot;type&quot;: &quot;Text&quot;</code>.</p>\n<p>But given the following NGSI-v2 entity representation:</p>\n<pre><code>{\n    &quot;type&quot;: &quot;Store&quot;,\n    &quot;id&quot;: &quot;Store:002&quot;,\n    &quot;address&quot;: {\n        &quot;type&quot;: &quot;PostalAddress&quot;,\n        &quot;value&quot;: {\n            &quot;streetAddress&quot;: &quot;Friedrichstra\u00dfe 44&quot;,\n            &quot;addressRegion&quot;: &quot;Berlin&quot;,\n            &quot;addressLocality&quot;: &quot;Kreuzberg&quot;,\n            &quot;postalCode&quot;: &quot;10969&quot;\n        }\n    }\n}\n</code></pre>\n<p>will be converted to:</p>\n<pre><code>{\n    &quot;@context&quot;: [\n        https://uri.etsi.org/ngsi-ld/v1/ngsi-ld-core-context.jsonld&quot;\n    ],\n    &quot;id&quot;: &quot;urn:ngsi-ld:Store:Store:002&quot;,\n    &quot;type&quot;: &quot;Store&quot;,\n    &quot;address&quot;: {\n        &quot;type&quot;: &quot;Property&quot;,\n        &quot;value&quot;: {\n            &quot;streetAddress&quot;: &quot;Friedrichstra\\u00dfe 44&quot;,\n            &quot;addressRegion&quot;: &quot;Berlin&quot;,\n            &quot;addressLocality&quot;: &quot;Kreuzberg&quot;,\n            &quot;postalCode&quot;: &quot;10969&quot;,\n            &quot;type&quot;: &quot;PostalAddress&quot;\n        }\n    }\n}\n</code></pre>\n<p>This is caused by a special case in the script:</p>\n<pre class=\"lang-py prettyprint-override\"><code>if attr['type'] == 'PostalAddress':\n    ld_attr['value']['type'] = 'PostalAddress'\n</code></pre>\n<p>Wouldn't it be possible to extend all converted attributes with such a <code>&quot;type&quot;: _</code>-pair in their value? Or is there a reason that this is restricted in the code to the type &quot;PostalAddress&quot; only? Otherwise, is there any norm for converting back these <code>&quot;type&quot;: &quot;Property&quot;</code> nodes?</p>\n",
                    "OwnerUserId": "15045756",
                    "LastActivityDate": "2021-01-24T15:21:38.620",
                    "Title": "Is there a standardized way to migrate FIWARE NGSI-LD entity representations to NGSI-v2?",
                    "Tags": "<fiware-orion>",
                    "AnswerCount": "2",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "65896708",
                "ParentRepo": "https://github.com/jspsych/jsPsych/blob/master/docs/plugins/jspsych-canvas-slider-response.md",
                "StackOverflow_Post": {
                    "Id": "65896708",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "65964523",
                    "CreationDate": "2021-01-26T06:18:36.277",
                    "Score": "1",
                    "ViewCount": "201",
                    "Body": "<p>I want to combine canvas-slider-response <a href=\"https://github.com/jspsych/jsPsych/blob/master/docs/plugins/jspsych-canvas-slider-response.md\" rel=\"nofollow noreferrer\">plugin</a> and RDK <a href=\"http:////https://www.jspsych.org/plugins/jspsych-rdk/\" rel=\"nofollow noreferrer\">plugin</a> to create response trial where observers change the coherence of the motion field using the slider.</p>\n<p>The RDK plugin creates a canvas element and append it to the DOM to draw dots on the canvas. Because I want the slider function, inside of the RDK plugin, I added HTML element:</p>\n<pre><code>var html = '&lt;div id=&quot;jspsych-canvas-slider-response-wrapper&quot; style=&quot;margin: 100px 0px;&quot;&gt;';\nhtml += '&lt;div id=&quot;jspsych-canvas-slider-response-stimulus&quot;&gt;' + '&lt;canvas id=&quot;jspsych-canvas-stimulus&quot; height=&quot;' + trial.canvas_size[0] + '&quot; width=&quot;' + trial.canvas_size[1] + '&quot;&gt;&lt;/canvas&gt;' + '&lt;/div&gt;';\nhtml += '&lt;div class=&quot;jspsych-canvas-slider-response-container&quot; style=&quot;position:relative; margin: 0 auto 3em auto; width:';\n</code></pre>\n<p>And then add that html variable to the html element with this method:</p>\n<pre><code>display_element.innerHTML = html;\n</code></pre>\n<p>Naturally, this overwrites on the canvas, shows the HTML element, but now the dots are gone (canvas is overwritten?).</p>\n<p>I am somewhat aware that rendering HTML into a canvas is severely limited for security reasons. So tried some emulations:</p>\n<p>1- I can render html element using creating SVG images:\n<a href=\"https://stackoverflow.com/questions/12652769/rendering-html-elements-to-canvas\">Rendering HTML elements to &lt;canvas&gt;</a>. But then I can't interact with the images using the methods such as <code>display_element.querySelector('#jspsych-canvas-slider-response-next').addEventListener('click', function () {}</code></p>\n<p>2- I can also insertAdjacentHTML but with this method, the canvas element appears after the RDK element shows up at the screen - not together.\n<a href=\"https://stackoverflow.com/questions/10309650/add-elements-to-the-dom-given-plain-text-html-using-only-pure-javascript-no-jqu/12042778#12042778\">Add elements to the DOM given plain text HTML using only pure JavaScript (no jQuery)</a>.</p>\n<p>3- I figured an HTML renderer in JsPsych could solve my problem here. So I tried including the RDK as a stimulus function to the canvas-slider-response, but I can't find a way to call the function within the RDK plugin object. This is what I was trying to achieve:</p>\n<pre><code>var slider_trial = {\n    type: 'canvas-slider-response',\n    stimulus: function(c) {\n        **callRDKPlugin(c);** ////// Something here /////\n    },\n    labels: ['Exactly&lt;br&gt;the same','Totally&lt;br&gt;different'],\n    canvas_size: [200, 500],\n    prompt: '&lt;p&gt;How different would you say the colors of these two squares are?&lt;/p&gt;',\n    on_finish: function(data) {\n        data.color1 = colors[0];\n        data.color2 = colors[1];\n    }\n};\n</code></pre>\n<p>Am I missing an easy step?</p>\n<p>This is the desired image:</p>\n<p><a href=\"https://i.stack.imgur.com/hmTBR.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/hmTBR.png\" alt=\"This is the desired image\" /></a></p>\n",
                    "OwnerUserId": "5694288",
                    "LastEditorUserId": "5694288",
                    "LastEditDate": "2021-01-30T04:17:31.457",
                    "LastActivityDate": "2021-01-30T04:17:31.457",
                    "Title": "including raw HTML node to canvas element",
                    "Tags": "<javascript><html><canvas><jspsych>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "65979056",
                "ParentRepo": "https://github.com/maiot-io/zenml/t",
                "StackOverflow_Post": {
                    "Id": "65979056",
                    "PostTypeId": "2",
                    "ParentId": "65525944",
                    "CreationDate": "2021-01-31T12:24:54.603",
                    "Score": "3",
                    "Body": "<p>(Copied from the related issue for greater visibility)</p>\n<p>After some digging, here is an alternative approach, which assumes no knowledge of the <code>feature_spec</code> before-hand.  Do the following:</p>\n<ul>\n<li>Set the <code>BulkInferrer</code> to write to <code>output_examples</code> rather than <code>inference_result</code> by adding a <a href=\"https://github.com/tensorflow/tfx/blob/3aeb6d1b19f1b6a8090f8cda22b45bb81aafdd1a/tfx/proto/bulk_inferrer.proto#L43\" rel=\"nofollow noreferrer\">output_example_spec</a> to the component construction.</li>\n<li>Add a  <code>StatisticsGen</code> and a <code>SchemaGen</code> component in the main pipeline right after the <code>BulkInferrer</code> to generate a schema for the aforementioned <code>output_examples</code></li>\n<li>Use the artifacts from <code>SchemaGen</code> and <code>BulkInferrer</code> to read the TFRecords and do whatever is neccessary.</li>\n</ul>\n<pre class=\"lang-py prettyprint-override\"><code>bulk_inferrer = BulkInferrer(\n     ....\n     output_example_spec=bulk_inferrer_pb2.OutputExampleSpec(\n         output_columns_spec=[bulk_inferrer_pb2.OutputColumnsSpec(\n             predict_output=bulk_inferrer_pb2.PredictOutput(\n                 output_columns=[bulk_inferrer_pb2.PredictOutputCol(\n                     output_key='original_label_name',\n                     output_column='output_label_column_name', )]))]\n     ))\n\n statistics = StatisticsGen(\n     examples=bulk_inferrer.outputs.output_examples\n )\n\n schema = SchemaGen(\n     statistics=statistics.outputs.output,\n )\n</code></pre>\n<p>After that, one can do the following:</p>\n<pre class=\"lang-py prettyprint-override\"><code>import tensorflow as tf\nfrom tfx.utils import io_utils\nfrom tensorflow_transform.tf_metadata import schema_utils\n\n# read schema from SchemaGen\nschema_path = '/path/to/schemagen/schema.pbtxt'\nschema_proto = io_utils.SchemaReader().read(schema_path)\nspec = schema_utils.schema_as_feature_spec(schema_proto).feature_spec\n\n# read inferred results\ndata_files = ['/path/to/bulkinferrer/output_examples/examples/examples-00000-of-00001.gz']\ndataset = tf.data.TFRecordDataset(data_files, compression_type='GZIP')\n\n# parse dataset with spec\ndef parse(raw_record):\n    return tf.io.parse_example(raw_record, spec)\n\ndataset = dataset.map(parse)\n</code></pre>\n<p>At this point, the dataset is like any other parsed dataset, so its trivial to write a CSV, or to a BigQuery table or whatever from there. It certainly helped us in <a href=\"https://github.com/maiot-io/zenml/t\" rel=\"nofollow noreferrer\">ZenML</a> with our <a href=\"https://github.com/maiot-io/zenml/blob/newpipelines/zenml/core/pipelines/infer_pipeline.py#L150\" rel=\"nofollow noreferrer\">BatchInferencePipeline</a>.</p>\n",
                    "OwnerUserId": "1561232",
                    "LastActivityDate": "2021-01-31T12:24:54.603",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "65981900",
                "ParentRepo": "https://github.com/apache/iceberg/issues/1078#issuecomment-638198029",
                "StackOverflow_Post": {
                    "Id": "65981900",
                    "PostTypeId": "2",
                    "ParentId": "65647574",
                    "CreationDate": "2021-01-31T17:06:10.073",
                    "Score": "2",
                    "Body": "<p>Probably (didn't test it), before writing a Spark DataFrame to HBase/BigTable you can transform it by filtering out columns with null values in each row using custom function, as suggested here for an example using pandas : <a href=\"https://stackoverflow.com/a/59641595/3227693\">https://stackoverflow.com/a/59641595/3227693</a>. However there is no built-in connector supporting this feature to my best knowledge.</p>\n<p>Alternatively, you can try store data in columnar file formats like Parquet instead, because they are <a href=\"https://github.com/apache/iceberg/issues/1078#issuecomment-638198029\" rel=\"nofollow noreferrer\">efficiently handle persistence of sparse columnar data</a> (at least in terms of output size in bytes). But to avoid writing many small files (due to sparse nature of the data) which can decrease write throughput, you probably will need to decrease number of output partitions before performing a write (i.e. write more rows per each parquet file: <a href=\"https://stackoverflow.com/questions/44808415/spark-parquet-partitioning-large-number-of-files\">Spark parquet partitioning : Large number of files</a>)</p>\n",
                    "OwnerUserId": "3227693",
                    "LastEditorUserId": "14524588",
                    "LastEditDate": "2021-02-02T19:13:04.143",
                    "LastActivityDate": "2021-02-02T19:13:04.143",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "66010368",
                "ParentRepo": "https://github.com/k0sproject/k0s/issues/665",
                "StackOverflow_Post": {
                    "Id": "66010368",
                    "PostTypeId": "2",
                    "ParentId": "65938104",
                    "CreationDate": "2021-02-02T13:05:58.487",
                    "Score": "1",
                    "Body": "<p>Workaround is to just remove the file.</p>\n<p><code>/var/lib/k0s/run/konnectivity-server/konnectivity-server.sock</code> and restart the server.</p>\n<p>Currenlty my github issue is still open.</p>\n<p><a href=\"https://github.com/k0sproject/k0s/issues/665\" rel=\"nofollow noreferrer\">https://github.com/k0sproject/k0s/issues/665</a></p>\n",
                    "OwnerUserId": "2948238",
                    "LastActivityDate": "2021-02-02T13:05:58.487",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "66054042",
                "ParentRepo": "https://github.com/rwightman/pytorch-image-models/blob/master/timm/models/vision_transformer.py#L309",
                "StackOverflow_Post": {
                    "Id": "66054042",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "66590833",
                    "CreationDate": "2021-02-04T21:26:43.203",
                    "Score": "0",
                    "ViewCount": "417",
                    "Body": "<p>I'm looking at the <code>timm</code> implementation of visual transformers and for the positional embedding, he is initializing his position embedding with zeros as follows:</p>\n<pre><code>self.pos_embed = nn.Parameter(torch.zeros(1, num_patches + 1, embed_dim))\n</code></pre>\n<p>See here:\n<a href=\"https://github.com/rwightman/pytorch-image-models/blob/master/timm/models/vision_transformer.py#L309\" rel=\"nofollow noreferrer\">https://github.com/rwightman/pytorch-image-models/blob/master/timm/models/vision_transformer.py#L309</a></p>\n<p>I'm not sure how this actually embeds anything about the position when it is later added to the patch?</p>\n<pre><code>x = x + self.pos_embed\n</code></pre>\n<p>Any feedback is appreciated.</p>\n",
                    "OwnerUserId": "1116654",
                    "LastEditorUserId": "7579547",
                    "LastEditDate": "2021-03-12T07:28:10.717",
                    "LastActivityDate": "2021-03-12T07:28:10.717",
                    "Title": "Why is the timm visual transformer position embedding initializing to zeros?",
                    "Tags": "<pytorch><vision><transformer-model>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "FavoriteCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "66062832",
                "ParentRepo": "https://github.com/HofmeisterAn/dotnet-testcontainers",
                "StackOverflow_Post": {
                    "Id": "66062832",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "66079165",
                    "CreationDate": "2021-02-05T11:55:07.200",
                    "Score": "1",
                    "ViewCount": "296",
                    "Body": "<p>I am trying to add keycloak as a testcontainer to my .net core (5) integration tests using the <a href=\"https://github.com/HofmeisterAn/dotnet-testcontainers\" rel=\"nofollow noreferrer\">dotnet-testcontainers</a> library .</p>\n<p>My Problem is, I am struggling with HTTPS-Support having a container using self-signed certificates and <a href=\"https://learn.microsoft.com/en-us/dotnet/api/microsoft.aspnetcore.testhost.testserver?view=aspnetcore-5.0\" rel=\"nofollow noreferrer\">TestServer</a>-Class for my integration tests.</p>\n<p>To be precise, I am using Microsofts TestServer class to create real API requests with an in-memory config for using a keycloak-testcontainer with exposed port 8443 and its self-signed certificate.</p>\n<p>The Problem is: I can\u2019t add a <code>HttpClientHandler</code> to TestServers HttpClient(created via <code>serverCreateClient()</code>) to allow non-trusted certs within this handler. I have created a concrete example <a href=\"https://github.com/Pinguwien/TestContainersNetCoreExample/tree/apitests-https\" rel=\"nofollow noreferrer\">here</a> on branch apitests-https. The failing test can be found <a href=\"https://github.com/Pinguwien/TestContainersNetCoreExample/blob/apitests-https/DemoAppTests/Api/ArticlesControllerTest.cs\" rel=\"nofollow noreferrer\">here</a>, its in the <code>SucceedsWhenGetRequestWithTokenReturnsListOfArticles</code>test method. I added some Comments to the class and the Startup.cs of DemoApi - Project that shows what i've tried.</p>\n<p>As a result, the TestServers internal Jwt Middleware uses the default HttpClient and throws the following AuthenticationException:</p>\n<pre><code> ---&gt; System.IO.IOException: IDX20804: Unable to retrieve document from: 'System.String'.\n ---&gt; System.Net.Http.HttpRequestException: The SSL connection could not be established, see inner exception.\n ---&gt; System.Security.Authentication.AuthenticationException: The remote certificate is invalid according to the validation procedure: RemoteCertificateNameMismatch, RemoteCertificateChainErrors\n   at System.Net.Security.SslStream.SendAuthResetSignal(ProtocolToken message, ExceptionDispatchInfo exception)\n   at System.Net.Security.SslStream.ForceAuthenticationAsync[TIOAdapter](TIOAdapter adapter, Boolean receiveFirst, Byte[] reAuthenticationData, Boolean isApm)\n   at System.Net.Http.ConnectHelper.EstablishSslConnectionAsyncCore(Boolean async, Stream stream, SslClientAuthenticationOptions sslOptions, CancellationToken cancellationToken)\n   --- End of inner exception stack trace ---\n</code></pre>\n<p>I already tried multiple things to make it work which are commented in the code.</p>\n<ul>\n<li><p><code>DemoApi/Startup.cs</code>: Tried to add my own &quot;Testing&quot; Environment with following Code:</p>\n<p>ServicePointManager.Expect100Continue = true;\nServicePointManager.SecurityProtocol = SecurityProtocolType.Tls\n| SecurityProtocolType.Tls11\n| SecurityProtocolType.Tls12;\nServicePointManager.ServerCertificateValidationCallback +=\n(sender, certificate, chain, sslPolicyErrors) =&gt; true;</p>\n</li>\n</ul>\n<p>using it via <code>UseEnvironment(&quot;Testing&quot;)</code> when creating the TestServer-Instance in the Api Test. Debugging shows the code is called, but still the exception occurs.</p>\n<ul>\n<li><code>DemoApiTestsApi/BaseFixture.cs</code> or <code>DemoApiTests/Infrastructure/Persistence/KeycloakTest.cs</code>: See here for a working Implementation of my own HttpClient with handler to obtain the token in general (this works in the branch) - <code>GetTestToken</code> is the method in BaseFixture.</li>\n</ul>\n<p>So, honestly I am a bit out of ideas on how to make this work with TestServer or otherwise. Essentially, I need the handler I use in <code>BaseFixture.GetTestToken()</code>/<code>KeycloakTest.cs</code> to be also used within my TestServer instance, but can't apply it in the <code>CreateClient()</code> which does not accept parameters. Any help is highly appreciated, may it be a solution or a hint to another way to solve this. TestServer is not necessarily fixed when there's another way to work this out.</p>\n",
                    "OwnerUserId": "1341599",
                    "LastEditorUserId": "1341599",
                    "LastEditDate": "2021-02-05T14:48:48.100",
                    "LastActivityDate": "2021-02-06T16:26:42.863",
                    "Title": "Calling thirdparty container with .net core TestHost/TestServer via SSL: Bypass SSL Validation using Testservers CreateClient() method",
                    "Tags": "<.net-core><https><.net-5><testcontainers><testserver>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "66142327",
                "ParentRepo": "https://github.com/DanielBok/copulae",
                "StackOverflow_Post": {
                    "Id": "66142327",
                    "PostTypeId": "1",
                    "CreationDate": "2021-02-10T17:51:38.333",
                    "Score": "1",
                    "ViewCount": "110",
                    "Body": "<p>I'm using Copulae package, following the example of <a href=\"https://github.com/DanielBok/copulae\" rel=\"nofollow noreferrer\">https://github.com/DanielBok/copulae</a>.\nMy understanding is that the simulated values should have similar distribution as the input ones.</p>\n<p>I would like to see the output dataframe of the fit (that is: the simulated data), and check its distribution. However, &quot;fitted&quot; produced below is not an array or df that I can open.\nHow can I extract the fitted data?</p>\n<pre><code>from copulae import NormalCopula\nimport numpy as np\n\nnp.random.seed(8)\ndata = np.random.normal(size=(300, 8))\nplt.hist(data[:,1],    bins=100) #checking input data histogram\ncop = NormalCopula(8)\ncop.fit(data)  #fitting data with copula\nfitted=cop.fit(data)\n</code></pre>\n",
                    "OwnerUserId": "11551502",
                    "LastEditorUserId": "11551502",
                    "LastEditDate": "2021-02-10T17:54:08.070",
                    "LastActivityDate": "2021-02-10T17:54:08.070",
                    "Title": "how to use Copulae in Python",
                    "Tags": "<python><distribution><data-augmentation>",
                    "AnswerCount": "0",
                    "CommentCount": "3",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "66186734",
                "ParentRepo": "https://github.com/mljar/mercury",
                "StackOverflow_Post": {
                    "Id": "66186734",
                    "PostTypeId": "5",
                    "CreationDate": "2021-02-13T15:24:59.470",
                    "Score": "0",
                    "Body": "<ul>\n<li>The MLJAR website: <a href=\"https://mljar.com\" rel=\"nofollow noreferrer\">https://mljar.com</a></li>\n<li>Mercury <a href=\"https://github.com/mljar/mercury\" rel=\"nofollow noreferrer\">https://github.com/mljar/mercury</a></li>\n<li>MLJAR AutoML <a href=\"https://github.com/mljar/mljar-supervised\" rel=\"nofollow noreferrer\">https://github.com/mljar/mljar-supervised</a>.</li>\n</ul>\n",
                    "OwnerUserId": "5605919",
                    "LastEditorUserId": "5605919",
                    "LastEditDate": "2022-07-12T19:28:41.237",
                    "LastActivityDate": "2022-07-12T19:28:41.237",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "66205631",
                "ParentRepo": "https://github.com/TheHive-Project/Cortex-Analyzers/blob/master/analyzers/EmlParser/parse.py#L47",
                "StackOverflow_Post": {
                    "Id": "66205631",
                    "PostTypeId": "2",
                    "ParentId": "61109662",
                    "CreationDate": "2021-02-15T09:36:21.223",
                    "Score": "0",
                    "Body": "<p>you need implement the <code>artifacts</code> method to returns an array that defined those observables. you can use the <code>build_artifact</code> utility method from the <code>Analyzer</code> class.</p>\n<p>Take a look at: <a href=\"https://github.com/TheHive-Project/Cortex-Analyzers/blob/master/analyzers/EmlParser/parse.py#L47\" rel=\"nofollow noreferrer\">https://github.com/TheHive-Project/Cortex-Analyzers/blob/master/analyzers/EmlParser/parse.py#L47</a></p>\n",
                    "OwnerUserId": "881447",
                    "LastEditorUserId": "1839439",
                    "LastEditDate": "2021-02-15T09:42:01.130",
                    "LastActivityDate": "2021-02-15T09:42:01.130",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "66209800",
                "ParentRepo": "https://github.com/traefik/mesh",
                "StackOverflow_Post": {
                    "Id": "66209800",
                    "PostTypeId": "1",
                    "CreationDate": "2021-02-15T14:25:20.660",
                    "Score": "2",
                    "ViewCount": "481",
                    "Body": "<p><img src=\"https://i.stack.imgur.com/RSix2.png\" alt=\"enter image description here\" /></p>\n<p>I'm working on the Canary Deployment Strategy.\nI use the <a href=\"https://argoproj.github.io/argo-rollouts/features/traffic-management/smi/\" rel=\"nofollow noreferrer\">Service Mesh Interface</a>, after installing <a href=\"https://github.com/traefik/mesh\" rel=\"nofollow noreferrer\">trafik mesh</a>.\nWhen starting the program for the first time with the command</p>\n<pre><code>kubectl apply -f applications.yaml\n</code></pre>\n<p>It should deploy the entire application i.e. 4 replicas, but it deploys only 20% (1 replica) of the application,\nand it goes into progressing state with an error:</p>\n<blockquote>\n<p><code>TrafficRoutingErro: the server could not find the requested resource (post trafficsplits.splits.smi-spec.io)</code>\n<code>TrafficSplitNotCreated: Unable to create traffic Split 'demo-traefficsplit'</code></p>\n</blockquote>\n<p>Here is my manifest:</p>\n<p><code>argocd-rollout.yaml</code></p>\n<p><div class=\"snippet\" data-lang=\"js\" data-hide=\"false\" data-console=\"true\" data-babel=\"false\">\r\n<div class=\"snippet-code\">\r\n<pre class=\"snippet-code-html lang-html prettyprint-override\"><code>---\napiVersion: argoproj.io/v1alpha1\nkind: Rollout\nmetadata:\n  name: demo\n  labels:\n    app: demo\nspec:\n  strategy:\n    canary:\n      steps:\n      - setWeight: 20\n      - pause:\n          duration: \"1m\"\n      - setWeight: 50\n      - pause:\n          duration: \"2m\"\n      canaryService: demo-canary\n      stableService: demo\n\n      trafficRouting:\n        smi:\n          rootService: demo-smi\n          trafficSplitName: demo-trafficsplit\n\n  replicas: 4\n  revisionHistoryLimit: 2\n  selector:\n    matchLabels:\n      app: demo\n      version: blue\n  template:\n    metadata:\n      labels:\n        app: demo\n        version: blue\n    spec:\n      containers:\n      - name: demo\n        image: argoproj/rollouts-demo:blue\n        imagePullPolicy: Always\n        ports:\n        - name: web\n          containerPort: 8080\n        resources:\n          requests:\n            memory: \"64Mi\"\n            cpu: \"100m\"\n          limits:\n            memory: \"128Mi\"\n            cpu: \"140m\"\n\n---\napiVersion: split.smi-spec.io/v1alpha3\nkind: TrafficSplit\nmetadata:\n  name: demo-trafficsplit\nspec:\n  service: demo-smi # controller uses the stableService if Rollout does not specify the rootService field\n  backends:\n  - service: demo\n    weight: 10\n  - service: demo-canary\n    weight: 90\n\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: demo-smi\nspec:\n  ports:\n  - port: 80\n    targetPort: 8080\n  selector:\n    app: demo\n    version: blue\n  type: ClusterIP\n\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: demo\nspec:\n  ports:\n  - port: 80\n    targetPort: 8080\n  selector:\n    app: demo\n    version: blue\n  type: ClusterIP\n\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: demo-canary\nspec:\n  ports:\n  - port: 80\n    targetPort: 8080\n  selector:\n    app: demo\n    version: blue\n  type: ClusterIP\n\n---\napiVersion: traefik.containo.us/v1alpha1\nkind: IngressRoute\nmetadata:\n  name: rollout-ing\nspec:\n  entryPoints:\n    - websecure\n  routes:\n    - kind: Rule\n      match: Host(`mycompagny.com`) \n      services:\n        - name: demo-smi\n          port: 80\n  tls:\n    certResolver: myresolver</code></pre>\r\n</div>\r\n</div>\r\n</p>\n<p><code>applications.yaml</code></p>\n<p><div class=\"snippet\" data-lang=\"js\" data-hide=\"false\" data-console=\"true\" data-babel=\"false\">\r\n<div class=\"snippet-code\">\r\n<pre class=\"snippet-code-html lang-html prettyprint-override\"><code>apiVersion: v1\nkind: Namespace\nmetadata:\n  name: net\n\n---\napiVersion: argoproj.io/v1alpha1\nkind: Application\nmetadata:\n  name: rollout\n  namespace: argocd\nspec:\n  project: default\n  source:\n    repoURL: git@github.com:telemaqueHQ/DevOps.git\n    targetRevision: master\n    path: gitOps/test/argocd\n  destination:\n    server: https://kubernetes.default.svc\n    namespace: net\n  syncPolicy:\n    automated:\n      prune: true\n      selfHeal: true</code></pre>\r\n</div>\r\n</div>\r\n</p>\n",
                    "OwnerUserId": "13259098",
                    "LastEditorUserId": "2452869",
                    "LastEditDate": "2021-02-19T00:19:35.227",
                    "LastActivityDate": "2021-02-19T00:19:35.227",
                    "Title": "Canary Deployment Strategy using Argocd rollout and Service Mesh Interface (Traefik Mesh)",
                    "Tags": "<traefik><canary-deployment><argocd><servicemesh>",
                    "AnswerCount": "0",
                    "CommentCount": "1",
                    "FavoriteCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "66305022",
                "ParentRepo": "https://github.com/ansible-community/ansible-lint/blob/schemas/src/ansiblelint/schemas/requirements.py",
                "StackOverflow_Post": {
                    "Id": "66305022",
                    "PostTypeId": "1",
                    "CreationDate": "2021-02-21T17:22:42.873",
                    "Score": "0",
                    "ViewCount": "190",
                    "Body": "<p>I am trying to write a schema that can be used to validate two different requirements formats, a v1 which used to be a list at root level and a newer one that is using a mapping:</p>\n<pre><code># requirements.yml v1\n- {}  # the mapping inside being a RoleModel\n...\n</code></pre>\n<pre><code># requirements.yml v2\nroles:\n  - {}  # the mapping inside being a RoleModel\n  ...\ncollections:\n  - {}  # the mapping inside being a CollectionModel\n  ...\n</code></pre>\n<p>I was able to generate different schemas for either of these versions but I have no idea how can I combine the two versions into a single schema.</p>\n<p>For practical reasons I cannot use different schemas as the filenames are the same and Ansible loads both, so there is no way to determine the schema before opening the file.</p>\n<p>For v2 fommat I do have an implementation at <a href=\"https://github.com/ansible-community/ansible-lint/blob/schemas/src/ansiblelint/schemas/requirements.py\" rel=\"nofollow noreferrer\">https://github.com/ansible-community/ansible-lint/blob/schemas/src/ansiblelint/schemas/requirements.py</a></p>\n<p>I did learn that in order to validate lists at root level, I need to do something like <a href=\"https://github.com/ansible-community/ansible-lint/blob/schemas/src/ansiblelint/schemas/playbook.py#L35\" rel=\"nofollow noreferrer\">https://github.com/ansible-community/ansible-lint/blob/schemas/src/ansiblelint/schemas/playbook.py#L35</a> :</p>\n<pre><code>top_level_schema = schema([RoleModel], title='Requiremetns v1 Schema')\n</code></pre>\n<p>How can I combine the two in a single schema, one that would cover both examples listed above?</p>\n",
                    "OwnerUserId": "99834",
                    "LastEditorUserId": "99834",
                    "LastEditDate": "2021-02-23T10:15:40.757",
                    "LastActivityDate": "2021-02-23T14:14:22.750",
                    "Title": "Generating a json schemas that validate both root lists and mappings using pydantic",
                    "Tags": "<python><jsonschema><pydantic>",
                    "AnswerCount": "1",
                    "CommentCount": "3",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "66362452",
                "ParentRepo": "https://github.com/yashaka/selene",
                "StackOverflow_Post": {
                    "Id": "66362452",
                    "PostTypeId": "2",
                    "ParentId": "66326655",
                    "CreationDate": "2021-02-25T04:34:40.833",
                    "Score": "0",
                    "Body": "<p>Take a screenshot and snapshot of the headless window when exception occurs. That will help you to find out why this happens. You can try to use selene library <a href=\"https://github.com/yashaka/selene\" rel=\"nofollow noreferrer\">https://github.com/yashaka/selene</a> which already have these features, or write your own snap-shooter.</p>\n<p>Depending on this quote</p>\n<blockquote>\n<p>I have seen other people mentioning that maximizing the window or\nsetting the window size of the headless driver will solve this, I have\nhad no luck with such solutions.</p>\n</blockquote>\n<p>you need to know, that maximizing in headless - doesn't work because it headless and doesn't know which screen size is to maximize.\nYou should take the dimensions of the browser in non-headless mode and set it up directly in selenium both for head and headless mode. This can solve your issue. And even if not - try to take screenshot or make a video to figure out what's going on in headless mode.</p>\n",
                    "OwnerUserId": "8091236",
                    "LastActivityDate": "2021-02-25T04:34:40.833",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "66431913",
                "ParentRepo": "https://github.com/DotBow/Blender-Launcher",
                "StackOverflow_Post": {
                    "Id": "66431913",
                    "PostTypeId": "2",
                    "ParentId": "66431098",
                    "CreationDate": "2021-03-02T01:14:35.477",
                    "Score": "1",
                    "Body": "<p>We run up against this kind of problem frequently, and realistically there's not a lot you can do about it. False positives are just a part of what we have to deal with, and the only way to deal with them for low-distribution items like personal remote administration tools - or my own common case, custom AV upgrade scripts - is to add exceptions for your own programs when you install them on a computer, and every time you update the code.</p>\n<blockquote>\n<p>It is as if Microsoft were banning the use of an API that it provides.</p>\n</blockquote>\n<p>Unfortunately malware uses those same APIs. AV vendors are constantly upgrading their definitions to catch as many threats as possible and common techniques used by malware are also present in remote administration tools.</p>\n<p>From a quick search it looks like <code>Wacatac.B!ml</code> is a particularly problematic detection that has struck all sorts of legitimate applications, including an open-source launcher for Blender <a href=\"https://github.com/DotBow/Blender-Launcher\" rel=\"nofollow noreferrer\">recently</a> and several other items.</p>\n<p>From experience the <code>!ml</code> tag means that the definition was derived via machine learning which means it most likely is a deep heuristic rather than a code fingerprint.</p>\n<h2>Possible Solutions</h2>\n<p>The most general way to get around this type of heuristic detection is with <a href=\"https://www.microsoft.com/security/blog/2018/08/16/partnering-with-the-industry-to-minimize-false-positives/\" rel=\"nofollow noreferrer\">extended validation code signing</a>. Since this requires a relatively expensive certification process it's unlikely to be a <em>useful</em> solution for your in-house child monitoring tools.</p>\n<p>In your case perhaps a path or <a href=\"https://www.windowscentral.com/how-exclude-files-and-folders-windows-defender-antivirus-scans\" rel=\"nofollow noreferrer\">file exclusion</a> would allow you to continue to refine your tool without having to worry about it constantly being detected and blocked. I wouldn't recommend this for production systems, but for home use only it's simple, althout occasionally unreliable.</p>\n<p>Finally, you could radically change the code. If you can't find a way to avoid detection using your current code base then consider using a different technique altogether. Enable powershell remoting and run a collector script on another machine on the network. Build a web-based agent that polls a web service (on the local network of course) to get commands to run. Use a popular library that will handle the actual communications for you rather than accessing the sockets yourself. Not as efficient maybe, but sometimes all it takes is one change to get the false positives to leave you the hell alone.</p>\n",
                    "OwnerUserId": "920669",
                    "LastActivityDate": "2021-03-02T01:14:35.477",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "66436034",
                "ParentRepo": "https://github.com/accurics/terrascan/blob/1027346ee6fb13c123e3695c34f5ef7c0fc815e9/pkg/policies/opa/rego/aws/aws_s3_bucket/s3EnforceUserACL.rego#L7",
                "StackOverflow_Post": {
                    "Id": "66436034",
                    "PostTypeId": "2",
                    "ParentId": "66117693",
                    "CreationDate": "2021-03-02T08:45:40.663",
                    "Score": "1",
                    "Body": "<p>You need to specify the Bucket Policy, either by:</p>\n<ul>\n<li><code>aws_s3_bucket.policy</code> parameter (so-called inline policy, note that this will <a href=\"https://github.com/accurics/terrascan/blob/1027346ee6fb13c123e3695c34f5ef7c0fc815e9/pkg/policies/opa/rego/aws/aws_s3_bucket/s3EnforceUserACL.rego#L7\" rel=\"nofollow noreferrer\">skip the whole policy analysis</a>)</li>\n<li><code>aws_s3_bucket_policy</code> dedicated resource</li>\n</ul>\n<p>Reference: <a href=\"https://github.com/accurics/terrascan/blob/1027346ee6fb13c123e3695c34f5ef7c0fc815e9/pkg/policies/opa/rego/aws/aws_s3_bucket/s3EnforceUserACL.rego\" rel=\"nofollow noreferrer\">s3EnforceUserACL.rego</a></p>\n",
                    "OwnerUserId": "3652468",
                    "LastActivityDate": "2021-03-02T08:45:40.663",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "66454184",
                "ParentRepo": "https://github.com/mkdocstrings/mkdocstrings/issues/135",
                "StackOverflow_Post": {
                    "Id": "66454184",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "66631131",
                    "CreationDate": "2021-03-03T09:27:01.840",
                    "Score": "4",
                    "ViewCount": "134",
                    "Body": "<p>I hope I am right here in this channel/tag.</p>\n<p>I am using <a href=\"https://pypi.org/project/lazydocs/\" rel=\"nofollow noreferrer\">lazydocs</a> for automatic generation of my md files.\nMy project is written in Python 3.7.5.</p>\n<p>I do have some bullet lists in my docstrings.\nAccording to this <a href=\"https://github.com/mkdocstrings/mkdocstrings/issues/135\" rel=\"nofollow noreferrer\">example</a> I need to leave a blank line, then 4 spaces and e.g. &quot;-&quot; follows, end of bullet list another blank line.</p>\n<p>Here an example:</p>\n<pre><code>&quot;&quot;&quot;This is my example docstring\n\nA simple bullet list:\n\n    - point 1\n    - point 2\n    - point 3\n\n&quot;&quot;&quot;\n</code></pre>\n<p>But when I generate my md file using <code>lazydocs</code> the md file looks like:</p>\n<pre><code>This is my example docstring\n\nA simple bullet list:\n\n    - point 1    - point 2    - point 3\n\n</code></pre>\n<p>I would expect my md file to look like</p>\n<pre><code>This is my example docstring\n\nA simple bullet list:\n\n    - point 1\n    - point 2\n    - point 3\n\n</code></pre>\n<p>Then I tried a bit around. I found out that leaving a blank line between the bullet items makes <code>lazydocs</code> generate my md5 file in the expected format.\nThat would look like this:</p>\n<pre><code>&quot;&quot;&quot;This is my example docstring\n\nA simple bullet list:\n\n    - point 1\n\n    - point 2\n\n    - point 3\n\n&quot;&quot;&quot;\n</code></pre>\n<p>But inserting blank lines into my code is not a nice way to document my code I guess :)</p>\n<p><b>So my question:</b></p>\n<p>Am I doing something wrong here or is <code>lazydocs</code> not processing the bullet points correctly?</p>\n<p>Thanks a lot for any help here!</p>\n",
                    "OwnerUserId": "15320829",
                    "LastActivityDate": "2021-03-15T01:05:31.817",
                    "Title": "LazyDocs - Generated *.md files do not represent bullet list",
                    "Tags": "<python-3.x><docstring>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "66509415",
                "ParentRepo": "https://github.com/jayqi/reprexlite",
                "StackOverflow_Post": {
                    "Id": "66509415",
                    "PostTypeId": "2",
                    "ParentId": "50959420",
                    "CreationDate": "2021-03-06T18:46:44.797",
                    "Score": "2",
                    "Body": "<p>You could also write a little function to replace the part of the path you want to change. Here's a runnable example:</p>\n<pre class=\"lang-py prettyprint-override\"><code>from pathlib import Path\n\npath1 = Path(&quot;a/b/c.txt&quot;)\npath2 = Path(&quot;b/c.txt&quot;)\n\ndef rename_dir(path, src, dst):\n    # convert to list so that we can change elements\n    parts = list(path.parts)\n    \n    # replace part that matches src with dst\n    parts[parts.index(src)] = dst\n    \n    return Path(*parts)\n\nrename_dir(path1, 'b', 'q')\n#&gt; PosixPath('a/q/c.txt')\n\nrename_dir(path2, 'b', 'q')\n#&gt; PosixPath('q/c.txt')\n</code></pre>\n<p><sup>Created at 2021-03-06 10:44:00 PST by <a href=\"https://github.com/jayqi/reprexlite\" rel=\"nofollow noreferrer\">reprexlite</a> v0.4.2</sup></p>\n",
                    "OwnerUserId": "1692709",
                    "LastActivityDate": "2021-03-06T18:46:44.797",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "66510958",
                "ParentRepo": "https://github.com/pwwang/datar",
                "StackOverflow_Post": {
                    "Id": "66510958",
                    "PostTypeId": "2",
                    "ParentId": "26822407",
                    "CreationDate": "2021-03-06T21:48:48.110",
                    "Score": "0",
                    "Body": "<p>It's something like the <code>uncount</code> in <code>tidyr</code>:</p>\n<p><a href=\"https://tidyr.tidyverse.org/reference/uncount.html\" rel=\"nofollow noreferrer\">https://tidyr.tidyverse.org/reference/uncount.html</a></p>\n<p>I wrote a package (<a href=\"https://github.com/pwwang/datar\" rel=\"nofollow noreferrer\">https://github.com/pwwang/datar</a>) that implements this API:</p>\n<pre class=\"lang-py prettyprint-override\"><code>from datar import f\nfrom datar.tibble import tibble\nfrom datar.tidyr import uncount\n\ndf = tibble(\n  id=range(1,5),\n  some_value=[2,'A','B',3],\n  weight=[5,2,1,3]\n)\ndf &gt;&gt; uncount(f.weight, _remove=False)\n</code></pre>\n<p>Output:</p>\n<pre><code>   id some_value  weight\n0   1          2       5\n0   1          2       5\n0   1          2       5\n0   1          2       5\n0   1          2       5\n1   2          A       2\n1   2          A       2\n2   3          B       1\n3   4          3       3\n3   4          3       3\n3   4          3       3\n</code></pre>\n",
                    "OwnerUserId": "5088165",
                    "LastActivityDate": "2021-03-06T21:48:48.110",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "66542647",
                "ParentRepo": "https://github.com/rochacbruno/dynaconf/pull/541",
                "StackOverflow_Post": {
                    "Id": "66542647",
                    "PostTypeId": "2",
                    "ParentId": "66526941",
                    "CreationDate": "2021-03-09T07:38:00.890",
                    "Score": "1",
                    "Body": "<p>Well I managed to overcome this issue, the problem was in dynaconf the current version 3.1.3 doesn't read the conf files properly which fails in the server run.</p>\n<p>Meanwhile, the only workaround is to install the previous version of dynaconf :</p>\n<pre><code>pip install 'dynaconf==3.1.2'\n</code></pre>\n<p>FYI dynaconf already has a fix proposed for the regression: <a href=\"https://github.com/rochacbruno/dynaconf/pull/541\" rel=\"nofollow noreferrer\">rochacbruno/dynaconf#541</a></p>\n<p>I've tested that it does resolve this issue and it will be released in dynaconf 3.1.4 soon.</p>\n",
                    "OwnerUserId": "15030631",
                    "LastActivityDate": "2021-03-09T07:38:00.890",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "66558590",
                "ParentRepo": "https://github.com/RhetTbull/osxmetadata",
                "StackOverflow_Post": {
                    "Id": "66558590",
                    "PostTypeId": "1",
                    "CreationDate": "2021-03-10T04:54:24.457",
                    "Score": "1",
                    "ViewCount": "255",
                    "Body": "<p>Having a file-specific comment visble in the finder is desirable as part of a larger Python project. So, I'm trying to set the finder comment for 4500 files with Python 3.8.2 running on Big Sur. I've achieved this using the <a href=\"https://github.com/RhetTbull/osxmetadata\" rel=\"nofollow noreferrer\">osxmetadata</a> package, but it takes 2-3 minutes, assumedly because of the calls to AppleScript.</p>\n<p>Can Python alone make finder comments stick, and if so how? Or, if you have to reach outside Python, are there more efficient methods than running an Applescript 4500 times?</p>\n<p>Using xattr doesn't do the trick. The code below successfully sets the extended attribute to the same value as Get Info or osxmetadata. But the string/comment is not reflected in the finder.</p>\n<pre><code>import xattr\nimport plistlib\nfrom plistlib import FMT_BINARY\n\nfile = 'test.json'\nbplist = plistlib.dumps('Hello World', fmt=FMT_BINARY)\n\nxattr.setxattr(file, 'com.apple.metadata:kMDItemFinderComment', bplist)\n</code></pre>\n<p>The result in Terminal:</p>\n<pre><code>% xattr -pl com.apple.metadata:kMDItemFinderComment test.json\n0000   62 70 6C 69 73 74 30 30 5B 48 65 6C 6C 6F 20 57    bplist00[Hello W\n0010   6F 72 6C 64 08 00 00 00 00 00 00 01 01 00 00 00    orld............\n0020   00 00 00 00 01 00 00 00 00 00 00 00 00 00 00 00    ................\n0030   00 00 00 00 14                                     .....\n</code></pre>\n<p>Some more investigation shows the directory's .DS_Store file doesn't change. So, I think I'm only changing the &quot;spotlight comment&quot; and not the &quot;finder comment&quot; (?). I thought about just writing a new .DS_Store file for my various directories, but it doesn't seem possible.</p>\n<p>Any thoughts about Python or hybrid solutions to the question would be appreciated. Thanks!</p>\n",
                    "OwnerUserId": "15348177",
                    "LastActivityDate": "2021-03-12T15:46:42.653",
                    "Title": "Unable to set MacOS Finder Comment Metadata using xattr in Python",
                    "Tags": "<python><macos><finder>",
                    "AnswerCount": "1",
                    "CommentCount": "5",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "66577469",
                "ParentRepo": "https://github.com/Roblox/testez/",
                "StackOverflow_Post": {
                    "Id": "66577469",
                    "PostTypeId": "2",
                    "ParentId": "66575540",
                    "CreationDate": "2021-03-11T06:27:51.500",
                    "Score": "5",
                    "Body": "<h1> Unit Testing </h1>\n<p>For lua modules, I would recommend the library <a href=\"https://github.com/Roblox/testez/\" rel=\"noreferrer\">TestEZ</a>. It was developed in-house by Roblox engineers to allow for behavior driven tests. It allows you to specify a location where test files exist and will gives you pretty detailed output as to how your tests did.</p>\n<p>This example will run in RobloxStudio, but you can pair it with other libraries like <a href=\"https://github.com/LPGhatguy/Lemur\" rel=\"noreferrer\">Lemur</a> for command-line and continuous integration workflows. Anyways, follow these steps :</p>\n<h2>1. Get the TestEZ Library into Roblox Studio</h2>\n<ol>\n<li>Download <a href=\"https://github.com/rojo-rbx/rojo\" rel=\"noreferrer\">Rojo</a>. This program allows you to convert project directories into .rbxm (Roblox model object) files.</li>\n<li>Download the <a href=\"https://github.com/Roblox/testez/\" rel=\"noreferrer\">TestEZ source code</a>.</li>\n<li>Open a Powershell or Terminal window and navigate into the downloaded TestEZ directory.</li>\n<li>Build the TestEZ library with this command  <code>rojo build --output TestEZ.rbxm .</code></li>\n<li>Make sure that it generated a new file called <code>TestEZ.rbxm</code> in that directory.</li>\n<li>Open RobloxStudio to your place.</li>\n<li>Drag the newly created <code>TestEZ.rbxm</code> file into the world. It will unpack the library into a ModuleScript with the same name.</li>\n<li>Move this ModuleScript somewhere like ReplicatedStorage.</li>\n</ol>\n<h2>2. Create unit tests</h2>\nIn this step we need to create ModuleScripts with names ending in `.spec` and write tests for our source code.\n<p>A common way to structure code is with your code classes in ModuleScripts and their tests right next to them. So let's say you have a simple utility class in a ModuleScript called <code>MathUtil</code></p>\n<pre><code>local MathUtil = {}\n\nfunction MathUtil.add(a, b)\n    assert(type(a) == &quot;number&quot;)\n    assert(type(b) == &quot;number&quot;)\n    return a + b\nend\n\nreturn MathUtil\n</code></pre>\n<p>To create tests for this file, create a ModuleScript next to it and call it <code>MathUtil.spec</code>. <b>This naming convention is important, as it allows TestEZ to discover the tests.</b></p>\n<pre><code>return function()\n    local MathUtil = require(script.parent.MathUtil)\n    \n    describe(&quot;add&quot;, function()\n        it(&quot;should verify input&quot;, function()\n            expect(function()\n                local result = MathUtil.add(&quot;1&quot;, 2)\n            end).to.throw()\n        end)\n        \n        it(&quot;should properly add positive numbers&quot;, function()\n            local result = MathUtil.add(1, 2)\n            expect(result).to.equal(3)\n        end)\n        \n        it(&quot;should properly add negative numbers&quot;, function()\n            local result = MathUtil.add(-1, -2)\n            expect(result).to.equal(-3)\n        end)\n    end)\nend\n</code></pre>\n<p>For a full breakdown on writing tests with TestEZ, please take a look at <a href=\"https://roblox.github.io/testez\" rel=\"noreferrer\">the official documentation</a>.</p>\n<h2>3. Create a test runner</h2>\n<p>In this step, we need to tell TestEZ where to find our tests. So create a Script in ServerScriptService with this :</p>\n<pre><code>local TestEZ = require(game.ReplicatedStorage.TestEZ)\n\n-- add any other root directory folders here that might have tests \nlocal testLocations = {\n    game.ServerStorage,\n}\nlocal reporter = TestEZ.TextReporter\n--local reporter = TestEZ.TextReporterQuiet -- use this one if you only want to see failing tests\n \nTestEZ.TestBootstrap:run(testLocations, reporter)\n</code></pre>\n<h2>4. Run your tests</h2>\nNow we can run the game and check the Output window. We should see our tests output :\n<pre><code>Test results:\n[+] ServerStorage\n   [+] MathUtil\n      [+] add\n         [+] should properly add negative numbers\n         [+] should properly add positive numbers\n         [+] should verify input\n3 passed, 0 failed, 0 skipped - TextReporter:87\n</code></pre>\n<hr />\n<h1> Automation Testing </h1>\n<p>Unfortunately, there does not exist a way to fully automate the testing of your game.</p>\n<p>You can use <a href=\"https://developer.roblox.com/en-us/api-reference/class/TestService\" rel=\"noreferrer\">TestService</a> to create tests that automate the testing of <em>some</em> interactions, like a player touching a kill block or checking bullet paths from guns. But there isn't a publicly exposed way to start your game, record inputs, and validate the game state.</p>\n<p>There's <a href=\"https://developer.roblox.com/en-us/api-reference/class/VirtualInputManager\" rel=\"noreferrer\">an internal service</a> for this, and a <a href=\"https://developer.roblox.com/en-us/api-reference/class/VirtualUser\" rel=\"noreferrer\">non-scriptable service for mocking inputs</a> but without overriding CoreScripts, it's really not possible at this moment in time.</p>\n",
                    "OwnerUserId": "2860267",
                    "LastActivityDate": "2021-03-11T06:27:51.500",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "66590547",
                "ParentRepo": "https://github.com/smallrye/smallrye-mutiny/issues/501",
                "StackOverflow_Post": {
                    "Id": "66590547",
                    "PostTypeId": "2",
                    "ParentId": "66575444",
                    "CreationDate": "2021-03-11T21:05:28.557",
                    "Score": "1",
                    "Body": "<p>According to the official team (<a href=\"https://github.com/smallrye/smallrye-mutiny/issues/501\" rel=\"nofollow noreferrer\">https://github.com/smallrye/smallrye-mutiny/issues/501</a>), <code>collect</code> collects all the items until a terminal event.\nI managed to tweak my algorithm to come up with a way to check each item upstream and early terminate using <code>multi.select().first</code> API.</p>\n",
                    "OwnerUserId": "2233683",
                    "LastActivityDate": "2021-03-11T21:05:28.557",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "67048679",
                "ParentRepo": "https://github.com/MobileFirstLLC/extension-cli/",
                "StackOverflow_Post": {
                    "Id": "67048679",
                    "PostTypeId": "1",
                    "CreationDate": "2021-04-11T18:20:52.973",
                    "Score": "0",
                    "ViewCount": "315",
                    "Body": "<p>I'm trying to develop a chrome extension that will be using an npm package, more specifically, 'yt-search'.</p>\n<p>I have tried to go at this both manually and using some available tools such as <a href=\"https://www.npmjs.com/package/generate-chrome-extension\" rel=\"nofollow noreferrer\">generate chrome extension</a> and <a href=\"https://github.com/MobileFirstLLC/extension-cli/\" rel=\"nofollow noreferrer\">extension-cli</a>, both of which are supposed to automate the process and add the capability of using node-modules.</p>\n<p>However, when importing the module either with <code>import 'yt-search</code> or <code>require()</code>, I get an error - 'Unable to find module cheerio', which is a dependency of 'yt-search'. My guess here is that the build process is just importing the main module and none of it's dependencies.</p>\n<p>I would love to provide a working example, but being a chrome extension environment, it's a bit hard to do so here.</p>\n",
                    "OwnerUserId": "4326630",
                    "LastActivityDate": "2021-04-11T18:20:52.973",
                    "Title": "Importing node_modules into a chrome extension",
                    "Tags": "<javascript><google-chrome><webpack><import><node-modules>",
                    "AnswerCount": "0",
                    "CommentCount": "4",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "67052017",
                "ParentRepo": "https://github.com/engineer-man/piston",
                "StackOverflow_Post": {
                    "Id": "67052017",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "67288357",
                    "CreationDate": "2021-04-12T02:39:03.997",
                    "Score": "0",
                    "ViewCount": "129",
                    "Body": "<p>I am trying to use <a href=\"https://github.com/engineer-man/piston\" rel=\"nofollow noreferrer\">this</a> api, from a webpage, and for that I am using php (because my host wont allow anything else)</p>\n<p>I have to make a post request to this url</p>\n<p><code>https://emkc.org/api/v1/piston/execute</code></p>\n<p>And the request body must look like this:</p>\n<pre class=\"lang-json prettyprint-override\"><code>{\n  &quot;language&quot;: &quot;python&quot;,\n  &quot;source&quot;: &quot;print('a')&quot;\n}\n</code></pre>\n<p>I have tried this code to achieve that, which I got by using postman, and checking that it worked:</p>\n<pre class=\"lang-php prettyprint-override\"><code>&lt;?php\n\n$curl = curl_init();\n\ncurl_setopt_array($curl, array(\n  CURLOPT_URL =&gt; 'https://emkc.org/api/v1/piston/execute',\n  CURLOPT_RETURNTRANSFER =&gt; true,\n  CURLOPT_ENCODING =&gt; '',\n  CURLOPT_MAXREDIRS =&gt; 10,\n  CURLOPT_TIMEOUT =&gt; 0,\n  CURLOPT_FOLLOWLOCATION =&gt; true,\n  CURLOPT_HTTP_VERSION =&gt; CURL_HTTP_VERSION_1_1,\n  CURLOPT_CUSTOMREQUEST =&gt; 'POST',\n  CURLOPT_POSTFIELDS =&gt;'{\n    &quot;language&quot;: &quot;python&quot;,\n    &quot;source&quot;: &quot;print(\\'a\\')&quot;\n  }',\n  CURLOPT_HTTPHEADER =&gt; array(\n    'Content-Type: application/json',\n    'Cookie: engineerman.sid=s%3AskNtfiOWjopn-CqdMwPS8SaWagDp5WYc.vJITp6lG8V9dteGzs92Xldaw88sfHfLO1sF%2FbfdLvbI'\n  ),\n));\n\n$response = curl_exec($curl);\n\ncurl_close($curl);\necho $response;\nvar_dump($response);\nprint_r($response);\n\n?&gt;\n</code></pre>\n<p>But when I run this from my local server it does not work. The <code>var_dump()</code> returns <code>bool(false)</code> and the rest return nothing.</p>\n<p>What is going on here?</p>\n",
                    "OwnerUserId": "14120696",
                    "LastActivityDate": "2021-04-27T17:59:28.783",
                    "Title": "PHP POST requests not returning anything",
                    "Tags": "<php><api><post><request>",
                    "AnswerCount": "1",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "67054979",
                "ParentRepo": "https://github.com/polkascan/py-substrate-interface",
                "StackOverflow_Post": {
                    "Id": "67054979",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "67071395",
                    "CreationDate": "2021-04-12T08:26:26.170",
                    "Score": "2",
                    "ViewCount": "418",
                    "Body": "<p>Hello guys I am working on submitting an extrinsic via the <a href=\"https://github.com/polkascan/py-substrate-interface\" rel=\"nofollow noreferrer\">py-substrate-interface</a>, but for some reason I keep getting an error while following the sample mentioned <a href=\"https://github.com/polkascan/py-substrate-interface#create-and-send-signed-extrinsics\" rel=\"nofollow noreferrer\">here</a>.\nMy code is as follows:</p>\n<pre><code>    def send_funds(self, destination, amount):\n        self.log.info(&quot;Sending {} DOT to {} ...&quot;.format(amount, destination.strip()))\n        substrate = self.create_substrate_instance(self.node_ws_port[0])\n\n        keypair = Keypair.create_from_mnemonic('level payment mom grape proof display cause engage erupt rain hair arm')\n        print(keypair)\n\n        call = substrate.compose_call(\n            call_module='Balances',\n            call_function='transfer',\n            call_params={\n                'dest': destination,\n                'value': ceil(amount * DOT)\n            }\n        )\n\n        try:\n            extrinsic = substrate.create_signed_extrinsic(call=call, keypair=keypair)\n        except Exception as e:\n            print(e)\n\n        try:\n            receipt = substrate.submit_extrinsic(extrinsic, wait_for_inclusion=True)\n            self.log.info(&quot;Extrinsic '{}' sent and included in block '{}'&quot;.format(receipt.extrinsic_hash, receipt.block_hash))\n            self.log.info(&quot;{} DOT sent to address: {}&quot;.format(amount, destination))\n        except SubstrateRequestException as e:\n            self.log.error(&quot;Failed to send: {}&quot;.format(e))\n</code></pre>\n<p>I put a try and except block here:</p>\n<pre><code>        try:\n            extrinsic = substrate.create_signed_extrinsic(call=call, keypair=keypair)\n        except Exception as e:\n            print(e)\n</code></pre>\n<p>and I get the following error while running this code block:</p>\n<pre><code>No more bytes available (offset: 80 / length: 72)\n</code></pre>\n<p>How can I resolve this problem.</p>\n",
                    "OwnerUserId": "15520869",
                    "LastActivityDate": "2021-04-14T11:29:45.117",
                    "Title": "Why can't I send an extrinsic from py-substrate-interface?",
                    "Tags": "<python><blockchain><substrate><polkadot>",
                    "AnswerCount": "2",
                    "CommentCount": "3",
                    "FavoriteCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "67071395",
                "ParentRepo": "https://github.com/polkascan/py-scale-codec/blob/master/scalecodec/type_registry/rococo.json",
                "StackOverflow_Post": {
                    "Id": "67071395",
                    "PostTypeId": "2",
                    "ParentId": "67054979",
                    "CreationDate": "2021-04-13T08:36:14.663",
                    "Score": "4",
                    "Body": "<p>Most of the time a <code>RemainingScaleBytesNotEmptyException</code> is raised, it is type registry related. In a Substrate runtime (like Kusama, Polkadot, etc) specific types are defined, which are not (yet) exposed in the metadata, so libraries have to include a decomposition to primitives of those types.</p>\n<p>Some pointers for troubleshooting:</p>\n<ul>\n<li><p>The wrong type registry is being used. Most of the time py-substrate-interface can auto-discover which chain its talking to, so only the <code>url</code> have to be specified (<a href=\"https://github.com/polkascan/py-substrate-interface#autodiscover-mode\" rel=\"nofollow noreferrer\">https://github.com/polkascan/py-substrate-interface#autodiscover-mode</a>). But with custom runtimes or development properties like <code>type_registry_preset</code> and <code>ss58_format</code> need to be set manually</p>\n</li>\n<li><p>Because of a recent runtime upgrade the local type registry is out-dated and needs to be updated. This can be achieved by updating the <code>py-scale-codec</code> package, run the <code>substrate.reload_type_registry()</code> function or always use the remote type registries with the <code>use_remote_preset</code> kwarg (See <a href=\"https://github.com/polkascan/py-substrate-interface#keeping-type-registry-presets-up-to-date\" rel=\"nofollow noreferrer\">https://github.com/polkascan/py-substrate-interface#keeping-type-registry-presets-up-to-date</a>)</p>\n</li>\n<li><p>When developing a custom runtime, introduced types can be added in a custom JSON file in the format like <a href=\"https://github.com/polkascan/py-scale-codec/blob/master/scalecodec/type_registry/rococo.json\" rel=\"nofollow noreferrer\">https://github.com/polkascan/py-scale-codec/blob/master/scalecodec/type_registry/rococo.json</a> and provided during init (See <a href=\"https://github.com/polkascan/py-substrate-interface#substrate-node-template\" rel=\"nofollow noreferrer\">https://github.com/polkascan/py-substrate-interface#substrate-node-template</a>)</p>\n</li>\n</ul>\n",
                    "OwnerUserId": "269465",
                    "LastEditorUserId": "269465",
                    "LastEditDate": "2021-04-14T11:29:45.117",
                    "LastActivityDate": "2021-04-14T11:29:45.117",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "67185849",
                "ParentRepo": "https://github.com/Zylann/godot_voxel",
                "StackOverflow_Post": {
                    "Id": "67185849",
                    "PostTypeId": "2",
                    "ParentId": "67184648",
                    "CreationDate": "2021-04-20T20:23:06.333",
                    "Score": "1",
                    "Body": "<p><em>This is something I wish I knew more, but I'll share what I know.</em></p>\n<p>First of all, consider having more chunks visible instead of chunks with more voxels.</p>\n<p>As you know, generating a chunk takes longer the more voxels it has. However, having a chunk that is only one voxel defeats the purpose. Thus, there must an optimal number of voxels per chunk. <em>And you are probably going over it, you may consider leave it configurable. A cube of 256 voxels per side, is 16777216 voxels. Try other sizes, 64 voxels per side worked better for me when I have attempted to do something like this.</em></p>\n<hr />\n<p>I have to suggest against having an instance per cube. If you want to use meshes to represent your voxels. I suggest to do meshing. Each chunk would be a single mesh.</p>\n<p>Voxel meshing is often intertwine with marching cubes. <em>And I feel I have to mention it, even if you have heard it a million times.</em> I doubt you want the kind of meshes marching generate, as they don't look like cubes. However, marching cubes is a way to mesh voxels. You can apply the same approach, except, you know, generate a mesh that looks like cubes. The idea is simple, you iterate over the voxels, and you construct a mesh from the voxel data, without any internal surface.</p>\n<hr />\n<p>By the way, an alternative is ray casting. You can upload the voxel data as a 3D texture to the GPU and have a shader implement the &quot;Fast Voxel Traversal Algorithm&quot; or similar. It can be implemented as a material, and then your chunks are simple cubes. I have done this with some success.</p>\n<p><strong>Addendum</strong>: an optimization is to store on every free voxel the distance to the nearest ocupied voxel in the same chunk. Then when traversing you know you can skip that many voxels ahead, regardless of the direction of traversal, which makes ray casting faster.</p>\n<p>You can optimize further by storing the distance to the nearest  occupied voxel on the same chunk for each of the six frustums that correspond to the faces of the voxel cube. Then for traversal you check on which frustum the ray would be, and that tells you which value to use. However, this begins to slow down the generation process, so you may have to readjust the chunk size.</p>\n<hr />\n<p>I know you can find more information on the sister site <a href=\"https://gamedev.stackexchange.com/\">gamedev.stackexchange.com</a>. Try searching <a href=\"https://gamedev.stackexchange.com/search?tab=votes&amp;q=voxel%20meshing\">&quot;voxel meshing&quot;</a> also <a href=\"https://gamedev.stackexchange.com/questions/tagged/marching-cubes?tab=Votes\">marching cubes</a> is a tag there!</p>\n<p>Another thing you can find about there is handling level of details for voxels. You probably don't really want all that detail for chunks that are far away. So you could generate a less detailed, but faster to compute, representation.</p>\n<hr />\n<p>Now, since the question is about Godot, I will also mention that Godot has an <a href=\"https://godotengine.org/asset-library/asset\" rel=\"nofollow noreferrer\">Asset Library</a>. <em>Not an asset store, it is not a store front, everything there is free. Free as in beer, and free as in speech.</em> And you can find voxel solutions on the Godot Asset Library. Which, even if you are not going to use them, you can look how they work. Because, <em>did I mention?</em> they are all free software.</p>\n<p>I haven't gone deep in them, but the <a href=\"https://godotengine.org/asset-library/asset/676\" rel=\"nofollow noreferrer\">3D Voxel Demo</a> claims to use another thread to create the meshes. Furthermore, they recommend <a href=\"https://github.com/Zylann/godot_voxel\" rel=\"nofollow noreferrer\">godot_voxel</a> which is C++. In fact, it is a Godot module for voxels. <em>Why not start there?</em></p>\n<hr />\n<p><em>Addendum: did you try GridMaps?</em></p>\n",
                    "OwnerUserId": "402022",
                    "LastEditorUserId": "402022",
                    "LastEditDate": "2022-01-18T12:36:21.383",
                    "LastActivityDate": "2022-01-18T12:36:21.383",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "67199100",
                "ParentRepo": "https://github.com/Breakthrough/PySceneDetect",
                "StackOverflow_Post": {
                    "Id": "67199100",
                    "PostTypeId": "1",
                    "CreationDate": "2021-04-21T15:42:58.120",
                    "Score": "2",
                    "ViewCount": "247",
                    "Body": "<p>I am trying to cut scenes from a video using scenedetect library in Python.</p>\n<p>The usual technique is done using changes in image compositions, done via <code>ContentDetector()</code> objects. This is the standard way recommended on their <a href=\"https://github.com/Breakthrough/PySceneDetect\" rel=\"nofollow noreferrer\">GitHub repository</a>. This is the example code they used:</p>\n<pre><code># Standard PySceneDetect imports:\nfrom scenedetect import VideoManager\nfrom scenedetect import SceneManager\n\n# For content-aware scene detection:\nfrom scenedetect.detectors import ContentDetector\n\ndef find_scenes(video_path, threshold=30.0):\n    # Create our video &amp; scene managers, then add the detector.\n    video_manager = VideoManager([video_path])\n    scene_manager = SceneManager()\n    scene_manager.add_detector(\n        ContentDetector(threshold=threshold))\n\n    # Improve processing speed by downscaling before processing.\n    video_manager.set_downscale_factor()\n\n    # Start the video manager and perform the scene detection.\n    video_manager.start()\n    scene_manager.detect_scenes(frame_source=video_manager)\n\n    # Each returned scene is a tuple of the (start, end) timecode.\n    return scene_manager.get_scene_list()\n</code></pre>\n<p>However, there is an alternative technique, based on brightness, that can be done via <code>ThresholdDetector()</code> objects. If I try to substitute <code>ThresholdDetector()</code> to <code>ContentDetector()</code>, I don't get a list of scenes anymore... just only one initial frame.</p>\n<p>What am I doing wrong?</p>\n",
                    "OwnerUserId": "10202729",
                    "LastActivityDate": "2021-04-21T15:42:58.120",
                    "Title": "Python, PySceneDetect library: How to use brightness method to cut scenes?",
                    "Tags": "<python><video-processing><brightness>",
                    "AnswerCount": "0",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "67254008",
                "ParentRepo": "https://github.com/burnedikt/mkdocs-jinja2-filters-plugin",
                "StackOverflow_Post": {
                    "Id": "67254008",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "67278596",
                    "CreationDate": "2021-04-25T13:38:24.923",
                    "Score": "1",
                    "ViewCount": "249",
                    "Body": "<p>While writing a Jinja2 template for MkDocs, I need some processing that is not covered by the filters/tests available (specifically, I need date formatting, which is a recurring example for custom filters in Jinja2-related resources across the Web). <strong>How can I define my own filters/tests and use them from templates?</strong></p>\n<p>To clarify the question, I know <a href=\"https://jinja.palletsprojects.com/en/2.11.x/api/#custom-filters\" rel=\"nofollow noreferrer\">how to register new filters/tests in a Jinja2 environment</a> <em>from Python</em>. My issue is that, <em>as a user</em> of MkDocs, I do not configure Jinja2 myself. So what I\u2019m looking for is a way to hook into the setup that MkDocs performs.</p>\n<p>I assume it is possible to add filters from a plugin. In fact, I have found <a href=\"https://github.com/burnedikt/mkdocs-jinja2-filters-plugin\" rel=\"nofollow noreferrer\">one such plugin</a> (undocumented and apparently not under active development, unfortunately). However, I hope that there is a simpler, local solution; one that would not involve <a href=\"https://www.mkdocs.org/user-guide/plugins/\" rel=\"nofollow noreferrer\">implementing a plugin</a>, packaging it as a Python package and publishing it on PyPi.</p>\n",
                    "OwnerUserId": "4615179",
                    "LastEditorUserId": "4615179",
                    "LastEditDate": "2021-04-25T13:45:51.900",
                    "LastActivityDate": "2021-04-28T17:43:54.517",
                    "Title": "Add custom Jinja2 filters/tests to MkDocs",
                    "Tags": "<jinja2><mkdocs>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "67259780",
                "ParentRepo": "https://github.com/Byron/google-apis-rs",
                "StackOverflow_Post": {
                    "Id": "67259780",
                    "PostTypeId": "1",
                    "CreationDate": "2021-04-26T01:26:15.660",
                    "Score": "2",
                    "ViewCount": "750",
                    "Body": "<p>I'm interested in validating a Google ID token that is returned upon a successful Google Sign In attempt. I have a Rust based webapp where I:</p>\n<ol>\n<li><p>Offer Google Sign in via Javascript, upon successful authentication, I get back, among other things, a Google ID token.</p>\n</li>\n<li><p>My Javascript code submits this Google ID token to my backend server (written in Rust) along with other info (i.e. user's account ID, current email etc).</p>\n</li>\n<li><p>I'd like to verify the integrity of this ID token via the directions cited in Google's official docs <a href=\"https://developers.google.com/identity/sign-in/web/backend-auth\" rel=\"nofollow noreferrer\">https://developers.google.com/identity/sign-in/web/backend-auth</a> before I can &quot;trust&quot; that the submitted user's info (i.e. user's account ID, current email etc) is valid and is not a malicious request.</p>\n</li>\n<li><p>Example of what I'd like to achieve: <a href=\"https://stackoverflow.com/questions/39061310/validate-google-id-token\">Validate Google Id Token</a></p>\n</li>\n</ol>\n<p>What I've tried:</p>\n<ol>\n<li>Thus far, I've attempt to use <a href=\"https://lib.rs/crates/google-signin\" rel=\"nofollow noreferrer\">https://lib.rs/crates/google-signin</a> with no luck, as I get the following error when attempting to use it as a dep:</li>\n</ol>\n<pre><code>cargo check\n    Updating crates.io index\nerror: failed to select a version for the requirement `untrusted = &quot;^0.5&quot;`\ncandidate versions found which didn't match: 0.7.1, 0.7.0, 0.6.2\nlocation searched: crates.io index\nrequired by package `webpki-roots v0.10.0`\n    ... which is depended on by `hyper-rustls v0.6.0`\n    ... which is depended on by `google-signin v0.3.0`\n    ... which is depended on by `&lt;my project&gt; v0.0.1 (&lt;my project&gt;)`\n</code></pre>\n<p>it appears that the crate's link to the repo is broken, so no ability to submit an Issue.</p>\n<ol start=\"2\">\n<li>I've tried <a href=\"https://github.com/Byron/google-apis-rs\" rel=\"nofollow noreferrer\">https://github.com/Byron/google-apis-rs</a> but I can't seem to find useable code in the generated output.</li>\n</ol>\n<p>What are folks using to validate ID tokens in Rust?</p>\n",
                    "OwnerUserId": "1154200",
                    "LastActivityDate": "2022-07-25T11:20:12.937",
                    "Title": "Validating Google sign in ID token in Rust",
                    "Tags": "<rust><google-oauth>",
                    "AnswerCount": "1",
                    "CommentCount": "3",
                    "FavoriteCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "67278596",
                "ParentRepo": "https://github.com/aklajnert/mkdocs-simple-hooks",
                "StackOverflow_Post": {
                    "Id": "67278596",
                    "PostTypeId": "2",
                    "ParentId": "67254008",
                    "CreationDate": "2021-04-27T07:22:08.647",
                    "Score": "1",
                    "Body": "<p>A possible solution is to use <a href=\"https://github.com/aklajnert/mkdocs-simple-hooks\" rel=\"nofollow noreferrer\">mkdocs-simple-hooks</a> that allows to implement the hooks without needing to create a plugin. For example in your case:</p>\n<pre class=\"lang-yaml prettyprint-override\"><code>plugins:\n  - mkdocs-simple-hooks:\n      hooks:\n        on_env: &quot;docs.hooks:on_env&quot;\n</code></pre>\n<p><strong>docs/hooks.py</strong></p>\n<pre class=\"lang-py prettyprint-override\"><code>def on_env(env, config, files, **kwargs): \n    env.filters['my_filter'] = my_filter\n    env.tests['my_test'] = my_test\n    return env\n</code></pre>\n",
                    "OwnerUserId": "6622587",
                    "LastEditorUserId": "6622587",
                    "LastEditDate": "2021-04-28T17:43:54.517",
                    "LastActivityDate": "2021-04-28T17:43:54.517",
                    "CommentCount": "3",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "67307835",
                "ParentRepo": "https://github.com/KevinOConnor/klipper",
                "StackOverflow_Post": {
                    "Id": "67307835",
                    "PostTypeId": "1",
                    "CreationDate": "2021-04-28T21:01:47.110",
                    "Score": "0",
                    "ViewCount": "46",
                    "Body": "<p>I've created a configuration file for a specific <a href=\"https://github.com/KevinOConnor/klipper\" rel=\"nofollow noreferrer\">open source project</a> that I want to integrate into the master branch.</p>\n<p>I know that there is a whole process to go through before it gets approved and integrated into the master branch.</p>\n<p>My question is, how do I go about requesting access to commit this file?</p>\n",
                    "OwnerUserId": "12765604",
                    "LastActivityDate": "2021-04-28T21:51:38.567",
                    "Title": "How to request rights to commit to an open source git repository?",
                    "Tags": "<git><github><branch><commit><pull-request>",
                    "AnswerCount": "1",
                    "CommentCount": "2",
                    "ClosedDate": "2021-04-28T21:51:19.993",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "67375858",
                "ParentRepo": "https://github.com/tweag/monad-bayes",
                "StackOverflow_Post": {
                    "Id": "67375858",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "67392764",
                    "CreationDate": "2021-05-03T21:10:09.870",
                    "Score": "3",
                    "ViewCount": "96",
                    "Body": "<p>I am trying to define a toy probabilistic programming language to test various inference algorithms and their effectiveness. I followed <a href=\"https://en.wikibooks.org/wiki/Write_Yourself_a_Scheme_in_48_Hours\" rel=\"nofollow noreferrer\">this tutorial</a> to create a Scheme like language with a basic structure. Now I want to use the <a href=\"https://github.com/tweag/monad-bayes\" rel=\"nofollow noreferrer\">monad-bayes</a> library to add the probabilistic backend. My end goal is to support sampling from and observing from distributions. This is the definition of my expressions</p>\n<pre><code>data LispVal = Atom String                  -- Stores a string naming the atom\n             | List [LispVal]               -- List of expressions\n             | DottedList [LispVal] LispVal -- List of elements but last\n             | Integer Integer               -- Int\n             | Float Double\n             | String String                -- Str\n             | Bool Bool                    -- Bool\n             | Port Handle\n             | PrimitiveFunc ([LispVal] -&gt; ThrowsError LispVal)\n             | IOFunc ([LispVal] -&gt; IOThrowsError LispVal)\n             | Func { params :: [String], vararg :: Maybe String,\n                      body :: [LispVal], closure :: Env }\n</code></pre>\n<p>Now, I want to add MonadSample and MonadInfer types to support the functions in the library. However, simply adding <code>| ModelSample MonadSample LispVal</code> does not work. I went over the source code of the library many times, but I dont seem to understand it well enough, there are quite some monad-transformations going on. This is how they define basic distributions in the library</p>\n<pre><code>class Monad m =&gt; MonadSample m where\n  -- | Draw from a uniform distribution.\n  random ::\n    -- | \\(\\sim \\mathcal{U}(0, 1)\\)\n    m Double\n\n  -- | Draw from a uniform distribution.\n  uniform ::\n    -- | lower bound a\n    Double -&gt;\n    -- | upper bound b\n    Double -&gt;\n    -- | \\(\\sim \\mathcal{U}(a, b)\\).\n    m Double\n  uniform a b = draw (uniformDistr a b)\n\n  -- | Draw from a normal distribution.\n  normal ::\n    -- | mean \u03bc\n    Double -&gt;\n    -- | standard deviation \u03c3\n    Double -&gt;\n    -- | \\(\\sim \\mathcal{N}(\\mu, \\sigma^2)\\)\n    m Double\n  normal m s = draw (normalDistr m s)\n\n  -- | Draw from a gamma distribution.\n  gamma ::\n    -- | shape k\n    Double -&gt;\n    -- | scale \u03b8\n    Double -&gt;\n    -- | \\(\\sim \\Gamma(k, \\theta)\\)\n    m Double\n  gamma shape scale = draw (gammaDistr shape scale)\n\n  -- | Draw from a beta distribution.\n  beta ::\n    -- | shape \u03b1\n    Double -&gt;\n    -- | shape \u03b2\n    Double -&gt;\n    -- | \\(\\sim \\mathrm{Beta}(\\alpha, \\beta)\\)\n    m Double\n  beta a b = draw (betaDistr a b)\n\n  -- | Draw from a Bernoulli distribution.\n  bernoulli ::\n    -- | probability p\n    Double -&gt;\n    -- | \\(\\sim \\mathrm{B}(1, p)\\)\n    m Bool\n  bernoulli p = fmap (&lt; p) random\n\n  -- | Draw from a categorical distribution.\n  categorical ::\n    Vector v Double =&gt;\n    -- | event probabilities\n    v Double -&gt;\n    -- | outcome category\n    m Int\n  categorical ps = fromPMF (ps !)\n\n  -- | Draw from a categorical distribution in the log domain.\n  logCategorical ::\n    (Vector v (Log Double), Vector v Double) =&gt;\n    -- | event probabilities\n    v (Log Double) -&gt;\n    -- | outcome category\n    m Int\n  logCategorical = categorical . VG.map (exp . ln)\n\n  -- | Draw from a discrete uniform distribution.\n  uniformD ::\n    -- | observable outcomes @xs@\n    [a] -&gt;\n    -- | \\(\\sim \\mathcal{U}\\{\\mathrm{xs}\\}\\)\n    m a\n  uniformD xs = do\n    let n = Prelude.length xs\n    i &lt;- categorical $ V.replicate n (1 / fromIntegral n)\n    return (xs !! i)\n\n  -- | Draw from a geometric distribution.\n  geometric ::\n    -- | success rate p\n    Double -&gt;\n    -- | \\(\\sim\\) number of failed Bernoulli trials with success probability p before first success\n    m Int\n  geometric = discrete . geometric0\n\n  -- | Draw from a Poisson distribution.\n  poisson ::\n    -- | parameter \u03bb\n    Double -&gt;\n    -- | \\(\\sim \\mathrm{Pois}(\\lambda)\\)\n    m Int\n  poisson = discrete . Poisson.poisson\n</code></pre>\n<p>Is there a way to make all of these be included in the LispVal data I have? Or am I just following a wrong logic here and is there a better way to do this?</p>\n<p>I would also welcome any more suggestions to how to go about integrating this library in my language. And as a side note, my goal is not to integrate all the functionality, but just the bare minimum to make a functioning probabilistic programming language.</p>\n<p>Thanks in advance!</p>\n<p>Edit: To clarify, here is an example program that I want to be able to run with my language.</p>\n<p><code>(define (model1 upper lower) (sample (uniform upper lower)))</code></p>\n<p>This function will just return a sample from a uniform distribution with the given constraints.The haskell library allows to do this via following</p>\n<p><code>a = sampleIO $ (uniform upper lower)</code></p>\n<p>I want to be able to use the same functionalities. What I initially tried was just to put <code>| ModelSample MonadSample LispVal</code> which gives the error &quot;Expected a type, but 'MonadSample LispVal' has type Constraint&quot; I looked up the error but couldnt find a way to solidify this Monad into a type which can be used by my expression</p>\n",
                    "OwnerUserId": "13056788",
                    "LastEditorUserId": "13056788",
                    "LastEditDate": "2021-05-04T12:35:16.810",
                    "LastActivityDate": "2021-05-04T22:03:03.520",
                    "Title": "Defining a data type as MonadSample",
                    "Tags": "<haskell><monad-transformers>",
                    "AnswerCount": "1",
                    "CommentCount": "8",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "67393747",
                "ParentRepo": "https://github.com/pyjanitor-devs/pyjanitor",
                "StackOverflow_Post": {
                    "Id": "67393747",
                    "PostTypeId": "2",
                    "ParentId": "67393474",
                    "CreationDate": "2021-05-05T00:26:58.967",
                    "Score": "3",
                    "Body": "<p>A couple of options to do this:</p>\n<p>with <a href=\"https://pandas.pydata.org/docs/reference/api/pandas.wide_to_long.html\" rel=\"nofollow noreferrer\">pd.wide_to_long</a>, you need to reorder the positions based on the delimiter; in this case we move the <code>a</code>, <code>b</code>, ... to the fore and the <code>p1</code>, <code>p2</code> to the back, before reshaping:</p>\n<pre><code>temp = df.copy()\ntemp = temp.rename(columns = lambda df: &quot;.&quot;.join(df.split(&quot;.&quot;)[::-1]))\n(pd.wide_to_long(temp.reset_index(), \n                 stubnames = [&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;, &quot;e&quot;, &quot;f&quot;, &quot;g&quot;], \n                 sep=&quot;.&quot;, \n                 suffix=&quot;.+&quot;, \n                 i = &quot;index&quot;, \n                 j = &quot;side&quot;)\n  .droplevel('index')\n  .reset_index()\n\n  side  a   b   c   d   e   f   g\n0   p1  4   1   2   3   4   5   6\n1   p1  0   4   8  12  16  20  24\n2   p2  0   3   6   9  12  15  18\n3   p2  0  12  24  36  48  60  72\n</code></pre>\n<p>One limitation with <a href=\"https://pandas.pydata.org/docs/reference/api/pandas.wide_to_long.html\" rel=\"nofollow noreferrer\">pd.wide_to_long</a> is the reshaping of positions. The other limitation is that the stubnames have to be explicitly specified.</p>\n<p>Another option is via <a href=\"https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.stack.html#pandas.DataFrame.stack\" rel=\"nofollow noreferrer\">stack</a>, where the columns are split, based on the delimiter and reshaped:</p>\n<pre><code>temp = df.copy()\ntemp.columns = temp.columns.str.split(&quot;.&quot;, expand = True)\n\ntemp.stack(0).droplevel(0).rename_axis('side').reset_index()\n\n  side  a   b   c   d   e   f   g\n0   p1  4   1   2   3   4   5   6\n1   p2  0   3   6   9  12  15  18\n2   p1  0   4   8  12  16  20  24\n3   p2  0  12  24  36  48  60  72\n</code></pre>\n<p><a href=\"https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.stack.html#pandas.DataFrame.stack\" rel=\"nofollow noreferrer\">stack</a> is quite flexible, and did not require us to list the column names. The limitation of <a href=\"https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.stack.html#pandas.DataFrame.stack\" rel=\"nofollow noreferrer\">stack</a> is that it fails if the index is not unique.</p>\n<p>Another option is <a href=\"https://pyjanitor-devs.github.io/pyjanitor/api/functions/#janitor.functions.pivot.pivot_longer\" rel=\"nofollow noreferrer\">pivot_longer</a> from <a href=\"https://pyjanitor-devs.github.io/pyjanitor/\" rel=\"nofollow noreferrer\">pyjanitor</a>, which abstracts the process:</p>\n<pre><code># pip install janitor\nimport janitor\ndf.pivot_longer(index = None, \n                names_to = (&quot;side&quot;, &quot;.value&quot;), \n                names_sep=&quot;.&quot;)\n \n  side  a   b   c   d   e   f   g\n0   p1  4   1   2   3   4   5   6\n1   p1  0   4   8  12  16  20  24\n2   p2  0   3   6   9  12  15  18\n3   p2  0  12  24  36  48  60  72\n</code></pre>\n<p>The <em>worker</em> here is <code>.value</code>. This tells the code that anything after <code>.</code> should remain as column names, while anything before <code>.</code> should be collated into a new column (<code>side</code>). Note that, unlike <code>wide_to_long</code>, the stubnames do not need to be stated - it abstracts that for us. Also, it can handle duplicate indices, since it uses <code>pd.melt</code> under the hood.\nOne limitation of <code>pivot_longer</code> is that you have to install the <a href=\"https://pyjanitor-devs.github.io/pyjanitor/\" rel=\"nofollow noreferrer\">pyjanitor</a> library.</p>\n<p>For the other example, I'll use  <a href=\"https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.stack.html#pandas.DataFrame.stack\" rel=\"nofollow noreferrer\">stack</a> and <a href=\"https://pyjanitor-devs.github.io/pyjanitor/api/functions/#janitor.functions.pivot.pivot_longer\" rel=\"nofollow noreferrer\">pivot_longer</a>; you can still use <a href=\"https://pandas.pydata.org/docs/reference/api/pandas.wide_to_long.html\" rel=\"nofollow noreferrer\">pd.wide_to_long</a> to solve it.</p>\n<p>With <a href=\"https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.stack.html#pandas.DataFrame.stack\" rel=\"nofollow noreferrer\">stack</a>:</p>\n<p>first split the columns and convert into a MultiIndex:</p>\n<pre><code>temp = df.copy()\ntemp.columns = temp.columns.str.split(&quot;.&quot;, expand = True)\n</code></pre>\n<p>Reshape the data:</p>\n<pre><code>temp = temp.stack(1).droplevel(0).rename_axis('side')\n</code></pre>\n<p>Merge the column names:</p>\n<pre><code>temp.columns = temp.columns.map(&quot;.&quot;.join)\n</code></pre>\n<p>Reset the index:</p>\n<pre><code>temp.reset_index()\n\n  side  foo.a  foo.b  foo.c  foo.d  foo.e  foo.f  foo.g\n0   p1      4      1      2      3      4      5      6\n1   p2      0      3      6      9     12     15     18\n2   p1      0      4      8     12     16     20     24\n3   p2      0     12     24     36     48     60     72\n</code></pre>\n<p>With <a href=\"https://pyjanitor-devs.github.io/pyjanitor/api/functions/#janitor.functions.pivot.pivot_longer\" rel=\"nofollow noreferrer\">pivot_longer</a>, one option is to reorder the columns, before reshaping:</p>\n<pre class=\"lang-py prettyprint-override\"><code>temp = df.copy()\n\ntemp.columns = [&quot;&quot;.join([first, last, middle]) \n                for first, middle, last in \n                temp.columns.str.split(r'(\\.p\\d)')]\n\n(\ntemp\n.pivot_longer(\n    index = None, \n    names_to = ('.value', 'side'), \n    names_pattern = r&quot;(.+)\\.(p\\d)&quot;)\n)\n  side  foo.a  foo.b  foo.c  foo.d  foo.e  foo.f  foo.g\n0   p1      4      1      2      3      4      5      6\n1   p1      0      4      8     12     16     20     24\n2   p2      0      3      6      9     12     15     18\n3   p2      0     12     24     36     48     60     72\n</code></pre>\n<p>In the <a href=\"https://github.com/pyjanitor-devs/pyjanitor\" rel=\"nofollow noreferrer\">dev</a> version however, the column reorder is not necessary; we can simply use multiple <code>.value</code> to reshape the dataframe - note that you'll have to install from the repo to get the latest dev version:</p>\n<pre class=\"lang-py prettyprint-override\"><code># pip install git+https://github.com/pyjanitor-devs/pyjanitor.git\n(df\n.pivot_longer(\n    index = None, \n    names_to = ('.value', 'side', '.value'), \n    names_pattern = r&quot;(.+)\\.(.\\d)(.+)&quot;)\n)\n  side  foo.a  foo.b  foo.c  foo.d  foo.e  foo.f  foo.g\n0   p1      4      1      2      3      4      5      6\n1   p1      0      4      8     12     16     20     24\n2   p2      0      3      6      9     12     15     18\n3   p2      0     12     24     36     48     60     72\n</code></pre>\n<p>Another option with <code>names_sep</code>:</p>\n<pre class=\"lang-py prettyprint-override\"><code>(df\n.pivot_longer(\n    index = None, \n    names_to = ('.value', 'side', '.value'), \n    names_sep = r'\\.(p\\d)')\n)\n  side  foo.a  foo.b  foo.c  foo.d  foo.e  foo.f  foo.g\n0   p1      4      1      2      3      4      5      6\n1   p1      0      4      8     12     16     20     24\n2   p2      0      3      6      9     12     15     18\n3   p2      0     12     24     36     48     60     72\n</code></pre>\n",
                    "OwnerUserId": "7175713",
                    "LastEditorUserId": "7175713",
                    "LastEditDate": "2022-04-21T13:41:05.803",
                    "LastActivityDate": "2022-04-21T13:41:05.803",
                    "CommentCount": "4",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "67561229",
                "ParentRepo": "https://github.com/uktrade/stream-unzip",
                "StackOverflow_Post": {
                    "Id": "67561229",
                    "PostTypeId": "2",
                    "ParentId": "67554520",
                    "CreationDate": "2021-05-16T20:19:28.790",
                    "Score": "0",
                    "Body": "<p>It is possible to do this from within Python, without calling to an external process, <em>and</em> it can handle all the files in the zip, not just the first.</p>\n<p>This can be done by using <a href=\"https://github.com/uktrade/stream-unzip\" rel=\"nofollow noreferrer\">stream-unzip</a> [disclaimer: written by me].</p>\n<pre class=\"lang-py prettyprint-override\"><code>from stream_unzip import stream_unzip\nimport httpx\n\ndef zipped_chunks():\n    with httpx.stream('GET', 'https://www.example.com/my.zip') as r:\n        yield from r.iter_bytes()\n\nfor file_name, file_size, file_chunks in stream_unzip(zipped_chunks()):\n    for chunk in file_chunks:\n        print(chunk)\n</code></pre>\n",
                    "OwnerUserId": "1319998",
                    "LastEditorUserId": "1319998",
                    "LastEditDate": "2021-05-19T06:24:29.947",
                    "LastActivityDate": "2021-05-19T06:24:29.947",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "67569873",
                "ParentRepo": "https://github.com/runningcode/gradle-doctor",
                "StackOverflow_Post": {
                    "Id": "67569873",
                    "PostTypeId": "2",
                    "ParentId": "45327617",
                    "CreationDate": "2021-05-17T12:41:12.200",
                    "Score": "2",
                    "Body": "<p>My case was completely different. I dont know why but it was caused by this line</p>\n<p><code>maven { url &quot;https://dl.bintray.com/crysis21/Android&quot; }</code></p>\n<p>It instantly improved build speed by about 99%...\nSo look for such links in your project and if there is any you dont need then remove them.</p>\n<p>Also check out <a href=\"https://github.com/runningcode/gradle-doctor\" rel=\"nofollow noreferrer\">Gradle Doctor</a> and <a href=\"https://www.youtube.com/watch?v=lgaqS0pmUzk\" rel=\"nofollow noreferrer\">The Secrets of the Build Scan Plugin and the internals of Gradle by Nelson Osacky, Soundcloud EN</a></p>\n",
                    "OwnerUserId": "4885394",
                    "LastActivityDate": "2021-05-17T12:41:12.200",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "67577364",
                "ParentRepo": "https://github.com/aio-libs/aioredis-py/blob/ff5a8fe068ebda837d14c3b3777a6182e610854a/aioredis/client.py#L1012",
                "StackOverflow_Post": {
                    "Id": "67577364",
                    "PostTypeId": "2",
                    "ParentId": "54770360",
                    "CreationDate": "2021-05-17T21:41:55.380",
                    "Score": "11",
                    "Body": "<p>As @Martijn Pieters said, you can't force the event loop to wait for an object's <code>__del__</code> destructor call. However, you can still use the <code>__del__</code> destructor to close asynchronous resources by first checking if the loop is running and starting a new loop if it's not. For example, the asyncio Redis module uses this technique <a href=\"https://github.com/aio-libs/aioredis-py/blob/ff5a8fe068ebda837d14c3b3777a6182e610854a/aioredis/client.py#L1012\" rel=\"noreferrer\">when destructing its Client class</a>. For your code, specifically, the the destructor would be as follows:</p>\n<pre class=\"lang-py prettyprint-override\"><code>import asyncio\nimport aiohttp\n\n\nclass MyAPI:\n\n    def __init__(self):\n        self.session = aiohttp.ClientSession()\n\n    def __del__(self):\n        # Close connection when this object is destroyed\n        try:\n            loop = asyncio.get_event_loop()\n            if loop.is_running():\n                loop.create_task(self.session.close())\n            else:\n                loop.run_until_complete(self.session.close())\n        except Exception:\n            pass\n</code></pre>\n",
                    "OwnerUserId": "1510445",
                    "LastEditorUserId": "1510445",
                    "LastEditDate": "2021-05-18T16:50:54.003",
                    "LastActivityDate": "2021-05-18T16:50:54.003",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "67602065",
                "ParentRepo": "https://github.com/ashnair1/COCO-Assistant",
                "StackOverflow_Post": {
                    "Id": "67602065",
                    "PostTypeId": "2",
                    "ParentId": "67061435",
                    "CreationDate": "2021-05-19T11:08:28.683",
                    "Score": "2",
                    "Body": "<p>Answering my own question. Apparently, there is no such method to try the multiple datasets. If you like to combine different datasets then use the <a href=\"https://github.com/ashnair1/COCO-Assistant\" rel=\"nofollow noreferrer\">COCO Assitant</a> library.</p>\n<p>Simple step to install is:</p>\n<pre><code>!pip install coco-assistant\n</code></pre>\n",
                    "OwnerUserId": "13716584",
                    "LastEditorUserId": "5752730",
                    "LastEditDate": "2021-12-29T01:36:28.633",
                    "LastActivityDate": "2021-12-29T01:36:28.633",
                    "CommentCount": "4",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "67603835",
                "ParentRepo": "https://github.com/ignc-research/arena-rosnav",
                "StackOverflow_Post": {
                    "Id": "67603835",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "67603964",
                    "CreationDate": "2021-05-19T13:02:47.820",
                    "Score": "1",
                    "ViewCount": "931",
                    "Body": "<p>I'm trying to install the code from this <a href=\"https://github.com/ignc-research/arena-rosnav\" rel=\"nofollow noreferrer\">git-repo</a> for a university project and I'm stuck because ld does not seem to be able to link lua properly. I followed the <a href=\"https://github.com/ignc-research/arena-rosnav/blob/local_planner_subgoalmode/docs/Installation.md\" rel=\"nofollow noreferrer\">install instructions</a> and compile the code with:</p>\n<pre><code>catkin_make -DCMAKE_BUILD_TYPE=Release -DPYTHON_EXECUTABLE=/usr/bin/python3 -DCMAKE_CXX_STANDARD=14 \n</code></pre>\n<p>which fails with several messages like:</p>\n<pre><code>/usr/bin/ld: /home/felixk/catkin_ws/devel/lib/libflatland_lib.so: undefined reference to `lua_toboolean(lua_State*, int)'\n/usr/bin/ld: /home/felixk/catkin_ws/devel/lib/libflatland_lib.so: undefined reference to `lua_tonumberx(lua_State*, int, int*)'\n...\n/usr/bin/ld: /home/felixk/catkin_ws/devel/lib/libflatland_lib.so: undefined reference to `lua_pushstring(lua_State*, char const*)'\n/usr/bin/ld: /home/felixk/catkin_ws/devel/lib/libflatland_lib.so: undefined reference to `lua_isstring(lua_State*, int)'\ncollect2: error: ld returned 1 exit status\n</code></pre>\n<p>The code was tested and works on Ubuntu 18.04 but I'm trying to get it to work on Manjaro. The manual states that <code>liblua5.2-dev</code> is needed and I installed <a href=\"https://archlinux.org/packages/extra/x86_64/lua52/\" rel=\"nofollow noreferrer\">lua52</a> from the AUR which seems to provide the right libraries.</p>\n<p>The output of <code>ldd</code> is:</p>\n<pre><code>ldd /home/felixk/catkin_ws/devel/lib/libflatland_lib.so | grep lua\n        liblua5.2.so.5.2 =&gt; /usr/lib/liblua5.2.so.5.2 (0x00007f23fd51c000)\n</code></pre>\n<p>Then I checked if <code>/usr/lib/liblua5.2.so.5.2</code> exists and it does. I tried to use <code>readelf</code> to check whether <code>liblua5.2.so.5.2</code> contains the <em>undefined references</em>:</p>\n<pre><code>readelf -s /usr/lib/liblua5.2.so.5.2                     \n\nSymbol table '.dynsym' contains 245 entries:\n   Num:    Value          Size Type    Bind   Vis      Ndx Name\n     0: 0000000000000000     0 NOTYPE  LOCAL  DEFAULT  UND \n     1: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND __[...]@GLIBC_2.3 (2)\n     2: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND [...]@GLIBC_2.2.5 (3)\n     3: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND free@GLIBC_2.2.5 (3)\n     4: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND abort@GLIBC_2.2.5 (3)\n     5: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND [...]@GLIBC_2.2.5 (3)\n     6: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND ldexp@GLIBC_2.2.5 (4)\n     7: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND [...]@GLIBC_2.2.5 (3)\n     8: 0000000000000000     0 NOTYPE  WEAK   DEFAULT  UND _ITM_deregisterT[...]\n     9: 0000000000000000     0 OBJECT  GLOBAL DEFAULT  UND [...]@GLIBC_2.2.5 (3)\n    10: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND [...]@GLIBC_2.2.5 (3)\n    11: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND __[...]@GLIBC_2.7 (5)\n    12: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND [...]@GLIBC_2.2.5 (3)\n    13: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND fread@GLIBC_2.2.5 (3)\n    14: 0000000000000000     0 OBJECT  GLOBAL DEFAULT  UND stdin@GLIBC_2.2.5 (3)\n    15: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND [...]@GLIBC_2.2.5 (3)\n    16: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND [...]@GLIBC_2.2.5 (3)\n    17: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND atan@GLIBC_2.2.5 (4)\n    18: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND pow@GLIBC_2.29 (6)\n    19: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND clock@GLIBC_2.2.5 (3)\n    20: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND [...]@GLIBC_2.2.5 (3)\n    21: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND [...]@GLIBC_2.2.5 (3)\n    22: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND __[...]@GLIBC_2.4 (7)\n    23: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND [...]@GLIBC_2.2.5 (3)\n    24: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND [...]@GLIBC_2.2.5 (3)\n    25: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND [...]@GLIBC_2.2.5 (3)\n    26: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND [...]@GLIBC_2.2.5 (3)\n    27: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND modf@GLIBC_2.2.5 (4)\n    28: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND [...]@GLIBC_2.2.5 (3)\n    29: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND [...]@GLIBC_2.2.5 (3)\n    30: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND [...]@GLIBC_2.2.5 (3)\n    31: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND close@GLIBC_2.2.5 (3)\n    32: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND log@GLIBC_2.29 (6)\n    33: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND fmod@GLIBC_2.2.5 (4)\n    34: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND [...]@GLIBC_2.2.5 (3)\n    35: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND cos@GLIBC_2.2.5 (4)\n    36: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND [...]@GLIBC_2.2.5 (3)\n    37: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND [...]@GLIBC_2.2.5 (3)\n    38: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND acos@GLIBC_2.2.5 (4)\n    39: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND srand@GLIBC_2.2.5 (3)\n    40: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND [...]@GLIBC_2.2.5 (3)\n    41: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND fgets@GLIBC_2.2.5 (3)\n    42: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND frexp@GLIBC_2.2.5 (4)\n    43: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND [...]@GLIBC_2.2.5 (3)\n    44: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND [...]@GLIBC_2.2.5 (3)\n    45: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND log10@GLIBC_2.2.5 (4)\n    46: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND [...]@GLIBC_2.3.4 (8)\n    47: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND feof@GLIBC_2.2.5 (3)\n    48: 0000000000000000     0 NOTYPE  WEAK   DEFAULT  UND __gmon_start__\n    49: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND [...]@GLIBC_2.2.5 (3)\n    50: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND [...]@GLIBC_2.2.5 (3)\n    51: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND memcpy@GLIBC_2.14 (9)\n    52: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND [...]@GLIBC_2.2.5 (3)\n    53: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND cosh@GLIBC_2.2.5 (4)\n    54: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND time@GLIBC_2.2.5 (3)\n    55: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND [...]@GLIBC_2.2.5 (10)\n    56: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND sinh@GLIBC_2.2.5 (4)\n    57: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND [...]@GLIBC_2.2.5 (3)\n    58: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND tan@GLIBC_2.2.5 (4)\n    59: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND [...]@GLIBC_2.2.5 (3)\n    60: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND [...]@GLIBC_2.2.5 (3)\n    61: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND [...]@GLIBC_2.2.5 (3)\n    62: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND atan2@GLIBC_2.2.5 (4)\n    63: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND [...]@GLIBC_2.2.5 (3)\n    64: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND [...]@GLIBC_2.2.5 (3)\n    65: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND [...]@GLIBC_2.2.5 (3)\n    66: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND [...]@GLIBC_2.2.5 (10)\n    67: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND [...]@GLIBC_2.2.5 (3)\n    68: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND [...]@GLIBC_2.2.5 (3)\n    69: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND [...]@GLIBC_2.2.5 (3)\n    70: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND [...]@GLIBC_2.11 (11)\n    71: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND [...]@GLIBC_2.2.5 (3)\n    72: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND popen@GLIBC_2.2.5 (3)\n    73: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND fopen@GLIBC_2.2.5 (3)\n    74: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND [...]@GLIBC_2.2.5 (3)\n    75: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND sin@GLIBC_2.2.5 (4)\n    76: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND tanh@GLIBC_2.2.5 (4)\n    77: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND asin@GLIBC_2.2.5 (4)\n    78: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND exit@GLIBC_2.2.5 (3)\n    79: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND [...]@GLIBC_2.2.5 (3)\n    80: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND [...]@GLIBC_2.3.4 (8)\n    81: 0000000000000000     0 NOTYPE  WEAK   DEFAULT  UND _ITM_registerTMC[...]\n    82: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND sqrt@GLIBC_2.2.5 (4)\n    83: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND [...]@GLIBC_2.2.5 (3)\n    84: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND [...]@GLIBC_2.2.5 (10)\n    85: 0000000000000000     0 FUNC    WEAK   DEFAULT  UND [...]@GLIBC_2.2.5 (3)\n    86: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND getc@GLIBC_2.2.5 (3)\n    87: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND [...]@GLIBC_2.2.5 (3)\n    88: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND exp@GLIBC_2.29 (6)\n    89: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND rand@GLIBC_2.2.5 (3)\n    90: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND [...]@GLIBC_2.2.5 (10)\n    91: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND __[...]@GLIBC_2.3 (2)\n    92: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND __[...]@GLIBC_2.3 (2)\n    93: 0000000000000000     0 OBJECT  GLOBAL DEFAULT  UND [...]@GLIBC_2.2.5 (3)\n    94: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND [...]@GLIBC_2.3.4 (8)\n    95: 0000000000007680   135 FUNC    GLOBAL DEFAULT    9 lua_arith\n    96: 0000000000008640    32 FUNC    GLOBAL DEFAULT    9 lua_getctx\n    97: 00000000000085d0    97 FUNC    GLOBAL DEFAULT    9 lua_setuservalue\n    98: 0000000000008bd0    24 FUNC    GLOBAL DEFAULT    9 lua_getallocf\n    99: 00000000000086f0   273 FUNC    GLOBAL DEFAULT    9 lua_pcallk\n   100: 0000000000007a80    47 FUNC    GLOBAL DEFAULT    9 lua_touserdata\n   101: 000000000000aff0  1192 FUNC    GLOBAL DEFAULT    9 lua_getinfo\n   102: 000000000001b420   169 FUNC    GLOBAL DEFAULT    9 luaL_openlib\n   103: 0000000000007460    60 FUNC    GLOBAL DEFAULT    9 lua_insert\n   104: 0000000000007580    83 FUNC    GLOBAL DEFAULT    9 lua_isnumber\n   105: 00000000000149d0   231 FUNC    GLOBAL DEFAULT    9 lua_newthread\n   106: 0000000000024d90   117 FUNC    GLOBAL DEFAULT    9 luaL_openlibs\n   107: 000000000001b360   183 FUNC    GLOBAL DEFAULT    9 luaL_setfuncs\n   108: 000000000001ae50   275 FUNC    GLOBAL DEFAULT    9 luaL_tolstring\n   109: 00000000000074a0    30 FUNC    GLOBAL DEFAULT    9 lua_replace\n   110: 000000000001a840    38 FUNC    GLOBAL DEFAULT    9 luaL_buffinitsize\n   111: 0000000000008df0    72 FUNC    GLOBAL DEFAULT    9 lua_upvalueid\n   112: 0000000000007ef0   108 FUNC    GLOBAL DEFAULT    9 lua_getglobal\n   113: 00000000000209c0    42 FUNC    GLOBAL DEFAULT    9 luaopen_os\n   114: 000000000001a870   214 FUNC    GLOBAL DEFAULT    9 luaL_ref\n   115: 000000000000ae00     5 FUNC    GLOBAL DEFAULT    9 lua_gethook\n   116: 0000000000007370    24 FUNC    GLOBAL DEFAULT    9 lua_version\n   117: 0000000000008260    39 FUNC    GLOBAL DEFAULT    9 lua_settable\n   118: 0000000000019b40   159 FUNC    GLOBAL DEFAULT    9 luaL_where\n   119: 000000000001a1f0    63 FUNC    GLOBAL DEFAULT    9 luaL_checktype\n   120: 000000000001a230    58 FUNC    GLOBAL DEFAULT    9 luaL_checkany\n   121: 0000000000019e90   132 FUNC    GLOBAL DEFAULT    9 luaL_fileresult\n   122: 000000000001a5b0    57 FUNC    GLOBAL DEFAULT    9 luaL_optunsigned\n   123: 0000000000008e40    92 FUNC    GLOBAL DEFAULT    9 lua_upvaluejoin\n   124: 000000000001a050    33 FUNC    GLOBAL DEFAULT    9 luaL_setmetatable\n   125: 000000000001a9b0   656 FUNC    GLOBAL DEFAULT    9 luaL_loadfilex\n   126: 0000000000008c00    76 FUNC    GLOBAL DEFAULT    9 lua_newuserdata\n   127: 0000000000007600    26 FUNC    GLOBAL DEFAULT    9 lua_isuserdata\n   128: 000000000001a2c0   106 FUNC    GLOBAL DEFAULT    9 luaL_optlstring\n   129: 000000000001a6f0    44 FUNC    GLOBAL DEFAULT    9 luaL_addstring\n   130: 0000000000007390    34 FUNC    GLOBAL DEFAULT    9 lua_absindex\n   131: 0000000000007c40    98 FUNC    GLOBAL DEFAULT    9 lua_pushstring\n   132: 00000000000078a0   133 FUNC    GLOBAL DEFAULT    9 lua_tounsignedx\n   133: 0000000000008660   135 FUNC    GLOBAL DEFAULT    9 lua_callk\n   134: 0000000000007560    26 FUNC    GLOBAL DEFAULT    9 lua_iscfunction\n   135: 000000000001ad60    85 FUNC    GLOBAL DEFAULT    9 luaL_callmeta\n   136: 000000000001c470   127 FUNC    GLOBAL DEFAULT    9 luaopen_base\n   137: 00000000000250e0   129 OBJECT  GLOBAL DEFAULT   11 lua_ident\n   138: 0000000000008810   219 FUNC    GLOBAL DEFAULT    9 lua_load\n   139: 000000000001acd0   139 FUNC    GLOBAL DEFAULT    9 luaL_getmetafield\n   140: 0000000000007fe0    44 FUNC    GLOBAL DEFAULT    9 lua_rawget\n   141: 00000000000074c0    37 FUNC    GLOBAL DEFAULT    9 lua_copy\n   142: 0000000000008290    94 FUNC    GLOBAL DEFAULT    9 lua_setfield\n   143: 00000000000072e0   102 FUNC    GLOBAL DEFAULT    9 lua_xmove\n   144: 000000000001f430   216 FUNC    GLOBAL DEFAULT    9 luaopen_io\n   145: 0000000000008d10   221 FUNC    GLOBAL DEFAULT    9 lua_setupvalue\n   146: 0000000000019cd0   315 FUNC    GLOBAL DEFAULT    9 luaL_argerror\n   147: 00000000000080c0   102 FUNC    GLOBAL DEFAULT    9 lua_createtable\n   148: 0000000000007350    22 FUNC    GLOBAL DEFAULT    9 lua_atpanic\n   149: 0000000000008010    50 FUNC    GLOBAL DEFAULT    9 lua_rawgeti\n   150: 000000000000c7a0   155 FUNC    GLOBAL DEFAULT    9 lua_yieldk\n   151: 0000000000008b10   145 FUNC    GLOBAL DEFAULT    9 lua_concat\n   152: 000000000001a330   157 FUNC    GLOBAL DEFAULT    9 luaL_checkoption\n   153: 0000000000008050   108 FUNC    GLOBAL DEFAULT    9 lua_rawgetp\n   154: 0000000000008930   391 FUNC    GLOBAL DEFAULT    9 lua_gc\n   155: 00000000000073e0    64 FUNC    GLOBAL DEFAULT    9 lua_settop\n   156: 000000000001b040   127 FUNC    GLOBAL DEFAULT    9 luaL_getsubtable\n   157: 0000000000007dd0   175 FUNC    GLOBAL DEFAULT    9 lua_pushcclosure\n   158: 000000000001ac40    72 FUNC    GLOBAL DEFAULT    9 luaL_loadbufferx\n   159: 0000000000008bf0    12 FUNC    GLOBAL DEFAULT    9 lua_setallocf\n   160: 0000000000007b30    20 FUNC    GLOBAL DEFAULT    9 lua_pushnil\n   161: 0000000000007a50    39 FUNC    GLOBAL DEFAULT    9 lua_tocfunction\n   162: 000000000001a490   109 FUNC    GLOBAL DEFAULT    9 luaL_checkinteger\n   163: 0000000000019f20   175 FUNC    GLOBAL DEFAULT    9 luaL_execresult\n   164: 000000000000ae10     5 FUNC    GLOBAL DEFAULT    9 lua_gethookmask\n   165: 00000000000082f0   126 FUNC    GLOBAL DEFAULT    9 lua_rawset\n   166: 0000000000008920     5 FUNC    GLOBAL DEFAULT    9 lua_status\n   167: 0000000000008ad0    50 FUNC    GLOBAL DEFAULT    9 lua_next\n   168: 000000000001a180   105 FUNC    GLOBAL DEFAULT    9 luaL_checkstack\n   169: 00000000000081e0   119 FUNC    GLOBAL DEFAULT    9 lua_setglobal\n   170: 000000000001a440    67 FUNC    GLOBAL DEFAULT    9 luaL_optnumber\n   171: 0000000000007420    55 FUNC    GLOBAL DEFAULT    9 lua_remove\n   172: 000000000000af50   154 FUNC    GLOBAL DEFAULT    9 lua_setlocal\n   173: 0000000000019fd0   122 FUNC    GLOBAL DEFAULT    9 luaL_newmetatable\n   174: 0000000000014b10    16 FUNC    GLOBAL DEFAULT    9 lua_close\n   175: 000000000000ae20     4 FUNC    GLOBAL DEFAULT    9 lua_gethookcount\n   176: 00000000000077a0   119 FUNC    GLOBAL DEFAULT    9 lua_tonumberx\n   177: 0000000000007cb0    64 FUNC    GLOBAL DEFAULT    9 lua_pushvfstring\n   178: 0000000000007710   143 FUNC    GLOBAL DEFAULT    9 lua_compare\n   179: 0000000000007e80    29 FUNC    GLOBAL DEFAULT    9 lua_pushboolean\n   180: 0000000000007f60    38 FUNC    GLOBAL DEFAULT    9 lua_gettable\n   181: 000000000001ffa0   118 FUNC    GLOBAL DEFAULT    9 luaopen_math\n   182: 0000000000007ba0    53 FUNC    GLOBAL DEFAULT    9 lua_pushunsigned\n   183: 000000000001b0c0   174 FUNC    GLOBAL DEFAULT    9 luaL_requiref\n   184: 000000000000c650   328 FUNC    GLOBAL DEFAULT    9 lua_resume\n   185: 0000000000008370   110 FUNC    GLOBAL DEFAULT    9 lua_rawseti\n   186: 00000000000088f0    41 FUNC    GLOBAL DEFAULT    9 lua_dump\n   187: 000000000001adc0   130 FUNC    GLOBAL DEFAULT    9 luaL_len\n   188: 0000000000022f50   167 FUNC    GLOBAL DEFAULT    9 luaopen_string\n   189: 0000000000007ec0    40 FUNC    GLOBAL DEFAULT    9 lua_pushthread\n   190: 000000000001b170   224 FUNC    GLOBAL DEFAULT    9 luaL_gsub\n   191: 0000000000008c50   181 FUNC    GLOBAL DEFAULT    9 lua_getupvalue\n   192: 00000000000083e0   174 FUNC    GLOBAL DEFAULT    9 lua_rawsetp\n   193: 0000000000007be0    88 FUNC    GLOBAL DEFAULT    9 lua_pushlstring\n   194: 000000000001a720    71 FUNC    GLOBAL DEFAULT    9 luaL_pushresult\n   195: 000000000000adc0    54 FUNC    GLOBAL DEFAULT    9 lua_sethook\n   196: 00000000000075e0    27 FUNC    GLOBAL DEFAULT    9 lua_isstring\n   197: 0000000000019820   800 FUNC    GLOBAL DEFAULT    9 luaL_traceback\n   198: 000000000001a5f0   193 FUNC    GLOBAL DEFAULT    9 luaL_prepbuffsize\n   199: 000000000001a120    85 FUNC    GLOBAL DEFAULT    9 luaL_checkudata\n   200: 0000000000008ac0     9 FUNC    GLOBAL DEFAULT    9 lua_error\n   201: 000000000001a950    83 FUNC    GLOBAL DEFAULT    9 luaL_unref\n   202: 000000000001e150    42 FUNC    GLOBAL DEFAULT    9 luaopen_debug\n   203: 000000000001b280   217 FUNC    GLOBAL DEFAULT    9 luaL_checkversion_\n   204: 000000000001caa0    42 FUNC    GLOBAL DEFAULT    9 luaopen_bit32\n   205: 0000000000007b50    25 FUNC    GLOBAL DEFAULT    9 lua_pushnumber\n   206: 000000000001a780   146 FUNC    GLOBAL DEFAULT    9 luaL_addvalue\n   207: 000000000001a500   107 FUNC    GLOBAL DEFAULT    9 luaL_checkunsigned\n   208: 000000000001a6c0    46 FUNC    GLOBAL DEFAULT    9 luaL_addlstring\n   209: 0000000000007ab0    21 FUNC    GLOBAL DEFAULT    9 lua_tothread\n   210: 000000000001cf50    42 FUNC    GLOBAL DEFAULT    9 luaopen_coroutine\n   211: 0000000000007620    87 FUNC    GLOBAL DEFAULT    9 lua_rawequal\n   212: 00000000000074f0    33 FUNC    GLOBAL DEFAULT    9 lua_pushvalue\n   213: 0000000000008130   105 FUNC    GLOBAL DEFAULT    9 lua_getmetatable\n   214: 0000000000014720   683 FUNC    GLOBAL DEFAULT    9 lua_newstate\n   215: 0000000000007b70    34 FUNC    GLOBAL DEFAULT    9 lua_pushinteger\n   216: 0000000000023b40    79 FUNC    GLOBAL DEFAULT    9 luaopen_table\n   217: 0000000000007f90    79 FUNC    GLOBAL DEFAULT    9 lua_getfield\n   218: 000000000001a570    57 FUNC    GLOBAL DEFAULT    9 luaL_optinteger\n   219: 0000000000019be0   234 FUNC    GLOBAL DEFAULT    9 luaL_error\n   220: 0000000000007930    47 FUNC    GLOBAL DEFAULT    9 lua_toboolean\n   221: 0000000000007ea0    23 FUNC    GLOBAL DEFAULT    9 lua_pushlightuserdata\n   222: 00000000000079e0   111 FUNC    GLOBAL DEFAULT    9 lua_rawlen\n   223: 0000000000007230   162 FUNC    GLOBAL DEFAULT    9 lua_checkstack\n   224: 0000000000007cf0   218 FUNC    GLOBAL DEFAULT    9 lua_pushfstring\n   225: 0000000000008490   317 FUNC    GLOBAL DEFAULT    9 lua_setmetatable\n   226: 0000000000007ad0    96 FUNC    GLOBAL DEFAULT    9 lua_topointer\n   227: 0000000000007540    18 FUNC    GLOBAL DEFAULT    9 lua_typename\n   228: 0000000000007960   128 FUNC    GLOBAL DEFAULT    9 lua_tolstring\n   229: 000000000001a820    28 FUNC    GLOBAL DEFAULT    9 luaL_buffinit\n   230: 000000000001a770    10 FUNC    GLOBAL DEFAULT    9 luaL_pushresultsize\n   231: 000000000001af70   207 FUNC    GLOBAL DEFAULT    9 luaL_pushmodule\n   232: 000000000001b250    47 FUNC    GLOBAL DEFAULT    9 luaL_newstate\n   233: 000000000001a080   148 FUNC    GLOBAL DEFAULT    9 luaL_testudata\n   234: 0000000000007520    30 FUNC    GLOBAL DEFAULT    9 lua_type\n   235: 000000000000ae80   199 FUNC    GLOBAL DEFAULT    9 lua_getlocal\n   236: 000000000001a270    77 FUNC    GLOBAL DEFAULT    9 luaL_checklstring\n   237: 0000000000008bb0    31 FUNC    GLOBAL DEFAULT    9 lua_len\n   238: 000000000000ae30    79 FUNC    GLOBAL DEFAULT    9 lua_getstack\n   239: 000000000001ac90    50 FUNC    GLOBAL DEFAULT    9 luaL_loadstring\n   240: 00000000000081a0    64 FUNC    GLOBAL DEFAULT    9 lua_getuservalue\n   241: 00000000000073c0    23 FUNC    GLOBAL DEFAULT    9 lua_gettop\n   242: 0000000000007820   117 FUNC    GLOBAL DEFAULT    9 lua_tointegerx\n   243: 0000000000024b50   568 FUNC    GLOBAL DEFAULT    9 luaopen_package\n   244: 000000000001a3d0   111 FUNC    GLOBAL DEFAULT    9 luaL_checknumber\n\n</code></pre>\n<p>It seems like all the <em>undefined references</em> exist in  <code>/usr/lib/liblua5.2.so.5.2</code> and I don't know how to go on from here.</p>\n<p><a href=\"https://stackoverflow.com/questions/14060009/undefined-reference-to-using-lua\">Other answers on SO</a> suggest to put the #includes of lua into a <code>extern &quot;C&quot;</code> like so:</p>\n<pre><code>extern &quot;C&quot;{\n    #include &lt;lua5.2/lualib.h&gt;\n    #include &lt;lua5.2/lauxlib.h&gt;\n    #include &lt;lua5.2/lua.h&gt;\n}\n</code></pre>\n<p>But I would rather not change the given code and wouldn't even know how to find out in which files lua is #included .</p>\n<p>Optimally I would only like to change the make command <code>catkin_make -DCMAKE_BUILD_TYPE=Release -DPYTHON_EXECUTABLE=/usr/bin/python3 -DCMAKE_CXX_STANDARD=14</code> to help <code>ld</code> to properly link but I don't know if thats possible. I'm not really familiar with <code>make</code>, <code>cmake</code> or in this case <code>catkin_make</code> and couldn't find out if it is possible to add linker options in the <code>make</code> command.</p>\n",
                    "OwnerUserId": "14105112",
                    "LastEditorUserId": "5494721",
                    "LastEditDate": "2022-08-12T11:50:24.417",
                    "LastActivityDate": "2022-08-12T11:50:24.417",
                    "Title": "ld: undefined reference to `lua_`. I don't know why ld cannot reference lua even though its there",
                    "Tags": "<c++><lua><ld><archlinux><manjaro>",
                    "AnswerCount": "2",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "67611597",
                "ParentRepo": "https://github.com/sonos/tract/blob/68db0209c9ffd1b91dff82884f4ae03b3622dd34/examples/onnx-mobilenet-v2/src/main.rs",
                "StackOverflow_Post": {
                    "Id": "67611597",
                    "PostTypeId": "1",
                    "CreationDate": "2021-05-19T22:15:23.587",
                    "Score": "0",
                    "ViewCount": "400",
                    "Body": "<p>I'm trying to translate a Python script using onnxruntime to Rust using tract_onnx. The specific POC I'm trying to implement is <a href=\"https://github.com/onnx/models/blob/master/vision/body_analysis/age_gender/rothe_vgg.py\" rel=\"nofollow noreferrer\">the <code>rothe_vgg.py</code> script</a> from the ONNX Model Zoo. This script uses three models:</p>\n<ul>\n<li>ultraface face detection (<a href=\"https://github.com/onnx/models/blob/master/vision/body_analysis/ultraface/models/version-RFB-320.onnx\" rel=\"nofollow noreferrer\"><code>version-RFB-320.onnx</code></a>)</li>\n<li><code>vgg_ilsvrc_16_age_imdb_wiki.onnx</code> and <code>vgg_ilsvrc_16_gender_imdb_wiki.onnx</code> <a href=\"https://github.com/onnx/models/tree/master/vision/body_analysis/age_gender#models\" rel=\"nofollow noreferrer\">age and gender models</a></li>\n</ul>\n<p>For now, I'm trying just the first model to detect faces. I can get <a href=\"https://github.com/onnx/models/blob/41ccf18ba5a815dab714899ac234e9b1e4293c20/vision/body_analysis/age_gender/rothe_vgg.py#L33\" rel=\"nofollow noreferrer\">the example Python code</a> to work:</p>\n<pre class=\"lang-py prettyprint-override\"><code>face_detector_onnx = &quot;models/version-RFB-320.onnx&quot;\nface_detector = ort.InferenceSession(face_detector_onnx)\n\ndef faceDetector(orig_image, threshold = 0.7):\n    image = cv2.cvtColor(orig_image, cv2.COLOR_BGR2RGB)\n    image = cv2.resize(image, (320, 240))\n    image_mean = np.array([127, 127, 127])\n    image = (image - image_mean) / 128\n    image = np.transpose(image, [2, 0, 1])\n    image = np.expand_dims(image, axis=0)\n    image = image.astype(np.float32)\n\n    input_name = face_detector.get_inputs()[0].name\n    confidences, boxes = face_detector.run(None, {input_name: image})\n    boxes, labels, probs = predict(orig_image.shape[1], orig_image.shape[0], confidences, boxes, threshold)\n    return boxes, labels, probs\n</code></pre>\n<p>I'm basing my tract_onnx translation on the <a href=\"https://github.com/sonos/tract/blob/68db0209c9ffd1b91dff82884f4ae03b3622dd34/examples/onnx-mobilenet-v2/src/main.rs\" rel=\"nofollow noreferrer\">onnx-mobilenet-v2 example</a>. My version currently looks like this:</p>\n<pre class=\"lang-rust prettyprint-override\"><code>let model = onnx()\n        .model_for_path(&quot;version-RFB-320.onnx&quot;)?\n        .with_input_fact(\n            0,\n            InferenceFact::dt_shape(f32::datum_type(), tvec!(1, 3, 240, 320)),\n        )?\n        .into_optimized()?\n        .into_runnable()?;\n\nlet image = image::open(&quot;bruce.jpg&quot;).unwrap().to_rgb8();\nlet resized = image::imageops::resize(&amp;image, 240, 320, ::image::imageops::FilterType::Triangle);\n\nlet image: Tensor = tract_ndarray::Array4::from_shape_fn((1, 3, 240, 320), |(_, c, y, x)| {\n    resized[(x as _, y as _)][c] as f32 / 255.0\n}).into();\n\nlet result = model.run(tvec!(image))?;\n</code></pre>\n<p>I'm running into an issue with the translation of the resized image into a tensor:</p>\n<pre><code>thread 'main' panicked at 'Image index (240, 0) out of bounds (240, 320)'.\n</code></pre>\n<p>Is this an issue of not having the right dimensions or the right ordering of each dimension? Am I missing something?</p>\n<p>I know I haven't yet implemented the other translations, which are my next questions: how can I properly normalize with <code>image_mean</code>, transpose, and expand dimensionality?</p>\n",
                    "OwnerUserId": "1191181",
                    "LastActivityDate": "2021-07-02T10:47:00.850",
                    "Title": "How can I translate Python onnxruntime code to Rust tract_onnx?",
                    "Tags": "<machine-learning><rust><onnx><onnxruntime>",
                    "AnswerCount": "1",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "67767314",
                "ParentRepo": "https://github.com/zix99/rare",
                "StackOverflow_Post": {
                    "Id": "67767314",
                    "PostTypeId": "2",
                    "ParentId": "6044539",
                    "CreationDate": "2021-05-31T02:32:43.620",
                    "Score": "0",
                    "Body": "<p>I had a similar problem as described, but across gigabytes of gzip'd log files.  Because many of these solutions necessitated waiting until all the data was parsed, I opted to write <a href=\"https://github.com/zix99/rare\" rel=\"nofollow noreferrer\">rare</a> to quickly parse and aggregate data based on a regexp.</p>\n<p>In the case above, it's as simple as passing in the data to the histogram function:</p>\n<pre class=\"lang-sh prettyprint-override\"><code>rare histo input.txt\n# OR\ncat input.txt | rare histo\n\n# Outputs:\n1                   3         \n0                   1         \n2                   1         \n3                   1\n</code></pre>\n<p>But it can also handle more complex cases via regex/expressions, such as:</p>\n<pre class=\"lang-sh prettyprint-override\"><code>rare histo --match &quot;(\\d+)&quot; --extract &quot;{1}&quot; input.txt\n</code></pre>\n",
                    "OwnerUserId": "3148325",
                    "LastActivityDate": "2021-05-31T02:32:43.620",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "67805404",
                "ParentRepo": "https://github.com/kvesteri/validators/blob/master/validators/url.py#L12-L14",
                "StackOverflow_Post": {
                    "Id": "67805404",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "67805984",
                    "CreationDate": "2021-06-02T12:48:34.713",
                    "Score": "0",
                    "ViewCount": "86",
                    "Body": "<p>I am a Python beginner. Python versions 3.8 and 3.9</p>\n<p>In an existing URL validation code, I ran into issues with the password containing '['. The password is <strong>PN-[.d.g5(R{bK}[5ZLx,4~K*hHrSy32=q+</strong></p>\n<p>URL:</p>\n<pre><code>&quot;https://p124_ddm028127:PN-[.d.g5(R{bK}[5ZLx,4~K*hHrSy32=q+@git.net/scm/sample-config.git&quot;\n</code></pre>\n<p>The code that is failing uses the validators==0.18.1 package:</p>\n<pre><code>if validators.url(url):\n//other code\n</code></pre>\n<p>I checked the <a href=\"https://github.com/kvesteri/validators/blob/master/validators/url.py#L12-L14\" rel=\"nofollow noreferrer\">regex used by the validators library</a>, it uses the following for username and password:</p>\n<pre><code># user:pass authentication\nr&quot;(?:[-a-z\\u00a1-\\uffff0-9._~%!$&amp;'()*+,;=:]+&quot;\nr&quot;(?::[-a-z0-9._~%!$&amp;'()*+,;=:]*)?@)?&quot;\n</code></pre>\n<p>I decided to write a simple test using the above regex but adding the square brackets as valid input. I tried the following:</p>\n<ul>\n<li>I read many threads on SOF and other places which suggested using a '' to escape the square brackets. This didn't work.</li>\n</ul>\n<pre><code>#user:pass authentication\nr&quot;(?:[-a-z\\u00a1-\\uffff0-9._~%!$&amp;'()*+,;=:]+&quot;\nr&quot;(?::[-a-z0-9._\\[\\]~%!$&amp;'()*+,;=:]*)?@)?&quot;\n</code></pre>\n<ul>\n<li>Adding the Unicode values of the square brackets, in vain.</li>\n<li>Instead of validators, tried urllib.urlparse</li>\n</ul>\n<pre><code>def url_parse(url):\n    try:\n        result = urlparse(url)\n        return all([result.scheme, result.netloc])\n    except ValueError:\n        return False\n</code></pre>\n<p>Any suggestions?</p>\n",
                    "OwnerUserId": "1106134",
                    "LastEditorUserId": "3832970",
                    "LastEditDate": "2021-06-02T12:51:25.970",
                    "LastActivityDate": "2021-06-02T13:20:53.960",
                    "Title": "Square brackets not getting escaped in regex",
                    "Tags": "<python><regex><url>",
                    "AnswerCount": "1",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "67863145",
                "ParentRepo": "https://github.com/kennylajara/runup",
                "StackOverflow_Post": {
                    "Id": "67863145",
                    "PostTypeId": "1",
                    "CreationDate": "2021-06-06T19:51:27.223",
                    "Score": "0",
                    "ViewCount": "42",
                    "Body": "<p>I am working on a Back Up system named <strong>RunUp</strong> - Is still on a very early stage.</p>\n<p>You can see all the source code on its <a href=\"https://github.com/kennylajara/runup\" rel=\"nofollow noreferrer\">GitHub page</a>. And also, I uploaded it to <a href=\"https://pypi.org/project/RunUp/\" rel=\"nofollow noreferrer\">PyPI</a>, so, probably you won't have any problem to see what is happening by your self.</p>\n<p>Well, this is the thing:</p>\n<p>If you download the repo, move to the root, create your virtual environment and run <code>pip install --editable .</code> (do not omit the dot), you will see that the installation runs well and if you use <code>runup --version</code> it will show the output <code>RunUp, version 0.1.dev4</code>. Everything is OK.</p>\n<p>But...</p>\n<p>If you open a new console (or uninstall the package) and download it directly from PyPI with <code>pip install runup</code>, it will be installed without problem but when you use it (running again <code>runup --version</code>) it will output an error message:</p>\n<pre><code>Traceback (most recent call last):\n  File &quot;/home/user/path/to/repo/venv/bin/runup&quot;, line 5, in &lt;module&gt;\n    from src.runup.cli import cli\nModuleNotFoundError: No module named 'src'\n</code></pre>\n<p>I don't know very well why this is happening but I may think that is related to my <a href=\"https://github.com/kennylajara/runup/blob/main/setup.py\" rel=\"nofollow noreferrer\">setuptools implementation</a> or the directory tree. Not really sure about that.</p>\n",
                    "OwnerUserId": "5708232",
                    "LastActivityDate": "2021-06-06T19:51:27.223",
                    "Title": "I receive ModuleNotFoundError only when the package is downloaded from PyPI",
                    "Tags": "<python><setuptools><pypi><python-packaging>",
                    "AnswerCount": "0",
                    "CommentCount": "7",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "67912695",
                "ParentRepo": "https://github.com/external-secrets/external-secrets",
                "StackOverflow_Post": {
                    "Id": "67912695",
                    "PostTypeId": "1",
                    "CreationDate": "2021-06-09T23:07:23.973",
                    "Score": "3",
                    "ViewCount": "3449",
                    "Body": "<p>I am trying out external secrets operator (ESO) by following below:</p>\n<p><a href=\"https://github.com/external-secrets/external-secrets\" rel=\"nofollow noreferrer\">https://github.com/external-secrets/external-secrets</a></p>\n<p><a href=\"https://external-secrets.io/guides-getting-started/\" rel=\"nofollow noreferrer\">https://external-secrets.io/guides-getting-started/</a></p>\n<p>I am using minikube and AWS secrets manager to do this (I also tried it out in k8s cluster hosted in EC2, but I get the same exact error).</p>\n<p>I followed the steps from the links above:</p>\n<ol>\n<li>Added the repo:</li>\n</ol>\n<p><code>helm repo add external-secrets https://charts.external-secrets.io</code></p>\n<ol start=\"2\">\n<li>Install it in the namespace. I'm already inside of the namespace, so I didn't create the namespace.</li>\n</ol>\n<p><code>helm install external-secrets external-secrets/external-secrets --set installCRDs=true</code></p>\n<ol start=\"3\">\n<li>Added k8s secret:</li>\n</ol>\n<p><code>k create secret generic aws-credentials --from-literal=aws-access-key-id='xxx'  --from-literal=aws-secret-access-key='xxx'</code></p>\n<ol start=\"4\">\n<li>I created a secret in AWS secrets manager called <em>test_user_1</em></li>\n<li>kubectl apply -f secret-store.yaml</li>\n</ol>\n<pre><code>kind: SecretStore\nmetadata:\n  name: secretstore-sample\nspec:\n  provider:\n    aws:\n      service: SecretsManager\n      role: arn:aws:iam::123456789012:role/somerole\n      region: us-east-1\n      auth:\n        secretRef:\n          accessKeyIDSecretRef:\n            name: aws-credentials\n            key: aws-access-key-id\n          secretAccessKeySecretRef:\n            name: aws-credentials\n            key: aws-secret-access-key\n</code></pre>\n<ol start=\"6\">\n<li>kubectl apply -f externalsecrets.yaml</li>\n</ol>\n<pre><code>apiVersion: external-secrets.io/v1alpha1\nkind: ExternalSecret\nmetadata:\n  name: example\nspec:\n  refreshInterval: 1h\n  secretStoreRef:\n    name: secretstore-sample\n    kind: SecretStore\n  target:\n    name: secret-to-be-created\n    creationPolicy: Owner\n  data:\n    - secretKey: user-1-username\n      remoteRef:\n        key: test_user_1\n        property: username\n    - secretKey: user-1-password\n      remoteRef:\n        key: test_user_1\n        property: password\n</code></pre>\n<p>Then it says</p>\n<p><code>externalsecret.external-secrets.io/example created</code></p>\n<p>When I do</p>\n<p><code>kubectl describe externalsecret.external-secrets.io/example</code></p>\n<p>Below is what I get and no <em>secret-to-be-created</em> is created:</p>\n<pre><code>...\nStatus:\n  Conditions:\n    Last Transition Time:  2021-06-09T22:45:10Z\n    Message:               could not get secret data from provider: key &quot;test_user_1&quot; from ExternalSecret &quot;example&quot;: InvalidClientTokenId: The security token included in the request is invalid.\n                           status code: 403, request id: 5a544aa0-3953-4c0d-9dab-37bde10e328b\n    Reason:                SecretSyncedError\n    Status:                False\n    Type:                  Ready\n  Refresh Time:            &lt;nil&gt;\nEvents:                    &lt;none&gt;\n\n</code></pre>\n<p>I know this role has access to aws secrets manager (I've run python scripts to access aws secrets manager from my laptop using this role). But, I have limited knowledge of k8s, so, I appreciate any help.</p>\n",
                    "OwnerUserId": "3483133",
                    "LastActivityDate": "2021-06-11T15:40:23.540",
                    "Title": "Kubernetes: external secrets operator error: InvalidClientTokenId: The security token included in the request is invalid",
                    "Tags": "<amazon-web-services><kubernetes><kubernetes-helm><minikube><aws-secrets-manager>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "68003255",
                "ParentRepo": "https://github.com/freqtrade/freqtrade/blob/develop/Dockerfile",
                "StackOverflow_Post": {
                    "Id": "68003255",
                    "PostTypeId": "2",
                    "ParentId": "68002640",
                    "CreationDate": "2021-06-16T13:05:59.723",
                    "Score": "0",
                    "Body": "<p>The way to get our Python code running in a container is to pack it as a Docker image and then run a container based on it.\n<a href=\"https://i.stack.imgur.com/91v98.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/91v98.png\" alt=\"enter image description here\" /></a></p>\n<p>To generate a Docker image we need to create a Dockerfile that contains instructions needed to build the image. The Dockerfile is then processed by the Docker builder which generates the Docker image. Then, with a simple docker run command, we create and run a container with the Python service.</p>\n<p>An example of a Dockerfile containing instructions for assembling a Docker image for Python service installing <code>finta</code> is the following</p>\n<pre><code># set base image (host OS)\nFROM python:3.8\n\n# install dependencies\nRUN pip install finta\n\n# command to run on container start\nCMD [ &quot;python&quot;, &quot;-V&quot; ]\n</code></pre>\n<p>For each instruction or command from the Dockerfile, the Docker builder generates an image layer and stacks it upon the previous ones. Therefore, the Docker image resulting from the process is simply a read-only stack of different layers.</p>\n<pre><code>docker build -t myimage .\n</code></pre>\n<p>Then, we can check the image is in the local image store:</p>\n<pre><code>docker images\n</code></pre>\n<p>Please refer to the freqtrade DockerFile <a href=\"https://github.com/freqtrade/freqtrade/blob/develop/Dockerfile\" rel=\"nofollow noreferrer\">https://github.com/freqtrade/freqtrade/blob/develop/Dockerfile</a></p>\n",
                    "OwnerUserId": "2025086",
                    "LastActivityDate": "2021-06-16T13:05:59.723",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "68171629",
                "ParentRepo": "https://github.com/conda-incubator/conda-lock/issues/4",
                "StackOverflow_Post": {
                    "Id": "68171629",
                    "PostTypeId": "1",
                    "CreationDate": "2021-06-29T01:39:52.617",
                    "Score": "4",
                    "ViewCount": "1433",
                    "Body": "<p>I'm trying to follow the best practice of installing fully pinned dependencies (for repeatable builds and better Docker caching, see <a href=\"https://pythonspeed.com/articles/pipenv-docker/\" rel=\"nofollow noreferrer\">this pythonspeed.com article</a>).</p>\n<p>My project needs to use both conda and pip (conda for complex ML packages, pip for stuff not available on conda). The <a href=\"https://pythonspeed.com/articles/conda-dependency-management/\" rel=\"nofollow noreferrer\">conda-lock</a> and <a href=\"https://hynek.me/articles/python-app-deps-2018/\" rel=\"nofollow noreferrer\">pip-compile</a> tools are able to generate all transitive dependencies at pinned versions. However, these tools are <strong>independent</strong>: when I run pip-compile, it's not aware of the dependencies that conda-lock wants to install, and vice versa.</p>\n<p>This results in different package versions, causing wasted space in the Docker image and potentially causing breakage/incompatibility, as the <code>pip install</code> step installs different versions of some transitive dependencies.</p>\n<p>Does anyone have a better solution for creating pinned Python dependency lists when using <strong>both conda and pip</strong>?</p>\n<p>(Edit: here's a github ticket on conda-lock to support pip dependencies: <a href=\"https://github.com/conda-incubator/conda-lock/issues/4\" rel=\"nofollow noreferrer\">https://github.com/conda-incubator/conda-lock/issues/4</a>)</p>\n",
                    "OwnerUserId": "14463419",
                    "LastEditorUserId": "14463419",
                    "LastEditDate": "2021-06-29T02:23:21.127",
                    "LastActivityDate": "2021-07-01T02:30:05.597",
                    "Title": "How do I pin versioned dependencies in Python when using both conda and pip?",
                    "Tags": "<python><conda><pip-tools>",
                    "AnswerCount": "1",
                    "CommentCount": "1",
                    "FavoriteCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "68172275",
                "ParentRepo": "https://github.com/bunkerity/bunkerized-nginx",
                "StackOverflow_Post": {
                    "Id": "68172275",
                    "PostTypeId": "1",
                    "CreationDate": "2021-06-29T03:29:36.320",
                    "Score": "0",
                    "ViewCount": "1394",
                    "Body": "<p>I'm using nodejs and a custom nginx docker image <a href=\"https://github.com/bunkerity/bunkerized-nginx\" rel=\"nofollow noreferrer\">https://github.com/bunkerity/bunkerized-nginx</a> for my application using docker compose.</p>\n<p>Nginx image has the automatic letsencrypt support and we can bind mount a folder to store the key files.However for security reasons it runs as an unprivileged user with UID/GID 101 and getting a permission error for the /etc/letsencrypt directorry.</p>\n<p>I searched through the source code and found the following lines that causing this error</p>\n<h3>Condition that docker image checks</h3>\n<pre><code># /etc/letsencrypt\nif [ ! -w &quot;/etc/letsencrypt&quot; ] || [ ! -r &quot;/etc/letsencrypt&quot; ] || [ ! -x &quot;/etc/letsencrypt&quot; ] ; then\n    echo &quot;[!] ERROR - wrong permissions on /etc/letsencrypt&quot;\n    exit 1\nfi\n</code></pre>\n<p>What I want is now to set owner of the above directory as root or give the 777 permissions using the docker compose/Docker file.</p>\n<h3>My Docker compose file</h3>\n<pre><code>version: '3'\nservices:\n  bunkerized_nginx:\n    image: bunkerity/bunkerized-nginx\n    restart: always\n    depends_on:\n      - express-app\n    ports:\n      - 80:8080\n      - 443:8443\n\n    volumes:\n      - ./nginx-bunkerized/:/etc/letsencrypt:rw\n    \n    #command:\n      #- chown root:root /etc/letsencrypt\n      #- chmod 777 /etc/letsencrypt\n    environment:\n      - SERVER_NAME=www.dasun123.ml\n      - USE_REVERSE_PROXY=yes\n      - REVERSE_PROXY_URL=/\n      - AUTO_LETS_ENCRYPT=yes\n      - REDIRECT_HTTP_TO_HTTPS=yes\n      - REVERSE_PROXY_HOST=http://express-app:3000\n\n  express-app:\n    build: .\n    environment:\n      - PORT=3000\n\n</code></pre>\n",
                    "OwnerUserId": "16337225",
                    "LastActivityDate": "2021-06-29T03:29:36.320",
                    "Title": "How to change folder permissions inside a docker container using docker compose?",
                    "Tags": "<javascript><node.js><docker><docker-compose><dockerfile>",
                    "AnswerCount": "0",
                    "CommentCount": "4",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "68179033",
                "ParentRepo": "https://github.com/NanoComp/meep",
                "StackOverflow_Post": {
                    "Id": "68179033",
                    "PostTypeId": "1",
                    "CreationDate": "2021-06-29T12:51:54.913",
                    "Score": "0",
                    "ViewCount": "94",
                    "Body": "<p>I'm a new user of a Python module called <a href=\"https://github.com/NanoComp/meep\" rel=\"nofollow noreferrer\">meep</a>. I followed <a href=\"https://meep.readthedocs.io/en/latest/Python_Tutorials/GDSII_Import/\" rel=\"nofollow noreferrer\">this tutorial</a> and everything works fine. However, I tried to change something and I keep having the same error : <strong>OverflowError : in method 'get_GDSII_prisms', argument 3 of type 'int'</strong></p>\n<p>Here is the part of the code that causes trouble :</p>\n<pre><code>gdsII_file = 'coupler.gds'\nUPPER_BRANCH_LAYER = 31\nsi_zmax = 10\nsi_zmin = -10\n\ndef test(p):\n    return mp.Medium(index=15)\n    \nupper_branch = mp.get_GDSII_prisms(test, gdsII_file, UPPER_BRANCH_LAYER, si_zmin, si_zmax)\n</code></pre>\n<p>The only change I made is that I put a function as first argument of get_GDSII_prisms instead of a mp.Medium instance (calling <code>mp.get_GDSII_prisms(mp.Medium(index=15), gdsII_file, UPPER_BRANCH_LAYER, si_zmin, si_zmax</code> doesn't create any trouble.) But this should work since every function of this module that takes a mp.Medium instance can also take a user-defined function. Moreover, I found it strange that Python finds an error on argument 3 whereas I only changed argument 1.</p>\n<p>I looked on the internet in order to understand why I have this error and how to resolve it but I didn't found anything.</p>\n<p>I'm using Python 3.8.5.</p>\n<p>Thank you for your help!</p>\n",
                    "OwnerUserId": "16342403",
                    "LastEditorUserId": "5460719",
                    "LastEditDate": "2021-06-29T12:55:18.707",
                    "LastActivityDate": "2021-06-29T12:55:18.707",
                    "Title": "Python OverflowError : in method 'get_GDSII_prisms', argument 3 of type 'int'",
                    "Tags": "<python><python-3.x><function><meep>",
                    "AnswerCount": "0",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "68241813",
                "ParentRepo": "https://github.com/aniketmaurya/chitra",
                "StackOverflow_Post": {
                    "Id": "68241813",
                    "PostTypeId": "2",
                    "ParentId": "49466033",
                    "CreationDate": "2021-07-04T04:54:07.670",
                    "Score": "5",
                    "Body": "<p>Another way of doing this is to use <a href=\"https://github.com/aniketmaurya/chitra\" rel=\"noreferrer\">CHITRA</a></p>\n<pre><code>image = Chitra(img_path, box, label)\n# Chitra can rescale your bounding box automatically based on the new image size.\nimage.resize_image_with_bbox((224, 224))\n\nprint('rescaled bbox:', image.bounding_boxes)\nplt.imshow(image.draw_boxes())\n</code></pre>\n<p><a href=\"https://chitra.readthedocs.io/en/latest/\" rel=\"noreferrer\">https://chitra.readthedocs.io/en/latest/</a></p>\n<blockquote>\n<p>pip install chitra</p>\n</blockquote>\n",
                    "OwnerUserId": "8052167",
                    "LastActivityDate": "2021-07-04T04:54:07.670",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "68280165",
                "ParentRepo": "https://github.com/AmanRathoreM/All-in-Python/blob/main/Tutorials/Python%20Modules/Plotly/Part%203%20(Plotly%20Basics)/flights.csv",
                "StackOverflow_Post": {
                    "Id": "68280165",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "68280259",
                    "CreationDate": "2021-07-07T04:44:52.277",
                    "Score": "2",
                    "ViewCount": "165",
                    "Body": "<p>When I'm hovering on a plot in Heatmap it is showing axis as x, y, z.</p>\n<p>But I wanted it to be like Year, Month, No. of Passengers respectively</p>\n<p>Heatmap:\n<a href=\"https://i.stack.imgur.com/BQbGC.gif\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/BQbGC.gif\" alt=\"See the image of Heatmap here\" /></a></p>\n<p>Here is my code:</p>\n<pre><code>import pandas as pd\nimport plotly.offline as pyo\nimport plotly.graph_objs as go\n\nflights_data_csv = pd.read_csv(&quot;flights.csv&quot;)\n\ndata = [go.Heatmap(x=flights_data_csv[&quot;year&quot;],\n                   y=flights_data_csv[&quot;month&quot;],\n                   z=flights_data_csv[&quot;passengers&quot;].values.tolist(),\n                   colorbar=dict(title=&quot;Passengers traveled &lt;br&gt;by Flights&quot;),\n                   colorscale=&quot;jet&quot;,\n                   zmin=100,\n                   zmax=650)]\n\nlayout = go.Layout(title=&quot;Exercise of HeatMaps &lt;br&gt;For Showing Flights details&quot;,\n                   title_x=0.5)\nfig = go.Figure(data, layout)\npyo.plot(fig, filename=&quot;Flights Heatmaps.html&quot;)\n</code></pre>\n<p><a href=\"https://github.com/AmanRathoreM/All-in-Python/blob/main/Tutorials/Python%20Modules/Plotly/Part%203%20(Plotly%20Basics)/flights.csv\" rel=\"nofollow noreferrer\">Here is flight dataset</a></p>\n",
                    "OwnerUserId": "15830900",
                    "LastEditorUserId": "15497888",
                    "LastEditDate": "2021-07-07T05:07:39.820",
                    "LastActivityDate": "2021-07-07T05:13:20.070",
                    "Title": "How can I edit hovertext labels in Plotly Python?",
                    "Tags": "<python><pandas><graph><plotly><heatmap>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "FavoriteCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "68359563",
                "ParentRepo": "https://github.com/learnables/learn2learn",
                "StackOverflow_Post": {
                    "Id": "68359563",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "68383396",
                    "CreationDate": "2021-07-13T09:10:26.543",
                    "Score": "0",
                    "ViewCount": "128",
                    "Body": "<p>I am doing a meta learning research and am using the MAML optimization provided by <a href=\"https://github.com/learnables/learn2learn\" rel=\"nofollow noreferrer\">learn2learn</a>. However as one of the baseline, I would like to test a non-meta-learning approach, i.e. the traditional training + testing.</p>\n<p><a href=\"https://github.com/PyTorchLightning/pytorch-lightning/discussions/678\" rel=\"nofollow noreferrer\">Due to the lightning's internal usage of optimizer it seems that it is difficult to make the MAML work with learn2learn in lightning</a>, so I couldn't use lightning in my meta-learning setup, however for my baseline, I really like to use lightning in that it provides many handy functionalities like deepspeed or ddp out of the box.</p>\n<p>Here is my question, other than setting up two separate folders/repos, how could I mix the vanilia pytorch (learn2learn) with pytorch lightning (baseline)? What is the best practice?</p>\n<p>Thanks!</p>\n",
                    "OwnerUserId": "14289302",
                    "LastActivityDate": "2021-07-14T18:27:55.957",
                    "Title": "Mix pytorch lightning with vanilla pytorch",
                    "Tags": "<pytorch><pytorch-lightning>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "68366789",
                "ParentRepo": "https://github.com/danielfrg/jupyter-flex/issues/88",
                "StackOverflow_Post": {
                    "Id": "68366789",
                    "PostTypeId": "2",
                    "ParentId": "68344086",
                    "CreationDate": "2021-07-13T17:15:41.363",
                    "Score": "0",
                    "Body": "<p>Thank you <a href=\"https://github.com/danielfrg\" rel=\"nofollow noreferrer\">Daniel</a>; I was able to upgrade to 0.6.5; D:\\ProgramData\\Anaconda3\\envs\\pd125\\share\\jupyter\\nbconvert\\templates\\flex is present as expected.\n<a href=\"https://github.com/danielfrg/jupyter-flex/issues/88\" rel=\"nofollow noreferrer\">more info @ github</a></p>\n<p>Just posting below update, if others face similar issue:\nSince git was not in my system path <code>pip install -U jupyter-flex</code> was failing to install the latest version; after adding git to system path, I could install latest jupyter-flex</p>\n",
                    "OwnerUserId": "4161807",
                    "LastActivityDate": "2021-07-13T17:15:41.363",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "68377432",
                "ParentRepo": "https://github.com/webdataset/webdataset/blob/master/webdataset/tariterators.py",
                "StackOverflow_Post": {
                    "Id": "68377432",
                    "PostTypeId": "2",
                    "ParentId": "68299665",
                    "CreationDate": "2021-07-14T11:44:14.420",
                    "Score": "1",
                    "Body": "<p>I have had the same error since yesterday, I finally found the culprit. <a href=\"https://github.com/webdataset/webdataset/blob/master/webdataset/tariterators.py\" rel=\"nofollow noreferrer\">WebDataset/tarIterators.py</a> makes use of <a href=\"https://github.com/webdataset/webdataset/blob/master/webdataset/gopen.py\" rel=\"nofollow noreferrer\">WebDataset/gopen.py</a>. In gopen.py <code>urllib.parse.urlparse</code> is called to parse the url to be opened, in your case the url is <code>D:/PhD/...</code>.</p>\n<pre><code>gopen_schemes = dict(\n    __default__=gopen_error,\n    pipe=gopen_pipe,\n    http=gopen_curl,\n    https=gopen_curl,\n    sftp=gopen_curl,\n    ftps=gopen_curl,\n    scp=gopen_curl)\n\ndef gopen(url, mode=&quot;rb&quot;, bufsize=8192, **kw):\n    &quot;&quot;&quot;Open the URL. This uses the `gopen_schemes` dispatch table to dispatch based on scheme.\n    Support for the following schemes is built-in: pipe, file, http, https, sftp, ftps, scp.\n    When no scheme is given the url is treated as a file. You can use the OPEN_VERBOSE argument to get info about files being opened.\n    :param url: the source URL\n    :param mode: the mode (&quot;rb&quot;, &quot;r&quot;)\n    :param bufsize: the buffer size\n    &quot;&quot;&quot;\n    global fallback_gopen\n    verbose = int(os.environ.get(&quot;GOPEN_VERBOSE&quot;, 0))\n    if verbose:\n        print(&quot;GOPEN&quot;, url, info, file=sys.stderr)\n    assert mode in [&quot;rb&quot;, &quot;wb&quot;], mode\n    if url == &quot;-&quot;:\n        if mode == &quot;rb&quot;:\n            return sys.stdin.buffer\n        elif mode == &quot;wb&quot;:\n            return sys.stdout.buffer\n        else:\n            raise ValueError(f&quot;unknown mode {mode}&quot;)\n    pr = urlparse(url)\n    if pr.scheme == &quot;&quot;:\n        bufsize = int(os.environ.get(&quot;GOPEN_BUFFER&quot;, -1))\n        return open(url, mode, buffering=bufsize)\n    if pr.scheme == &quot;file&quot;:\n        bufsize = int(os.environ.get(&quot;GOPEN_BUFFER&quot;, -1))\n        return open(pr.path, mode, buffering=bufsize)\n    handler = gopen_schemes[&quot;__default__&quot;]\n    handler = gopen_schemes.get(pr.scheme, handler)\n    return handler(url, mode, bufsize, **kw)\n</code></pre>\n<p>As you can see in the dictionary the <code>__default__</code> function is <code>gopen_error</code>. This is the function returning the error you are seeing. <code>pr = urlparse(url)</code> on your url will generate an urlparse where the scheme (<code>pr.scheme</code>) is <code>'d'</code> because your disk is named D. However, it should be <code>'file'</code> for the function to work as intended. Since it is not equal to 'file' or any of the other schemes in the dictionary (http, https, sftp, etc), the default function will be used, which returns the error. I circumvented this issue by adding <code>d=gopen_file</code> to the <code>gopen_schemes</code> dictionary. I hope this helps you further temporarily. I will address this issue on the WebDataset GitHub page as well and keep this page updated if I get a more practical update.</p>\n<p>Good luck!</p>\n",
                    "OwnerUserId": "14618676",
                    "LastActivityDate": "2021-07-14T11:44:14.420",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "68415525",
                "ParentRepo": "https://github.com/westandskif/convtools",
                "StackOverflow_Post": {
                    "Id": "68415525",
                    "PostTypeId": "2",
                    "ParentId": "3749512",
                    "CreationDate": "2021-07-16T21:42:52.713",
                    "Score": "0",
                    "Body": "<p>You could use <a href=\"https://github.com/westandskif/convtools\" rel=\"nofollow noreferrer\">convtools</a> library which generates ad-hoc code for your exact task and allows for dynamic code generation.</p>\n<pre class=\"lang-py prettyprint-override\"><code>from convtools import conversion as c\n\n# grouping by second elements of tuples;\n# aggregate defines the schema of the expected output elements\nconverter = c.group_by(c.item(1)).aggregate({\n    &quot;type&quot;: c.item(1),\n    &quot;items&quot;: c.ReduceFuncs.Array(c.item(0)),\n}).gen_converter()\n\n# now you have a function which does what you asked,\n# store it somewhere for further reuse\nconverter(input_data)\n</code></pre>\n",
                    "OwnerUserId": "5387738",
                    "LastEditorUserId": "5387738",
                    "LastEditDate": "2021-11-12T10:22:55.007",
                    "LastActivityDate": "2021-11-12T10:22:55.007",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "68505779",
                "ParentRepo": "https://github.com/spaceship-prompt/spaceship-prompt/issues/167#issuecomment-313875172",
                "StackOverflow_Post": {
                    "Id": "68505779",
                    "PostTypeId": "2",
                    "ParentId": "68505184",
                    "CreationDate": "2021-07-23T23:08:51.240",
                    "Score": "1",
                    "Body": "<p>Some folks using <code>spaceship-prompt</code> <a href=\"http://%20https://github.com/spaceship-prompt/spaceship-prompt/issues/167#issuecomment-313875172\" rel=\"nofollow noreferrer\">were running into a similar issues and it appears to have to do with</a></p>\n<ul>\n<li>having a <code>package.json</code> file somewhere</li>\n<li><code>node_modules</code> directory somewhere</li>\n</ul>\n<p>Try locating and removing those as described in the posted <code>git issue</code>, additionally, there is guidance on how to disable or ignore via the <code>.zshrc</code> file.</p>\n",
                    "OwnerUserId": "16471349",
                    "LastActivityDate": "2021-07-23T23:08:51.240",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "68515856",
                "ParentRepo": "https://github.com/TomMalkin/SimQLe",
                "StackOverflow_Post": {
                    "Id": "68515856",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "68516085",
                    "CreationDate": "2021-07-25T05:47:32.423",
                    "Score": "1",
                    "ViewCount": "64",
                    "Body": "<p>I tried the exact same code as found here...\n<a href=\"https://github.com/TomMalkin/SimQLe\" rel=\"nofollow noreferrer\">https://github.com/TomMalkin/SimQLe</a></p>\n<p>I am not sure how to connect to mysql database.</p>\n<pre><code>from simqle import ConnectionManager\ncm = ConnectionManager(&quot;connections.yaml&quot;)\n\nsql = &quot;SELECT name, age FROM people WHERE category = :category&quot;\nparams = {&quot;category&quot;: 5}\n\nresult = cm.recordset(con_name=&quot;my-database&quot;, sql=sql, params=params)\n</code></pre>\n<p>Getting an error:</p>\n<blockquote>\n<p>UnknownConnectionError: Unknown connection my-database</p>\n</blockquote>\n<p>This is how I can connect to mysql database from command prompt.</p>\n<blockquote>\n<p>mysql -h 172.31.84.39 -udba -pXXXX -P 3392</p>\n</blockquote>\n<p>How do I write the connection string?</p>\n",
                    "OwnerUserId": "139150",
                    "LastActivityDate": "2021-07-25T06:47:37.353",
                    "Title": "Creating connection sring for mysql DB",
                    "Tags": "<python>",
                    "AnswerCount": "1",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "68563722",
                "ParentRepo": "https://github.com/RedisGrafana/RedisGrafana/issues",
                "StackOverflow_Post": {
                    "Id": "68563722",
                    "PostTypeId": "2",
                    "ParentId": "68557005",
                    "CreationDate": "2021-07-28T16:00:00.220",
                    "Score": "2",
                    "Body": "<p>To be able to access Redis Server from Grafana Cloud it should be exposed to the Internet as Jan mentioned.</p>\n<p>If you run Grafana in Docker container it should be started in the host network mode (<a href=\"https://docs.docker.com/network/host/\" rel=\"nofollow noreferrer\">https://docs.docker.com/network/host/</a>) to be able to access it from other devices.</p>\n<p>If something is lacking or not clear in the Redis plugins documentation, please open an issue and we will update it: <a href=\"https://github.com/RedisGrafana/RedisGrafana/issues\" rel=\"nofollow noreferrer\">https://github.com/RedisGrafana/RedisGrafana/issues</a></p>\n",
                    "OwnerUserId": "15775592",
                    "LastActivityDate": "2021-07-28T16:00:00.220",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "68649140",
                "ParentRepo": "https://github.com/ktomk/pipelines/blob/master/lib/build/coverage-checker.php",
                "StackOverflow_Post": {
                    "Id": "68649140",
                    "PostTypeId": "2",
                    "ParentId": "68589782",
                    "CreationDate": "2021-08-04T09:52:09.993",
                    "Score": "2",
                    "Body": "<p>What you refer to is the <a href=\"https://phpunit.readthedocs.io/en/9.5/textui.html#command-line-options\" rel=\"nofollow noreferrer\">phpunit text-output for coverage</a>:</p>\n<pre><code>  --coverage-text=&lt;file&gt;      Generate code coverage report in text format [default: standard output]\n</code></pre>\n<hr />\n<p>An alternative to it is a small script that you can run after running the tests with coverage to check on the gathered data.</p>\n<p>Here an excerpt from a <code>composer.json</code>  <code>{&quot;script&quot;: {}}</code> section:</p>\n<pre class=\"lang-json prettyprint-override\"><code>    &quot;unit-test&quot;: [\n      &quot;@phpunit --log-junit build/log/junit.xml --coverage-clover build/log/clover.xml test/unit&quot;,\n      &quot;@php -f lib/build/coverage-checker.php -- build/log/clover.xml&quot;\n    ],\n</code></pre>\n<p>Taken from an existing project which has the script:</p>\n<ul>\n<li><a href=\"https://github.com/ktomk/pipelines/blob/master/lib/build/coverage-checker.php\" rel=\"nofollow noreferrer\">https://github.com/ktomk/pipelines/blob/master/lib/build/coverage-checker.php</a></li>\n</ul>\n<p>It is a maintained version that originated in this blog-post:</p>\n<ul>\n<li><a href=\"http://ocramius.github.io/blog/automated-code-coverage-check-for-github-pull-requests-with-travis/\" rel=\"nofollow noreferrer\">http://ocramius.github.io/blog/automated-code-coverage-check-for-github-pull-requests-with-travis/</a></li>\n</ul>\n<p>The percentage to check for by default is 100%. You can pass it as the second positional argument if you would like to lower it.</p>\n",
                    "OwnerUserId": "367456",
                    "LastEditorUserId": "367456",
                    "LastEditDate": "2021-08-04T18:22:15.353",
                    "LastActivityDate": "2021-08-04T18:22:15.353",
                    "CommentCount": "4",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "68695345",
                "ParentRepo": "https://github.com/Descent098/ahd",
                "StackOverflow_Post": {
                    "Id": "68695345",
                    "PostTypeId": "1",
                    "CreationDate": "2021-08-07T18:59:09.007",
                    "Score": "2",
                    "ViewCount": "30",
                    "Body": "<p>I am wondering if there is a package available to help create something similar to what git has built in when you misspell a command, and it suggests existing commands. I am currently writing a CLI, and one of the features of the CLI is dynamically defining commands to dispatch <a href=\"https://github.com/Descent098/ahd\" rel=\"nofollow noreferrer\">here is the link for context</a>, so misspellings are quite common.</p>\n<p>Ideally I am looking for a way to pass a word, with a list of target words and get suggestions based on how close the input word is to one of the target words.</p>\n<p>So for example:</p>\n<pre class=\"lang-py prettyprint-override\"><code>def suggest(input_word:str, valid_words:list) -&gt; str:\n  suggestion = &quot;&quot; # The word in list valid_words that input_word is closest to \n  ... # Do stuff\n  return suggestion\n</code></pre>\n<p>Which can be used like so:</p>\n<pre class=\"lang-py prettyprint-override\"><code>suggest(&quot;biild&quot;, [&quot;build&quot;, &quot;init&quot;, &quot;preview&quot;]) # Returns &quot;build&quot;\n</code></pre>\n<p>Then with the cli I can use the function to print a message if a command does not exist and is likely misspelled like:</p>\n<pre class=\"lang-sh prettyprint-override\"><code>$ ahd biild\nCommand &quot;biild&quot; does not exist, did you mean:\n    \n    ahd build\n</code></pre>\n<p>I am not even looking for a full implementation, even just a suggestion on libraries that could help to do the string similarity check would be appreciated. Everything I have found so far is only a CLI with no API to hook into.</p>\n",
                    "OwnerUserId": "11602400",
                    "LastActivityDate": "2021-08-07T18:59:09.007",
                    "Title": "Is there a way to easily do word suggestions in a CLI?",
                    "Tags": "<python><python-3.x><command-line-interface>",
                    "AnswerCount": "0",
                    "CommentCount": "2",
                    "ClosedDate": "2021-08-07T19:03:19.410",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "68722249",
                "ParentRepo": "https://github.com/farridav/django-jazzmin/issues/126",
                "StackOverflow_Post": {
                    "Id": "68722249",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "69230357",
                    "CreationDate": "2021-08-10T06:57:16.873",
                    "Score": "0",
                    "ViewCount": "566",
                    "Body": "<p>I'm using jazzmin for django admin and mptt. After adding mptt to admin, in jazzmin theme add button disappeared.\nI'm using latest versions of all libraries</p>\n<pre><code>class CustomMPTTModelAdmin(MPTTModelAdmin):\n    # specify pixel amount for this ModelAdmin only:\n    mptt_level_indent = 30\n\n\nadmin.site.register(Menu, CustomMPTTModelAdmin)\n</code></pre>\n<p><a href=\"https://i.stack.imgur.com/zKvLQ.jpg\" rel=\"nofollow noreferrer\">Here you can see the admin where button disappeared</a></p>\n<p>When I disable jazzmin or remove Mptt add button returns back on place</p>\n<pre><code>INSTALLED_APPS = [\n    # 'jazzmin',\n    .....\n]\n</code></pre>\n<p><a href=\"https://i.stack.imgur.com/xJ9q7.png\" rel=\"nofollow noreferrer\">Here you can button returns back</a></p>\n<p>There is also issue was opened on github\n<a href=\"https://github.com/farridav/django-jazzmin/issues/126\" rel=\"nofollow noreferrer\">https://github.com/farridav/django-jazzmin/issues/126</a></p>\n<p>but I could not find solution for this problem</p>\n",
                    "OwnerUserId": "16630324",
                    "LastActivityDate": "2021-09-17T23:15:08.933",
                    "Title": "Django Jazzmin add button disappeared after adding mptt admin",
                    "Tags": "<python><django><django-mptt>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "68738718",
                "ParentRepo": "https://github.com/collerek/ormar",
                "StackOverflow_Post": {
                    "Id": "68738718",
                    "PostTypeId": "2",
                    "ParentId": "68738454",
                    "CreationDate": "2021-08-11T08:42:41.227",
                    "Score": "0",
                    "Body": "<p>According to the readme <a href=\"https://github.com/collerek/ormar\" rel=\"nofollow noreferrer\">https://github.com/collerek/ormar</a> Ormar is built using</p>\n<pre><code>sqlalchemy core for query building.\ndatabases for cross-database async support.\npydantic for data validation.\ntyping_extensions for python 3.6 - 3.7\n</code></pre>\n<p>Your error implies that <code>databases</code> is not installed on your system and therefore has to be installed in order for the library to work.</p>\n<p>Install it via <code>pip3 install databases</code> (or <code>pip</code>)</p>\n",
                    "OwnerUserId": "12120101",
                    "LastEditorUserId": "515189",
                    "LastEditDate": "2021-08-20T16:06:18.047",
                    "LastActivityDate": "2021-08-20T16:06:18.047",
                    "CommentCount": "5",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "68763036",
                "ParentRepo": "https://github.com/adw0rd/instagrapi",
                "StackOverflow_Post": {
                    "Id": "68763036",
                    "PostTypeId": "2",
                    "ParentId": "68636841",
                    "CreationDate": "2021-08-12T19:16:03.663",
                    "Score": "2",
                    "Body": "<p>I've written a countless number of Instagram data scraping applications for clients... and I'll keep it real with you: stay far, far away from the Facebook Business API. It's atrocious.</p>\n<p>What I <em>do</em> recommend, is using Instagram's private API that they expose to mobile or their public web-facing API. Luckily for us, people have written many libraries that utilise both of these APIs. Most of these libraries also automatically handle Instagram's rate limiting.</p>\n<p>Here are some of the libraries I've used and would recommend:</p>\n<ul>\n<li>Python:  <a href=\"https://github.com/adw0rd/instagrapi\" rel=\"nofollow noreferrer\">instagrapi</a></li>\n<li>TypeScript: <a href=\"https://github.com/dilame/instagram-private-api\" rel=\"nofollow noreferrer\">instagram-private-api</a></li>\n<li>Java: <a href=\"https://github.com/instagram4j/instagram4j\" rel=\"nofollow noreferrer\">instagram4j</a></li>\n<li>C#: <a href=\"https://github.com/ramtinak/InstagramApiSharp\" rel=\"nofollow noreferrer\">InstagramApiSharp</a></li>\n</ul>\n",
                    "OwnerUserId": "6126726",
                    "LastActivityDate": "2021-08-12T19:16:03.663",
                    "CommentCount": "4",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "68852635",
                "ParentRepo": "https://github.com/aws/jsii/issues/2963",
                "StackOverflow_Post": {
                    "Id": "68852635",
                    "PostTypeId": "2",
                    "ParentId": "68763854",
                    "CreationDate": "2021-08-19T18:01:06.280",
                    "Score": "0",
                    "Body": "<p>AWS has resolved the issue in jsii.</p>\n<p><a href=\"https://github.com/aws/jsii/issues/2963\" rel=\"nofollow noreferrer\">https://github.com/aws/jsii/issues/2963</a></p>\n<p>It should be available with CDK 1.121.0.</p>\n",
                    "OwnerUserId": "492773",
                    "LastEditorUserId": "492773",
                    "LastEditDate": "2021-08-31T18:07:15.623",
                    "LastActivityDate": "2021-08-31T18:07:15.623",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "68909021",
                "ParentRepo": "https://github.com/botcity-dev/botcity-framework-core-python",
                "StackOverflow_Post": {
                    "Id": "68909021",
                    "PostTypeId": "2",
                    "ParentId": "11825322",
                    "CreationDate": "2021-08-24T14:23:44.350",
                    "Score": "1",
                    "Body": "<p>Take a look at <a href=\"https://github.com/botcity-dev/botcity-framework-core-python\" rel=\"nofollow noreferrer\">BotCity Framework</a>, an open-source RPA framework.\u00a0</p>\n<p>It's just python (no intermediary code, no jython, etc).</p>\n<p>The example below executes SAP and logs in:</p>\n<pre><code>from botcity.core import DesktopBot\nfrom botcity.maestro import AlertType, AutomationTaskFinishStatus, Column\n\nclass Bot(DesktopBot):\n    def action(self, execution):\n        self.execute(&quot;saplogon.exe&quot;)\n        \n        # #{image:&quot;login&quot;}\n    \n        if not self.find( &quot;user&quot;, matching=0.97, waiting_time=10000):\n            self.not_found(&quot;user&quot;)\n        self.click_relative(172, 5)\n        \n        self.paste(user)\n        self.tab()\n        self.paste(pass)\n        self.enter()\n        \nif __name__ == '__main__':\n    Bot.main()\n</code></pre>\n<p>As Sikuli, you have a tool to crop elements and have visual clues about the interface and UI elements. But in this case, it's a tool for editing .py files (not intermediary code) so you can use any python lib in your automation.</p>\n<img src=\"https://i.stack.imgur.com/EX6qi.png\" width=\"420\" />\n",
                    "OwnerUserId": "16465123",
                    "LastEditorUserId": "16465123",
                    "LastEditDate": "2021-08-24T14:36:25.850",
                    "LastActivityDate": "2021-08-24T14:36:25.850",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "68932099",
                "ParentRepo": "https://github.com/tiangolo/sqlmodel",
                "StackOverflow_Post": {
                    "Id": "68932099",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "69063829",
                    "CreationDate": "2021-08-26T03:21:45.503",
                    "Score": "8",
                    "ViewCount": "4117",
                    "Body": "<p>Using <a href=\"https://github.com/tiangolo/sqlmodel\" rel=\"noreferrer\">SQLModel</a> how to get alembic to recognise the below model?</p>\n<pre><code>from sqlmodel import Field, SQLModel\n\nclass Hero(SQLModel, table=True):\n    id: int = Field(default=None, primary_key=True)\n    name: str\n    secret_name: str\n    age: Optional[int] = None\n</code></pre>\n<p>One approach I've been looking at is to import the SQLalchemy model for Alembic but looking through the source code I can't find how to do that.</p>\n<p>How to make Alembic work with SQLModel models?</p>\n",
                    "OwnerUserId": "4605629",
                    "LastActivityDate": "2022-02-27T05:01:11.110",
                    "Title": "How to get Alembic to recognise SQLModel database model?",
                    "Tags": "<sqlalchemy><fastapi><alembic><pydantic><sqlmodel>",
                    "AnswerCount": "2",
                    "CommentCount": "3",
                    "FavoriteCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "69092169",
                "ParentRepo": "https://github.com/spotify/pedalboard",
                "StackOverflow_Post": {
                    "Id": "69092169",
                    "PostTypeId": "2",
                    "ParentId": "37555711",
                    "CreationDate": "2021-09-07T17:09:16.827",
                    "Score": "4",
                    "Body": "<p>Spotify has released <a href=\"https://github.com/spotify/pedalboard\" rel=\"nofollow noreferrer\"><code>pedalboard</code></a>, a <code>pip</code>-installable Python library based on <a href=\"https://juce.com/\" rel=\"nofollow noreferrer\">JUCE</a> with support for loading and running audio plugins on macOS, Windows, and Linux. VST3 plugins are supported on all platforms, and Audio Units are supported on macOS. (As of September 2021, Pedalboard only supports audio effects, but contributors may add support for instrument plug-ins in the future.)</p>\n<p>An example of using <code>pedalboard</code>:</p>\n<pre class=\"lang-py prettyprint-override\"><code># After installing with `pip install pedalboard`:\n\nimport soundfile as sf\nfrom pedalboard import Pedalboard, Compressor, Chorus, Distortion, Reverb\n\naudio, sample_rate = soundfile.read('some-file.wav')\n\n# Make a Pedalboard object, containing multiple plugins:\nboard = Pedalboard([\n    Compressor(threshold_db=-50, ratio=25),\n    Distortion(drive_db=30),\n    Chorus(),\n    load_plugin(&quot;./VSTs/SomePlugin.vst3&quot;), # Load a VST3 plugin\n    Reverb(room_size=0.25),\n], sample_rate=sample_rate)\n\n# Run the audio through this pedalboard!\neffected = board(audio)\n</code></pre>\n",
                    "OwnerUserId": "679081",
                    "LastActivityDate": "2021-09-07T17:09:16.827",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "69099720",
                "ParentRepo": "https://github.com/encode/orm/issues/33",
                "StackOverflow_Post": {
                    "Id": "69099720",
                    "PostTypeId": "2",
                    "ParentId": "67406165",
                    "CreationDate": "2021-09-08T08:38:41.003",
                    "Score": "0",
                    "Body": "<p>Running this command solved the issue for me:</p>\n<pre><code>pip install databases[sqlite]\n</code></pre>\n<p>Refer to this discussion <a href=\"https://github.com/encode/orm/issues/33\" rel=\"nofollow noreferrer\">https://github.com/encode/orm/issues/33</a>.</p>\n",
                    "OwnerUserId": "11609896",
                    "LastEditorUserId": "446477",
                    "LastEditDate": "2021-09-08T09:43:55.010",
                    "LastActivityDate": "2021-09-08T09:43:55.010",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "69106949",
                "ParentRepo": "https://github.com/FelixTheC/strongtyping",
                "StackOverflow_Post": {
                    "Id": "69106949",
                    "PostTypeId": "2",
                    "ParentId": "43646823",
                    "CreationDate": "2021-09-08T16:49:03.997",
                    "Score": "7",
                    "Body": "<p>This is what I have discovered recently, basically this decorator does type checking at runtime raising exception if some type definition did not match. It can also do type checking for nested types (dict of strings, etc)</p>\n<p><a href=\"https://github.com/FelixTheC/strongtyping\" rel=\"noreferrer\">https://github.com/FelixTheC/strongtyping</a></p>\n<p>Example:</p>\n<pre><code>from strongtyping.strong_typing import match_typing\n\n@match_typing\ndef func_a(a: str, b: int, c: list):\n   ...\n\nfunc_a('1', 2, [i for i in range(5)])\n# &gt;&gt;&gt; True\n\nfunc_a(1, 2, [i for i in range(5)])\n# &gt;&gt;&gt; will raise a TypeMismatch Exception\n</code></pre>\n",
                    "OwnerUserId": "3209908",
                    "LastActivityDate": "2021-09-08T16:49:03.997",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "69235202",
                "ParentRepo": "https://github.com/apache/incubator-sedona/pull/513",
                "StackOverflow_Post": {
                    "Id": "69235202",
                    "PostTypeId": "2",
                    "ParentId": "69001115",
                    "CreationDate": "2021-09-18T13:41:28.913",
                    "Score": "0",
                    "Body": "<p>To achieve this you need to use some library, like, <a href=\"https://sedona.apache.org/\" rel=\"nofollow noreferrer\">Apache Sedona</a>, <a href=\"https://www.geomesa.org/documentation/stable/tutorials/spark.html\" rel=\"nofollow noreferrer\">GeoMesa</a>, or something else.  Sedona, for example, has the <a href=\"https://sedona.apache.org/api/sql/Function/#st_transform\" rel=\"nofollow noreferrer\">ST_TRANSFORM</a> function, maybe it has the rest as well.</p>\n<p>The only thing that you need to take care, is that if you're using pure SQL, then on Databricks you will need:</p>\n<ul>\n<li>install Sedona libraries using the <a href=\"https://learn.microsoft.com/en-us/azure/databricks/clusters/init-scripts\" rel=\"nofollow noreferrer\">init script</a>, so libraries should be there before Spark starts</li>\n<li>set Spark configuration parameters, as described in the following <a href=\"https://github.com/apache/incubator-sedona/pull/513\" rel=\"nofollow noreferrer\">pull request</a></li>\n</ul>\n<p>Update June 2022nd: people at Databricks developed the <a href=\"https://github.com/databrickslabs/mosaic/\" rel=\"nofollow noreferrer\">Mosaic library</a> that is heavily optimized for geospatial analysis on Databricks, and it's compatible with standard <code>ST_</code> functions.</p>\n",
                    "OwnerUserId": "18627",
                    "LastEditorUserId": "18627",
                    "LastEditDate": "2022-06-09T07:58:48.190",
                    "LastActivityDate": "2022-06-09T07:58:48.190",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "69251134",
                "ParentRepo": "https://github.com/iml130/firos",
                "StackOverflow_Post": {
                    "Id": "69251134",
                    "PostTypeId": "2",
                    "ParentId": "69209048",
                    "CreationDate": "2021-09-20T08:17:02.017",
                    "Score": "1",
                    "Body": "<p>As you can see in the diagram available in [1], the FIROS component does not send data to CrateDB but to the Orion Context Broker. I suggest you to have a look at the FIROS example from [2].</p>\n<p>Once you have your data in the Orion Context Broker, which is the only mandatory component of every Powered by FIWARE architecture, heterogeneous data consumers and providers can interact with them using the standard NGSI API.</p>\n<p>In turn, the FIWARE catalague [3] offers a number of IoT agents and data connectors to ease the integration of heterogeneous technologies and protocols with the Context Broker using NGSI.</p>\n<p>CrateDB is one of the technologies that can be easily integrated using existing NGSI Data Connectors (e.g., QuantumLeap). A working example which illustrates the integration between the Orion Context Broker and CrateDB using QuantumLeap is available at [4].</p>\n<p>I hope this helps you make progress towards your goals.</p>\n<p>[1] FIROS github: <a href=\"https://github.com/iml130/firos\" rel=\"nofollow noreferrer\">https://github.com/iml130/firos</a></p>\n<p>[2] FIROS Example: <a href=\"https://firos.readthedocs.io/en/latest/install/turtlesim-example.html\" rel=\"nofollow noreferrer\">https://firos.readthedocs.io/en/latest/install/turtlesim-example.html</a></p>\n<p>[3] FIWARE Catalogue: <a href=\"https://github.com/FIWARE/catalogue\" rel=\"nofollow noreferrer\">https://github.com/FIWARE/catalogue</a></p>\n<p>[4] CrateDB Example: <a href=\"https://fiware-tutorials.readthedocs.io/en/1.0.0/time-series-data/index.html\" rel=\"nofollow noreferrer\">https://fiware-tutorials.readthedocs.io/en/1.0.0/time-series-data/index.html</a></p>\n",
                    "OwnerUserId": "16576662",
                    "LastActivityDate": "2021-09-20T08:17:02.017",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "69298208",
                "ParentRepo": "https://github.com/camunda-community-hub/camunda-rest-client-spring-boot/",
                "StackOverflow_Post": {
                    "Id": "69298208",
                    "PostTypeId": "2",
                    "ParentId": "69297495",
                    "CreationDate": "2021-09-23T10:23:20.743",
                    "Score": "1",
                    "Body": "<p>How about using this client project?\n<a href=\"https://github.com/camunda-community-hub/camunda-rest-client-spring-boot/\" rel=\"nofollow noreferrer\">https://github.com/camunda-community-hub/camunda-rest-client-spring-boot/</a></p>\n<p>For example:\n<a href=\"https://github.com/camunda-community-hub/camunda-rest-client-spring-boot/blob/dce6bd777e3350dd30286311c5351aa9460a34f4/examples/example/src/main/java/org/camunda/bpm/extension/rest/example/standalone/client/ProcessClient.java#L98\" rel=\"nofollow noreferrer\">https://github.com/camunda-community-hub/camunda-rest-client-spring-boot/blob/dce6bd777e3350dd30286311c5351aa9460a34f4/examples/example/src/main/java/org/camunda/bpm/extension/rest/example/standalone/client/ProcessClient.java#L98</a></p>\n",
                    "OwnerUserId": "1491439",
                    "LastActivityDate": "2021-09-23T10:23:20.743",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "69302891",
                "ParentRepo": "https://github.com/wallarm/ingress",
                "StackOverflow_Post": {
                    "Id": "69302891",
                    "PostTypeId": "2",
                    "ParentId": "69300966",
                    "CreationDate": "2021-09-23T15:28:15.740",
                    "Score": "2",
                    "Body": "<p>i would suggest checking out : <a href=\"https://lab.wallarm.com/how-to-protect-your-kubernetes-cluster-with-wallarm-configuration-and-finetuning-part-2-of-3/\" rel=\"nofollow noreferrer\">https://lab.wallarm.com/how-to-protect-your-kubernetes-cluster-with-wallarm-configuration-and-finetuning-part-2-of-3/</a></p>\n<p>And nice <strong>Wallarm WAF ingress controller</strong> : <a href=\"https://github.com/wallarm/ingress\" rel=\"nofollow noreferrer\">https://github.com/wallarm/ingress</a></p>\n<p>With <code>Nginx ingress</code>, there are options to increase to security</p>\n<p><strong><a href=\"https://cloudzone.io/implementing-waf-and-mutual-tls-on-kubernetes-with-nginx-modsecurity/\" rel=\"nofollow noreferrer\">ModSecurity</a></strong> at application level metadata and proxy payload size management.</p>\n<p>For DDoS protection, you can use the <a href=\"https://medium.com/@chadsaun/mitigating-a-ddos-attack-with-ingress-nginx-and-kubernetes-12f309072367\" rel=\"nofollow noreferrer\">rate-limiting</a> and connection handling option</p>\n<pre><code>nginx.ingress.kubernetes.io/limit-connections: '2'\nnginx.ingress.kubernetes.io/limit-rpm: '60'\n</code></pre>\n<p>you can whitelist the List of IPs also.</p>\n",
                    "OwnerUserId": "5525824",
                    "LastActivityDate": "2021-09-23T15:28:15.740",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "69381448",
                "ParentRepo": "https://github.com/commitizen-tools/commitizen",
                "StackOverflow_Post": {
                    "Id": "69381448",
                    "PostTypeId": "1",
                    "CreationDate": "2021-09-29T18:08:29.170",
                    "Score": "1",
                    "ViewCount": "360",
                    "Body": "<p>I want to run the <a href=\"https://github.com/commitizen-tools/commitizen\" rel=\"nofollow noreferrer\">commitizen</a> (python implementation of conventional commit message enforcement) lint check (<code>cz check</code>) within my GitLab CI pipeline but <strong>ONLY</strong> on the squash commit that precedes a merge into master from a feature branch.</p>\n<p>I can't get my head around how to do this. My understanding/assumption is as follows:</p>\n<ul>\n<li>This is only going to be possible if my merge strategy is merge commit (i.e. not fast forward) because I need there to be a commit that can fail (before the merge into master) so that the merge can then abort - if it was just 1 commit as per fast-forward strategy, it would be too late; the code would already be in master and then the pipeline would fail. Luckily, I am fine with this but I'm curious as to how you would solve for this with fast-forward.</li>\n<li>The squash commit runs on the feature branch which triggers a pipeline.</li>\n<li>If I fail the squash commit pipeline, GitLab CI will not proceed to the merge commit.</li>\n</ul>\n<p>If my assumptions are correct, I would need to detect whether the commit a given pipeline is handling is a squash commit or not - but I can't figure out how to do this - there doesn't seem to be any <em>signal</em> from either gitlab or git that I could use in my pipeline.</p>\n<p>In terms of implementation, I intend to add the <a href=\"https://github.com/commitizen-tools/commitizen#integrating-with-pre-commit\" rel=\"nofollow noreferrer\">pre-commit hook provided by commitizen</a> but I will use <code>stages: [manual]</code> and then within my pipeline, I'll run <code>pre-commit run --hook-stage manual [hookid]</code> as per <a href=\"https://pre-commit.com/#confining-hooks-to-run-at-certain-stages\" rel=\"nofollow noreferrer\">pre-commit docs</a>.</p>\n",
                    "OwnerUserId": "4095865",
                    "LastActivityDate": "2021-09-29T18:08:29.170",
                    "Title": "Run pre-commit conventional commit check on squash commit before merge into master only",
                    "Tags": "<python><version-control><gitlab-ci><pre-commit-hook><pre-commit.com>",
                    "AnswerCount": "0",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "69472246",
                "ParentRepo": "https://github.com/michaelhly/solana-py/blob/a366253a3f043979bc6f61869ee8faad98292dc2/solana/keypair.py#L46",
                "StackOverflow_Post": {
                    "Id": "69472246",
                    "PostTypeId": "2",
                    "ParentId": "69448716",
                    "CreationDate": "2021-10-06T20:20:27.827",
                    "Score": "0",
                    "Body": "<p>There's a couple of things you can try.  First, you can use the <code>Keypair</code> type instead, since <code>Account</code> is deprecated, specifically using <code>from_secret_key</code>: <a href=\"https://github.com/michaelhly/solana-py/blob/a366253a3f043979bc6f61869ee8faad98292dc2/solana/keypair.py#L46\" rel=\"nofollow noreferrer\">https://github.com/michaelhly/solana-py/blob/a366253a3f043979bc6f61869ee8faad98292dc2/solana/keypair.py#L46</a></p>\n<p>If that still doesn't work, the format of the private key is likely incorrect. Phantom generates private keys as base-64 strings, whereas these functions are expecting byte arrays.  You can convert between the two using some of the answers at <a href=\"https://stackoverflow.com/questions/69245982/import-phantom-wallet-private-key-into-solana-cli/69256259#69256259\">Import phantom wallet private key into solana CLI</a></p>\n",
                    "OwnerUserId": "16310679",
                    "LastActivityDate": "2021-10-06T20:20:27.827",
                    "CommentCount": "3",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "69576463",
                "ParentRepo": "https://github.com/marcosschroh/dataclasses-avroschema",
                "StackOverflow_Post": {
                    "Id": "69576463",
                    "PostTypeId": "1",
                    "CreationDate": "2021-10-14T19:39:11.650",
                    "Score": "0",
                    "ViewCount": "433",
                    "Body": "<p>I searched quite a lot before asking this question and looks like I am stuck and therefore asking question here. I know such type of errors are encountered when Schema and object are not a match, maybe some datatype is missing or have other type of value for a field.</p>\n<p>However, I believe my case is different.\nMy application is simple, which only serialize and deserialize an object into avro</p>\n<p>My DataClass:</p>\n<pre class=\"lang-py prettyprint-override\"><code>\nfrom time import time\nfrom faker import Faker\nfrom dataclasses import dataclass, field\n\nfrom dataclasses_avroschema import AvroModel\n\nFaker.seed(0)\nfake = Faker()\n\n\n@dataclass\nclass Head(AvroModel):\n    msgId: str = field()\n    msgCode: str = field()\n\n    @staticmethod\n    def fakeMe():\n        return Head(fake.md5(),\n                fake.pystr(min_chars=5, max_chars=5)\n            )\n\n\n@dataclass\nclass Message(AvroModel):\n    head: Head = field()\n    status: bool = field()\n\n    class Meta:\n        namespace = &quot;me.com.Message.v1&quot;\n\n    def fakeMe(self):\n        self.head = Head.fakeMe()\n        self.bool = fake.pybool()\n\n\n</code></pre>\n<p>Now the script that runs the serialization:</p>\n<pre class=\"lang-py prettyprint-override\"><code>import json, io as mainio\nfrom dto.temp_schema import Message\nfrom avro import schema, datafile, io as avroio\n\nobj = Message(None, True)\nobj.fakeMe()\n\nschema_obj = schema.parse(json.dumps(Message.avro_schema_to_python()))\n\nbuf = mainio.BytesIO()\nwriter = datafile.DataFileWriter(buf, avroio.DatumWriter(), schema_obj)\nwriter.append(obj)\nwriter.flush()\nbuf.seek(0)\ndata = buf.read()\n\nprint(&quot;serialized avro: &quot;, data)\n\n</code></pre>\n<p>When I run this I get following error:</p>\n<pre class=\"lang-sh prettyprint-override\"><code>\nTraceback (most recent call last):\n  File &quot;/Users/office/Documents/projects/msg-bench/scrib.py&quot;, line 28, in &lt;module&gt;\n    writer.append(obj)\n  File &quot;/Users/office/opt/anaconda3/envs/benchenv/lib/python3.9/site-packages/avro/datafile.py&quot;, line 329, in append\n    self.datum_writer.write(datum, self.buffer_encoder)\n  File &quot;/Users/office/opt/anaconda3/envs/benchenv/lib/python3.9/site-packages/avro/io.py&quot;, line 771, in write\n    raise AvroTypeException(self.writer_schema, datum)\n\n\navro.io.AvroTypeException: The datum Message(head=Head(msgId='f112d652ecf13dacd9c78c11e1e7f987', msgCode='cYzVR'), status=True) is not an example of the schema {\n  &quot;type&quot;: &quot;record&quot;,\n  &quot;name&quot;: &quot;Message&quot;,\n  &quot;namespace&quot;: &quot;me.com.Message.v1&quot;,\n  &quot;fields&quot;: [\n    {\n      &quot;type&quot;: {\n        &quot;type&quot;: &quot;record&quot;,\n        &quot;name&quot;: &quot;Head&quot;,\n        &quot;namespace&quot;: &quot;me.com.Message.v1&quot;,\n        &quot;fields&quot;: [\n          {\n            &quot;type&quot;: &quot;string&quot;,\n            &quot;name&quot;: &quot;msgId&quot;\n          },\n          {\n            &quot;type&quot;: &quot;string&quot;,\n            &quot;name&quot;: &quot;msgCode&quot;\n          }\n        ],\n        &quot;doc&quot;: &quot;Head(msgId: str, msgCode: str)&quot;\n      },\n      &quot;name&quot;: &quot;head&quot;\n    },\n    {\n      &quot;type&quot;: &quot;boolean&quot;,\n      &quot;name&quot;: &quot;status&quot;\n    }\n  ],\n  &quot;doc&quot;: &quot;Message(head: dto.temp_schema.Head, status: bool)&quot;\n}\n\n\n</code></pre>\n<p>Please note I am generating the schema using Dataclass Object with help of a python library:\n<a href=\"https://github.com/marcosschroh/dataclasses-avroschema\" rel=\"nofollow noreferrer\">dataclasses-avroschema</a></p>\n<p>And still after using the same schema I am not able to serialize data to Avro.</p>\n<p>Currently I am not sure where I am going wrong and I am new to avro. Why this won't compile?</p>\n<p>System and Library stats:</p>\n<pre class=\"lang-sh prettyprint-override\"><code>\nPython==3.9.7\navro==1.10.2\navro-python3==1.10.2\ndataclasses-avroschema==0.25.1\nFaker==9.3.1\nfastavro==1.4.5\n\n\n</code></pre>\n",
                    "OwnerUserId": "681790",
                    "LastActivityDate": "2021-10-19T02:57:06.583",
                    "Title": "Python Avro avro.io.AvroTypeException The datum is not an example of schema",
                    "Tags": "<python><python-3.x><serialization><avro>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "69670666",
                "ParentRepo": "https://github.com/SPARQL-Anything/sparql.anything",
                "StackOverflow_Post": {
                    "Id": "69670666",
                    "PostTypeId": "2",
                    "ParentId": "69332794",
                    "CreationDate": "2021-10-22T02:11:58.400",
                    "Score": "0",
                    "Body": "<p>Yes, and <a href=\"https://github.com/SPARQL-Anything/sparql.anything\" rel=\"nofollow noreferrer\">SPARQL Anything</a> uses that capability to triplify non-RDF data at query time and makes it available in the execution context's DatasetGraph.</p>\n<p>Here is an example of that being done:</p>\n<pre><code>                if (this.execCxt.getDataset().isEmpty()) {\n                // we only need to call getDatasetGraph() if we have an empty one\n                // otherwise we could triplify the same data multiple times\n                dg = getDatasetGraph(p, opBGP);\n            } else {\n                dg = this.execCxt.getDataset();\n            }\n</code></pre>\n<p><a href=\"https://github.com/SPARQL-Anything/sparql.anything/blob/cdc285256df323a70bf18c977f16498994184d37/sparql-anything-engine/src/main/java/com/github/sparqlanything/engine/FacadeXOpExecutor.java#L532-L538\" rel=\"nofollow noreferrer\">These lines</a></p>\n<p>This answer might not address your particular need (adding individual triples) but hopefully some of code in the project could serve as an example of what you are looking for.</p>\n",
                    "OwnerUserId": "11022895",
                    "LastActivityDate": "2021-10-22T02:11:58.400",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "69731636",
                "ParentRepo": "https://github.com/jitsi/jiwer",
                "StackOverflow_Post": {
                    "Id": "69731636",
                    "PostTypeId": "2",
                    "ParentId": "50211629",
                    "CreationDate": "2021-10-27T01:16:32.040",
                    "Score": "0",
                    "Body": "<p>Good to try jiwer package. It does take care of some data cleaning and transformation as well (please see <a href=\"https://github.com/jitsi/jiwer\" rel=\"nofollow noreferrer\">https://github.com/jitsi/jiwer</a>). It works for me for a medium size of data; it needs to be checked for large data.</p>\n<p>Some codes to calculate errors:</p>\n<pre><code>    import jitwer \n    ground_truth = &quot;ground truth text&quot;\n    modified_text = &quot;modified text or output of model to ground truth text&quot; \n    \n    # list of transformations you can apply on your text data\n    transformation = jiwer.Compose([\n        jiwer.ToLowerCase(),\n        jiwer.Strip(),\n        jiwer.RemoveEmptyStrings(),\n        jiwer.RemoveMultipleSpaces(),\n        jiwer.RemoveWhiteSpace(replace_by_space=False),\n        jiwer.SentencesToListOfWords(word_delimiter=&quot; &quot;),\n        jiwer.ExpandCommonEnglishContractions(),\n        jiwer.RemoveKaldiNonWords()\n    ]) \n\n    wer = jiwer.wer(\n        ground_truth, \n        modified_text, \n        truth_transform=transformation, \n        hypothesis_transform=transformation\n    )\n    mer = jiwer.mer(\n        ground_truth, \n        modified_text, \n        truth_transform=transformation, \n        hypothesis_transform=transformation\n    )\n    wil = jiwer.wil(\n        ground_truth, \n        modified_text, \n        truth_transform=transformation, \n        hypothesis_transform=transformation\n    )\n    measures = jiwer.compute_measures(ground_truth, modified_text)\n</code></pre>\n",
                    "OwnerUserId": "6395930",
                    "LastEditorUserId": "6395930",
                    "LastEditDate": "2021-10-27T02:34:59.543",
                    "LastActivityDate": "2021-10-27T02:34:59.543",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "69895555",
                "ParentRepo": "https://github.com/titu1994/pyshac/issues/1",
                "StackOverflow_Post": {
                    "Id": "69895555",
                    "PostTypeId": "1",
                    "CreationDate": "2021-11-09T09:20:18.433",
                    "Score": "2",
                    "ViewCount": "482",
                    "Body": "<p>I am trying to use parallel computing to train many XGBoost models. I am using <code>joblib</code>. I tried the code below and it doesn't work:</p>\n<pre><code># SET UP\nfrom joblib import Parallel, delayed\nimport numpy as np\nimport pandas as pd\nimport xgboost as xgb\n# prepare data\nX = pd.DataFrame(np.random.randint(0,100,size=(100, 4)),\n                    index=range(100), columns=['f1', 'f2', 'f3', 'f4'])\ny = pd.Series(np.random.randint(0,100,size=100))\ndata = xgb.DMatrix(X, y)\n# prepare parameters to try out\nparam_nms = ['subsample', 'learning_rate', 'reg_alpha', 'reg_lambda', \n             'colsample_bytree', 'colsample_bylevel', 'gamma', 'min_child_weight']\nparams_ls = [{param_nm: f for param_nm, f in zip (param_nms, fs)}\n              for fs in firefly]\n\n# TRY 1: this doesn't work\ndef eval_params(params):\n    return xgb.train(params, data)\nParallel(n_jobs=4)(delayed(eval_params)(params) for params in params_ls)\n</code></pre>\n<p>The error message is this:</p>\n<pre><code>---------------------------------------------------------------------------\n_RemoteTraceback                          Traceback (most recent call last)\n_RemoteTraceback: \n&quot;&quot;&quot;\nTraceback (most recent call last):\n  File &quot;C:\\Users\\119433\\Anaconda3\\envs\\py38\\lib\\site-packages\\joblib\\externals\\loky\\backend\\queues.py&quot;, line 153, in _feed\n    obj_ = dumps(obj, reducers=reducers)\n  File &quot;C:\\Users\\119433\\Anaconda3\\envs\\py38\\lib\\site-packages\\joblib\\externals\\loky\\backend\\reduction.py&quot;, line 271, in dumps\n    dump(obj, buf, reducers=reducers, protocol=protocol)\n  File &quot;C:\\Users\\119433\\Anaconda3\\envs\\py38\\lib\\site-packages\\joblib\\externals\\loky\\backend\\reduction.py&quot;, line 264, in dump\n    _LokyPickler(file, reducers=reducers, protocol=protocol).dump(obj)\n  File &quot;C:\\Users\\119433\\Anaconda3\\envs\\py38\\lib\\site-packages\\joblib\\externals\\cloudpickle\\cloudpickle_fast.py&quot;, line 563, in dump\n    return Pickler.dump(self, obj)\nValueError: ctypes objects containing pointers cannot be pickled\n&quot;&quot;&quot;\n\nThe above exception was the direct cause of the following exception:\n\nPicklingError                             Traceback (most recent call last)\n~\\AppData\\Local\\Temp/ipykernel_24472/3216539096.py in &lt;module&gt;\n     18 def eval_params(params):\n     19     return xgb.train(params, data)\n---&gt; 20 Parallel(n_jobs=4)(delayed(eval_params)(params) for params in params_ls)\n     21 \n\n~\\Anaconda3\\envs\\py38\\lib\\site-packages\\joblib\\parallel.py in __call__(self, iterable)\n   1052 \n   1053             with self._backend.retrieval_context():\n-&gt; 1054                 self.retrieve()\n   1055             # Make sure that we get a last message telling us we are done\n   1056             elapsed_time = time.time() - self._start_time\n\n~\\Anaconda3\\envs\\py38\\lib\\site-packages\\joblib\\parallel.py in retrieve(self)\n    931             try:\n    932                 if getattr(self._backend, 'supports_timeout', False):\n--&gt; 933                     self._output.extend(job.get(timeout=self.timeout))\n    934                 else:\n    935                     self._output.extend(job.get())\n\n~\\Anaconda3\\envs\\py38\\lib\\site-packages\\joblib\\_parallel_backends.py in wrap_future_result(future, timeout)\n    540         AsyncResults.get from multiprocessing.&quot;&quot;&quot;\n    541         try:\n--&gt; 542             return future.result(timeout=timeout)\n    543         except CfTimeoutError as e:\n    544             raise TimeoutError from e\n\n~\\Anaconda3\\envs\\py38\\lib\\concurrent\\futures\\_base.py in result(self, timeout)\n    442                     raise CancelledError()\n    443                 elif self._state == FINISHED:\n--&gt; 444                     return self.__get_result()\n    445                 else:\n    446                     raise TimeoutError()\n\n~\\Anaconda3\\envs\\py38\\lib\\concurrent\\futures\\_base.py in __get_result(self)\n    387         if self._exception:\n    388             try:\n--&gt; 389                 raise self._exception\n    390             finally:\n    391                 # Break a reference cycle with the exception in self._exception\n\nPicklingError: Could not pickle the task to send it to the workers.\n</code></pre>\n<p><a href=\"https://github.com/titu1994/pyshac/issues/1\" rel=\"nofollow noreferrer\">This thread</a> suggests class-scope is not pickle able, and <a href=\"https://stackoverflow.com/questions/56884020/spacy-with-joblib-library-generates-pickle-picklingerror-could-not-pickle-the\">this post</a> suggest using a different pacakge. But <a href=\"https://stackoverflow.com/questions/29589327/train-multiple-models-in-parallel-with-sklearn\">this example</a> with sklearn's SVM model works just fine. So I tried to do the same thing with xgboost, and it works!</p>\n<pre><code># TRY 2: this works!\ndef eval_model(X, y, params):\n    model = xgb.XGBRegressor(**params)\n    return model.fit(X, y)\nParallel(n_jobs=4)(delayed(train_model)(X, y, params) for params in params_ls)\n</code></pre>\n<p>So it doesn't seem to be class-scope problem. And I can't figure out where the problem lies. Why does <code>TRY 1</code> fails and <code>TRY 2</code> succeeds?</p>\n",
                    "OwnerUserId": "11278433",
                    "LastEditorUserId": "11989081",
                    "LastEditDate": "2021-11-09T11:26:01.060",
                    "LastActivityDate": "2021-11-09T17:24:59.537",
                    "Title": "Using XGBoost with joblib",
                    "Tags": "<python><machine-learning><parallel-processing><xgboost><joblib>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "69906383",
                "ParentRepo": "https://github.com/ramnes/notion-sdk-py",
                "StackOverflow_Post": {
                    "Id": "69906383",
                    "PostTypeId": "2",
                    "ParentId": "66941759",
                    "CreationDate": "2021-11-09T23:42:21.583",
                    "Score": "0",
                    "Body": "<p>For fetching the data you can use <code>notion-client</code>. The great thing about it is that it supports both sync and async interfaces. What it lacks, though, is an easy way to navigate the data's structure (which is quite complicated in Notion)</p>\n<p>For that you can use <code>basic-notion</code>. It allows you to use model classes to easily access all the properties and attributes of your Notion objects - kind of like you would with an ORM.</p>\n<p>In your case the code might look something like this:</p>\n<pre><code>from notion_client import Client\n\nfrom basic_notion.query import Query\nfrom basic_notion.page import NotionPage, NotionPageList\nfrom basic_notion.field import SelectField, TitleField, NumberField\n\n# First define models\n\nclass MyRow(NotionPage):\n    name = TitleField(property_name='Name')\n    subscription = SelectField(property_name='Subscription')\n    some_number = NumberField(property_name='Some Number')\n    # ... your other fields go here\n    # See your database's schema and the available field classes\n    # in basic_notion.field to define this correctly.\n\nclass MyData(NotionPageList[MyRow]):\n    ITEM_CLS = MyRow\n\n# You need to create an integration and get an API token from Notion:\nNOTION_TOKEN = '&lt;your-notion-api-token&gt;'\nDATABASE_ID = '&lt;your-database-ID&gt;'\n\n# Now you can fetch the data\n\ndef get_data(database_id: str) -&gt; MyData:\n    client = Client(auth=NOTION_TOKEN)\n    data = client.databases.query(\n        **Query(database_id=database_id).filter(\n            # Some filter here\n            MyRow.name.filter.starts_with('John')\n        ).sorts(\n            # You can sort it here\n            MyRow.name.sort.ascending\n        ).serialize()\n    )\n    return MyData(data=data)\n\n\nmy_data = get_data()\nfor row in my_data.items():\n    print(f'{row.name.get_text()} - {row.some_number.number}')\n# Do whatever else you may need to do\n</code></pre>\n<p>For more info, examples and docs see:</p>\n<ul>\n<li>notion-client: <a href=\"https://github.com/ramnes/notion-sdk-py\" rel=\"nofollow noreferrer\">https://github.com/ramnes/notion-sdk-py</a></li>\n<li>basic-notion: <a href=\"https://github.com/altvod/basic-notion\" rel=\"nofollow noreferrer\">https://github.com/altvod/basic-notion</a></li>\n<li>Notion API Reference: <a href=\"https://developers.notion.com/reference/intro\" rel=\"nofollow noreferrer\">https://developers.notion.com/reference/intro</a></li>\n</ul>\n",
                    "OwnerUserId": "1411132",
                    "LastActivityDate": "2021-11-09T23:42:21.583",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "69908274",
                "ParentRepo": "https://github.com/chaostoolkit/chaostoolkit-documentation/blob/master/sources/drivers/kubernetes.md#create_node",
                "StackOverflow_Post": {
                    "Id": "69908274",
                    "PostTypeId": "2",
                    "ParentId": "69898846",
                    "CreationDate": "2021-11-10T05:15:17.683",
                    "Score": "0",
                    "Body": "<p>i think you are using it the right way but</p>\n<pre><code>name: create-node\nprovider:\n  func: create_node\n  module: chaosk8s.node.actions\n  type: python\ntype: action\n</code></pre>\n<p>however, looks like there could be chances it wont work with AKS as mentioned.</p>\n<blockquote>\n<p>Due to the way things work on certain cloud providers, you won't be\nable to use this meaningfully on them. For instance on GCE, this will\nlikely fail.</p>\n</blockquote>\n<p>Read more at : <a href=\"https://github.com/chaostoolkit/chaostoolkit-documentation/blob/master/sources/drivers/kubernetes.md#create_node\" rel=\"nofollow noreferrer\">https://github.com/chaostoolkit/chaostoolkit-documentation/blob/master/sources/drivers/kubernetes.md#create_node</a></p>\n",
                    "OwnerUserId": "5525824",
                    "LastActivityDate": "2021-11-10T05:15:17.683",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "69913676",
                "ParentRepo": "https://github.com/zenml-io/zenml",
                "StackOverflow_Post": {
                    "Id": "69913676",
                    "PostTypeId": "2",
                    "ParentId": "69868258",
                    "CreationDate": "2021-11-10T12:57:44.797",
                    "Score": "4",
                    "Body": "<p>Completely agree with @Talgat that Airflow is not really built for this. It focuses on task-dependencies rather than data-dependencies.</p>\n<p>Perhaps you can look at a data-focused pipeline-ing solution like <a href=\"https://github.com/zenml-io/zenml\" rel=\"nofollow noreferrer\">ZenML</a> to solve this problem? It has a <a href=\"https://docs.zenml.io/guides/low-level-api\" rel=\"nofollow noreferrer\">guide</a> with examples off passing Pandas Dataframes across pipeline steps. You can also leverage data caching across steps and other features that make it more suited to what you're doing.</p>\n<p>On top, a ZenML pipeline is also <a href=\"https://docs.zenml.io/guides/low-level-api/chapter-7\" rel=\"nofollow noreferrer\">deploy-able as an Airflow DAG</a>. So rather than focusing on writing the persisting of artifact logic yourself, you can just let ZenML handle it.</p>\n<p>Disclaimer: I am one of the core contributors of ZenML, so this is admittedly biased. Still thought it might be helpful for the OP!</p>\n",
                    "OwnerUserId": "1561232",
                    "LastActivityDate": "2021-11-10T12:57:44.797",
                    "CommentCount": "3",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "69926305",
                "ParentRepo": "https://github.com/Roald87/TwinCatChangelog/blob/main/tc3_changelog.md#bug-fix",
                "StackOverflow_Post": {
                    "Id": "69926305",
                    "PostTypeId": "2",
                    "ParentId": "69926304",
                    "CreationDate": "2021-11-11T09:56:49.000",
                    "Score": "1",
                    "Body": "<h2>Short answer</h2>\n<p>The .tmcRefac can be ignored as also mentioned <a href=\"https://alltwincat.com/2019/12/02/gitignore-for-twincat/\" rel=\"nofollow noreferrer\">here</a> and it was included in the <a href=\"https://github.com/github/gitignore/blob/master/TwinCAT3.gitignore\" rel=\"nofollow noreferrer\">official GitHub gitignore for TwinCAT</a>. The .tpr file can't be ignored, because it contains important information about the rename history for the System Manager.</p>\n<h2>Long answer</h2>\n<p>The .tmcRefac file contains information about which variable got renamed to what:</p>\n<pre class=\"lang-xml prettyprint-override\"><code>&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt;\n&lt;Refactors&gt;\n  &lt;Renames&gt;\n    &lt;RenamedSymbol&gt;\n      &lt;Type guid=&quot;904700f4-ab78-477a-973a-562c3c32f400&quot;&gt;MAIN&lt;/Type&gt;\n      &lt;From&gt;number1&lt;/From&gt;\n      &lt;To&gt;number2&lt;/To&gt;\n    &lt;/RenamedSymbol&gt;\n  &lt;/Renames&gt;\n&lt;/Refactors&gt;\n</code></pre>\n<p>After building the project with TwinCAT 4024.12 this files seems to get removed. However, if you have a <a href=\"https://infosys.beckhoff.com/content/1033/tc3_plc_intro/47020711795124677131.html?id=8693496841604521684\" rel=\"nofollow noreferrer\">stand alone plc project</a>, it gets converted into a .tpr file. This .tpr file again contains information about  the refactored variable:</p>\n<pre class=\"lang-xml prettyprint-override\"><code>&lt;TcModuleRefactorInfos RefactorCnt=&quot;1&quot;&gt;\n  &lt;TcModuleRefactorInfo RefactorCnt=&quot;1&quot; DateTime=&quot;2021-11-11T10:46:12&quot;&gt;\n    &lt;Renames&gt;\n      &lt;RenameSymbol&gt;\n        &lt;From&gt;MAIN.number1&lt;/From&gt;\n        &lt;To&gt;MAIN.number2&lt;/To&gt;\n      &lt;/RenameSymbol&gt;\n    &lt;/Renames&gt;\n  &lt;/TcModuleRefactorInfo&gt;\n&lt;/TcModuleRefactorInfos&gt;\n</code></pre>\n<p>Beckhoff support says about this file:</p>\n<blockquote>\n<p>The .tpr file is required to save the rename history of I/O variables in a stand-alone PLC project, since the PLC project and the System Manager are not in the same project. I don't think you should ignore the file as it is relevant to the rename history.</p>\n</blockquote>\n<h2>Bug</h2>\n<p>If you're running TwinCAT 4024.10-4024.12 there can be a <a href=\"https://github.com/Roald87/TwinCatChangelog/blob/main/tc3_changelog.md#bug-fix\" rel=\"nofollow noreferrer\">bug</a> which crashes Visual Studio/XAE when a .tpr file is present. Solution is to upgrade to &gt; 4024.15.</p>\n",
                    "OwnerUserId": "6329629",
                    "LastEditorUserId": "6329629",
                    "LastEditDate": "2021-11-15T16:46:52.640",
                    "LastActivityDate": "2021-11-15T16:46:52.640",
                    "CommentCount": "4",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "70107438",
                "ParentRepo": "https://github.com/argoproj-labs/argocd-image-updater",
                "StackOverflow_Post": {
                    "Id": "70107438",
                    "PostTypeId": "2",
                    "ParentId": "59543373",
                    "CreationDate": "2021-11-25T07:47:39.593",
                    "Score": "0",
                    "Body": "<p>This functionality is provided by open-source project <code>argocd-image-updater</code>:</p>\n<p><a href=\"https://github.com/argoproj-labs/argocd-image-updater\" rel=\"nofollow noreferrer\">https://github.com/argoproj-labs/argocd-image-updater</a></p>\n",
                    "OwnerUserId": "16543651",
                    "LastActivityDate": "2021-11-25T07:47:39.593",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "70135068",
                "ParentRepo": "https://github.com/tomcounsell/popoto",
                "StackOverflow_Post": {
                    "Id": "70135068",
                    "PostTypeId": "2",
                    "ParentId": "48179417",
                    "CreationDate": "2021-11-27T13:09:54.960",
                    "Score": "1",
                    "Body": "<p>I've experienced this same situation many times and I wanted something faster than a typical relational database. Redis is very fast and scalable key/value database. You can get started quickly using the <a href=\"https://github.com/tomcounsell/popoto\" rel=\"nofollow noreferrer\">Popoto ORM</a></p>\n<p>Here is an example:</p>\n<pre class=\"lang-py prettyprint-override\"><code>import popoto\n\nclass City(popoto.Model):\n    id = popoto.UniqueKeyField()\n    name = popoto.KeyField()\n    description = popoto.Field()\n\n\nfor line in open(&quot;cities.csv&quot;):\n    csv_row = line.split('\\t')\n    City.create(\n        id=csv_row[0],\n        name=csv_row[1],\n        description=csv_row[2]\n    )\n\nnew_york = City.query.get(name=&quot;New York&quot;)\n</code></pre>\n<p>This is the absolute fastest way to store and retrieve data without having to learn the nuances of a new database system.</p>\n<p>Keep in mind that if your database grows beyond 5GB, an in-memory database like Redis can start to become expensive compared to slower disk-based databases like Postgres or MySQL</p>\n<p>full disclosure: I help maintain the open source Popoto project</p>\n",
                    "OwnerUserId": "2102461",
                    "LastActivityDate": "2021-11-27T13:09:54.960",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "70146199",
                "ParentRepo": "https://github.com/matthewdeanmartin/pydoc_fork",
                "StackOverflow_Post": {
                    "Id": "70146199",
                    "PostTypeId": "2",
                    "ParentId": "69224888",
                    "CreationDate": "2021-11-28T18:15:53.450",
                    "Score": "1",
                    "Body": "<p>I can't reproduce.</p>\n<p>I took your code and faked <code>cv.py</code></p>\n<pre class=\"lang-py prettyprint-override\"><code>class VideoCapture:\n    def __init__(self, *args, **kwargs):\n        pass\n\n    def read(self):\n        pass\n\ndef putText(*args, **kwargs):\n    pass\n</code></pre>\n<p>And then ran:</p>\n<pre class=\"lang-sh prettyprint-override\"><code>python -m pydoc -w your_code\n</code></pre>\n<p>And I got <code>cap = &lt;cv2.VideoCapture object&gt;</code> in the output.</p>\n<p>If you want do also generate documents for cv2, you will need:</p>\n<pre class=\"lang-sh prettyprint-override\"><code>python -m pydoc -w cv2\n</code></pre>\n<p>It is hard to get pydoc to do what you want without either <a href=\"https://github.com/matthewdeanmartin/pydoc_fork\" rel=\"nofollow noreferrer\">forking</a> it or switching to one of the many better alternatives, e.g. pdoc3, pydoctor, or pycco.</p>\n",
                    "OwnerUserId": "33264",
                    "LastEditorUserId": "10521959",
                    "LastEditDate": "2021-11-28T18:38:34.057",
                    "LastActivityDate": "2021-11-28T18:38:34.057",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "70190770",
                "ParentRepo": "https://github.com/rentruewang/koila",
                "StackOverflow_Post": {
                    "Id": "70190770",
                    "PostTypeId": "2",
                    "ParentId": "59129812",
                    "CreationDate": "2021-12-01T20:23:12.333",
                    "Score": "0",
                    "Body": "<p>There is now a pretty awesome library which makes this very simple: <a href=\"https://github.com/rentruewang/koila\" rel=\"nofollow noreferrer\">https://github.com/rentruewang/koila</a></p>\n<pre><code>pip install koila\n</code></pre>\n<p>in your code, simply wrap the input with lazy:</p>\n<pre><code>from koila import lazy\ninput = lazy(input, batch=0)\n</code></pre>\n",
                    "OwnerUserId": "2418922",
                    "LastActivityDate": "2021-12-01T20:23:12.333",
                    "CommentCount": "4",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "70298758",
                "ParentRepo": "https://github.com/math2001/FileManager",
                "StackOverflow_Post": {
                    "Id": "70298758",
                    "PostTypeId": "2",
                    "ParentId": "33324380",
                    "CreationDate": "2021-12-10T01:37:32.370",
                    "Score": "0",
                    "Body": "<p>Tested on: <strong>Sublime Text Build 4113</strong></p>\n<p>For package <a href=\"https://github.com/math2001/FileManager\" rel=\"nofollow noreferrer\">FileManager</a>.</p>\n<p>Open: <em>Preferences -&gt; Key Bindings - User</em></p>\n<p>Paste this code:</p>\n<pre><code>[\n    {\n    &quot;keys&quot;: [&quot;ctrl+alt+n&quot;],\n    &quot;command&quot;: &quot;fm_create&quot;,\n    &quot;args&quot;: { &quot;initial_text&quot;: &quot;$here/&quot; }\n    },\n]\n</code></pre>\n<blockquote>\n<p>Note: <code>&quot;args&quot;: { &quot;initial_text&quot;: &quot;$here/&quot; }</code> allows you to create the\nnew file on the same route as the current file (thaks <a href=\"https://stackoverflow.com/questions/50953535/how-to-create-a-directory-faster-in-sublime-text-3\">OdatNurd</a>).<br/>\nLook at the <code>&quot;aliases&quot;</code> section in <em>Preferences -&gt; Package Settings -&gt; FileManager</em> to see other Alias useful in addition to <code>&quot;$here/&quot;</code></p>\n</blockquote>\n<p>Then, press the assigned keys, this will open an input.</p>\n<p>Write part of the name of an existing folder, and just press <kbd>TAB</kbd> to cycle through the auto completion.</p>\n<p>If you want to create nested folders, write the names of the intermediate folders and pressing <kbd>ENTER</kbd>, these will be created.</p>\n<p>If the last character you type in is a <code>/</code> folder will be created. Otherwise it will be a file.</p>\n",
                    "OwnerUserId": "11447740",
                    "LastEditorUserId": "11447740",
                    "LastEditDate": "2022-04-22T02:38:20.850",
                    "LastActivityDate": "2022-04-22T02:38:20.850",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "70317018",
                "ParentRepo": "https://github.com/moj-analytical-services/splink/blob/4a1704a3bf29703a90f19606989c8a6f8c25ec71/splink/blocking.py#L142",
                "StackOverflow_Post": {
                    "Id": "70317018",
                    "PostTypeId": "1",
                    "CreationDate": "2021-12-11T16:42:16.057",
                    "Score": "2",
                    "ViewCount": "118",
                    "Body": "<p>I am using an inner join to generate record comparisons, for the purpose of <a href=\"https://github.com/moj-analytical-services/splink/blob/4a1704a3bf29703a90f19606989c8a6f8c25ec71/splink/blocking.py#L142\" rel=\"nofollow noreferrer\">deduplicating data</a>.</p>\n<p>I would like to salt these joins so that record comparisons are more equally distributed in the presence of skew.</p>\n<p>What follows is a very simple motivating example - the real input data is much larger.</p>\n<p>Suppose we have a table as follows (csv <a href=\"https://gist.github.com/RobinL/e34dee0e06f982e9b43a43ce90ab2652\" rel=\"nofollow noreferrer\">here</a>).</p>\n<div class=\"s-table-container\">\n<table class=\"s-table\">\n<thead>\n<tr>\n<th>first_name</th>\n<th>surname</th>\n<th>city</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>charles</td>\n<td>dickens</td>\n<td>london</td>\n</tr>\n<tr>\n<td>charlie</td>\n<td>dickens</td>\n<td>london</td>\n</tr>\n<tr>\n<td>virginia</td>\n<td>woolf</td>\n<td>london</td>\n</tr>\n<tr>\n<td>virginia</td>\n<td>wolf</td>\n<td>london</td>\n</tr>\n<tr>\n<td>mary</td>\n<td>shelley</td>\n<td>london</td>\n</tr>\n<tr>\n<td>jane</td>\n<td>austen</td>\n<td>steventon</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>To generate record comparisons I can write sql like:</p>\n<pre class=\"lang-py prettyprint-override\"><code>df = spark.read.csv()\ndf.createOrReplaceTempView(&quot;df&quot;)\n\nsql = &quot;&quot;&quot;\nselect \n  l.first_name as first_name_l,\n  r.first_name as first_name_r,\n  l.surname as surname_l, \n  r.surname as surname_r,\n  l.city as city_l,\n  r.city as city_r\nfrom df as l\ninner join df as r\non l.city = r.city\n&quot;&quot;&quot;\nspark.sql(sql)\n</code></pre>\n<p>On a large dataset, spark will chose a <code>SortMergeJoin</code>.  The data will be HashPartitioned on <code>city</code>.</p>\n<p>All 5 records with <code>city = london</code> will therefore end up on a single executor, on which the cartesian product of the <code>london</code> records will be produced - 25 records in total.</p>\n<p>This creates a problem on real datasets where the count of <code>city=london</code> may be 10,000 - generating 100,000,000 comparisons in a single task on a single executor.</p>\n<p>My question is <strong>how can I salt this join to split up the work more evenly?</strong>. Note that all 25 (or 100m) record comparisons need to be generated - it's just we want them to be spit between different tasks</p>\n<h2>Solutions I've attempted</h2>\n<p>I have a working solution that's very inelegant, as follows.  I'm looking to improve on this.</p>\n<p>Step 1:\nCreate a random integer column, <code>random_int</code>.  For simplicity, let's say this contains integers in the range 1-3.</p>\n<p>Step 2:\nRun the left join three times, and union all</p>\n<pre><code>select {cols}\nfrom df as l\ninner join df as r\non l.city = r.city and l.random_int = 1\n\nUNION ALL\n\nselect {cols}\nfrom df as l\ninner join df as r\non l.city = r.city and l.random_int = 2\n\nUNION ALL\n\nselect {cols}\nfrom df as l\ninner join df as r\non l.city = r.city and l.random_int = 3\n</code></pre>\n<p>This solution gives the right answer, and does run faster on large datasets in the presence of skew.  But it creates a lot of complexity on the execution plan, and I can't help feeling there must be a better way.</p>\n<p>This real context problem is the blocking step of my open source software, <a href=\"https://github.com/moj-analytical-services/splink\" rel=\"nofollow noreferrer\">Splink</a>.  So any help provided will help improve this software.  (PRs are of course welcome as well!)</p>\n",
                    "OwnerUserId": "1779128",
                    "LastActivityDate": "2021-12-11T16:42:16.057",
                    "Title": "PySpark - Salting an inner join in the presence of skew",
                    "Tags": "<apache-spark><pyspark><saltedhash>",
                    "AnswerCount": "0",
                    "CommentCount": "1",
                    "FavoriteCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "70454189",
                "ParentRepo": "https://github.com/camunda-community-hub/camunda-bpm-process-test-coverage",
                "StackOverflow_Post": {
                    "Id": "70454189",
                    "PostTypeId": "2",
                    "ParentId": "70366939",
                    "CreationDate": "2021-12-22T19:27:19.313",
                    "Score": "0",
                    "Body": "<p>I found that a good way of doing unit tests is to use a &quot;hidden&quot; engine configuration, which will always get looked for when you only have an Engine Rule and no other spring based context.\nThis can be accomplished by simply adding a camunda.cfg.xml to your test resources, which could look like this:</p>\n<pre><code>&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;\n\n&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; \n       xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;\n       xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans   http://www.springframework.org/schema/beans/spring-beans.xsd&quot;&gt;\n\n    &lt;bean id=&quot;processEngineConfiguration&quot; class=&quot;org.camunda.bpm.extension.process_test_coverage.junit.rules.ProcessCoverageInMemProcessEngineConfiguration&quot;&gt;\n\n    &lt;property name=&quot;jdbcUrl&quot; value=&quot;jdbc:h2:mem:camunda;DB_CLOSE_DELAY=1000&quot; /&gt;\n    &lt;property name=&quot;jdbcDriver&quot; value=&quot;org.h2.Driver&quot; /&gt;\n    &lt;property name=&quot;jdbcUsername&quot; value=&quot;sa&quot; /&gt;\n    &lt;property name=&quot;jdbcPassword&quot; value=&quot;&quot; /&gt;\n\n    &lt;!-- Database configurations --&gt;\n    &lt;property name=&quot;databaseSchemaUpdate&quot; value=&quot;true&quot; /&gt;\n\n    &lt;!-- job executor configurations --&gt;\n    &lt;property name=&quot;jobExecutorActivate&quot; value=&quot;false&quot; /&gt;\n\n    &lt;property name=&quot;history&quot; value=&quot;full&quot; /&gt;    \n  &lt;/bean&gt;\n&lt;/beans&gt;\n</code></pre>\n<p>Note that this uses a process-coverage engine-configuration, which you can look up <a href=\"https://github.com/camunda-community-hub/camunda-bpm-process-test-coverage\" rel=\"nofollow noreferrer\">here</a>. But you could use any other configuration.</p>\n<p>Once you have this engine configuration you may simply create a unit test like this:</p>\n<pre class=\"lang-java prettyprint-override\"><code>@Deployment(resources = &quot;myBpmFile.bpmn&quot;)\npublic class ApplicationTest {\n\n    private static final String PROCESS_DEFINITION_KEY = &quot;myProcessDefinitionKey&quot;;\n\n    @Rule\n    @ClassRule\n    public static ProcessEngineRule rule = TestCoverageProcessEngineRuleBuilder.create().build();\n\n    private RuntimeService runtimeService;\n\n    @Before\n    public void setup() {\n        runtimeService = rule.getRuntimeService();\n\n        registerJavaDelegateMock(MyDelegate.class)\n        //register more mocks\n    }\n\n    @Test\n    public void testHappyPath() {\n        ProcessInstance processInstance = runtimeService.startProcessInstanceByKey(PROCESS_DEFINITION_KEY);\n        assertThat(processInstance).isActive();\n\n        assertThat(processInstance).hasPassed(&quot;MyServiceTask&quot;);\n        verifyJavaDelegateMock(MyDelegate.class).executed();\n\n        assertThat(processInstance).isWaitingAtExactly(&quot;MyUserTask&quot;);\n        complete(task());\n\n        assertThat(processInstance).isEnded();\n    }\n}\n\n</code></pre>\n<p>Note that this uses <a href=\"https://github.com/camunda-community-hub/camunda-bpm-mockito\" rel=\"nofollow noreferrer\">camunda-bpm-mockito</a> and <a href=\"https://github.com/camunda/camunda-bpm-assert\" rel=\"nofollow noreferrer\">camunda-bpm-assert</a>.\nDefinitely worth looking into this, because it makes your tests lightweight, fast, well defined and easily readable.</p>\n<p>As an added bonus, the test-coverage EngineRule will provide you with valuable coverage diagrams (in html format) and allow for percentage based coverage assertion.</p>\n<p>Edit: this is for JUnit4. You can do it with JUnit 5 aswell.</p>\n",
                    "OwnerUserId": "10608339",
                    "LastActivityDate": "2021-12-22T19:27:19.313",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "70461422",
                "ParentRepo": "https://github.com/taylormcnally/keras-rl2",
                "StackOverflow_Post": {
                    "Id": "70461422",
                    "PostTypeId": "2",
                    "ParentId": "70261352",
                    "CreationDate": "2021-12-23T11:19:51.080",
                    "Score": "1",
                    "Body": "<p>As we talked about in the comments, it seems that the Keras-rl library is no longer supported (the last update in the repository was in 2019), so it's possible that everything is inside Keras now. I take a look at Keras documentation and there are no high-level functions to build a reinforcement learning model, but is possible to use lower-level functions to this.</p>\n<ul>\n<li>Here is an example of how to use Deep Q-Learning with Keras: <a href=\"https://keras.io/examples/rl/deep_q_network_breakout/\" rel=\"nofollow noreferrer\">link</a></li>\n</ul>\n<p>Another solution may be to downgrade to Tensorflow 1.0 as it seems the compatibility problem occurs due to some changes in version 2.0. I didn't test, but maybe the Keras-rl + Tensorflow 1.0 may work.</p>\n<p>There is also a <a href=\"https://github.com/taylormcnally/keras-rl2\" rel=\"nofollow noreferrer\">branch</a> of Keras-rl to support Tensorflow 2.0, the repository is archived, but there is a chance that it will work for you</p>\n",
                    "OwnerUserId": "12361037",
                    "LastActivityDate": "2021-12-23T11:19:51.080",
                    "CommentCount": "7",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "70488760",
                "ParentRepo": "https://github.com/auredentan/starlette-session",
                "StackOverflow_Post": {
                    "Id": "70488760",
                    "PostTypeId": "2",
                    "ParentId": "70455897",
                    "CreationDate": "2021-12-26T18:05:11.743",
                    "Score": "1",
                    "Body": "<p>This is because FastAPI session variables are stored client-side as a cookie, which has a limit of 4096 bytes of data. The data being stored from the redirect url is pushes the cookie size over this limit and results in the data not being stored. <a href=\"https://github.com/auredentan/starlette-session\" rel=\"nofollow noreferrer\">Starlette-session</a> is an alternative SessionMiddleware that stores variables server-side, eliminating cookie limit. Below is a basic (but messy) implementation:</p>\n<pre><code>from fastapi import FastAPI\nfrom fastapi.templating import Jinja2Templates\n\nfrom starlette.requests import Request\nfrom starlette.responses import RedirectResponse\n\nfrom starlette_session import SessionMiddleware\nfrom starlette_session.backends import BackendType\n\nfrom redis import Redis\n\nimport uvicorn\nimport functools\nimport msal\n\n\napp_client_id = &quot;sample_msal_client_id&quot;\napp_client_secret = &quot;sample_msal_client_secret&quot;\ntenant_id = &quot;sample_msal_tenant_id&quot;\n\napp = FastAPI()\n\n\nredis_client = Redis(host=&quot;localhost&quot;, port=6379)\napp.add_middleware(\n    SessionMiddleware,\n    secret_key=&quot;SECURE_SECRET_KEY&quot;,\n    cookie_name=&quot;auth_cookie&quot;,\n    backend_type=BackendType.redis,\n    backend_client=redis_client,\n)\n\ntemplates = Jinja2Templates(directory=&quot;templates&quot;)\n\ndefault_scope = [&quot;https://graph.microsoft.com/.default&quot;]\ntoken_cache_key = &quot;token_cache&quot;\n\n# Private Functions - Start\ndef _load_cache(session):\n    cache = msal.SerializableTokenCache()\n    if session.get(token_cache_key):\n        cache.deserialize(session[token_cache_key])\n    return cache\n\ndef _save_cache(cache,session):\n    if cache.has_state_changed:\n        session[token_cache_key] = cache.serialize()\n\ndef _build_msal_app(cache=None):\n    return msal.ConfidentialClientApplication(\n        app_client_id, \n        client_credential=app_client_secret,\n        authority=f&quot;https://login.microsoftonline.com/{tenant_id}&quot;,\n        token_cache=cache\n    )\n\ndef _build_auth_code_flow(request):\n    return _build_msal_app().initiate_auth_code_flow(\n        default_scope, #Scopes\n        redirect_uri=request.url_for(&quot;callback&quot;) #Redirect URI\n    )\n\ndef _get_token_from_cache(session):\n    cache = _load_cache(session)  # This web app maintains one cache per session\n    cca = _build_msal_app(cache=cache)\n    accounts = cca.get_accounts()\n    if accounts:  # So all account(s) belong to the current signed-in user\n        result = cca.acquire_token_silent(default_scope, account=accounts[0])\n        _save_cache(cache,session)\n        return result\n# Private Functions - End\n\n\n# Custom Decorators - Start\ndef authenticated_endpoint(func):\n    @functools.wraps(func)\n    def is_authenticated(*args,**kwargs):\n        try:\n            request = kwargs[&quot;request&quot;]\n            token = _get_token_from_cache(request.session)\n            if not token:\n                return RedirectResponse(request.url_for(&quot;login&quot;))\n            return func(*args,**kwargs)\n        except:\n            return RedirectResponse(request.url_for(&quot;login&quot;))\n\n    return is_authenticated\n# Custom Decorators - End\n\n\n# Endpoints - Start\n@app.get(&quot;/&quot;)\n@authenticated_endpoint\ndef index(request:Request):\n    return {\n        &quot;result&quot;: &quot;good&quot;\n    }\n\n@app.get(&quot;/login&quot;)\ndef login(request:Request):\n    return templates.TemplateResponse(&quot;login.html&quot;,{\n        &quot;version&quot;: msal.__version__,\n        'request': request,\n        &quot;config&quot;: {\n            &quot;B2C_RESET_PASSWORD_AUTHORITY&quot;: False\n        }\n    })\n\n@app.get(&quot;/oauth/redirect&quot;)\ndef get_redirect_url(request:Request):\n    request.session[&quot;flow&quot;] = _build_auth_code_flow(request)\n    return RedirectResponse(request.session[&quot;flow&quot;][&quot;auth_uri&quot;])\n\n@app.get(&quot;/callback&quot;)\nasync def callback(request:Request):\n    cache = _load_cache(request.session)\n    result = _build_msal_app(cache=cache).acquire_token_by_auth_code_flow(request.session.get(&quot;flow&quot;, {}), dict(request.query_params))\n    if &quot;error&quot; in result:\n        return templates.TemplateResponse(&quot;auth_error.html&quot;,{\n            &quot;result&quot;: result,\n            'request': request\n        })\n    request.session[&quot;user&quot;] = result.get(&quot;id_token_claims&quot;)\n    request.session[token_cache_key] = cache.serialize()\n    return RedirectResponse(request.url_for(&quot;index&quot;))\n# Endpoints - End\n\nif __name__ == &quot;__main__&quot;:\n    uvicorn.run(&quot;main:app&quot;,host='0.0.0.0', port=4557,reload=True)`\n</code></pre>\n",
                    "OwnerUserId": "13217247",
                    "LastActivityDate": "2021-12-26T18:05:11.743",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "70489061",
                "ParentRepo": "https://github.com/carla-simulator/ros-bridge/issues/368",
                "StackOverflow_Post": {
                    "Id": "70489061",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "70724051",
                    "CreationDate": "2021-12-26T18:55:28.363",
                    "Score": "1",
                    "ViewCount": "490",
                    "Body": "<p>When I'm running <code>bazel test ...</code> the cpp code will compile, but Python gets stuck.\nI read these before I wrote this question, but I can not find any solution:</p>\n<p><a href=\"https://github.com/pybind/pybind11/issues/314\" rel=\"nofollow noreferrer\">https://github.com/pybind/pybind11/issues/314</a></p>\n<p><a href=\"https://stackoverflow.com/questions/56002315/undefined-symbol-pythreadstate-current-when-importing-tensorflow\">undefined symbol: _PyThreadState_Current when importing tensorflow</a></p>\n<p><a href=\"https://github.com/carla-simulator/ros-bridge/issues/368\" rel=\"nofollow noreferrer\">https://github.com/carla-simulator/ros-bridge/issues/368</a></p>\n<p><a href=\"https://python-forum.io/thread-32297.html\" rel=\"nofollow noreferrer\">https://python-forum.io/thread-32297.html</a></p>\n<p>OS:\n<code>Linux 5.11.0-43-generic #47~20.04.2-Ubuntu SMP Mon Dec 13 11:06:56 UTC 2021 x86_64 x86_64 x86_64 GNU/Linux</code></p>\n<p>Python: <code>Python 3.8.10</code></p>\n<p>g++: <code>g++ (Ubuntu 9.3.0-17ubuntu1~20.04) 9.3.0</code></p>\n<p>pybind11: <code>v2.8.1</code></p>\n<p>C++ Code:</p>\n<pre class=\"lang-cpp prettyprint-override\"><code>//math.cc\n#include &lt;pybind11/pybind11.h&gt;\n\nint add(int i, int j) {\n  return i + j;\n}\n\nint subtract(int i, int j) {\n  return i - j;\n}\n\nnamespace py = pybind11;\n\nPYBIND11_MODULE(math, m) {\n  m.def(&quot;add&quot;, &amp;add);\n\n  m.def(&quot;subtract&quot;, &amp;subtract);\n}\n</code></pre>\n<p>Python code:</p>\n<pre class=\"lang-py prettyprint-override\"><code>#math_test.py\nfrom module import t_math\n\nassert t_math.add(1, 1) == 2\nassert t_math.subtract(1, 1) == 0\n</code></pre>\n<p>BUILD :</p>\n<pre class=\"lang-py prettyprint-override\"><code>load(&quot;@pybind11_bazel//:build_defs.bzl&quot;, &quot;pybind_extension&quot;)\n\npybind_extension(\n  name = &quot;t_math&quot;,\n  srcs = [&quot;math.cc&quot;],\n)\n    \npy_test(\n  python_version = &quot;PY3&quot;,\n  name = &quot;math_test&quot;,\n  size = &quot;small&quot;,\n  srcs = [&quot;math_test.py&quot;],\n  data = [&quot;:t_math.so&quot;],\n)\n</code></pre>\n<p>error :</p>\n<blockquote>\n<p>Traceback (most recent call last):   File\n&quot;/home/user/.cache/bazel/_bazel_user/a768e2cde210bf677ee66cfded678e04/sandbox/linux-sandbox/52/execroot/<strong>main</strong>/bazel-out/k8-fastbuild/bin/module/math_test.runfiles/<strong>main</strong>/module/math_test.py&quot;,\nline 7, in \nfrom module import t_math ImportError: /home/user/.cache/bazel/_bazel_user/a768e2cde210bf677ee66cfded678e04/sandbox/linux-sandbox/52/execroot/<strong>main</strong>/bazel-out/k8-fastbuild/bin/module/math_test.runfiles/<strong>main</strong>/module/t_math.so:\nundefined symbol: _PyThreadState_Current</p>\n</blockquote>\n",
                    "OwnerUserId": "13198008",
                    "LastActivityDate": "2022-06-10T05:45:28.653",
                    "Title": "undefined symbol: _PyThreadState_Current when using pybind wrapped C++ code",
                    "Tags": "<python><c++><bazel><pybind11>",
                    "AnswerCount": "2",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "70523284",
                "ParentRepo": "https://github.com/uktrade/stream-zip",
                "StackOverflow_Post": {
                    "Id": "70523284",
                    "PostTypeId": "2",
                    "ParentId": "10405210",
                    "CreationDate": "2021-12-29T18:09:10.890",
                    "Score": "0",
                    "Body": "<p>An option is to use <a href=\"https://github.com/uktrade/stream-zip\" rel=\"nofollow noreferrer\">stream-zip</a> (full disclosure: written by me)</p>\n<p>Amending its example slightly:</p>\n<pre class=\"lang-py prettyprint-override\"><code>from datetime import datetime\nfrom stream_zip import stream_zip, ZIP_64\n\ndef non_zipped_files():\n    modified_at = datetime.now()\n    perms = 0o600\n\n    # Hard coded in this example, but in real cases could\n    # for example yield data from a remote source\n    def file_1_data():\n        for i in range(0, 1000):\n            yield b'Some bytes'\n\n    def file_2_data():\n        for i in range(0, 1000):\n            yield b'Some bytes'\n\n    yield 'my-file-1.txt', modified_at, perms, ZIP64, file_1_data()\n    yield 'my-file-2.txt', modified_at, perms, ZIP64, file_2_data()\n\nzipped_chunks = stream_zip(non_zipped_files())\n\n# Can print each chunk, or return them to a client,\n# say using Django's StreamingHttpResponse\nfor zipped_chunk in zipped_chunks:\n    print(zipped_chunk)\n</code></pre>\n",
                    "OwnerUserId": "1319998",
                    "LastEditorUserId": "1319998",
                    "LastEditDate": "2022-01-04T08:26:45.793",
                    "LastActivityDate": "2022-01-04T08:26:45.793",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "70616859",
                "ParentRepo": "https://github.com/amundsen-io/amundsen/blob/main/docs/installation.md#bootstrap-a-default-",
                "StackOverflow_Post": {
                    "Id": "70616859",
                    "PostTypeId": "1",
                    "CreationDate": "2022-01-07T05:10:30.900",
                    "Score": "1",
                    "ViewCount": "28",
                    "Body": "<p>Dears\nRecently I came across with issue while constructing the metadata solution - Amundsen for the enterprise DWH. with the below mentioned github repository everything went well. But, unfortunately I unable to connect to the database with Amundsen databuilder.\nI have entered all the credentials and IP of data source to the respective loader files\nfrom the amundsen\\databuilder\\example\\scripts folder.</p>\n<p>Could you please advice any suggestions for connecting to the database?</p>\n<p><a href=\"https://github.com/amundsen-io/amundsen/blob/main/docs/installation.md#bootstrap-a-default-\" rel=\"nofollow noreferrer\">https://github.com/amundsen-io/amundsen/blob/main/docs/installation.md#bootstrap-a-default-</a>\nversion-of-amundsen-using-docker</p>\n",
                    "OwnerUserId": "13266304",
                    "LastActivityDate": "2022-01-07T05:10:30.900",
                    "Title": "Connecting to database with Amundsen databuilder",
                    "Tags": "<database><metadata><data-warehouse>",
                    "AnswerCount": "0",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "70632319",
                "ParentRepo": "https://github.com/strawberry-graphql/strawberry-graphql-django",
                "StackOverflow_Post": {
                    "Id": "70632319",
                    "PostTypeId": "2",
                    "ParentId": "70631914",
                    "CreationDate": "2022-01-08T12:30:21.640",
                    "Score": "1",
                    "Body": "<p>As @IainShelvington said in comments the parameter to <code>GraphQLView</code> should be a schema object you can also see it in <a href=\"https://github.com/strawberry-graphql/strawberry-graphql-django\" rel=\"nofollow noreferrer\">docs</a>:</p>\n<pre><code> path('graphql', GraphQLView.as_view(schema=schema), name='graphql'),\n</code></pre>\n",
                    "OwnerUserId": "5067761",
                    "LastActivityDate": "2022-01-08T12:30:21.640",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "70653752",
                "ParentRepo": "https://github.com/jdoiro3/mkdocs-multirepo-plugin",
                "StackOverflow_Post": {
                    "Id": "70653752",
                    "PostTypeId": "2",
                    "ParentId": "62793874",
                    "CreationDate": "2022-01-10T14:13:24.087",
                    "Score": "2",
                    "Body": "<p>You can accomplish this using <a href=\"https://www.mkdocs.org/\" rel=\"nofollow noreferrer\">MkDocs</a> as your static site generator and the <a href=\"https://github.com/jdoiro3/mkdocs-multirepo-plugin\" rel=\"nofollow noreferrer\">multirepo plugin</a>. Below are the steps to get it all setup. I assume you have Python installed and you created a Python <a href=\"https://docs.python.org/3/library/venv.html\" rel=\"nofollow noreferrer\">venv</a>.</p>\n<ol>\n<li><code>python -m pip install git+https://github.com/jdoiro3/mkdocs-multirepo-plugin</code></li>\n<li><code>mkdocs new my-project</code></li>\n<li><code>cd my-project</code></li>\n<li>Add the below to your newly created <code>mkdocs.yml</code>. This will configure the plugin.</li>\n</ol>\n<pre class=\"lang-yaml prettyprint-override\"><code>plugins:\n  - multirepo:\n      repos:\n        - section: Repo1\n          import_url: {Repo1 url}\n        - section: Repo2\n          import_url: {Repo2 url}\n        - section: Repo3\n          import_url: {Repo3 url}\n</code></pre>\n<p>Now, you can run <code>mkdocs serve</code> or <code>mkdocs build</code>, which will build a static site with all the documentation in one site.</p>\n",
                    "OwnerUserId": "10044811",
                    "LastActivityDate": "2022-01-10T14:13:24.087",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "70721025",
                "ParentRepo": "https://github.com/sdispater/tomlkit",
                "StackOverflow_Post": {
                    "Id": "70721025",
                    "PostTypeId": "1",
                    "CreationDate": "2022-01-15T11:34:37.333",
                    "Score": "0",
                    "ViewCount": "352",
                    "Body": "<p>I am trying to use <a href=\"https://github.com/sdispater/tomlkit\" rel=\"nofollow noreferrer\">tomlkit</a>  0.8.0 to create a TOML from the following data:</p>\n<pre class=\"lang-py prettyprint-override\"><code>data = {\n    'stuff': [\n        {'a':1, 'b': 2},\n        {'c': 3},\n        {'a': 4},\n    ]\n}\n</code></pre>\n<p>in this format exactly:</p>\n<pre><code>stuff = [\n    {a = 1, b = 2},\n    {c = 3},\n    {a = 4}, \n]\n</code></pre>\n<p>A simple<code>print(tomlkit.dumps(data))</code> creates:</p>\n<pre><code>[[stuff]]\na = 1\nb = 2\n\n[[stuff]]\nc = 3\n\n[[stuff]]\na = 4\n</code></pre>\n<p>How can this be done is a simple way?</p>\n",
                    "OwnerUserId": "57952",
                    "LastActivityDate": "2022-01-15T11:34:37.333",
                    "Title": "tomlkit: nicely formatted array with inline tables",
                    "Tags": "<python><toml><tomlkit>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "70724968",
                "ParentRepo": "https://github.com/PyFPDF/fpdf2/blob/master/fpdf/image_parsing.py",
                "StackOverflow_Post": {
                    "Id": "70724968",
                    "PostTypeId": "2",
                    "ParentId": "50635651",
                    "CreationDate": "2022-01-15T20:00:05.700",
                    "Score": "0",
                    "Body": "<p>Yes, you can use bytes instead of a file ...</p>\n<p>In my case i have an MSSQL query that contains images as a binary string. And i want to use them directly, without saving multiple image-files. So i was looking for a solution.</p>\n<p>What we need:</p>\n<pre><code>pip install fpdf2\n</code></pre>\n<p>Then import IO and FPDF2 into your python 3.x file:</p>\n<pre><code>import io\nfrom fpdf import FPDF\n</code></pre>\n<p>A look into the <a href=\"https://github.com/PyFPDF/fpdf2/blob/master/fpdf/image_parsing.py\" rel=\"nofollow noreferrer\">image_parsing.py</a> of the fpdf2-repository on Github shows that fpdf2 can work with binary objects too. No real image-file needed.</p>\n<p>With <a href=\"https://docs.python.org/3/library/io.html#binary-i-o\" rel=\"nofollow noreferrer\">BytesIO from io</a> we can create a binary object out of our bytes string.</p>\n<p>We name the binary object 'picture' and place it as our image into the PDF page.</p>\n<pre><code>import io\nfrom fpdf import FPDF\n\n# create bytes object of the image data\npicture = io.BytesIO(b&quot;some initial binary data: \\x00\\x01&quot;)\n\n# set page to portrait A4 and positioning in mm\npdf = FPDF(&quot;P&quot;, &quot;mm&quot;, &quot;A4&quot;)\n\n# create a page\npdf.add_page()\n\n# insert image\n# on position: x=10mm, y=10mm\n# size: width=50mm hight=auto\npdf.image(picture,10,10,50)\n\n# create PDF file\npdf.output(&quot;fpdf_test.pdf&quot;)\n</code></pre>\n<p>I hope this is helpful to some people.</p>\n",
                    "OwnerUserId": "15606721",
                    "LastEditorUserId": "15606721",
                    "LastEditDate": "2022-01-16T13:33:01.453",
                    "LastActivityDate": "2022-01-16T13:33:01.453",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "71011192",
                "ParentRepo": "https://github.com/sp1thas/scrapy-folder-tree",
                "StackOverflow_Post": {
                    "Id": "71011192",
                    "PostTypeId": "2",
                    "ParentId": "12956653",
                    "CreationDate": "2022-02-06T20:05:52.830",
                    "Score": "0",
                    "Body": "<p>This scrapy pipeline extension provides an easy way to store downloaded files into a folder tree.</p>\n<p>You have to install it:</p>\n<pre class=\"lang-sh prettyprint-override\"><code>pip install scrapy_folder_tree\n</code></pre>\n<p>and then, add the pipeline on your configuration:</p>\n<pre class=\"lang-py prettyprint-override\"><code>ITEM_PIPELINES = {\n    'scrapy_folder_tree.ImagesHashTreePipeline': 300\n}\n</code></pre>\n<p>Disclaimer: I'm the author of <a href=\"https://github.com/sp1thas/scrapy-folder-tree\" rel=\"nofollow noreferrer\">scrapy-folder-tree</a></p>\n",
                    "OwnerUserId": "6779252",
                    "LastActivityDate": "2022-02-06T20:05:52.830",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "71243391",
                "ParentRepo": "https://github.com/ma7555/evalify",
                "StackOverflow_Post": {
                    "Id": "71243391",
                    "PostTypeId": "2",
                    "ParentId": "62339925",
                    "CreationDate": "2022-02-23T20:06:30.583",
                    "Score": "0",
                    "Body": "<p>Pretty old post but I am replying for future readers. I created <a href=\"https://github.com/ma7555/evalify\" rel=\"nofollow noreferrer\">https://github.com/ma7555/evalify</a> for all those rowwise similarity/distance calculations (disclaimer: i am the owner of the package)</p>\n",
                    "OwnerUserId": "10549044",
                    "LastEditorUserId": "10619147",
                    "LastEditDate": "2022-02-24T22:55:54.820",
                    "LastActivityDate": "2022-02-24T22:55:54.820",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "71305090",
                "ParentRepo": "https://github.com/k3d-io/k3d/issues/209",
                "StackOverflow_Post": {
                    "Id": "71305090",
                    "PostTypeId": "2",
                    "ParentId": "71254632",
                    "CreationDate": "2022-03-01T07:34:33.957",
                    "Score": "0",
                    "Body": "<p>It depends on your context, OS, version.</p>\n<p>For instance, you will see various proxy issue in <a href=\"https://github.com/k3d-io/k3d/issues/209\" rel=\"nofollow noreferrer\"><code>k3d-io/k3d</code> issue 209</a></p>\n<p>this could be related to the way k3d creates the docker network.</p>\n<blockquote>\n<p>Indeed, k3d creates a custom docker network for each cluster and when this happens resolving is done through the docker daemon.<br />\nThe requests are actually forwarded to the DNS servers configured in your host's <code>resolv.conf</code>. But through a single DNS server (the embedded one of docker).</p>\n<p>This means that if your daemon.json is, like mine, not configured to provide extra DNS servers it defaults to 8.8.8.8 which does not resolve any company address for example.</p>\n<p>It would be useful to have a custom options to provide to k3d when it starts the cluster and specify the DNS servers there</p>\n</blockquote>\n<p>Which is why there is &quot;<a href=\"https://github.com/k3d-io/k3d/issues/220\" rel=\"nofollow noreferrer\">v3/networking: <code>--network</code> flag to attach to existing networks</a>&quot;, referring to <a href=\"https://k3d.io/v5.3.0/design/networking/\" rel=\"nofollow noreferrer\">Networking</a>.</p>\n<p>Before that new flag:</p>\n<blockquote>\n<p>For those who have the problem, a simple fix is to mount your <code>/etc/resolve.conf</code> onto the cluster:</p>\n<pre><code>k3d cluster create --volume /etc/resolv.conf:/etc/resolv.conf\n</code></pre>\n</blockquote>\n",
                    "OwnerUserId": "6309",
                    "LastActivityDate": "2022-03-01T07:34:33.957",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "71339314",
                "ParentRepo": "https://github.com/encode/typesystem",
                "StackOverflow_Post": {
                    "Id": "71339314",
                    "PostTypeId": "2",
                    "ParentId": "71331557",
                    "CreationDate": "2022-03-03T15:03:05.120",
                    "Score": "0",
                    "Body": "<p>You have multiple well knowns module to perform serialization (independant of any framework):</p>\n<p>Marshmallow: <a href=\"https://marshmallow.readthedocs.io/en/stable/\" rel=\"nofollow noreferrer\">https://marshmallow.readthedocs.io/en/stable/</a>\nTypesystem (by the creator of DRF): <a href=\"https://github.com/encode/typesystem\" rel=\"nofollow noreferrer\">https://github.com/encode/typesystem</a></p>\n<p>You can also do your own serializer, based on DRF serializer code, if your use case is simple, or just perform a lookup of your dict fields that perform validation/transformation.</p>\n",
                    "OwnerUserId": "10034177",
                    "LastActivityDate": "2022-03-03T15:03:05.120",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "71375546",
                "ParentRepo": "https://github.com/edd313/ndicts",
                "StackOverflow_Post": {
                    "Id": "71375546",
                    "PostTypeId": "2",
                    "ParentId": "10756427",
                    "CreationDate": "2022-03-07T01:23:47.683",
                    "Score": "1",
                    "Body": "<p>For a ready-made solution install <a href=\"https://github.com/edd313/ndicts\" rel=\"nofollow noreferrer\">ndicts</a></p>\n<pre><code>pip install ndicts\n</code></pre>\n<p>Import a NestedDict in your script</p>\n<pre><code>from ndicts.ndicts import NestedDict\n</code></pre>\n<p>Initialize</p>\n<pre><code>dictionary = {\n    u'xml': {\n        u'config': {\n            u'portstatus': {u'status': u'good'}, \n            u'target': u'1'\n        },\n    u'port': u'11'\n    }\n}\n\nnd = NestedDict(dictionary)\n</code></pre>\n<p>Iterate</p>\n<pre><code>for key, value in nd.items():\n    print(key, value)\n</code></pre>\n",
                    "OwnerUserId": "12040751",
                    "LastActivityDate": "2022-03-07T01:23:47.683",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "71433131",
                "ParentRepo": "https://github.com/Textualize/textual",
                "StackOverflow_Post": {
                    "Id": "71433131",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "71503651",
                    "CreationDate": "2022-03-11T02:55:22.490",
                    "Score": "2",
                    "ViewCount": "774",
                    "Body": "<p>I'm trying to get it so I can add links in text rendered by <a href=\"https://github.com/Textualize/textual\" rel=\"nofollow noreferrer\">Textual</a>.</p>\n<p>My text may have multiple links, for example:</p>\n<pre><code>Hello [@click=hello]World[/] there, how are you?\nThis is a test of [@click=more] more info[/] being clickable as well.\n</code></pre>\n<p>In this simple sample I made, clicking on the word &quot;World&quot; should hopefully change the background color to red, but it doesn't work.</p>\n<p>NOTE: I also bound the &quot;b&quot; key to do pretty much the same thing, so I could see it work\nIt should change the background color, and the subtitle of the app.</p>\n<pre class=\"lang-py prettyprint-override\"><code>import os\nimport sys\nfrom rich.console import RenderableType\nfrom rich.panel import Panel\nfrom rich.text import Text\nfrom textual.app import App\nfrom textual.widgets import Header, Footer, ScrollView\nfrom textual.widgets import Placeholder\n\nclass MyApp(App):\n\n    async def on_load(self) -&gt; None:\n        await self.bind(&quot;b&quot;, &quot;color('blue')&quot;)\n\n    async def on_mount(self) -&gt; None:\n        await self.view.dock(Header(), size=5, edge=&quot;top&quot;)\n        await self.view.dock(Footer(), edge=&quot;bottom&quot;)\n        await self.view.dock(ScrollView(Panel(&quot;Hello [@click=hello]World[/] more info here&quot;)), edge=&quot;top&quot;)\n\n    async def action_color(self, color:str) -&gt; None:\n        self.app.sub_title = &quot;KEYBOARD&quot;\n        self.background = f&quot;on {color}&quot;\n\n    async def action_hello(self) -&gt; None:\n        self.app.sub_title = &quot;CLICKED&quot;\n        self.background = &quot;on red&quot;\n\nMyApp.run(title=&quot;Test click&quot;, log=&quot;textual.log&quot;)\n</code></pre>\n<p>I asked this same question in the <a href=\"https://github.com/Textualize/textual/discussions/323\" rel=\"nofollow noreferrer\">textual discussions</a> and originally <a href=\"https://github.com/Textualize/rich/discussions/2021#discussioncomment-2288880\" rel=\"nofollow noreferrer\">rich discussions</a>, but haven't been able to see how to make this work from the feedback I received there, which was helpful for sure, but I'm missing something here, so thanks for any input.</p>\n",
                    "OwnerUserId": "26510",
                    "LastEditorUserId": "26510",
                    "LastEditDate": "2022-03-16T11:27:15.290",
                    "LastActivityDate": "2022-04-26T05:50:46.963",
                    "Title": "Textual (python) - how to add click event in simple Text object?",
                    "Tags": "<python><tui><rich>",
                    "AnswerCount": "2",
                    "CommentCount": "0",
                    "FavoriteCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "71562082",
                "ParentRepo": "https://github.com/roman-right/beanie/blob/main/tests/odm/documents/test_bulk_write.py",
                "StackOverflow_Post": {
                    "Id": "71562082",
                    "PostTypeId": "1",
                    "CreationDate": "2022-03-21T18:00:46.843",
                    "Score": "0",
                    "ViewCount": "1077",
                    "Body": "<p>I am using <code>beanie==1.10.1</code></p>\n<p>I want to perform bulk operation with updating multiple documents with <code>upsert=True</code>. I expect following code to insert full document if find query didn't give results.\nI was using this as a reference: <a href=\"https://github.com/roman-right/beanie/blob/main/tests/odm/documents/test_bulk_write.py\" rel=\"nofollow noreferrer\">https://github.com/roman-right/beanie/blob/main/tests/odm/documents/test_bulk_write.py</a></p>\n<p>Here is full code:</p>\n<pre><code>import beanie\nimport asyncio\nimport random\nfrom beanie import BulkWriter\nfrom beanie.odm.operators.update.general import Set\nfrom motor.motor_asyncio import AsyncIOMotorClient\n\n\nclass TestDoc(beanie.Document):\n    a: str\n    b: int\n\n\nasync def init_mongo():\n    mongo_client = AsyncIOMotorClient(&quot;mongodb://127.0.0.1:27017&quot;)\n    await beanie.init_beanie(\n        database=mongo_client.db_name, document_models=[TestDoc]\n    )\n\n\nasync def run_test():\n    await init_mongo()\n\n    docs = [TestDoc(a=f&quot;id_{i}&quot;, b=random.randint(1, 100)) for i in range(10)]\n    async with BulkWriter() as bulk_writer:\n        for doc in docs:\n            await TestDoc \\\n                .find_one({TestDoc.a: doc.a}, bulk_writer=bulk_writer) \\\n                .upsert(Set({TestDoc.b: doc.b}), on_insert=doc, bulk_writer=bulk_writer)\n                # .update_one(Set(doc), bulk_writer=bulk_writer, upsert=True)\n\n    read_docs = await TestDoc.find().to_list()\n    print(f&quot;read_docs: {read_docs}&quot;)\n\n\nif __name__ == '__main__':\n    pool = asyncio.get_event_loop()\n    pool.run_until_complete(run_test())\n\n</code></pre>\n<p>After executing no documents are inserted into db. Not with <code>.upsert()</code> nor with <code>.update_one()</code> method. What is correct way to achieve that logic?</p>\n<p>With <code>pymongo</code> such operation would be written like so (and it works):</p>\n<pre><code>def write_reviews(self, docs: List[TestDoc]):\n    operations = []\n    for doc in docs:\n        doc_dict = to_dict(doc)\n        update_operation = pymongo.UpdateOne(\n            {&quot;a&quot;: doc.a}, {&quot;$set&quot;: doc_dict}, upsert=True\n        )\n        operations.append(update_operation)\n\n    result = self.test_collection.bulk_write(operations)\n \n</code></pre>\n<p>PS: Cannot create <code>beanie</code> tag here. Can someone create it for me?</p>\n",
                    "OwnerUserId": "7968764",
                    "LastEditorUserId": "7968764",
                    "LastEditDate": "2022-03-21T18:08:04.387",
                    "LastActivityDate": "2022-09-04T01:56:19.863",
                    "Title": "Python `beanie` mongo ODM: Bulk update with upsert=True",
                    "Tags": "<python><mongodb><python-asyncio><tornado-motor>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "71608898",
                "ParentRepo": "https://github.com/hrcorval/behavex",
                "StackOverflow_Post": {
                    "Id": "71608898",
                    "PostTypeId": "2",
                    "ParentId": "69475920",
                    "CreationDate": "2022-03-24T20:17:52.367",
                    "Score": "1",
                    "Body": "<p>We have been trying for a while to implement parallel test executions with behave (which is an amazing framework). Finally, we created our own wrapper on top of Behave, called BehaveX, that not only allow us to execute tests in parallel, but also comes with great reports and some additional features:\u00a0\n<a href=\"https://github.com/hrcorval/behavex\" rel=\"nofollow noreferrer\">https://github.com/hrcorval/behavex</a></p>\n<p>As BehaveX is implemented over the Behave framework, with this wrapper you should be able to replace the &quot;behave&quot; executable by &quot;behavex&quot;, and run the tests in parallel using the following commands:</p>\n<p>behavex -t @TAG --parallel-processes 4 --parallel-scheme scenario</p>\n<p>behavex -t @TAG --parallel-processes 3 --parallel-scheme feature</p>\n",
                    "OwnerUserId": "17358700",
                    "LastEditorUserId": "17358700",
                    "LastEditDate": "2022-06-24T20:32:41.267",
                    "LastActivityDate": "2022-06-24T20:32:41.267",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "71672778",
                "ParentRepo": "https://github.com/citrix/workspace-windows-vcsdk/blob/master/docs/using-example-programs.md",
                "StackOverflow_Post": {
                    "Id": "71672778",
                    "PostTypeId": "1",
                    "CreationDate": "2022-03-30T06:56:41.833",
                    "Score": "0",
                    "ViewCount": "118",
                    "Body": "<p>i use <a href=\"https://github.com/citrix/workspace-windows-vcsdk/blob/master/docs/using-example-programs.md\" rel=\"nofollow noreferrer\">https://github.com/citrix/workspace-windows-vcsdk/blob/master/docs/using-example-programs.md</a> to using Citrix Virtual Channel.</p>\n<ol>\n<li>I compiled example solution</li>\n<li>I puted vdpingn.dll to $ICAROOT\\ICA Client (like other dlls)</li>\n<li>And add regkeys\n<img src=\"https://i.stack.imgur.com/LTYtl.png\" alt=\"enter image description here\" />\n<img src=\"https://i.stack.imgur.com/O5Cxo.png\" alt=\"enter image description here\" /></li>\n<li>Reboot machine</li>\n<li>Run citrix workspace</li>\n<li>Run virtual app ( calc.exe )</li>\n<li>dll not loaded\n<img src=\"https://i.stack.imgur.com/VY8NW.png\" alt=\"enter image description here\" /></li>\n<li>I started looking for my mistake and found this:</li>\n</ol>\n<p>Compiled dll (from citrix's examples) has <strong>cdecl</strong> calling convention on 'Load' function ('Load' provided by your sdk's lib)\nInstruction told me i should use <strong>stdcall</strong>.\n<img src=\"https://i.stack.imgur.com/iB3I5.png\" alt=\"enter image description here\" /></p>\n<p>SDK version: VCSDK 2202</p>\n<p>What i do wrong? Could anybody help me?</p>\n<p>Hope\nlittle programmer</p>\n",
                    "OwnerUserId": "13806726",
                    "LastEditorUserId": "703163",
                    "LastEditDate": "2022-03-30T07:07:54.403",
                    "LastActivityDate": "2022-03-30T07:07:54.403",
                    "Title": "How to: load client dll by citrix workspace",
                    "Tags": "<c++><dll><citrix><virtual-channel>",
                    "AnswerCount": "0",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "71673816",
                "ParentRepo": "https://github.com/JoaquinAmatRodrigo/skforecast",
                "StackOverflow_Post": {
                    "Id": "71673816",
                    "PostTypeId": "1",
                    "CreationDate": "2022-03-30T08:18:51.050",
                    "Score": "0",
                    "ViewCount": "899",
                    "Body": "<p>I am trying to install in jupyter (python), with anaconda prompt, skforecast library.</p>\n<p>LINK: <a href=\"https://github.com/JoaquinAmatRodrigo/skforecast\" rel=\"nofollow noreferrer\">https://github.com/JoaquinAmatRodrigo/skforecast</a>\n<a href=\"https://www.cienciadedatos.net/documentos/py27-forecasting-series-temporales-python-scikitlearn.html\" rel=\"nofollow noreferrer\">https://www.cienciadedatos.net/documentos/py27-forecasting-series-temporales-python-scikitlearn.html</a></p>\n<p>Here you can see how to install and the requirements, but when i use pip install comand, it gives me error with tqmd library.</p>\n<p>Someone has this library and could solve the issue or tell me how to install or something?\nThank you</p>\n",
                    "OwnerUserId": "18266312",
                    "LastActivityDate": "2022-03-30T08:18:51.050",
                    "Title": "Skforecast library",
                    "Tags": "<python>",
                    "AnswerCount": "0",
                    "CommentCount": "4",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "71674345",
                "ParentRepo": "https://github.com/Clinical-Genomics/cgbeacon2/pull/221/files",
                "StackOverflow_Post": {
                    "Id": "71674345",
                    "PostTypeId": "2",
                    "ParentId": "71673404",
                    "CreationDate": "2022-03-30T08:58:40.807",
                    "Score": "183",
                    "Body": "<p>This has been fixed by Black 22.3.0. Versions before that won't work with click 8.1.0.</p>\n<p><em><a href=\"https://github.com/psf/black/issues/2964\" rel=\"noreferrer\">Incompatible with click 8.1.0 (ImportError: cannot import name '_unicodefun' from 'click') #2964</a></em></p>\n<p>E.g.: <code>black.yml</code></p>\n<pre class=\"lang-none prettyprint-override\"><code>          python-version: 3.8\n      - name: install black\n        run: |\n-          pip install black==20.8b1\n+          pip install black==22.3.0\n      - name: run black\n        run: |\n          black . --check --line-length 100\n</code></pre>\n<p><a href=\"https://github.com/Clinical-Genomics/cgbeacon2/pull/221/files\" rel=\"noreferrer\">https://github.com/Clinical-Genomics/cgbeacon2/pull/221/files</a></p>\n<p>As a workaround, pin <code>click</code> to the last version via <code>pip install --upgrade click==8.0.2</code>.</p>\n",
                    "OwnerUserId": "10036039",
                    "LastEditorUserId": "63550",
                    "LastEditDate": "2022-05-05T10:15:25.707",
                    "LastActivityDate": "2022-05-05T10:15:25.707",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "71713486",
                "ParentRepo": "https://github.com/vizzuhq/ipyvizzu",
                "StackOverflow_Post": {
                    "Id": "71713486",
                    "PostTypeId": "1",
                    "CreationDate": "2022-04-01T22:55:17.357",
                    "Score": "3",
                    "ViewCount": "28",
                    "Body": "<p>This simple code in a single cell works in Jupyter Notebook, but Deepnote seems to render the <code>display_javascript</code> calls into separate <code>iframe</code>s. Is there any way to get this work in Deepnote?</p>\n<pre><code>from IPython.display import display_javascript\n\ndisplay_javascript(&quot;var a = 10&quot;, raw=True)\ndisplay_javascript(&quot;console.log(a)&quot;, raw=True)\n</code></pre>\n<p><code>Uncaught (in promise) ReferenceError: a is not defined</code></p>\n<p>Example:\n<a href=\"https://deepnote.com/project/How-to-access-Javascript-variable-from-separate-displayjavascript-call-hvyWPhDWRGahj9NvgJtuGw/%2Fnotebook.ipynb\" rel=\"nofollow noreferrer\">https://deepnote.com/project/How-to-access-Javascript-variable-from-separate-displayjavascript-call-hvyWPhDWRGahj9NvgJtuGw/%2Fnotebook.ipynb</a></p>\n<p>Background: I'm working on a JS charting library Jupyter integration (<a href=\"https://github.com/vizzuhq/ipyvizzu\" rel=\"nofollow noreferrer\">ipyvizzu</a>), where I would like to access the JS chart object eventually from different cells in the notebook.</p>\n",
                    "OwnerUserId": "535473",
                    "LastEditorUserId": "535473",
                    "LastEditDate": "2022-04-01T23:00:20.033",
                    "LastActivityDate": "2022-04-01T23:00:20.033",
                    "Title": "How to access a JS variable from separate display_javascript calls in Deepnote?",
                    "Tags": "<javascript><ipython><deepnote>",
                    "AnswerCount": "0",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "71832263",
                "ParentRepo": "https://github.com/planety/prologue",
                "StackOverflow_Post": {
                    "Id": "71832263",
                    "PostTypeId": "5",
                    "CreationDate": "2022-04-11T17:54:58.880",
                    "Score": "0",
                    "Body": "<p>Prologue is a web framework for the Nim programming language. (See <a href=\"/questions/tagged/nim-lang\" class=\"post-tag\" title=\"show questions tagged &#39;nim-lang&#39;\" rel=\"tag\">nim-lang</a>).</p>\n<p>Links:</p>\n<ul>\n<li>Homepage for the docs: <a href=\"https://planety.github.io/prologue/\" rel=\"nofollow noreferrer\">https://planety.github.io/prologue/</a>.</li>\n<li>Github repo: <a href=\"https://github.com/planety/prologue\" rel=\"nofollow noreferrer\">https://github.com/planety/prologue</a></li>\n</ul>\n",
                    "OwnerUserId": "4294399",
                    "LastEditorUserId": "4294399",
                    "LastEditDate": "2022-05-12T13:06:37.723",
                    "LastActivityDate": "2022-05-12T13:06:37.723",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "71852651",
                "ParentRepo": "https://github.com/housepower/spark-clickhouse-connector",
                "StackOverflow_Post": {
                    "Id": "71852651",
                    "PostTypeId": "2",
                    "ParentId": "69066006",
                    "CreationDate": "2022-04-13T06:10:19.407",
                    "Score": "0",
                    "Body": "<p>It's definitly a good idea! There is a new <a href=\"https://github.com/housepower/spark-clickhouse-connector\" rel=\"nofollow noreferrer\">spark-clickhouse-connector</a> based on DataSource V2 API and ClickHouse gRPC protocol which makes you write/read data to/from ClickHouse more efficiently. In particular, it can transparently convert your access to Distributed table to Local table.</p>\n<p><a href=\"https://housepower.github.io/spark-clickhouse-connector/quick_start/02_play_with_spark_sql/\" rel=\"nofollow noreferrer\">Quick Start Demo with Spark SQL</a></p>\n<p><a href=\"https://housepower.github.io/spark-clickhouse-connector/quick_start/03_play_with_spark_shell/\" rel=\"nofollow noreferrer\">Quick Start Demo with Spark Shell</a></p>\n",
                    "OwnerUserId": "16172670",
                    "LastEditorUserId": "16172670",
                    "LastEditDate": "2022-04-14T06:49:43.903",
                    "LastActivityDate": "2022-04-14T06:49:43.903",
                    "CommentCount": "4",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "71871340",
                "ParentRepo": "https://github.com/MaKaNu/rainbowdrinkinggame/tree/gh-pages",
                "StackOverflow_Post": {
                    "Id": "71871340",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "71884003",
                    "CreationDate": "2022-04-14T12:05:50.780",
                    "Score": "0",
                    "ViewCount": "142",
                    "Body": "<p>I created successfully a very basic gh-page on <a href=\"https://makanu.github.io/\" rel=\"nofollow noreferrer\">https://makanu.github.io</a>. The Repo just includes a <code>README.md</code>, a <code>LICENSE</code> and the most basic <code>index.html</code> I could imagine.</p>\n<p>My problem is now, that I have a another <a href=\"https://github.com/MaKaNu/rainbowdrinkinggame/tree/gh-pages\" rel=\"nofollow noreferrer\">Repo</a> which includes a gh-pages branch which includes the files created with mkdocs. But for some reason <a href=\"https://makanu.github.io/rainbowdrinkinggame\" rel=\"nofollow noreferrer\">https://makanu.github.io/rainbowdringinggame</a> results in Error 404.</p>\n<p>What am I doing wrong?</p>\n",
                    "OwnerUserId": "10985257",
                    "LastActivityDate": "2022-04-15T12:24:40.690",
                    "Title": "How to setup gh-pages correctly",
                    "Tags": "<github-pages><mkdocs>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "71879852",
                "ParentRepo": "https://github.com/nazmulnnb/fastapi-paginate/blob/main/examples/pagination_motor.py",
                "StackOverflow_Post": {
                    "Id": "71879852",
                    "PostTypeId": "2",
                    "ParentId": "67571946",
                    "CreationDate": "2022-04-15T03:44:58.297",
                    "Score": "1",
                    "Body": "<p>You can use this package to paginate:\n<a href=\"https://pypi.org/project/fastapi-paginate\" rel=\"nofollow noreferrer\">https://pypi.org/project/fastapi-paginate</a></p>\n<p>How to use it:\n<a href=\"https://github.com/nazmulnnb/fastapi-paginate/blob/main/examples/pagination_motor.py\" rel=\"nofollow noreferrer\">https://github.com/nazmulnnb/fastapi-paginate/blob/main/examples/pagination_motor.py</a></p>\n",
                    "OwnerUserId": "3077037",
                    "LastActivityDate": "2022-04-15T03:44:58.297",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "71890447",
                "ParentRepo": "https://github.com/betcode-org/betfair",
                "StackOverflow_Post": {
                    "Id": "71890447",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "72421732",
                    "CreationDate": "2022-04-16T01:47:15.637",
                    "Score": "0",
                    "ViewCount": "143",
                    "Body": "<p>Betfairlightweight API: <a href=\"https://github.com/betcode-org/betfair\" rel=\"nofollow noreferrer\">https://github.com/betcode-org/betfair</a></p>\n<p>To work with this module, it is necessary to pass the APIClient data and login:</p>\n<pre class=\"lang-py prettyprint-override\"><code>trading = betfairlightweight.APIClient(username, pw, app_key=app_key, cert_files=('blablabla.crt','blablabla.key'))\ntrading.login()\n</code></pre>\n<p>To speed up the data collection process, I'm use multiprocessing:</p>\n<pre class=\"lang-py prettyprint-override\"><code>from multiprocessing import Pool\n\ntrading = betfairlightweight.APIClient(username, pw, app_key=app_key, cert_files=('blablabla.crt','blablabla.key'))\ntrading.login()\n\ndef main():\n    matches_bf = # DataFrame...\n    try:\n        max_process = multiprocessing.cpu_count()-1 or 1\n        pool = multiprocessing.Pool(max_process)\n        list_pool = pool.map(data_event, matches_bf.iterrows())\n    finally:\n        pool.close()\n        pool.join()\n\n    trading.logout()\n\ndef data_event(event_bf):\n    _, event_bf = event_bf\n    event_id = event_bf['event_id']\n    filter_catalog_markets = betfairlightweight.filters.market_filter(\n        event_ids=[event_id],\n        market_type_codes = [\n            'MATCH_ODDS'\n            ]\n        )\n\n    catalog_markets = trading.betting.list_market_catalogue(\n        filter=filter_catalog_markets,\n        max_results='100',\n        sort='FIRST_TO_START',\n        market_projection=['RUNNER_METADATA']\n    )\n\n     ... # some more code\n     ... # some more code\n     ... # some more code\n</code></pre>\n<p>That way <em>12 logins</em> are made. For accessing an API, this is not the ideal way.</p>\n<p><em><strong>Why 12 logins?</strong></em></p>\n<p>When I activate the code it makes 1 login and when the multiprocessing pool is created, it generates 11 more logins, one for each process. If I put <code>print(trading)</code> exactly below <code>trading.login()</code>, one print statement appears in the terminal when the code starts to run, then another 11 happen simultaneously when the pool is created.</p>\n<p>So I need to find a way to be able to do this same service using only <strong>ONE</strong> <em>login</em>.</p>\n<p>I tried to throw the <em>login</em> inside <code>main()</code> and add as an argument to call the function:</p>\n<pre class=\"lang-py prettyprint-override\"><code>from multiprocessing import Pool\nfrom itertools import repeat\n\ndef main():\n    trading = betfairlightweight.APIClient(username, pw, app_key=app_key, cert_files=('blablabla.crt','blablabla.key'))\n    trading.login()\n\n    matches_bf = # DataFrame...\n    try:\n        max_process = multiprocessing.cpu_count()-1 or 1\n        pool = multiprocessing.Pool(max_process)\n        list_pool = pool.map(data_event, zip(repeat(trading),matches_bf.iterrows()))\n    finally:\n        pool.close()\n        pool.join()\n\n    trading.logout()\n\ndef data_event(trading,event_bf):\n    trading = trading\n    _, event_bf = event_bf\n    event_id = event_bf['event_id']\n    filter_catalog_markets = betfairlightweight.filters.market_filter(\n        event_ids=[event_id],\n        market_type_codes = [\n            'MATCH_ODDS'\n            ]\n        )\n\n    catalog_markets = trading.betting.list_market_catalogue(\n        filter=filter_catalog_markets,\n        max_results='100',\n        sort='FIRST_TO_START',\n        market_projection=['RUNNER_METADATA']\n    )\n\n     ... # some more code\n     ... # some more code\n     ... # some more code\n</code></pre>\n<p>But the error encountered is:</p>\n<pre><code>TypeError: cannot pickle 'module' object\n</code></pre>\n<p>I tried to put <code>trading</code> inside the function <code>data_event</code>:</p>\n<pre class=\"lang-py prettyprint-override\"><code>from multiprocessing import Pool\n\ndef main():\n    trading = betfairlightweight.APIClient(username, pw, app_key=app_key, cert_files=('blablabla.crt','blablabla.key'))\n    trading.login()\n\n    matches_bf = # DataFrame...\n    try:\n        max_process = multiprocessing.cpu_count()-1 or 1\n        pool = multiprocessing.Pool(max_process)\n        list_pool = pool.map(data_event, matches_bf.iterrows())\n    finally:\n        pool.close()\n        pool.join()\n\n    trading.logout()\n\ndef data_event(event_bf):\n    trading = betfairlightweight.APIClient(username, pw, app_key=app_key, cert_files=('blablabla.crt','blablabla.key'))\n    _, event_bf = event_bf\n    event_id = event_bf['event_id']\n    filter_catalog_markets = betfairlightweight.filters.market_filter(\n        event_ids=[event_id],\n        market_type_codes = [\n            'MATCH_ODDS'\n            ]\n        )\n\n    catalog_markets = trading.betting.list_market_catalogue(\n        filter=filter_catalog_markets,\n        max_results='100',\n        sort='FIRST_TO_START',\n        market_projection=['RUNNER_METADATA']\n    )\n\n     ... # some more code\n     ... # some more code\n     ... # some more code\n</code></pre>\n<p>But the error encountered is:</p>\n<pre><code>errorCode': 'INVALID_SESSION_INFORMATION'\n</code></pre>\n<p>The reason is logical: multiprocessing did not login.</p>\n<p>How should I proceed so that I use only one login and can do everything I need without being forced to work one by one (line by line without multiprocessing takes too long, not feasible)?</p>\n<p><strong>Additional info:</strong></p>\n<ul>\n<li><a href=\"https://github.com/betcode-org/betfair/blob/master/betfairlightweight/endpoints/login.py\" rel=\"nofollow noreferrer\"><em>betfairlightweight</em> login</a> if it helps in understanding the case:</li>\n</ul>\n",
                    "OwnerUserId": "11462274",
                    "LastEditorUserId": "9350720",
                    "LastEditDate": "2022-05-28T08:21:47.963",
                    "LastActivityDate": "2022-05-29T07:29:20.253",
                    "Title": "Error when trying to send data from APIClient to a function using multiprocessing",
                    "Tags": "<python><python-multiprocessing><betfair><apiclient>",
                    "AnswerCount": "2",
                    "CommentCount": "0",
                    "FavoriteCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "71894933",
                "ParentRepo": "https://github.com/flask-extensions/Flask-GoogleMaps",
                "StackOverflow_Post": {
                    "Id": "71894933",
                    "PostTypeId": "1",
                    "CreationDate": "2022-04-16T14:55:28.523",
                    "Score": "1",
                    "ViewCount": "130",
                    "Body": "<p>I'm a newbie writing a Flask web app that displays in a Google Map a series of locations stored in a SQLite database. In order to do this I'm trying to use the Flask-GoogleMaps extension (<a href=\"https://github.com/flask-extensions/Flask-GoogleMaps\" rel=\"nofollow noreferrer\">https://github.com/flask-extensions/Flask-GoogleMaps</a>), but even  when I only try the example code given in the documentation the map won't display in the page. The server returns a 403 error:</p>\n<pre><code>GET http://maps.googleapis.com/maps/api/mapsjs/gen_204?csp_test=true 403 (Forbidden).\n</code></pre>\n<p>I know the Google Maps JS API key given is correct since the map displayed just fine when I included the raw code as explained in the Google Maps API documentation.</p>\n<p>This is the app that I'm running:</p>\n<pre><code>from flask import Flask, render_template\nfrom flask_googlemaps import GoogleMaps, Map\n\napp = Flask(__name__)\n\nGoogleMaps(app, key=&quot;MY_KEY&quot;)\n\n@app.route(&quot;/&quot;)\ndef mapview():\n    # creating a map in the view\n    mymap = Map(\n        identifier=&quot;view-side&quot;,\n        lat=37.4419,\n        lng=-122.1419,\n        markers=[(37.4419, -122.1419)]\n    )\n    return render_template('example.html', mymap=mymap)\n\nif __name__ == &quot;__main__&quot;:\n    app.run(debug=True)\n</code></pre>\n<p>This is the rendered HTML:</p>\n<pre><code>&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n  &lt;head&gt;\n    {{mymap.js}}\n  &lt;/head&gt;\n  &lt;body&gt;\n    &lt;h1&gt;Flask Google Maps Example&lt;/h1&gt;\n    {{mymap.html}}\n  &lt;/body&gt;\n&lt;/html&gt;\n</code></pre>\n<p>What could be the problem? Thank you very much in advance!</p>\n",
                    "OwnerUserId": "18175585",
                    "LastEditorUserId": "18175585",
                    "LastEditDate": "2022-04-17T15:33:55.480",
                    "LastActivityDate": "2022-04-17T15:33:55.480",
                    "Title": "Flask-GoogleMaps returns 403 Forbidden error",
                    "Tags": "<python><flask><google-maps-api-3>",
                    "AnswerCount": "0",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "71901290",
                "ParentRepo": "https://github.com/demberto/tkinter-msgcat",
                "StackOverflow_Post": {
                    "Id": "71901290",
                    "PostTypeId": "1",
                    "CreationDate": "2022-04-17T10:57:17.877",
                    "Score": "1",
                    "ViewCount": "102",
                    "Body": "<p>This is my workflow (shortened):</p>\n<pre class=\"lang-yaml prettyprint-override\"><code>on: [push, pull_request]\n\njobs:\n  tests:\n    name: Run tests\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        python-version: [&quot;3.7&quot;, &quot;3.8&quot;, &quot;3.9&quot;, &quot;3.10&quot;]\n    steps:\n      - uses: actions/checkout@v3\n      - name: Set up Python ${{ matrix.python-version }}\n        uses: actions/setup-python@v3\n        with:\n          python-version: ${{ matrix.python-version }}\n      - name: Install dependencies\n        run: |\n          python -m pip install --upgrade pip\n          python -m pip install tox tox-gh-actions\n      - name: Test with tox\n        run: tox\n      - name: Upload coverage artifact\n        uses: actions/upload-artifact@v3\n        with:\n          name: coverage-data\n          path: .coverage.*\n          if-no-files-found: error\n</code></pre>\n<p>This is <code>tox.ini</code> (shortened):</p>\n<pre><code>[tox]\nminversion = 3.24.5\nenvlist = py{37,38,39,310}\nisolated_build = true\n\n[testenv]\ndeps =\n  {[testenv:coverage]deps}\ncommands =\n  {[testenv:coverage]commands}\n\n[testenv:coverage]\nsetenv =\n  PYTHONPATH = {toxinidir}\ndeps =\n  coverage[toml]\n  pytest\ncommands =\n  coverage run -m pytest\n</code></pre>\n<p>The <code>.coverage</code> files get created locally on my Windows PC, but do not on Github Actions CI.</p>\n<p>You can find the full files <a href=\"https://github.com/demberto/tkinter-msgcat\" rel=\"nofollow noreferrer\">here</a>. SO wasn't allowing me to put it all here.</p>\n",
                    "OwnerUserId": "5541355",
                    "LastEditorUserId": "5541355",
                    "LastEditDate": "2022-04-17T11:03:20.753",
                    "LastActivityDate": "2022-04-17T11:03:20.753",
                    "Title": "Coverage files not getting created in CI",
                    "Tags": "<github-actions><coverage.py>",
                    "AnswerCount": "0",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "71903779",
                "ParentRepo": "https://github.com/Zefiros-Software/BSPLib",
                "StackOverflow_Post": {
                    "Id": "71903779",
                    "PostTypeId": "1",
                    "CreationDate": "2022-04-17T16:55:38.383",
                    "Score": "0",
                    "ViewCount": "17",
                    "Body": "<p>Im setting up the bsplib (<a href=\"https://github.com/Zefiros-Software/BSPLib\" rel=\"nofollow noreferrer\">https://github.com/Zefiros-Software/BSPLib</a>) on a windows system (in VS Code) using WSL. When compiling I get the error message:</p>\n<pre><code>test.cpp:4:5: error: conflicting declaration of C function \u2018int main()\u2019\n    4 | int main()\n      |     ^~~~\nIn file included from /mnt/d/study/software/bsp/include/bsp/bspExt.h:30,\n                 from /mnt/d/study/software/bsp/include/bsp/bsp.h:34,\n                 from test.cpp:2:\n/mnt/d/study/software/bsp/include/bsp/bspClass.h:59:12: note: previous declaration \u2018int main(int, char**)\u2019\n   59 | extern int main(int argc, char **argv);\n</code></pre>\n<p>The program is used is just a bare example for BSP:</p>\n<pre><code>#include &lt;iostream&gt;\n#include &quot;bsp/bsp.h&quot;\n\nint main()\n{\n    bsp_begin(bsp_nprocs());\n    int s = bsp_pid();\n    int p = bsp_nprocs();\n    printf(&quot;Hello World from processor %d / %d&quot;, s, p);\n    bsp_end();\n\n    return 0;\n}\n</code></pre>\n<p>Compiled with:</p>\n<pre><code>g++ -I/mnt/d/study/software/bsp/include -g -lpthread -o main test.cpp\n</code></pre>\n<p>To my (quite limited) knowledge, the 'extern' in the header file should prevent the compiler from labelling the main as 'duplicate' of some sort. Im mostly interested in some of BSPs functionalities as part of a class of mine, that sadly does not include any support on the installation. What I've done so far:</p>\n<ul>\n<li>Copied the include files from the repo</li>\n<li>Added the include path to the compilation (-I Flag) and the -lpthread as instructed by the class script</li>\n<li>Added the include path to the configuration (c_cpp_properties.json) [tested both with and without this, no difference]</li>\n</ul>\n<p>Due to the many possible sources of that error (program, compiler, wsl, library, configuration, vs code, my stupidity) I cant determine where I am mistaken, nor am I able to find online resources to that combination.</p>\n",
                    "OwnerUserId": "18838058",
                    "LastActivityDate": "2022-04-17T16:55:38.383",
                    "Title": "extern main declaration from bsplib returns error",
                    "Tags": "<c++><visual-studio-code><compiler-errors><windows-subsystem-for-linux><bsp>",
                    "AnswerCount": "0",
                    "CommentCount": "3",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "71955745",
                "ParentRepo": "https://github.com/tiangolo/asyncer/blob/66a967b85fb3cf9c0978ec778870f8615a5149fe/asyncer/_main.py#L341",
                "StackOverflow_Post": {
                    "Id": "71955745",
                    "PostTypeId": "2",
                    "ParentId": "71953454",
                    "CreationDate": "2022-04-21T13:57:06.020",
                    "Score": "1",
                    "Body": "<p>I would say ideally asynchronous code should only use asynchronous means for IO-bound tasks. In this case, everything will work <a href=\"https://docs.python.org/3/library/asyncio-dev.html#concurrency-and-multithreading\" rel=\"nofollow noreferrer\">in one thread</a>.</p>\n<p>In the example with the <code>asyncer</code> that you provided, executing by means of thread pool is used <a href=\"https://github.com/tiangolo/asyncer/blob/66a967b85fb3cf9c0978ec778870f8615a5149fe/asyncer/_main.py#L341\" rel=\"nofollow noreferrer\">under the hood</a>. This imposes certain costs on starting, switching threads and passing parameters (queue is used).</p>\n<p>As a temporary or compromise solution, this may be suitable. But if we want to get more performance for an IO-bound solution, it's better to use asynchronous tools.</p>\n",
                    "OwnerUserId": "13782669",
                    "LastActivityDate": "2022-04-21T13:57:06.020",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "71958176",
                "ParentRepo": "https://github.com/vitalik/django-ninja/issues/424#issuecomment-1099930539",
                "StackOverflow_Post": {
                    "Id": "71958176",
                    "PostTypeId": "2",
                    "ParentId": "71868771",
                    "CreationDate": "2022-04-21T16:55:55.883",
                    "Score": "0",
                    "Body": "<p>According to: <a href=\"https://github.com/vitalik/django-ninja/issues/424#issuecomment-1099930539\" rel=\"nofollow noreferrer\">https://github.com/vitalik/django-ninja/issues/424#issuecomment-1099930539</a></p>\n<p>remove this part</p>\n<pre><code>, response=HttpResponse)\n</code></pre>\n<p><strong>And it actually worked</strong></p>\n",
                    "OwnerUserId": "10305444",
                    "LastActivityDate": "2022-04-21T16:55:55.883",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "71990430",
                "ParentRepo": "https://github.com/vwxyzjn/cleanrl/blob/master/cleanrl/dqn_atari.py",
                "StackOverflow_Post": {
                    "Id": "71990430",
                    "PostTypeId": "1",
                    "CreationDate": "2022-04-24T16:44:28.313",
                    "Score": "3",
                    "ViewCount": "1052",
                    "Body": "<p>I am using the cleanrl library, in particular the script <a href=\"https://github.com/vwxyzjn/cleanrl/blob/master/cleanrl/dqn_atari.py\" rel=\"nofollow noreferrer\">dqn_atari.py</a>  dqn_atari.py where  I followed the  <a href=\"https://docs.cleanrl.dev/advanced/resume-training/\" rel=\"nofollow noreferrer\">instructions</a> in order to save and load the target and Q-network.</p>\n<p>I am running it locally within a conda environment.</p>\n<p>I haven't loaded something before, so the error may be due to my wandb configuration. The error is &quot;wandb: ERROR Permission denied to access wandb_entity/wandb_project_name/project_id&quot; and appears on line:</p>\n<pre><code>model = run.file(&quot;agent.pt&quot;)\n</code></pre>\n<p>The full  output is:</p>\n<pre><code>wandb: Currently logged in as: elena (use `wandb login --relogin` to force relogin)\n    wandb: Tracking run with wandb version 0.12.15\nwandb: Run data is saved locally in /home/elena/workspace/playground/cleanrl/wandb/run-20220424_180429-2moec0qp\nwandb: Run `wandb offline` to turn off syncing.\nwandb: Resuming run BreakoutNoFrameskip-v4__dqn-save__1__1650816268\nwandb: \u2b50 View project at https://wandb.ai/elena/test\nwandb:  View run at https://wandb.ai/elena/test/runs/2moec0qp\nA.L.E: Arcade Learning Environment (version 0.7.4+069f8bd)\n[Powered by Stella]\n/home/elena/anaconda3/envs/cleanrl/lib/python3.8/site-packages/stable_baselines3/common/buffers.py:219: UserWarning: This system does not have apparently enough memory to store the complete replay buffer 28.24GB &gt; 8.35GB\n  warnings.warn(\nwandb: ERROR Permission denied to access elena/test/2moec0qp\nTraceback (most recent call last):\n  File &quot;/home/elena/anaconda3/envs/cleanrl/lib/python3.8/site-packages/wandb/sdk/lib/retry.py&quot;, line 102, in __call__\n    result = self._call_fn(*args, **kwargs)\n  File &quot;/home/elena/anaconda3/envs/cleanrl/lib/python3.8/site-packages/wandb/apis/public.py&quot;, line 2428, in download\n    util.download_file_from_url(path, self.url, Api().api_key)\n  File &quot;/home/elena/anaconda3/envs/cleanrl/lib/python3.8/site-packages/wandb/util.py&quot;, line 1197, in download_file_from_url\n    response.raise_for_status()\n  File &quot;/home/elena/anaconda3/envs/cleanrl/lib/python3.8/site-packages/requests/models.py&quot;, line 960, in raise_for_status\n    raise HTTPError(http_error_msg, response=self)\nrequests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://api.wandb.ai/files/elena/test/2moec0qp/td_network.pt\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File &quot;/home/elena/anaconda3/envs/cleanrl/lib/python3.8/site-packages/wandb/apis/normalize.py&quot;, line 22, in wrapper\n    return func(*args, **kwargs)\n  File &quot;/home/elena/anaconda3/envs/cleanrl/lib/python3.8/site-packages/wandb/sdk/lib/retry.py&quot;, line 159, in wrapped_fn\n    return retrier(*args, **kargs)\n  File &quot;/home/elena/anaconda3/envs/cleanrl/lib/python3.8/site-packages/wandb/sdk/lib/retry.py&quot;, line 118, in __call__\n    if not check_retry_fn(e):\n  File &quot;/home/elena/anaconda3/envs/cleanrl/lib/python3.8/site-packages/wandb/util.py&quot;, line 877, in no_retry_auth\n    raise CommError(f&quot;Permission denied to access {wandb.run.path}&quot;)\nwandb.errors.CommError: Permission denied to access elena/test/2moec0qp\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File &quot;cleanrl/dqn_atari_save.py&quot;, line 184, in &lt;module&gt;\n    model.download(f&quot;models/{args.exp_name}/&quot;)\n  File &quot;/home/elena/anaconda3/envs/cleanrl/lib/python3.8/site-packages/wandb/apis/normalize.py&quot;, line 58, in wrapper\n    raise CommError(message, err).with_traceback(sys.exc_info()[2])\n  File &quot;/home/elena/anaconda3/envs/cleanrl/lib/python3.8/site-packages/wandb/apis/normalize.py&quot;, line 22, in wrapper\n    return func(*args, **kwargs)\n  File &quot;/home/elena/anaconda3/envs/cleanrl/lib/python3.8/site-packages/wandb/sdk/lib/retry.py&quot;, line 159, in wrapped_fn\n    return retrier(*args, **kargs)\n  File &quot;/home/elena/anaconda3/envs/cleanrl/lib/python3.8/site-packages/wandb/sdk/lib/retry.py&quot;, line 118, in __call__\n    if not check_retry_fn(e):\n  File &quot;/home/elena/anaconda3/envs/cleanrl/lib/python3.8/site-packages/wandb/util.py&quot;, line 877, in no_retry_auth\n    raise CommError(f&quot;Permission denied to access {wandb.run.path}&quot;)\nwandb.errors.CommError: Permission denied to access elena/test/2moec0qp\nwandb: Waiting for W&amp;B process to finish... (failed 1). Press Control-C to abort syncing.\nwandb:                                                                                \nwandb: \nwandb: Run history:\nwandb: global_step \u2581\nwandb: \nwandb: Run summary:\nwandb: charts/episodic_return 0\nwandb:         charts/epsilon 0.01\nwandb:          charts/update 1969\nwandb:            global_step 0\nwandb: \nwandb: Synced BreakoutNoFrameskip-v4__dqn-save__1__1650816268: https://wandb.ai/elena/test/runs/2moec0qp\nwandb: Synced 3 W&amp;B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\nwandb: Find logs at: ./wandb/run-20220424_180429-2moec0qp/logs\n</code></pre>\n<p>So as you can see I am logged in and I can see the files under &quot;https://wandb.ai/elena/test/runs/2moec0qp?workspace=user-elena&quot;. Something that drew my attention was &quot;requests.exceptions.HTTPError: 404 Client Error: Not Found for url: <a href=\"https://api.wandb.ai/files/elena/test/2moec0qp/agent.pt%22\" rel=\"nofollow noreferrer\">https://api.wandb.ai/files/elena/test/2moec0qp/agent.pt&quot;</a>. This path indeed looks different from the https path, but maybe this is not the issue?\nAny ideas?</p>\n",
                    "OwnerUserId": "4358113",
                    "LastActivityDate": "2022-08-30T22:12:01.087",
                    "Title": "Wandb throws Permission denied error although I am logged in",
                    "Tags": "<python><wandb>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "71995028",
                "ParentRepo": "https://github.com/ankicommunity/anki-sync-server",
                "StackOverflow_Post": {
                    "Id": "71995028",
                    "PostTypeId": "2",
                    "ParentId": "71309225",
                    "CreationDate": "2022-04-25T05:58:09.320",
                    "Score": "1",
                    "Body": "<p>AnkiWeb does not posses a public interface for adding, removing or modifying notes. It only allows you to synchronize databases, which is not quite the same. However, even though I am not aware of any documentation regarding the interface used for the synchronization, some people achieved rewriting the synchronization protocol from the server pov (and thus to write a <a href=\"https://github.com/ankicommunity/anki-sync-server\" rel=\"nofollow noreferrer\">custom synchronization server</a>).</p>\n<p>However, there is an other way, which is interacting with Anki Desktop instead of Anki Web, through <a href=\"https://ankiweb.net/shared/info/2055492159\" rel=\"nofollow noreferrer\">Anki Connect</a>, which is an add-on that exposes some API.</p>\n<p>Also note that AnkiWeb has purposefully no API to access to, and accessing through a non-official mean is a violation of <a href=\"https://ankiweb.net/account/terms\" rel=\"nofollow noreferrer\">Anki's terms</a>:</p>\n<blockquote>\n<p>Because other clients can cause problems, AnkiWeb does not currently allow access from browser extensions or other third-party clients.</p>\n</blockquote>\n<p>They even encourage you to use AnkiConnect:</p>\n<blockquote>\n<p>Instead, please use AnkiConnect, which lets you modify your local connection over a web socket without any negative impact on AnkiWeb.</p>\n</blockquote>\n",
                    "OwnerUserId": "5956261",
                    "LastEditorUserId": "5956261",
                    "LastEditDate": "2022-04-25T09:39:21.453",
                    "LastActivityDate": "2022-04-25T09:39:21.453",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "72107516",
                "ParentRepo": "https://github.com/liusy58/LearningCS/runs/6283584439?check_suite_focus=true",
                "StackOverflow_Post": {
                    "Id": "72107516",
                    "PostTypeId": "1",
                    "CreationDate": "2022-05-04T03:01:47.590",
                    "Score": "0",
                    "ViewCount": "84",
                    "Body": "<p>Today I want to add a new page to my Github page. My repo worked well before. But when I add a new directory <code>lsy/README.md</code> to <code>docs</code>. Error shows.  It just says <code>Error reading page 'lsy/README.md': no such group</code>. I cannot understand why. I added some config to <code>mkdocs.yml</code>. In fact, even I don't add the config to <code>mkdocs.yml</code>, the error shows the same. Any help?</p>\n<p>The action log is <a href=\"https://github.com/liusy58/LearningCS/runs/6283584439?check_suite_focus=true\" rel=\"nofollow noreferrer\">here</a></p>\n",
                    "OwnerUserId": "13073924",
                    "LastActivityDate": "2022-05-06T15:30:42.173",
                    "Title": "Publish docs via GitHub Pages failed",
                    "Tags": "<github><mkdocs>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "72143993",
                "ParentRepo": "https://github.com/apenwarr/mkdocs-exclude",
                "StackOverflow_Post": {
                    "Id": "72143993",
                    "PostTypeId": "2",
                    "ParentId": "72107516",
                    "CreationDate": "2022-05-06T15:30:42.173",
                    "Score": "1",
                    "Body": "<p>You can use the <code>mkdocs-exlclude</code> <a href=\"https://github.com/apenwarr/mkdocs-exclude\" rel=\"nofollow noreferrer\">plugin</a> and setup the configuration inside the mkdocs.yml file as:</p>\n<pre><code>plugins:\n  - exclude:\n      glob:\n        - lsy/README.md\n</code></pre>\n",
                    "OwnerUserId": "4684597",
                    "LastActivityDate": "2022-05-06T15:30:42.173",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "72153479",
                "ParentRepo": "https://github.com/modzy/chassis",
                "StackOverflow_Post": {
                    "Id": "72153479",
                    "PostTypeId": "2",
                    "ParentId": "71276294",
                    "CreationDate": "2022-05-07T14:34:02.747",
                    "Score": "0",
                    "Body": "<p>Assuming your main objective is to build a 100% no cloud MLOps pipeline you can do that with mostly open source tech. All of the following can be installed on prem / without cloud services</p>\n<p><strong>For Training</strong>: You can use whatever you want. I'd recommend Pytorch because it plays nicer with some of the following suggestions, but Tensorflow is also a popular choice.</p>\n<p><strong>For CI/CD</strong>: if this is going to be on prem and you are going to retrain the model with production data / need to trigger updates to your deployment with each code update you can use Jenkins (open source) or CircleCI (commercial)</p>\n<p><strong>For Model Packaging</strong>: Chassis (open source) is the only project I am aware of for generically turning AI/ ML model files into something useful that can be run on your intended hardware. It basically takes an AI / ML model file as input and creates a docker image as its output. It's open source and supports Intel, ARM, CPU, and GPU. The website is here: <a href=\"http://www.chassis.ml\" rel=\"nofollow noreferrer\">http://www.chassis.ml</a> and the git repo is here: <a href=\"https://github.com/modzy/chassis\" rel=\"nofollow noreferrer\">https://github.com/modzy/chassis</a></p>\n<p><strong>For Deployment</strong>: Chassis model containers are automatically built with internal gRPC servers that can be deployed locally as docker containers. If you just want to stream a single source of data through them, the SDK has methods for doing that. If you want something that accepts multiple streams or auto scales to available resources on infrastructure you'll need a Kubernetes cluster with a deployment solution like Modzy or KServe. Chassis containers work out of the box with either.</p>\n<ul>\n<li><p>KServe (<a href=\"https://github.com/kserve/kserve\" rel=\"nofollow noreferrer\">https://github.com/kserve/kserve</a>) is free, but basically just\ngives you a centralized processing platform hosting a bunch of copies\nof your running model. It doesn't allow later triage of the model's processing history.</p>\n</li>\n<li><p>Modzy (<a href=\"https://www.modzy.com/\" rel=\"nofollow noreferrer\">https://www.modzy.com/</a>) is commercial, but also adds in all\nthe RBAC, Job history preservation, auditing, etc. Modzy also has an\nedge deployment feature if you want to mange your models centrally, but run them in a distributed manner on the camera hardware instead of on a centralized\nserver.</p>\n</li>\n</ul>\n",
                    "OwnerUserId": "3052890",
                    "LastActivityDate": "2022-05-07T14:34:02.747",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "72275061",
                "ParentRepo": "https://github.com/MushroomMaula/fastapi_login/issues/61",
                "StackOverflow_Post": {
                    "Id": "72275061",
                    "PostTypeId": "1",
                    "CreationDate": "2022-05-17T13:38:22.397",
                    "Score": "0",
                    "ViewCount": "270",
                    "Body": "<p>I'm confronted to an issue with fastapi_login. I'm trying to pass my db connection function to the manager user_loader.</p>\n<p>I follow this doc : <a href=\"https://fastapi-login.readthedocs.io/advanced_usage/\" rel=\"nofollow noreferrer\">https://fastapi-login.readthedocs.io/advanced_usage/</a></p>\n<p>database.py</p>\n<pre><code>def get_db():\n    db = SessionLocal()\n    try:\n        yield db\n    except:\n        db.close()\n</code></pre>\n<p>users.py</p>\n<pre><code>@manager.user_loader(session_provider=database.get_db)\nasync def get_user(username: str, session_provider) :\n    db = session_provider()\n    user = db.query(UserDb).filter_by(username=username).first()\n\n    return user\n</code></pre>\n<p>routes.py</p>\n<pre><code>@router.post('/login', response_model=UserSchema)\nasync def login(data: OAuth2PasswordRequestForm = Depends()):\n    username = data.username\n    password = data.password\n\n    user = await users.get_user(username)\n</code></pre>\n<p>It look like the session_provider is not catched by the @manager. I have the feeling that I respect what that said in the documentation. Here is the guvicorn error I get:</p>\n<pre><code>eb_1      | Traceback (most recent call last):\nweb_1      |   File &quot;/usr/local/lib/python3.9/site-packages/uvicorn/protocols/http/h11_impl.py&quot;, line 366, in run_asgi\nweb_1      |     result = await app(self.scope, self.receive, self.send)\nweb_1      |   File &quot;/usr/local/lib/python3.9/site-packages/uvicorn/middleware/proxy_headers.py&quot;, line 75, in __call__\nweb_1      |     return await self.app(scope, receive, send)\nweb_1      |   File &quot;/usr/local/lib/python3.9/site-packages/fastapi/applications.py&quot;, line 261, in __call__\nweb_1      |     await super().__call__(scope, receive, send)\nweb_1      |   File &quot;/usr/local/lib/python3.9/site-packages/starlette/applications.py&quot;, line 112, in __call__\nweb_1      |     await self.middleware_stack(scope, receive, send)\nweb_1      |   File &quot;/usr/local/lib/python3.9/site-packages/starlette/middleware/errors.py&quot;, line 181, in __call__\nweb_1      |     raise exc\nweb_1      |   File &quot;/usr/local/lib/python3.9/site-packages/starlette/middleware/errors.py&quot;, line 159, in __call__\nweb_1      |     await self.app(scope, receive, _send)\nweb_1      |   File &quot;/usr/local/lib/python3.9/site-packages/starlette/exceptions.py&quot;, line 82, in __call__\nweb_1      |     raise exc\nweb_1      |   File &quot;/usr/local/lib/python3.9/site-packages/starlette/exceptions.py&quot;, line 71, in __call__\nweb_1      |     await self.app(scope, receive, sender)\nweb_1      |   File &quot;/usr/local/lib/python3.9/site-packages/fastapi/middleware/asyncexitstack.py&quot;, line 21, in __call__\nweb_1      |     raise e\nweb_1      |   File &quot;/usr/local/lib/python3.9/site-packages/fastapi/middleware/asyncexitstack.py&quot;, line 18, in __call__\nweb_1      |     await self.app(scope, receive, send)\nweb_1      |   File &quot;/usr/local/lib/python3.9/site-packages/starlette/routing.py&quot;, line 656, in __call__\nweb_1      |     await route.handle(scope, receive, send)\nweb_1      |   File &quot;/usr/local/lib/python3.9/site-packages/starlette/routing.py&quot;, line 259, in handle\nweb_1      |     await self.app(scope, receive, send)\nweb_1      |   File &quot;/usr/local/lib/python3.9/site-packages/starlette/routing.py&quot;, line 61, in app\nweb_1      |     response = await func(request)\nweb_1      |   File &quot;/usr/local/lib/python3.9/site-packages/fastapi/routing.py&quot;, line 227, in app\nweb_1      |     raw_response = await run_endpoint_function(\nweb_1      |   File &quot;/usr/local/lib/python3.9/site-packages/fastapi/routing.py&quot;, line 160, in run_endpoint_function\nweb_1      |     return await dependant.call(**values)\nweb_1      |   File &quot;/code/app/routers/users.py&quot;, line 56, in login\nweb_1      |     user = await lib.users.get_user(username)\nweb_1      | TypeError: get_user() missing 1 required positional argument: 'session_provider'\n</code></pre>\n<p>Any idea how to deal with this ?</p>\n<p>Some references I tried without success :</p>\n<ul>\n<li><a href=\"https://github.com/MushroomMaula/fastapi_login/issues/61\" rel=\"nofollow noreferrer\">https://github.com/MushroomMaula/fastapi_login/issues/61</a></li>\n</ul>\n<p>Actually, I bypass the problem by sending the connection session as parameter of get_user in the route.But I prefer put my connection directly in @manager</p>\n",
                    "OwnerUserId": "19136514",
                    "LastActivityDate": "2022-05-17T13:38:22.397",
                    "Title": "FastAPI : pass session provider through @manager.user_loader",
                    "Tags": "<python><fastapi>",
                    "AnswerCount": "0",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "72434631",
                "ParentRepo": "https://github.com/MaxDragonheart/docker-geoserver",
                "StackOverflow_Post": {
                    "Id": "72434631",
                    "PostTypeId": "1",
                    "CreationDate": "2022-05-30T12:51:32.787",
                    "Score": "0",
                    "ViewCount": "157",
                    "Body": "<p>I've two containers:</p>\n<ul>\n<li>DOCKERIZED-PYTHON: test python project that use flask and owslib3</li>\n<li>DOCKERIZED-GEOSERVER: Geoserver version from <a href=\"https://github.com/MaxDragonheart/docker-geoserver\" rel=\"nofollow noreferrer\">here</a></li>\n</ul>\n<p>I need to read some information from a WMS like layer title or bounding box. I use a JSON file on DOCKERIZED-PYTHON for call a WMS:</p>\n<pre><code>{\n  &quot;url&quot;: &quot;https://geoserver.massimilianomoraca.me&quot;,\n  &quot;workspace&quot;: &quot;MassimilianoMoraca&quot;,\n  &quot;service_version&quot;: &quot;1.3.0&quot;,\n  &quot;layer_name&quot;: &quot;edificicasalnuovo&quot;,\n  &quot;layer_type&quot;: &quot;vector&quot;\n}\n</code></pre>\n<p>When I use this configuration I can see the information related to every layer on my server; this happen both if I start a project in local or inside a container.\nBut when I try to use DOCKERIZED-GEOSERVER with the JSON below:</p>\n<pre><code>{\n  &quot;url&quot;: &quot;http://geoserver&quot;,\n  &quot;workspace&quot;: &quot;tiger&quot;,\n  &quot;service_version&quot;: &quot;1.3.0&quot;,\n  &quot;layer_name&quot;: &quot;poi&quot;,\n  &quot;layer_type&quot;: &quot;vector&quot;\n}\n</code></pre>\n<p>I see this error:</p>\n<blockquote>\n<p>requests.exceptions.ConnectionError:\nHTTPConnectionPool(host='geoserver', port=80): Max retries exceeded\nwith url:\n/geoserver/tiger/wms?service=WMS&amp;request=GetCapabilities&amp;version=1.3.0\n(Caused by NewConnectionError('&lt;urllib3.connection.HTTPConnection\nobject at 0x7f8fd6c13a60&gt;: Failed to establish a new connection:\n[Errno 111] Connection refused'))</p>\n</blockquote>\n<p>Here my docker compose:</p>\n<pre><code>version: '3.7'\n\nservices:\n  geoserver:\n    image: maxdragonheart/geoserver\n    environment:\n      GS_VERSION: ${GS_VERSION}\n      GS_DEMO_DATA: ${GS_DEMO_DATA}\n      GS_HTTP_PORT: ${GS_HTTP_PORT}\n      GS_INITIAL_MEMORY: ${GS_INITIAL_MEMORY}\n      GS_MAXIMUM_MEMORY: ${GS_MAXIMUM_MEMORY}\n    container_name: dev_geoserver\n    restart: always\n    ports:\n    - ${GS_HTTP_PORT}:8080\n    volumes:\n    - geoserver:/opt/tomcat/webapps/geoserver\n    networks:\n      - test\n\n  python-api:\n    image: maxdragonheart/${PROJECT_NAME}\n    build:\n      context: ./pythonapi\n      dockerfile: Dockerfile\n    environment:\n      PROJECT_NAME: ${PROJECT_NAME}\n    container_name: dev_pythonapi\n    restart: always\n    ports:\n    - ${PYTHON_API_PORT}:5000\n    depends_on:\n      - geoserver\n    networks:\n      - test\n\nvolumes:\n  geoserver:\n\nnetworks:\n  test:\n    driver: bridge\n</code></pre>\n<p>Probably there is a mistake with network but this is not clear for me. Someone can explain to me this point?</p>\n",
                    "OwnerUserId": "10012856",
                    "LastActivityDate": "2022-05-30T12:51:32.787",
                    "Title": "Connection refused between two containers",
                    "Tags": "<python><docker><docker-compose><geoserver>",
                    "AnswerCount": "0",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "72436074",
                "ParentRepo": "https://github.com/hassio-addons/repository",
                "StackOverflow_Post": {
                    "Id": "72436074",
                    "PostTypeId": "2",
                    "ParentId": "72434356",
                    "CreationDate": "2022-05-30T14:37:18.803",
                    "Score": "0",
                    "Body": "<p>If you want to install vs code in home assistant, go to settings -&gt; addon-&gt; addon store. search for vs code.</p>\n<p>if it isn't there, click the three dots and add</p>\n<p><a href=\"https://github.com/hassio-addons/repository\" rel=\"nofollow noreferrer\">https://github.com/hassio-addons/repository</a></p>\n<p>to the repository list.\ngo back and search for vs code and install it. enable show in sidebar.\nI hope this solves your problem</p>\n",
                    "OwnerUserId": "19232946",
                    "LastActivityDate": "2022-05-30T14:37:18.803",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "72497969",
                "ParentRepo": "https://github.com/andreas-vester/df2img/blame/3ba6e046c8d30ab3896b23835513740bd5aa97fa/.readthedocs.yaml#L12-L14",
                "StackOverflow_Post": {
                    "Id": "72497969",
                    "PostTypeId": "2",
                    "ParentId": "72486078",
                    "CreationDate": "2022-06-04T07:39:03.500",
                    "Score": "2",
                    "Body": "<p>Although you may have disabled the epub and PDF builds in the RTD UI, you must take note in the RTD UI under Advanced Settings &gt; Default settings:</p>\n<blockquote>\n<p>These settings can be configured using a <a href=\"https://docs.readthedocs.io/page/config-file/v2.html\" rel=\"nofollow noreferrer\">configuration file</a>. That's the recommended way to set up your project. Settings listed here are ignored when using a configuration file.</p>\n</blockquote>\n<p>Therefore you must be using a configuration file that enables both pdf and epub builds. Lo and behold:</p>\n<p><a href=\"https://github.com/andreas-vester/df2img/blame/3ba6e046c8d30ab3896b23835513740bd5aa97fa/.readthedocs.yaml#L12-L14\" rel=\"nofollow noreferrer\">https://github.com/andreas-vester/df2img/blame/3ba6e046c8d30ab3896b23835513740bd5aa97fa/.readthedocs.yaml#L12-L14</a></p>\n<pre><code>formats:\n  - pdf\n  - epub\n</code></pre>\n",
                    "OwnerUserId": "2214933",
                    "LastEditorUserId": "2214933",
                    "LastEditDate": "2022-06-07T10:48:04.550",
                    "LastActivityDate": "2022-06-07T10:48:04.550",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "72574073",
                "ParentRepo": "https://github.com/datashim-io/datashim",
                "StackOverflow_Post": {
                    "Id": "72574073",
                    "PostTypeId": "2",
                    "ParentId": "72570211",
                    "CreationDate": "2022-06-10T12:08:59.013",
                    "Score": "0",
                    "Body": "<p>You can use the <strong>init container</strong> &amp; <strong>cronjobs</strong> with AWS CLI to copy the files to S3 bucket.</p>\n<p>To add further you can also use the <strong>Volume mount</strong> with datshim it's nice option :</p>\n<pre><code>apiVersion: com.ie.ibm.hpsys/v1alpha1\nkind: Dataset\nmetadata:\n  name: example-dataset\nspec:\n  local:\n    type: &quot;COS&quot;\n    accessKeyID: &quot;{AWS_ACCESS_KEY_ID}&quot;\n    secretAccessKey: &quot;{AWS_SECRET_ACCESS_KEY}&quot;\n    endpoint: &quot;{S3_SERVICE_URL}&quot;\n    bucket: &quot;{BUCKET_NAME}&quot;\n    readonly: &quot;true&quot; #OPTIONAL, default is false  \n    region: &quot;&quot; #OPTIONAL\n</code></pre>\n<p><a href=\"https://github.com/datashim-io/datashim\" rel=\"nofollow noreferrer\">https://github.com/datashim-io/datashim</a></p>\n<p>If you are looking for something with FUSE you should also checkout the <a href=\"https://github.com/s3fs-fuse/s3fs-fuse\" rel=\"nofollow noreferrer\">https://github.com/s3fs-fuse/s3fs-fuse</a></p>\n",
                    "OwnerUserId": "5525824",
                    "LastActivityDate": "2022-06-10T12:08:59.013",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "72641331",
                "ParentRepo": "https://github.com/proofit404/dependencies",
                "StackOverflow_Post": {
                    "Id": "72641331",
                    "PostTypeId": "2",
                    "ParentId": "156230",
                    "CreationDate": "2022-06-16T06:21:27.437",
                    "Score": "1",
                    "Body": "<p>Here's a good comparison (19 September 2020):\n<a href=\"https://wasinski.dev/comparison-of-dependency-injection-libraries-in-python/\" rel=\"nofollow noreferrer\">Comparison of Dependency Injection Libraries in Python, and my favorite one</a></p>\n<p>His winners are:</p>\n<ol>\n<li><p><a href=\"https://github.com/proofit404/dependencies\" rel=\"nofollow noreferrer\">proofit404/dependencies (Injector)</a> &quot;simple, but provided all the necessary features. If you need something that\u2019s not provided then just think about the design in your application, cause the flow might be somewhere there. Beautiful configuration. Perfect match for agile projects&quot;</p>\n</li>\n<li><p><a href=\"http://python-dependency-injector.ets-labs.org/introduction/di_in_python.html\" rel=\"nofollow noreferrer\">ets-labs/python-dependency-injector</a> &quot;very expanded library, with constant support, the problem is it\u2019s boilerplate, if that does not bother you, then it\u2019s a great choice&quot;</p>\n</li>\n</ol>\n",
                    "OwnerUserId": "813946",
                    "LastEditorUserId": "-1",
                    "LastEditDate": "2022-09-23T14:12:37.067",
                    "LastActivityDate": "2022-09-23T14:12:37.067",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "72728194",
                "ParentRepo": "https://github.com/FIWARE/tutorials.NGSI-v2/tree/master/docker",
                "StackOverflow_Post": {
                    "Id": "72728194",
                    "PostTypeId": "2",
                    "ParentId": "72690865",
                    "CreationDate": "2022-06-23T09:54:43.950",
                    "Score": "0",
                    "Body": "<p>As the error message suggests, you are hitting an <code>exec format error</code> when trying to run the dockerization of the <code>fiware/tutorials.context-provider</code> on a Raspberry PI since the compiled binaries are based on the amd64 architecture.</p>\n<p>As can be seen from the answer to this <a href=\"https://stackoverflow.com/questions/68764069/how-to-run-amd64-image-docker-on-arm-raspberry-os\">question</a>, that won't work on an ARM based machine, since Docker is a virtualisation platform, not an emulator.</p>\n<p>Since no image based on your architecture is currently available, if you need it, you will have to build an ARM version yourself. The current code and <code>Dockerfile</code> can be found here: <a href=\"https://github.com/FIWARE/tutorials.NGSI-v2/tree/master/docker\" rel=\"nofollow noreferrer\">https://github.com/FIWARE/tutorials.NGSI-v2/tree/master/docker</a></p>\n<p>So I would assume you will need to amend the dockerization and rebuild the binaries to overcome the <code>exec format error</code> issue - this seems to be a commons <a href=\"https://forums.raspberrypi.com/viewtopic.php?t=181389\" rel=\"nofollow noreferrer\">Issue</a> with Raspberry Pi.</p>\n<p>However I'm still unsure why creating a ARM dockerization is necessary, as all you are attempting to do is to containerize and run code <strong>emulating dummy IoT devices</strong> on a Raspberry Pi. A Raspberry Pi itself can send a stream of data directly as a <strong>real device</strong> - it doesn't need a device emulator to be a device, it is one.</p>\n",
                    "OwnerUserId": "1179828",
                    "LastActivityDate": "2022-06-23T09:54:43.950",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "72773538",
                "ParentRepo": "https://github.com/django-hijack/django-hijack/blob/master/docs/index.md",
                "StackOverflow_Post": {
                    "Id": "72773538",
                    "PostTypeId": "1",
                    "CreationDate": "2022-06-27T14:12:09.610",
                    "Score": "0",
                    "ViewCount": "73",
                    "Body": "<p>I have follow the <a href=\"https://github.com/django-hijack/django-hijack/blob/master/docs/index.md\" rel=\"nofollow noreferrer\">django-hijack</a> installation process but unfortunately the usage demonstration is using the django template.</p>\n<p>But like most current applications, my application uses Django Rest Framework and has a javascript application for the front end.</p>\n<p>I can't find a solution to impersonate an user from the front-end. I've tried to do a POST while logged in as an admin on <code>/hijack/5</code> or <code>/hijack/acquire/5</code> where <code>5</code>is the ID of the user I want to impersonate but I got a 404 error on my POST.</p>\n<p>So my question is how to impersonate an user while an admin with Django when using a javascript front end application ?</p>\n<p>I'm open to other projects than django-hijack if this one is not compatible.</p>\n",
                    "OwnerUserId": "4157512",
                    "LastActivityDate": "2022-06-27T14:12:09.610",
                    "Title": "How to use django-hijack from api",
                    "Tags": "<javascript><python><django><frontend><impersonation>",
                    "AnswerCount": "0",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "72796059",
                "ParentRepo": "https://github.com/blb-ventures/strawberry-django-plus",
                "StackOverflow_Post": {
                    "Id": "72796059",
                    "PostTypeId": "2",
                    "ParentId": "72782586",
                    "CreationDate": "2022-06-29T05:12:23.860",
                    "Score": "1",
                    "Body": "<p>I think <em>strawberry_django</em> has a bug here, though you should prefer using the <a href=\"https://github.com/blb-ventures/strawberry-django-plus\" rel=\"nofollow noreferrer\">strawberry_django_plus</a> package,\nbecause it is better maintained. Hopefully, it will be merged to the official strawberry soon.</p>\n<p>In your case, it would be:</p>\n<pre class=\"lang-py prettyprint-override\"><code>from strawberry_django_plus import gql\nfrom strawberry import auto\n\n@gql.django.type(models.Person)\nclass Person:\n    id: auto\n    name: auto\n    address:'Address'\n\n@gql.django.input(models.Person)\nclass Person:\n    id: auto\n    name: auto\n    address:'AddressInput'\n\n@gql.type\nclass Mutation:\n    createAddress: Address = gql.django.create_mutation(AddressInput)\n    createPerson: Person = gql.django.create_mutation(PersonInput)\n\nschema = strawberry.Schema(mutation=Mutation)\n</code></pre>\n",
                    "OwnerUserId": "16776498",
                    "LastEditorUserId": "63550",
                    "LastEditDate": "2022-06-30T14:36:01.873",
                    "LastActivityDate": "2022-06-30T14:36:01.873",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "72849049",
                "ParentRepo": "https://github.com/DataDog/apigentools",
                "StackOverflow_Post": {
                    "Id": "72849049",
                    "PostTypeId": "1",
                    "CreationDate": "2022-07-03T18:41:21.783",
                    "Score": "0",
                    "ViewCount": "17",
                    "Body": "<p>I'm getting started with <a href=\"https://github.com/OpenAPITools/openapi-generator\" rel=\"nofollow noreferrer\">OpenAPI generator</a> and would like to learn the best practices and see a list of companies that are actually using SDK generated by this tool (the reason is I feel like the tooling is a little bit behind for OpenAPI v3 so I'd like to see if anyone has a build an end-to-end pipeline).</p>\n<p>So far I've found DataDog and their <a href=\"https://github.com/DataDog/apigentools\" rel=\"nofollow noreferrer\">custom tooling</a> and OneSignal's <a href=\"https://github.com/OneSignal/OneSignal-iOS-SDK\" rel=\"nofollow noreferrer\">SDK</a>.</p>\n",
                    "OwnerUserId": "18509753",
                    "LastActivityDate": "2022-07-03T18:41:21.783",
                    "Title": "Where can I find latest tooling for OpenAPI Generator (except the repository itself)?",
                    "Tags": "<openapi-generator><openapi-generator-cli>",
                    "AnswerCount": "0",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "72875597",
                "ParentRepo": "https://github.com/paperless-ngx/paperless-ngx/issues/817",
                "StackOverflow_Post": {
                    "Id": "72875597",
                    "PostTypeId": "2",
                    "ParentId": "72874159",
                    "CreationDate": "2022-07-05T21:12:57.480",
                    "Score": "0",
                    "Body": "<p>The answer is here : it needs a special configuration of nginx\n<a href=\"https://github.com/paperless-ngx/paperless-ngx/issues/817\" rel=\"nofollow noreferrer\">https://github.com/paperless-ngx/paperless-ngx/issues/817</a></p>\n<pre><code>location / {\n                proxy_pass http://10.0.0.1:8000;\n                proxy_set_header Host $http_host;\n                proxy_set_header X-Real-IP $remote_addr;\n                proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n                proxy_set_header X-Forwarded-Proto $scheme;\n                add_header P3P 'CP=&quot;&quot;';\n        }\n</code></pre>\n",
                    "OwnerUserId": "19413311",
                    "LastActivityDate": "2022-07-05T21:12:57.480",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "72879308",
                "ParentRepo": "https://github.com/camunda-community-hub/camunda-platform-7-rest-client-spring-boot",
                "StackOverflow_Post": {
                    "Id": "72879308",
                    "PostTypeId": "2",
                    "ParentId": "72868636",
                    "CreationDate": "2022-07-06T07:15:56.753",
                    "Score": "0",
                    "Body": "<p>If you want to talk to a camunda engine on a different machine, you will definitely have to use the REST interface.</p>\n<p>You can however wrap the REST client in a runtimeService interface by using the rest-spring-boot <a href=\"https://github.com/camunda-community-hub/camunda-platform-7-rest-client-spring-boot\" rel=\"nofollow noreferrer\">community extension</a>.</p>\n<pre><code>@SpringBootApplication\n@EnableCamundaRestClient\npublic class CamundaRestClientExampleApplication {}\n\n@Component\npublic class ProcessClient {\n  private final RuntimeService runtimeService;\n  private final RepositoryService repositoryService;\n  private final Map&lt;String, String&gt; instances = new ConcurrentHashMap();\n\n  public ProcessClient(\n    @Qualifier(&quot;remote&quot;) RuntimeService runtimeService,\n    @Qualifier(&quot;remote&quot;) RepositoryService repositoryService\n  ) {\n    this.runtimeService = runtimeService;\n    this.repositoryService = repositoryService;\n  }\n\n\n  public void startProcess() {\n    VariableMap variables = createVariables()\n      .putValueTyped(&quot;ID&quot;, stringValue(&quot;MESSAGING-&quot; + UUID.randomUUID()));\n    return runtimeService.startProcessInstanceByKey(\n      KEY, \n      businessKey, \n      variables);\n  }\n}\n</code></pre>\n<p>By doing so, you write code as if you where running inside the engine, but requests are directed to the remote engine.</p>\n",
                    "OwnerUserId": "290425",
                    "LastActivityDate": "2022-07-06T07:15:56.753",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "72890382",
                "ParentRepo": "https://github.com/pulp/pulp_installer",
                "StackOverflow_Post": {
                    "Id": "72890382",
                    "PostTypeId": "1",
                    "CreationDate": "2022-07-06T22:08:53.193",
                    "Score": "0",
                    "ViewCount": "356",
                    "Body": "<p>I'm getting an error from ansible.  Any idea of how to fix this?  How do I add the collection <code>mdellweg.filters</code> to Jinja2?</p>\n<pre><code>TASK [pulp_common : Create configuration file for Pulp] ********************************************************************************\n[WARNING]: an unexpected error occurred during Jinja2 environment setup: unable to locate collection mdellweg.filters\nfatal: [localhost]: FAILED! =&gt; {&quot;changed&quot;: false, &quot;msg&quot;: &quot;AnsibleError: template error while templating string: unable to locate collection mdellweg.filters. String: # Do NOT edit this file. It may be subject of change when PULP is updated.\\n# Put new or overridden settings in {{ pulp_settings_file_local }} instead.\\n{% for setting, value in __pulp_common_merged_pulp_settings.items() %}\\n{{ setting | upper }} = {{ value | mdellweg.filters.repr }}\\n{% endfor %}\\n{# https://github.com/pulp/pulpcore/blob/master/pulpcore/app/settings.py#L37-L38 #}\\nDEPLOY_ROOT = \\&quot;{{ pulp_user_home }}\\&quot;\\nMEDIA_ROOT = \\&quot;{{ pulp_media_root }}\\&quot;\\nSTATIC_ROOT = \\&quot;{{ pulp_user_home }}/assets\\&quot;\\nWORKING_DIRECTORY = \\&quot;{{ pulp_user_home }}/tmp\\&quot;\\nFILE_UPLOAD_TEMP_DIR = \\&quot;{{ pulp_user_home }}/tmp\\&quot;\\nDB_ENCRYPTION_KEY = \\&quot;{{ pulp_certs_dir }}/database_fields.symmetric.key\\&quot;\\n&quot;}\n</code></pre>\n<p>I am getting this from the <a href=\"https://github.com/pulp/pulp_installer\" rel=\"nofollow noreferrer\">pulp_installer project</a>.</p>\n",
                    "OwnerUserId": "18113679",
                    "LastEditorUserId": "2123530",
                    "LastEditDate": "2022-07-07T07:20:52.800",
                    "LastActivityDate": "2022-07-07T07:20:52.800",
                    "Title": "Unexpected error occurred during Jinja2 environment setup",
                    "Tags": "<ansible><jinja2><ansible-template>",
                    "AnswerCount": "0",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "72944146",
                "ParentRepo": "https://github.com/xhluca/dl-translate",
                "StackOverflow_Post": {
                    "Id": "72944146",
                    "PostTypeId": "2",
                    "ParentId": "68587883",
                    "CreationDate": "2022-07-11T20:11:52.990",
                    "Score": "1",
                    "Body": "<p>Python library <em>dl-translate</em> gets the job done very well. It is based on Huggingface transformers, with 2 available model options - mBART-50 Large (50 languages, personally I find it to be very accurate) and m2m100 (100 languages, but slightly less accurate). Link to github: <a href=\"https://github.com/xhluca/dl-translate\" rel=\"nofollow noreferrer\">https://github.com/xhluca/dl-translate</a></p>\n",
                    "OwnerUserId": "15172687",
                    "LastActivityDate": "2022-07-11T20:11:52.990",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "72992062",
                "ParentRepo": "https://github.com/jthomperoo/predictive-horizontal-pod-autoscaler",
                "StackOverflow_Post": {
                    "Id": "72992062",
                    "PostTypeId": "2",
                    "ParentId": "72962155",
                    "CreationDate": "2022-07-15T09:43:31.087",
                    "Score": "1",
                    "Body": "<p>A <a href=\"https://github.com/jthomperoo/predictive-horizontal-pod-autoscaler\" rel=\"nofollow noreferrer\">Digital OCean Predictive Horizontal Pod Autoscaler</a> has the same kind of parameter: <a href=\"https://predictive-horizontal-pod-autoscaler.readthedocs.io/en/latest/reference/configuration/#cpuinitializationperiod\" rel=\"nofollow noreferrer\"><code>cpuInitializationPeriod</code></a>.</p>\n<p>It rephrases what  <code>--horizontal-pod-autoscaler-cpu-initialization-period</code> as:</p>\n<blockquote>\n<p>the period after pod start when CPU samples might be skipped.</p>\n</blockquote>\n<p>And for <code>horizontal-pod-autoscaler-initial-readiness-delay</code></p>\n<blockquote>\n<p>the period after pod start during which readiness changes will be treated as initial readiness.</p>\n</blockquote>\n<p>The idea is to:</p>\n<ul>\n<li>not trigger any scaling based on CPU change alone (because the initial <code>cpu-initialization-period</code> means the pod is still being ready, with potential CPU spike)</li>\n<li>not trigger any scaling based on readiness state changes (because the initial <code>readiness-delay</code> means, even if the pod reports it is ready, that can change during that delay)</li>\n</ul>\n<p><a href=\"https://github.com/kubernetes/website/issues/12657\" rel=\"nofollow noreferrer\"><code>kubernetes/website</code> issue 12657</a> has more (mainly to confirm the original documentation is confusing).</p>\n",
                    "OwnerUserId": "6309",
                    "LastEditorUserId": "6309",
                    "LastEditDate": "2022-07-15T09:52:13.250",
                    "LastActivityDate": "2022-07-15T09:52:13.250",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "73100224",
                "ParentRepo": "https://github.com/microsoft/AzureTRE/blob/main/templates/shared_services/airlock_notifier/terraform/airlock_notifier.tf#L58",
                "StackOverflow_Post": {
                    "Id": "73100224",
                    "PostTypeId": "2",
                    "ParentId": "73021699",
                    "CreationDate": "2022-07-24T16:38:41.233",
                    "Score": "0",
                    "Body": "<p>As far as I know, this is currently not possible. <a href=\"https://github.com/hashicorp/terraform-provider-azurerm/issues/16195\" rel=\"nofollow noreferrer\">See the github issue</a></p>\n<p>I had a similar problem, and to workaround it I've used an ARM template and the 'azurerm_resource_group_template_deployment' terraform module.</p>\n<p>Here is a reference:\n<a href=\"https://github.com/microsoft/AzureTRE/blob/main/templates/shared_services/airlock_notifier/terraform/airlock_notifier.tf#L58\" rel=\"nofollow noreferrer\">https://github.com/microsoft/AzureTRE/blob/main/templates/shared_services/airlock_notifier/terraform/airlock_notifier.tf#L58</a></p>\n",
                    "OwnerUserId": "15393799",
                    "LastActivityDate": "2022-07-24T16:38:41.233",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "73105719",
                "ParentRepo": "https://github.com/pypi/warehouse/blob/main/docs/api-reference/json.rst",
                "StackOverflow_Post": {
                    "Id": "73105719",
                    "PostTypeId": "2",
                    "ParentId": "4888027",
                    "CreationDate": "2022-07-25T07:52:58.180",
                    "Score": "0",
                    "Body": "<p>As of what I understood from <a href=\"https://discuss.python.org/t/backwards-incompatible-change-to-pypi-json-api/17154\" rel=\"nofollow noreferrer\">this</a> and <a href=\"https://github.com/pypi/warehouse/blob/main/docs/api-reference/json.rst\" rel=\"nofollow noreferrer\">this</a>, the <code>releases</code> key will be dropped in a near future so solutions using <code>GET &quot;https://pypi.python.org/pypi/{package_name}/json&quot;</code> will not work anymore.</p>\n",
                    "OwnerUserId": "8750662",
                    "LastActivityDate": "2022-07-25T07:52:58.180",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "73192339",
                "ParentRepo": "https://github.com/Digital-Sapphire/PyUpdater/issues/320",
                "StackOverflow_Post": {
                    "Id": "73192339",
                    "PostTypeId": "2",
                    "ParentId": "72300399",
                    "CreationDate": "2022-08-01T10:25:45.350",
                    "Score": "1",
                    "Body": "<p>Unfortunately, PyUpdater 4.0 is broken. See <a href=\"https://github.com/Digital-Sapphire/PyUpdater/issues/320\" rel=\"nofollow noreferrer\">PyUpdater issue 320</a>.</p>\n<p>Some options:</p>\n<ul>\n<li>downgrade to PyUpdater 3.1.1.</li>\n<li>wait until <a href=\"https://github.com/Digital-Sapphire/PyUpdater/pull/322\" rel=\"nofollow noreferrer\">PR 322</a> is accepted (or install directly from the fork)</li>\n<li>wait for <a href=\"https://github.com/Digital-Sapphire/PyUpdater/issues/320\" rel=\"nofollow noreferrer\">PyUpdater 5.x</a></li>\n<li>try an alternative, e.g. our <a href=\"https://github.com/dennisvang/tufup\" rel=\"nofollow noreferrer\">tufup</a> (TUF-updater)</li>\n</ul>\n<h2>Update:</h2>\n<p>Its seems PyUpdater is now <a href=\"https://github.com/Digital-Sapphire/PyUpdater/blob/main/README.md?plain=1#L1\" rel=\"nofollow noreferrer\">officially archived</a>, so there won't be any new releases there.</p>\n",
                    "OwnerUserId": "4720018",
                    "LastEditorUserId": "4720018",
                    "LastEditDate": "2022-09-26T08:06:11.363",
                    "LastActivityDate": "2022-09-26T08:06:11.363",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "73201187",
                "ParentRepo": "https://github.com/dtcooper/python-dispmanx",
                "StackOverflow_Post": {
                    "Id": "73201187",
                    "PostTypeId": "2",
                    "ParentId": "17583295",
                    "CreationDate": "2022-08-02T01:46:06.317",
                    "Score": "0",
                    "Body": "<p>Check out my library built for exactly this use case: <a href=\"https://github.com/dtcooper/python-dispmanx\" rel=\"nofollow noreferrer\">https://github.com/dtcooper/python-dispmanx</a></p>\n<p>You can use pygame as follows,</p>\n<pre class=\"lang-py prettyprint-override\"><code>from random import randint\nimport pygame\nfrom dispmanx import DispmanX\n\n# Generate a random color with alpha compontent\ndef random_color_with_alpha():\n    return tuple(randint(0, 0xFF) for _ in range(3)) + (randint(0x44, 0xFF),)\n\ndisplay = DispmanX(pixel_format=&quot;RGBA&quot;)\nsurface = pygame.image.frombuffer(\n    display.buffer, display.size, display.pixel_format\n)\nclock = pygame.time.Clock()\n\nfor _ in range(20):\n    surface.fill(random_color_with_alpha())\n    display.update()\n    clock.tick(2)\n</code></pre>\n<p>Alternately, there's an another C Python extension that I didn't write that also functions the same way: <a href=\"https://github.com/eclispe/pyDispmanx\" rel=\"nofollow noreferrer\">https://github.com/eclispe/pyDispmanx</a></p>\n",
                    "OwnerUserId": "1864783",
                    "LastEditorUserId": "1864783",
                    "LastEditDate": "2022-08-08T08:30:56.670",
                    "LastActivityDate": "2022-08-08T08:30:56.670",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "73204787",
                "ParentRepo": "https://github.com/openshift/hypershift/issues/313",
                "StackOverflow_Post": {
                    "Id": "73204787",
                    "PostTypeId": "2",
                    "ParentId": "72168893",
                    "CreationDate": "2022-08-02T09:04:24.633",
                    "Score": "0",
                    "Body": "<p>I have seen this error when the liveness probe is timing out. Try lengthening the timeoutSeconds on your livenessProbe and see if the problem goes away.</p>\n<p>Refer this <a href=\"https://github.com/openshift/hypershift/issues/313\" rel=\"nofollow noreferrer\">link</a> for more information.</p>\n",
                    "OwnerUserId": "15745115",
                    "LastActivityDate": "2022-08-02T09:04:24.633",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "73236013",
                "ParentRepo": "https://github.com/RobertCraigie/prisma-client-py/discussions",
                "StackOverflow_Post": {
                    "Id": "73236013",
                    "PostTypeId": "2",
                    "ParentId": "73203340",
                    "CreationDate": "2022-08-04T12:33:27.617",
                    "Score": "1",
                    "Body": "<p>It is recommended that you create one instance of <code>PrismaClient</code> and reuse it across your application and you should only set it to a global variable in the development environment only and you do not need to explicitly <code>$disconnect</code>. You can learn more about Prisma connection management in the <a href=\"https://www.prisma.io/docs/guides/performance-and-optimization/connection-management\" rel=\"nofollow noreferrer\">docs</a>. Also, I\u2019ll encourage you to ask your Prisma Python client questions in prisma-client-py repositories <a href=\"https://github.com/RobertCraigie/prisma-client-py/discussions\" rel=\"nofollow noreferrer\">GitHub Discussion</a></p>\n",
                    "OwnerUserId": "1645620",
                    "LastActivityDate": "2022-08-04T12:33:27.617",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "73241648",
                "ParentRepo": "https://github.com/laurents/slowapi",
                "StackOverflow_Post": {
                    "Id": "73241648",
                    "PostTypeId": "2",
                    "ParentId": "73220174",
                    "CreationDate": "2022-08-04T20:00:03.147",
                    "Score": "2",
                    "Body": "<h2>Returning a File Response</h2>\n<p>First, to return a <code>file</code> that is saved on disk from a FastAPI backend, you could use <a href=\"https://fastapi.tiangolo.com/advanced/custom-response/#fileresponse\" rel=\"nofollow noreferrer\"><code>FileResponse</code></a> (in case the file was already fully loaded into memory, see <a href=\"https://stackoverflow.com/a/71639658/17865804\">here</a>). For example:</p>\n<pre class=\"lang-py prettyprint-override\"><code>from fastapi import FastAPI\nfrom fastapi.responses import FileResponse\n\nsome_file_path = &quot;large-video-file.mp4&quot;\napp = FastAPI()\n\n@app.get(&quot;/&quot;)\ndef main():\n    return FileResponse(some_file_path)\n</code></pre>\n<p>In case the <code>file</code> is too large to fit into memory\u2014as you may not have enough memory to handle the file data, e.g., if you have 16GB of RAM, you can\u2019t load a 100GB file\u2014you could use <a href=\"https://fastapi.tiangolo.com/advanced/custom-response/#using-streamingresponse-with-file-like-objects\" rel=\"nofollow noreferrer\"><code>StreamingResponse</code></a>. That way, you don't have to read it all first in memory, but, instead, load it into memory in chunks, thus processing the data one chunk at a time. Example is given below. If you find <code>yield from f</code> being rather slow when using <code>StreamingResponse</code>, you could instead create a custom generator, as described in <a href=\"https://stackoverflow.com/a/73843234/17865804\">this answer</a>.</p>\n<pre class=\"lang-py prettyprint-override\"><code>from fastapi import FastAPI\nfrom fastapi.responses import StreamingResponse\n\nsome_file_path = &quot;large-video-file.mp4&quot;\napp = FastAPI()\n\n@app.get(&quot;/&quot;)\ndef main():\n    def iterfile():\n        with open(some_file_path, mode=&quot;rb&quot;) as f:\n            yield from f\n\n    return StreamingResponse(iterfile(), media_type=&quot;video/mp4&quot;)\n</code></pre>\n<h2>Exposing the API to the public</h2>\n<p>As for exposing your API to the public\u2014i.e., external APIs, users, developers, etc.\u2014you can use <a href=\"https://ngrok.com/\" rel=\"nofollow noreferrer\">ngrok</a> (or <a href=\"https://expose.dev/\" rel=\"nofollow noreferrer\">expose</a>, as suggested in <a href=\"https://stackoverflow.com/a/70802911/17865804\">this answer</a>).</p>\n<p>Ngrok is a cross-platform application that enables developers to expose a local <em>development server</em> to the Internet with minimal effort. To embed the <code>ngrok</code> agent into your FastAPI application, you could use <a href=\"https://github.com/alexdlaird/pyngrok\" rel=\"nofollow noreferrer\"><code>pyngrok</code></a>\u2014as suggested <a href=\"https://ngrok.com/docs/using-ngrok-with#fastapi\" rel=\"nofollow noreferrer\">here</a> (see <a href=\"https://pyngrok.readthedocs.io/en/latest/integrations.html#fastapi\" rel=\"nofollow noreferrer\">here</a> for a FastAPI integration example). If you would like to run and expose your FastAPI app through <a href=\"https://colab.research.google.com/\" rel=\"nofollow noreferrer\">Google Colab</a> (using <code>ngrok</code>), instead of your local machine, please have a look at <a href=\"https://stackoverflow.com/a/63833779/17865804\">this answer</a> (plenty of tutorials/examples can also be found on the web).</p>\n<p>If you are looking for a more permanent solution, you may want to have a look at cloud platforms\u2014more specifically, a Platform as a Service (PaaS)\u2014such as <a href=\"https://www.heroku.com/\" rel=\"nofollow noreferrer\">Heroku</a>. I would strongly recommend you thoroughly read <a href=\"https://fastapi.tiangolo.com/deployment/\" rel=\"nofollow noreferrer\">FastAPI's Deployment documentation</a>. Have a closer look at <a href=\"https://fastapi.tiangolo.com/deployment/https/\" rel=\"nofollow noreferrer\">About HTTPS</a> and <a href=\"https://fastapi.tiangolo.com/deployment/concepts/\" rel=\"nofollow noreferrer\">Deployments Concepts</a>.</p>\n<h4>Important to note</h4>\n<p>By exposing your API to the outside world, you are also exposing it to various forms of attack. Before exposing your API to the public\u2014even if it\u2019s for free\u2014you need to make sure you are offering secure access (use <code>HTTPS</code>), as well as <code>authentication</code> (verify the identity of a user) and <code>authorisation</code> (verify their access rights; in other words, verify what specific routes, files and data a user has access to)\u2014take a look at 1. <a href=\"https://fastapi.tiangolo.com/tutorial/security/oauth2-jwt/\" rel=\"nofollow noreferrer\">OAuth2 and JWT tokens</a>, 2. <a href=\"https://fastapi.tiangolo.com/advanced/security/oauth2-scopes/\" rel=\"nofollow noreferrer\">OAuth2 scopes</a>, 3. <a href=\"https://en.wikipedia.org/wiki/Role-based_access_control\" rel=\"nofollow noreferrer\">Role-Based Access Control (RBAC)</a>, 4. <a href=\"https://fastapi.tiangolo.com/tutorial/security/get-current-user/\" rel=\"nofollow noreferrer\">Get Current User</a> and <a href=\"https://learnings.desipenguin.com/post/rolechecker-with-fastapi/\" rel=\"nofollow noreferrer\">How to Implement Role based Access Control With FastAPI</a>.</p>\n<p>Addtionally,  if you are exposing your API to be used publicly, you may want to limit the usage of the API because of expensive computation, limited resources, <a href=\"https://en.wikipedia.org/wiki/Denial-of-service_attack\" rel=\"nofollow noreferrer\">DDoS attacks</a>, <a href=\"https://en.wikipedia.org/wiki/Brute-force_attack\" rel=\"nofollow noreferrer\">Brute-force attacks</a>, <a href=\"https://en.wikipedia.org/wiki/Web_scraping\" rel=\"nofollow noreferrer\">Web scraping</a>, or simply due to monthly cost for a fixed amount of requests. You can do that at the application level using, for instance, <a href=\"https://github.com/laurents/slowapi\" rel=\"nofollow noreferrer\">slowapi</a> (related post <a href=\"https://stackoverflow.com/a/71183527/17865804\">here</a>), or at the platform level by setting the rate limit through your hosting service (if permitted). Furthermore, you would need to make sure that the files uploaded by users have the permitted file extension, e.g., <code>.mp4</code>, and are not files with, for instance, a <code>.exe</code> extension that are potentially harmful to your system. Finally, you would also need to ensure that the uploaded files do not exceed a predefined <code>MAX_FILE_SIZE</code> limit (based on your needs and system's resources), so that authenticated users, or an attacker, would be prevented from uploading extremely large files that would result in consuming server resources in a way that the application may end up crashing. You shouldn't rely, though, on the <code>Content-Length</code> header being present in the <code>request</code> to do that, as this might be easily altered, or even removed, by the client. You should rather use an approach similar to <a href=\"https://stackoverflow.com/a/70667530/17865804\"><strong>this answer</strong></a> (have a look at the &quot;Update&quot; section) that uses <code>request.stream()</code> to process the incoming data in chunks as they arrive, instead of loading the entire file into memory first. By using a simple counter, e.g., <code>total_len += len(chunk)</code>, you can check if the file size has exceeded the <code>MAX_FILE_SIZE</code>, and if so, raise an <a href=\"https://fastapi.tiangolo.com/tutorial/handling-errors/#use-httpexception\" rel=\"nofollow noreferrer\"><code>HTTPException</code></a> with <code>HTTP_413_REQUEST_ENTITY_TOO_LARGE</code> status code (see <a href=\"https://stackoverflow.com/a/73443824/17865804\"><strong>this answer</strong></a> as well, for more details and code examples).</p>\n<p>Read more on FastAPI's <a href=\"https://fastapi.tiangolo.com/tutorial/security/\" rel=\"nofollow noreferrer\">Security documentation</a> and <a href=\"https://www.cloudflare.com/learning/security/api/what-is-api-security/\" rel=\"nofollow noreferrer\">API Security</a> on Cloudflare.</p>\n",
                    "OwnerUserId": "17865804",
                    "LastEditorUserId": "17865804",
                    "LastEditDate": "2022-10-23T05:34:04.983",
                    "LastActivityDate": "2022-10-23T05:34:04.983",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "73349350",
                "ParentRepo": "https://github.com/giosali/HotkeyUtility",
                "StackOverflow_Post": {
                    "Id": "73349350",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "73381722",
                    "CreationDate": "2022-08-14T05:39:31.373",
                    "Score": "0",
                    "ViewCount": "69",
                    "Body": "<p>On my C# WPF project that runs in the background from the system tray I installed a package called NHotkey to try and turn my keyboard hotkey into a global hotkey that works even if the window isn't up: <a href=\"https://github.com/thomaslevesque/NHotkey\" rel=\"nofollow noreferrer\">https://github.com/thomaslevesque/NHotkey</a></p>\n<p>And I added it through XAML:</p>\n<pre><code>&lt;Window.Resources&gt;\n    &lt;RoutedUICommand x:Key=&quot;CtrLeft&quot; Text=&quot;Left&quot; /&gt;\n&lt;/Window.Resources&gt;\n&lt;Window.InputBindings&gt;\n    &lt;KeyBinding Gesture=&quot;Ctrl+Windows+Alt+Left&quot; Command=&quot;{StaticResource CtrLeft}&quot; HotkeyManager.RegisterGlobalHotkey=&quot;True&quot; /&gt;\n&lt;/Window.InputBindings&gt;\n&lt;Window.CommandBindings&gt;\n    &lt;CommandBinding Command=&quot;{StaticResource CtrLeft}&quot; Executed=&quot;Test&quot; /&gt;\n&lt;/Window.CommandBindings&gt;\n</code></pre>\n<p>Unfortunately it still only executes the &quot;Test&quot; function if the window is open and focused.</p>\n<p>Using the NHotkey readme I also tried implementing the hotkey programmatically and ended up with the same result. NHotkey is a very popular package and there don't appear to be any related open issues with it so I suspect I'm doing something wrong.</p>\n<p>I've also tried other global hotkey packages which either result in the same thing, or in the application crashing and giving an error about the hotkey already being registered in Event Viewer. In those instances I've tried obscure key combinations that wouldn't ever be in use by anything and still get an error in Event Viewer about it already being registered. An example of one of the packages I tried with this outcome is HotkeyUtility: <a href=\"https://github.com/giosali/HotkeyUtility\" rel=\"nofollow noreferrer\">https://github.com/giosali/HotkeyUtility</a></p>\n<p>These results are on a fresh test virtual machine with no third party software. Tried on both Windows 10 and 11.</p>\n<p>A global hotkey would be very useful for my application and any help getting there would be very much appreciated. Any ideas? Thanks.</p>\n",
                    "OwnerUserId": "14113049",
                    "LastActivityDate": "2022-08-17T00:39:11.813",
                    "Title": "WPF NHotkey global hotkey only runs when window is focused",
                    "Tags": "<c#><wpf><hotkeys><registerhotkey><global-hotkey>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "73349892",
                "ParentRepo": "https://github.com/LottieFiles/lottie-docs",
                "StackOverflow_Post": {
                    "Id": "73349892",
                    "PostTypeId": "2",
                    "ParentId": "63265720",
                    "CreationDate": "2022-08-14T07:38:37.127",
                    "Score": "1",
                    "Body": "<p>There are a few resources available online for studying the Lottie format.</p>\n<p>The most easily digestible is the <a href=\"https://github.com/LottieFiles/lottie-docs\" rel=\"nofollow noreferrer\">lottie-docs project</a>, which is by the same person who did the python-lottie package (Matt Basaglia).</p>\n<ul>\n<li><a href=\"https://github.com/marcusstenbeck/lottie-types\" rel=\"nofollow noreferrer\">TypeScript definition</a></li>\n<li><a href=\"https://github.com/bodymovin/bodymovin/tree/master/docs/json\" rel=\"nofollow noreferrer\">Bodymovin JSON docs</a></li>\n<li><a href=\"https://mattbas.gitlab.io/python-lottie/group__Lottie.html#details\" rel=\"nofollow noreferrer\">python-lottie docs</a></li>\n<li><a href=\"https://github.com/LottieFiles/lottie-docs\" rel=\"nofollow noreferrer\">Matt Basaglia\u2019s lottie-docs</a></li>\n<li><a href=\"https://github.com/lottie-animation-community/\" rel=\"nofollow noreferrer\">Lottie Animation Community repos</a></li>\n</ul>\n",
                    "OwnerUserId": "1331179",
                    "LastActivityDate": "2022-08-14T07:38:37.127",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "73388121",
                "ParentRepo": "https://github.com/jacebrowning/universal-startfile",
                "StackOverflow_Post": {
                    "Id": "73388121",
                    "PostTypeId": "2",
                    "ParentId": "434597",
                    "CreationDate": "2022-08-17T11:59:22.387",
                    "Score": "0",
                    "Body": "<p>I built a <a href=\"https://github.com/jacebrowning/universal-startfile\" rel=\"nofollow noreferrer\">small library</a> combining the best answers here for cross-platform support:</p>\n<pre class=\"lang-bash prettyprint-override\"><code>$ pip install universal-startfile\n</code></pre>\n<p>then launch a file or URL:</p>\n<pre class=\"lang-py prettyprint-override\"><code>from startfile import startfile\n\nstartfile(&quot;~/Downloads/example.png&quot;)\nstartfile(&quot;http://example.com&quot;)\n</code></pre>\n",
                    "OwnerUserId": "429533",
                    "LastActivityDate": "2022-08-17T11:59:22.387",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "73421183",
                "ParentRepo": "https://github.com/lstein/stable-diffusion",
                "StackOverflow_Post": {
                    "Id": "73421183",
                    "PostTypeId": "1",
                    "CreationDate": "2022-08-19T18:59:48.323",
                    "Score": "3",
                    "ViewCount": "2505",
                    "Body": "<p><strong>UPDATE:</strong> I have edited and changed more code, now I dont get an error and it either works but taked hours, or it is stuck on step one</p>\n<p>I have tried running Stable Diffusion, the new text2image model. The Problem is: I don\u00b4t have a NVIDIA GPU... After a bit of research, I found out you can &quot;force&quot; PyTorch to run on your CPU, not GPU. But up to this point, everything I tried while modifying the existing code, did not work. I always get to the point where it starts sampling, and prints the following error (everyting after the command):</p>\n<pre><code>Falling back to LAION 400M model...\nGlobal seed set to 42\nLoading model from models/ldm/text2img-large/model.ckpt\nLatentDiffusion: Running in eps-prediction mode\nDiffusionWrapper has 872.30 M params.\nmaking attention of type 'vanilla' with 512 in_channels\nWorking with z of shape (1, 4, 32, 32) = 4096 dimensions.\nmaking attention of type 'vanilla' with 512 in_channels\ndata:   0%|                                                                                                                                           | 0/1 [00:00&lt;?, ?it/s]\nSampling:   0%|                                                                                                                                       | 0/2 [00:00&lt;?, ?it/s]\nTraceback (most recent call last):\n  File &quot;scripts/txt2img.py&quot;, line 279, in &lt;module&gt;\n    main()\n  File &quot;scripts/txt2img.py&quot;, line 233, in main\n    uc = model.get_learned_conditioning(batch_size * [&quot;&quot;])\n  File &quot;c:\\users\\louis\\stable-diffusion\\ldm\\models\\diffusion\\ddpm.py&quot;, line 558, in get_learned_conditioning\n    c = self.cond_stage_model.encode(c)\n  File &quot;c:\\users\\louis\\stable-diffusion\\ldm\\modules\\encoders\\modules.py&quot;, line 111, in encode\n    return self(text)\n  File &quot;C:\\Users\\louis\\anaconda3\\envs\\ldm\\lib\\site-packages\\torch\\nn\\modules\\module.py&quot;, line 1110, in _call_impl\n    return forward_call(*input, **kwargs)\n  File &quot;c:\\users\\louis\\stable-diffusion\\ldm\\modules\\encoders\\modules.py&quot;, line 103, in forward\n    tokens = self.tknz_fn(text)#.to(self.device)\n  File &quot;C:\\Users\\louis\\anaconda3\\envs\\ldm\\lib\\site-packages\\torch\\nn\\modules\\module.py&quot;, line 1110, in _call_impl\n    return forward_call(*input, **kwargs)\n  File &quot;c:\\users\\louis\\stable-diffusion\\ldm\\modules\\encoders\\modules.py&quot;, line 74, in forward\n    tokens = batch_encoding[&quot;input_ids&quot;].to(self.device)\n  File &quot;C:\\Users\\louis\\anaconda3\\envs\\ldm\\lib\\site-packages\\torch\\cuda\\__init__.py&quot;, line 216, in _lazy_init\n    torch._C._cuda_init()\nRuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx\n</code></pre>\n<p>I already defined to use CPU in text2img.py, so the error of something like &quot;user defined to use cuda, but no cuda device available&quot; is fixed.</p>\n<p>So my question(s):<br />\n-Is what I\u00b4m trying even possible?<br />\n-If yes, how should I edit the code to work?<br />\n(-Would it even be possible to modify it to work on AMD GPUs using ROCm?)</p>\n<p>The Repo: <a href=\"https://github.com/CompVis/stable-diffusion\" rel=\"nofollow noreferrer\">https://github.com/CompVis/stable-diffusion</a><br />\nUsing the LAION400m weights, because I currently don\u00b4t have access to the SD ones.\nI got them using:<br />\n<code>wget -O models/ldm/text2img-large/model.ckpt https://ommer-lab.com/files/latent-diffusion/nitro/txt2img-f8-large/model.ckpt</code><br />\nGuide I followed:<a href=\"https://github.com/lstein/stable-diffusion\" rel=\"nofollow noreferrer\">https://github.com/lstein/stable-diffusion</a></p>\n",
                    "OwnerUserId": "11990914",
                    "LastEditorUserId": "4685471",
                    "LastEditDate": "2022-08-19T23:13:03.323",
                    "LastActivityDate": "2022-08-19T23:13:03.323",
                    "Title": "No NVIDIA GPU found error, even though I defined Torch to use CPU",
                    "Tags": "<python><machine-learning><pytorch><torch>",
                    "AnswerCount": "0",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "73425513",
                "ParentRepo": "https://github.com/petereon/beaupy",
                "StackOverflow_Post": {
                    "Id": "73425513",
                    "PostTypeId": "2",
                    "ParentId": "30993731",
                    "CreationDate": "2022-08-20T09:21:27.843",
                    "Score": "0",
                    "Body": "<p>I am a bit late to the party, but for anyone looking for such libraries now:</p>\n<ul>\n<li>Go - <a href=\"https://github.com/charmbracelet/bubbletea\" rel=\"nofollow noreferrer\">charmbracelet/bubbletea</a></li>\n<li>Python - <a href=\"https://github.com/petereon/beaupy\" rel=\"nofollow noreferrer\">petereon/beaupy</a></li>\n<li>Shell - <a href=\"https://github.com/charmbracelet/gum\" rel=\"nofollow noreferrer\">charmbracelet/gum</a></li>\n</ul>\n<p>Disclaimer: I am a maintainer of beaupy</p>\n",
                    "OwnerUserId": "9019559",
                    "LastActivityDate": "2022-08-20T09:21:27.843",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "73446979",
                "ParentRepo": "https://github.com/raynigon/raylevation",
                "StackOverflow_Post": {
                    "Id": "73446979",
                    "PostTypeId": "2",
                    "ParentId": "73445349",
                    "CreationDate": "2022-08-22T14:44:04.277",
                    "Score": "1",
                    "Body": "<p>This library seems promising: <a href=\"https://github.com/komoot/batch-dem-reader\" rel=\"nofollow noreferrer\">https://github.com/komoot/batch-dem-reader</a></p>\n<p>This Kotlin app also seems relevant: <a href=\"https://github.com/raynigon/raylevation\" rel=\"nofollow noreferrer\">https://github.com/raynigon/raylevation</a></p>\n<p>If none of the options give you what you need, you'll probably have to implement parsing the file yourself. For that, you can get inspiration from libraries written in other languages (e.g. <a href=\"https://github.com/tkrajina/srtm.py\" rel=\"nofollow noreferrer\">https://github.com/tkrajina/srtm.py</a>)</p>\n",
                    "OwnerUserId": "3738870",
                    "LastActivityDate": "2022-08-22T14:44:04.277",
                    "CommentCount": "3",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "73527241",
                "ParentRepo": "https://github.com/dynaconf/dynaconf/blob/master/tests/test_validators.py",
                "StackOverflow_Post": {
                    "Id": "73527241",
                    "PostTypeId": "2",
                    "ParentId": "71376564",
                    "CreationDate": "2022-08-29T10:11:50.340",
                    "Score": "0",
                    "Body": "<p>As a rule of thumb, when it comes to open source tools, go through both the docs and the tests suit.</p>\n<p><a href=\"https://github.com/dynaconf/dynaconf/blob/master/tests/test_validators.py\" rel=\"nofollow noreferrer\">Ex from one of their many tests</a>:</p>\n<pre><code>YAML = &quot;&quot;&quot;\nserver:\n    hostname: &quot;localhost&quot;\n    port: 22\n    users:\n      - &quot;Bruno&quot;\n      - &quot;Lula&quot;\napp:\n    name: &quot;testname&quot;\n    path: &quot;/tmp/app_startup&quot;\n    args:\n        arg1: &quot;a&quot;\n        arg2: &quot;b&quot;\n        arg3: &quot;c&quot;\nhasemptyvalues:\n    key1:\n    key2:\n    key3: null\n    key4: &quot;@empty&quot;\n&quot;&quot;&quot;\n\n@pytest.fixture\ndef yaml_validators_good():\n    return [\n        Validator(\n            &quot;server.hostname&quot;, &quot;server.port&quot;, &quot;server.users&quot;, must_exist=True\n        ),\n        Validator(\n            &quot;app.name&quot;,\n            &quot;app.path&quot;,\n            &quot;app.args.arg1&quot;,\n            &quot;app.args.arg2&quot;,\n            &quot;app.args.arg3&quot;,\n            must_exist=True,\n        ),\n    ]\n\n\n@pytest.fixture\ndef yaml_validators_bad():\n    return [\n        Validator(&quot;missing.value&quot;, must_exist=True),\n        Validator(&quot;app.missing&quot;, must_exist=True),\n        Validator(&quot;app.args.missing&quot;, must_exist=True),\n    ]\n</code></pre>\n",
                    "OwnerUserId": "16788006",
                    "LastActivityDate": "2022-08-29T10:11:50.340",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "73558430",
                "ParentRepo": "https://github.com/sopherapps/pydantic-redis",
                "StackOverflow_Post": {
                    "Id": "73558430",
                    "PostTypeId": "1",
                    "CreationDate": "2022-08-31T15:36:51.583",
                    "Score": "1",
                    "ViewCount": "46",
                    "Body": "<p>I am learning pydantic-redis,and I tried to modify the example at\n<a href=\"https://github.com/sopherapps/pydantic-redis\" rel=\"nofollow noreferrer\">https://github.com/sopherapps/pydantic-redis</a></p>\n<p>by adding a new field <code>new_field: dict = {}</code> as follows</p>\n<pre><code>class Book(Model):\n    _primary_key_field: str = 'title'\n    title: str\n    author: str\n    published_on: date\n    in_stock: bool = True\n    new_field: dict = {}\n</code></pre>\n<p>when I run the example it says (in the end):\n<code>value is not a valid dict (type=type_error.dict)</code></p>\n<p>I have also tried other types, like <code>new_field: List[int] = [8]</code> (and then importing typing.List)\nOn the other hand, when I add a new field with a primitive type like int, everything works fine.</p>\n<p>What have I missed?</p>\n<p>Best regards</p>\n",
                    "OwnerUserId": "19888470",
                    "LastActivityDate": "2022-09-02T09:21:59.880",
                    "Title": "Failed to validate dict when adding it as a new field in pydantic-redis example",
                    "Tags": "<python-3.8><pydantic>",
                    "AnswerCount": "1",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "73582568",
                "ParentRepo": "https://github.com/daveblackuk/VSR",
                "StackOverflow_Post": {
                    "Id": "73582568",
                    "PostTypeId": "1",
                    "CreationDate": "2022-09-02T12:26:23.703",
                    "Score": "0",
                    "ViewCount": "9",
                    "Body": "<p>I have developed a MSFS toolbar app using tabulator.</p>\n<p><a href=\"https://github.com/daveblackuk/VSR\" rel=\"nofollow noreferrer\">https://github.com/daveblackuk/VSR</a></p>\n<p>Users have noted that the MSFS internal browser does not render certain icons in tabulator correctly (although Chrome does). These include cell overflow indicators and menu icons. Whilst I recognise this is an MS bug it is likely to be way down on their priorities.\n<a href=\"https://i.stack.imgur.com/OJ5Iw.png\" rel=\"nofollow noreferrer\">Missing overflow</a></p>\n<p>I am therefore considering modifying the CSS or JS that renders these elements, by either removing them or replacing them with something (possibly an FA-Icon or img) - can someone point me to the right elements, as the element inspector in chrome does not distinguish them from the cell?</p>\n<p>thanks</p>\n<p>/DB</p>\n",
                    "OwnerUserId": "19903953",
                    "LastActivityDate": "2022-09-02T12:26:23.703",
                    "Title": "Issues rendering elements in MS Fight Simulator",
                    "Tags": "<icons>",
                    "AnswerCount": "0",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "73615226",
                "ParentRepo": "https://github.com/spietras/rules_conda",
                "StackOverflow_Post": {
                    "Id": "73615226",
                    "PostTypeId": "2",
                    "ParentId": "48131363",
                    "CreationDate": "2022-09-05T22:40:39.763",
                    "Score": "0",
                    "Body": "<p>Here is an open-source set of rules for creating conda environments within a bazel build:\n<a href=\"https://github.com/spietras/rules_conda\" rel=\"nofollow noreferrer\">https://github.com/spietras/rules_conda</a></p>\n<p>The following example code is copied from the README of that github repository. It demonstrates how to create a conda environment from a <code>@//:environment.yml</code> file:</p>\n<blockquote>\n<pre class=\"lang-py prettyprint-override\"><code>load(&quot;@bazel_tools//tools/build_defs/repo:http.bzl&quot;, &quot;http_archive&quot;)\n\nhttp_archive(\n    name = &quot;rules_conda&quot;,\n    sha256 = &quot;...&quot;,  # copy from release\n    url = &quot;...&quot;,  # copy from release\n)\n\nload(&quot;@rules_conda//:defs.bzl&quot;, &quot;conda_create&quot;, &quot;load_conda&quot;, &quot;register_toolchain&quot;)\n\nload_conda(\n    conda_version = &quot;4.10.3&quot;,  # version of conda to download, default is 4.10.3\n    installer = &quot;miniforge&quot;,  # which conda installer to download, either miniconda or miniforge, default is miniconda\n    install_mamba = True,  # whether to install mamba, which is a faster drop-in replacement for conda, default is False\n    mamba_version = &quot;0.17.0&quot;,  # version of mamba to install, default is 0.17.0\n    quiet = False,  # True if conda output should be hidden, default is True\n    timeout = 600,  # how many seconds each execute action can take, default is 3600\n)\n\nconda_create(\n    name = &quot;env&quot;,  # name of the environment\n    environment = &quot;@//:environment.yml&quot;,  # label pointing to environment configuration file\n    use_mamba = True,  # Whether to use mamba to create the conda environment. If this is True, install_mamba must also be True\n    clean = False,  # True if conda cache should be cleaned (less space taken, but slower subsequent builds), default is False\n    quiet = False,  # True if conda output should be hidden   True, default is True\n    timeout = 600,  # how many seconds each execute action can take, default is 3600\n)\n\nregister_toolchain(env = &quot;env&quot;)\n</code></pre>\n</blockquote>\n",
                    "OwnerUserId": "4256346",
                    "LastEditorUserId": "4256346",
                    "LastEditDate": "2022-09-06T00:29:28.127",
                    "LastActivityDate": "2022-09-06T00:29:28.127",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "73688654",
                "ParentRepo": "https://github.com/PrefectHQ/prefect-dask/issues",
                "StackOverflow_Post": {
                    "Id": "73688654",
                    "PostTypeId": "2",
                    "ParentId": "73683413",
                    "CreationDate": "2022-09-12T11:36:39.610",
                    "Score": "0",
                    "Body": "<p>Could you share a full example of your flow to see how you apply that?  Also, what is your Prefect version? Printing the output of <code>prefect version</code> would be helpful.</p>\n<p>If you run on self-hosted Orion, the likely problem is networking -- this is something that would be easier to set up for a PoC with Cloud (there is a free tier so you can just sign up to troubleshoot: <a href=\"https://app.prefect.cloud/\" rel=\"nofollow noreferrer\">https://app.prefect.cloud/</a>).</p>\n<p>If nothing else works, it might help to create a GitHub issue on the Collection repo <a href=\"https://github.com/PrefectHQ/prefect-dask/issues\" rel=\"nofollow noreferrer\">https://github.com/PrefectHQ/prefect-dask/issues</a> describing all the steps you've taken so far and what doesn't work as expected</p>\n",
                    "OwnerUserId": "9509388",
                    "LastActivityDate": "2022-09-12T11:36:39.610",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "73774076",
                "ParentRepo": "https://github.com/testcontainers/testcontainers-dotnet",
                "StackOverflow_Post": {
                    "Id": "73774076",
                    "PostTypeId": "2",
                    "ParentId": "73773938",
                    "CreationDate": "2022-09-19T13:24:02.850",
                    "Score": "0",
                    "Body": "<p>The best way I know of to run against real databases in tests would be using docker. There is a library called <a href=\"https://github.com/testcontainers/testcontainers-dotnet\" rel=\"nofollow noreferrer\">testcontainers</a> that can greatly simplify the setup for .net testing. The real chore is getting realistic test data. For Some things you can use <a href=\"https://github.com/oriches/faker-cs\" rel=\"nofollow noreferrer\">faker</a> to generate realistic looking test data. But for others you\u00b4re gonna have to manually maintain a test data set when it\u00b4s too hard to generate.</p>\n<p>Testing against production databases is also an option for some things that don\u00b4t need to write a lot to the database, or is easy to undo / written in a way a user will never seen it. Though, your integration tests loose portability and everything that runs said tests now needs access to the production database.</p>\n",
                    "OwnerUserId": "9697266",
                    "LastEditorUserId": "9697266",
                    "LastEditDate": "2022-09-19T13:33:22.610",
                    "LastActivityDate": "2022-09-19T13:33:22.610",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "73778730",
                "ParentRepo": "https://github.com/code-specialist/fastapi-keycloak/pull/38/",
                "StackOverflow_Post": {
                    "Id": "73778730",
                    "PostTypeId": "2",
                    "ParentId": "71787580",
                    "CreationDate": "2022-09-19T20:06:18.153",
                    "Score": "1",
                    "Body": "<p>This issue was resolved by a PR a few days after your question:\n<a href=\"https://github.com/code-specialist/fastapi-keycloak/pull/38/\" rel=\"nofollow noreferrer\">https://github.com/code-specialist/fastapi-keycloak/pull/38/</a></p>\n<p>Nevertheless, you still encounter the same issue, because the <code>realm-export.json</code> file referenced in the docs website has not been updated. If you use the one from the <a href=\"https://github.com/code-specialist/fastapi-keycloak/blob/master/documentation/docs/downloads/realm-export.json\" rel=\"nofollow noreferrer\">repo</a> then everything should work as expected.</p>\n",
                    "OwnerUserId": "592289",
                    "LastActivityDate": "2022-09-19T20:06:18.153",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "73784643",
                "ParentRepo": "https://github.com/microsoft/AzureTre/",
                "StackOverflow_Post": {
                    "Id": "73784643",
                    "PostTypeId": "1",
                    "CreationDate": "2022-09-20T09:41:44.907",
                    "Score": "0",
                    "ViewCount": "20",
                    "Body": "<p>Working on Azure and want's to create Azure resource using Azure TRE(Trusted resource environment). We have downloaded the TRE code from GitHub (<a href=\"https://github.com/microsoft/AzureTre/\" rel=\"nofollow noreferrer\">https://github.com/microsoft/AzureTre/</a>), but not able to run the code.</p>\n<p>Any help would be appreciated. Thanks!</p>\n",
                    "OwnerUserId": "19975471",
                    "LastActivityDate": "2022-09-20T09:41:44.907",
                    "Title": "How to created resource using Azure TRE",
                    "Tags": "<azure>",
                    "AnswerCount": "0",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "73835639",
                "ParentRepo": "https://github.com/koxudaxi/pydantic-pycharm-plugin",
                "StackOverflow_Post": {
                    "Id": "73835639",
                    "PostTypeId": "2",
                    "ParentId": "73778158",
                    "CreationDate": "2022-09-24T08:01:43.307",
                    "Score": "3",
                    "Body": "<p>What you are describing is impossible in theory and unlikely to be viable in practice.</p>\n<h2>TL;DR</h2>\n<p>Type checkers don't run your code, they just read it. A dynamic type annotation is a contradiction in terms.</p>\n<h2>Theory</h2>\n<p>As I am sure you know, the term <strong>static</strong> type checker is not coincidental. A static type checker is not executing the code your write. It just parses it and infers types according to <strong>it's own</strong> internal logic by applying certain rules to a graph that it derives from your code.</p>\n<p>This is important because unlike some other languages, Python is <strong>dynamically</strong> typed, which as you know means that the type of a &quot;thing&quot; (variable) can completely change <strong>at any point</strong>. In general, there is <strong>theoretically</strong> no way of knowing the type of all variables in your code, without actually stepping through the entire algorithm, which is to say running the code.</p>\n<p>As a silly but illustrative example, you could decide to put the name of a type into a text file to be read at runtime and then used to annotate some variable in your code. Could you do that with valid Python code and typing? Sure. But I think it is beyond clear, that static type checkers will never know the type of that variable.</p>\n<h2>Why your proposition won't work</h2>\n<p>Abstracting away all the <code>dataclass</code> stuff and the possible logic <em>inside</em> your <code>__init__</code> method, what you are asking boils down to the following.</p>\n<p><em>&quot;I want to define a method (<code>__init__</code>), but the types of its parameters will only be known at runtime.&quot;</em></p>\n<p>Why am I claiming that? I mean, you <em>do</em> annotate the types of the class' attributes, right? So there you have the types!</p>\n<p>Sure, but these have -- in general -- nothing whatsoever to do with the arguments you could pass to the <code>__init__</code> method, as you yourself point out. You want the <code>__init__</code> method to accept arbitrary keyword-arguments. Yet you also want a static type checker to infer which types are allowed/expected there.</p>\n<p>To connect the two (attribute types and method parameter types), you could of course write some kind of logic. You could even implement it in a way that <em>enforces</em> adherence to those types. That logic could read the type annotations of the class attributes, match up the <code>**kwargs</code> and raise <code>TypeError</code> if one of them doesn't match up. This is entirely possible and you almost implemented that already in your example code. <strong>But this only works at runtime!</strong></p>\n<p>Again, a static type checker has <strong>no way</strong> to infer that, <em>especially</em> since your desired class is supposed to just be a base class and any descendant can introduce its own attributes/types at any point.</p>\n<h2>But <code>dataclasses</code> work, don't they?</h2>\n<p>You could argue that this dynamic way of annotating the <code>__init__</code> method works with dataclasses. So why are they so different? Why are they correctly inferred, but your proposed code can't?</p>\n<p>The answer is, they aren't.</p>\n<p>Even <code>dataclasses</code> don't have any magical way of telling a static type checker which parameter types the <code>__init__</code> method is to expect, even though they <em>do</em> annotate them, when they dynamically construct the method in <a href=\"https://github.com/python/cpython/blob/v3.10.7/Lib/dataclasses.py#L529\" rel=\"nofollow noreferrer\"><code>_init_fn</code></a>.</p>\n<p>The only reason <code>mypy</code> correctly infers those types, is because they implemented a separate plugin <em>just</em> for dataclasses. Meaning it works because they read through <a href=\"https://peps.python.org/pep-0557/\" rel=\"nofollow noreferrer\">PEP 557</a> and hand-crafted a plugin for <code>mypy</code> that specifically facilitates type inference based on the rules described there.</p>\n<p>You can see the magic happening in the <a href=\"https://github.com/python/mypy/blob/v0.971/mypy/plugins/dataclasses.py#L122\" rel=\"nofollow noreferrer\"><code>DataclassTransformer.transform</code></a> method. You cannot generalize this behavior to arbitrary code, which is why they had to write a whole plugin just for this.</p>\n<p>I am not familiar enough with how PyCharm does its type checking, but I strongly suspect they used something similar.</p>\n<p>So you could argue that <code>dataclasses</code> are &quot;cheating&quot; with regards to static type checking. Though I am certainly not complaining.</p>\n<h2>Pragmatic solution</h2>\n<p>Even something as &quot;high-profile&quot; as Pydantic, which I personally love and use extensively, requires its own <code>mypy</code> plugin to realize the <code>__init__</code> type inference properly (see <a href=\"https://pydantic-docs.helpmanual.io/mypy_plugin/\" rel=\"nofollow noreferrer\">here</a>). For PyCharm they have their own separate <a href=\"https://github.com/koxudaxi/pydantic-pycharm-plugin\" rel=\"nofollow noreferrer\">Pydantic plugin</a>, without which the internal type checker cannot provide those nice auto-suggestions for initialization etc.</p>\n<p>That approach would be your best bet, if you really want to take this further. Just be aware that this will be (in the best sense of the word) a <em>hack</em> to allow <em>specifc</em> type checkers to catch &quot;errors&quot; that they otherwise would have no way of catching.</p>\n<p>The reason I argue that it is unlikely to be viable is because it will essentially blow up the amount of work for your project to also cover the specific hacks for those type checkers that you want to satisfy. If you are committed enough and have the resources, go for it.</p>\n<h2>Conclusion</h2>\n<p>I am not trying to discourage you. But it is important to know the limitations enforced by the environment. It's either dynamic types and hacky imperfect type checking (still love <code>mypy</code>), or static types and no <em>&quot;<code>kwargs</code> can be anything&quot;</em> behavior.</p>\n<p>Hope this makes sense. Please let me know, if I made any errors. This is just based on my understanding of typing in Python.</p>\n",
                    "OwnerUserId": "19770795",
                    "LastActivityDate": "2022-09-24T08:01:43.307",
                    "CommentCount": "3",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "73870154",
                "ParentRepo": "https://github.com/Roblox/roact",
                "StackOverflow_Post": {
                    "Id": "73870154",
                    "PostTypeId": "2",
                    "ParentId": "73857012",
                    "CreationDate": "2022-09-27T15:30:31.413",
                    "Score": "1",
                    "Body": "<p>As a disclaimer, this answer is how to generally use libraries in Roblox Studio. I was unable to get this to work with Lua-cURL for a few different reasons. Lua-cURL requires a C compiler and a system installation of the cURL library. These things are inaccessible in Roblox Studio, so as a warning, this answer will not work if you are trying to use a library that is not pure lua.</p>\n<hr />\n<p>The best tool I have found for taking lua libraries and making it available in Roblox Studio is <a href=\"https://github.com/rojo-rbx/rojo\" rel=\"nofollow noreferrer\">Rojo, by LPGHatguy</a>. Among its features is the ability to take a library of lua code and convert it to a <code>.rbxm</code> (Roblox Model) file, which can be dragged and dropped into an open place in Roblox Studio.</p>\n<p>So here's the pipeline to get your code into Roblox Studio...</p>\n<h2>1. Install Rojo</h2>\n<p>Rojo is a tool written in rust, so the easiest way to get it is to also install <a href=\"https://www.rust-lang.org/\" rel=\"nofollow noreferrer\">rust</a>. It comes with a package manager, cargo, and we'll use that to download the commandline version of rojo.</p>\n<p>Then to download rojo, <a href=\"https://rojo.space/docs/v7/getting-started/installation/\" rel=\"nofollow noreferrer\">follow the installation guide</a> or simply use the command :</p>\n<pre class=\"lang-rust prettyprint-override\"><code>cargo install rojo\n</code></pre>\n<h2>2. Get the source code</h2>\n<p>This step involves getting all of the .lua files for the library. In order for the library to work in Roblox, it must use code that will run in a Roblox environment, so anything that tries to access the filesystem will likely not work. Anyways, you can clone the git repository to get a local copy of it, or use Luarocks.</p>\n<pre><code>gh repo clone &lt;REPOSITORY_NAME&gt;\n</code></pre>\n<p>I personally don't recommend Luarocks, it is really annoying to get working on a Windows system, and the latest version expects at least lua version 5.4, and Roblox runs on a forked version of lua 5.1.</p>\n<h2>3. Convert the code to an .rbxm</h2>\n<p>Now that you have the raw lua files, we can package them up into a format that can be easily imported into Roblox Studio.</p>\n<p>So open up a terminal and navigate into the source folder. Then use the <code>rojo build</code> command to package it all up</p>\n<pre><code>C:\\&gt; cd git\\REPOSITORY_NAME\\src\nC:\\git\\REPOSITORY_NAME\\src&gt; rojo build --output REPOSITORY_NAME.rbxm\n</code></pre>\n<p>In the resulting <code>.rbxm</code> file, Rojo will convert all <code>.lua</code> files into ModuleScripts, <code>.server.lua</code> files into Scripts, and <code>.client.lua</code> files into LocalScripts. It will also convert directories into Folders.</p>\n<p>Also, if a directory has an <code>init.lua</code> file, instead of creating a Folder, it will create a ModuleScript with the contents of that file as its source.</p>\n<h2>4. Use in Roblox Studio</h2>\n<p>Now that you have an <code>.rbxm</code>, you can simply drag and drop it into your place file in Roblox Studio. By default, it will land in the Workspace, but you can move it to ReplicatedStorage or ServerStorage or wherever you are organizing your code.</p>\n<p>Then you can use the <code>require</code> keyword to access the contents of the library.</p>\n<p>For example, if you were using Roblox's React-like framework, <a href=\"https://github.com/Roblox/roact\" rel=\"nofollow noreferrer\">Roact</a>, you could use it in your LocalScripts like this :</p>\n<pre class=\"lang-lua prettyprint-override\"><code>local ReplicatedStorage = game:GetService(&quot;ReplicatedStorage&quot;)\nlocal Roact = require(ReplicatedStorage.Roact)\n\n-- Create our virtual tree describing a full-screen text label.\nlocal tree = Roact.createElement(&quot;ScreenGui&quot;, {}, {\n    Label = Roact.createElement(&quot;TextLabel&quot;, {\n        Text = &quot;Hello, world!&quot;,\n        Size = UDim2.new(1, 0, 1, 0),\n    }),\n})\n\n-- Turn our virtual tree into real instances and put them in PlayerGui\nRoact.mount(tree, LocalPlayer.PlayerGui, &quot;HelloWorld&quot;)\n</code></pre>\n<p>If your code didn't have an <code>init.lua</code> file, it is likely that all of the files are in a Folder, so you'll need to reach into the contents of the library to access the individual ModuleScripts.</p>\n<p>Hope this helps.</p>\n",
                    "OwnerUserId": "2860267",
                    "LastActivityDate": "2022-09-27T15:30:31.413",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "73906761",
                "ParentRepo": "https://github.com/iHeadWater/station-simulator/tree/master/dijkstra_conda",
                "StackOverflow_Post": {
                    "Id": "73906761",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "73961594",
                    "CreationDate": "2022-09-30T09:38:20.137",
                    "Score": "-1",
                    "ViewCount": "98",
                    "Body": "<p>I'm using click 8.1.3 to parse my command,and my cli.py is like this:</p>\n<pre><code>@click.option('--output_dir', default=os.curdir, help='when outdated is true,choose directory which you want to put your cache file')\n@click.option('--cache_dir', default=os.curdir, help='when outdated if false,choose directory where put cache file')\ndef main(outdated, nodes_path, river_path, cur_sta, up_sta, cutoff, upstream, downstream, cache_dir, output_dir):\n\u2026\u2026\n</code></pre>\n<p>But when I try to read cache files from a directory such as <code>C:\\Users\\UserName\\Desktop\\test-cache</code>, it occured wrong:</p>\n<pre><code>PS C:\\Users\\UserName\\Desktop\\test_cache2&gt; calcstream --nodes_path XXX --river_path YYY --cur_sta 0 --up_sta 10 --cache_dir C:\\Users\\UserName\\Desktop\\test-cache --outdated False\nTraceback (most recent call last):\nFile &quot;C:\\Python310\\lib\\runpy.py&quot;, line 196, in _run_module_as_main\nreturn _run_code(code, main_globals, None,\nFile &quot;C:\\Python310\\lib\\runpy.py&quot;, line 86, in _run_code\nexec(code, run_globals)\nFile &quot;C:\\Python310\\Scripts\\calcstream.exe\\__main__.py&quot;, line 7, in &lt;module&gt;\nFile &quot;C:\\Python310\\lib\\site-packages\\click\\core.py&quot;, line 1130, in __call__\nreturn self.main(*args, **kwargs)\nFile &quot;C:\\Python310\\lib\\site-packages\\click\\core.py&quot;, line 1055, in main\nrv = self.invoke(ctx)\nFile &quot;C:\\Python310\\lib\\site-packages\\click\\core.py&quot;, line 1404, in invoke\nreturn ctx.invoke(self.callback, **ctx.params)\nFile &quot;C:\\Python310\\lib\\site-packages\\click\\core.py&quot;, line 760, in invoke\nreturn __callback(*args, **kwargs)\nFile &quot;C:\\Python310\\lib\\site-packages\\dijkstra_conda\\cli.py&quot;, line 35, in main\nupstream_node_on_mainstream(nodes_reader, network_reader, cur_sta, up_sta, outdated, cache_dir, output_dir)\nFile &quot;C:\\Python310\\lib\\site-packages\\dijkstra_conda\\dfs_path_test.py&quot;, line 463, in upstream_node_on_mainstream\norigin_graph = get_upstream_stations_graph(node_reader, network_reader, number_src, outdated)[2]\nFile &quot;C:\\Python310\\lib\\site-packages\\dijkstra_conda\\dfs_path_test.py&quot;, line 348, in get_upstream_stations_graph\nupstream_graph = get_upstream_stations(node_reader, network_reader, number, outdated, cutoff, cache_dir, output_path)[0]\nFile &quot;C:\\Python310\\lib\\site-packages\\dijkstra_conda\\dfs_path_test.py&quot;, line 243, in get_upstream_stations\nstations_graph = build_graph(node_reader, network_reader, outdated, cache_dir, output_path)\nFile &quot;C:\\Python310\\lib\\site-packages\\dijkstra_conda\\dfs_path_test.py&quot;, line 205, in build_graph\nnearest_point_line_dict = tie_outside_node(node_reader, network_reader, outdated, cache_dir, output_path)[1]\nFile &quot;C:\\Python310\\lib\\site-packages\\dijkstra_conda\\dfs_path_test.py&quot;, line 115, in tie_outside_node\nsource_point_frame = pd.read_csv(os.path.join(cache_dir, 'source_project_points.csv'))\nFile &quot;C:\\Python310\\lib\\site-packages\\pandas\\util\\_decorators.py&quot;, line 211, in wrapper\nreturn func(*args, **kwargs)\nFile &quot;C:\\Python310\\lib\\site-packages\\pandas\\util\\_decorators.py&quot;, line 317, in wrapper\nreturn func(*args, **kwargs)\nFile &quot;C:\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py&quot;, line 950, in read_csv\nreturn _read(filepath_or_buffer, kwds)\nFile &quot;C:\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py&quot;, line 605, in _read\nparser = TextFileReader(filepath_or_buffer, **kwds)\nFile &quot;C:\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py&quot;, line 1442, in __init__\nself._engine = self._make_engine(f, self.engine)\nFile &quot;C:\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py&quot;, line 1729, in _make_engine\nself.handles = get_handle(\nFile &quot;C:\\Python310\\lib\\site-packages\\pandas\\io\\common.py&quot;, line 857, in get_handle\nhandle = open(\nFileNotFoundError: [Errno 2] No such file or directory: '.\\\\source_project_points.csv'\n</code></pre>\n<p>It seems that the program still uses <code>os.curdir</code>(C:\\Users\\UserName\\Desktop\\test_cache2) to find <code>source_project_points.csv</code>, and I'm sure <code>source_project_points.csv</code> is in <code>C:\\Users\\UserName\\Desktop\\test-cache</code>, so how to solve the problem?</p>\n<p><a href=\"https://github.com/iHeadWater/station-simulator/tree/master/dijkstra_conda\" rel=\"nofollow noreferrer\">This</a> is my project link.</p>\n",
                    "OwnerUserId": "19356117",
                    "LastActivityDate": "2022-10-05T14:04:38.640",
                    "Title": "Error 'No such file or directory' when use click",
                    "Tags": "<python-3.x><path><command-line-interface><python-click>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "73983078",
                "ParentRepo": "https://github.com/eigenein/protobuf",
                "StackOverflow_Post": {
                    "Id": "73983078",
                    "PostTypeId": "2",
                    "ParentId": "73979425",
                    "CreationDate": "2022-10-07T06:13:48.170",
                    "Score": "1",
                    "Body": "<p>The alternative Python protobuf libraries of <a href=\"https://github.com/eigenein/protobuf\" rel=\"nofollow noreferrer\">pure-protobuf</a> and <a href=\"https://github.com/danielgtaylor/python-betterproto\" rel=\"nofollow noreferrer\">python-betterproto</a> both have their own syntax that can be used directly from Python, without a <code>.proto</code> file.</p>\n<p>It however doesn't work for completely plain Python objects, as you still need to specify the field types and tag numbers (example from pure-protobuf):</p>\n<pre><code>@message\n@dataclass\nclass SearchRequest:\n    query: str = field(1, default='')\n    page_number: int32 = field(2, default=int32(0))\n    result_per_page: int32 = field(3, default=int32(0))\n</code></pre>\n",
                    "OwnerUserId": "914716",
                    "LastActivityDate": "2022-10-07T06:13:48.170",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "74008690",
                "ParentRepo": "https://github.com/samuelcolvin/watchfiles",
                "StackOverflow_Post": {
                    "Id": "74008690",
                    "PostTypeId": "2",
                    "ParentId": "182197",
                    "CreationDate": "2022-10-09T22:08:10.187",
                    "Score": "0",
                    "Body": "<p>watchfiles (<a href=\"https://github.com/samuelcolvin/watchfiles\" rel=\"nofollow noreferrer\">https://github.com/samuelcolvin/watchfiles</a>) is a Python API and CLI that uses the Notify (<a href=\"https://github.com/notify-rs/notify\" rel=\"nofollow noreferrer\">https://github.com/notify-rs/notify</a>) library written in Rust.</p>\n<p>The rust implementation currently (2022-10-09) supports:</p>\n<ul>\n<li>Linux / Android: inotify</li>\n<li>macOS: FSEvents or kqueue, see features</li>\n<li>Windows: ReadDirectoryChangesW</li>\n<li>FreeBSD / NetBSD / OpenBSD / DragonflyBSD: kqueue</li>\n<li>All platforms: polling</li>\n</ul>\n<p>Binaries available on PyPI (<a href=\"https://pypi.org/project/watchfiles/\" rel=\"nofollow noreferrer\">https://pypi.org/project/watchfiles/</a>) and conda-forge (<a href=\"https://github.com/conda-forge/watchfiles-feedstock\" rel=\"nofollow noreferrer\">https://github.com/conda-forge/watchfiles-feedstock</a>).</p>\n",
                    "OwnerUserId": "642372",
                    "LastActivityDate": "2022-10-09T22:08:10.187",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "74014268",
                "ParentRepo": "https://github.com/PrefectHQ/prefect-dbt",
                "StackOverflow_Post": {
                    "Id": "74014268",
                    "PostTypeId": "2",
                    "ParentId": "74011028",
                    "CreationDate": "2022-10-10T11:32:15.560",
                    "Score": "1",
                    "Body": "<p>Have you tried Prefect 2 already? Regarding the load process, you may consider loading data to a temp table and merging from there -- by doing that in SQL, it might be faster and easier to troubleshoot. dbt is also a tool you can consider, and you can orchestrate dbt with prefect using the prefect-dbt package: <a href=\"https://github.com/PrefectHQ/prefect-dbt\" rel=\"nofollow noreferrer\">https://github.com/PrefectHQ/prefect-dbt</a></p>\n",
                    "OwnerUserId": "9509388",
                    "LastActivityDate": "2022-10-10T11:32:15.560",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "74064316",
                "ParentRepo": "https://github.com/sabuhish/fastapi-mail",
                "StackOverflow_Post": {
                    "Id": "74064316",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "74067930",
                    "CreationDate": "2022-10-14T04:28:08.380",
                    "Score": "0",
                    "ViewCount": "227",
                    "Body": "<p>I'm using <a href=\"https://github.com/sabuhish/fastapi-mail\" rel=\"nofollow noreferrer\"><code>fastapi-mail</code></a> package, and trying to send multiple files to multiple email addresses. When I send the email to only one email address, the application works as expected. However, when I change to <code>List[EmailStr]</code> for sending to multiple email addresses, I get this error:</p>\n<pre><code>not a valid email address\n</code></pre>\n<p>Here is my code:</p>\n<pre><code>@app.post(&quot;/file&quot;)async def send_file(\nbackground_tasks: BackgroundTasks,\nemail:List[EmailStr] = Form(...), #I Change here before EmailStr = Form(...)\nfile:Optional[List[UploadFile]] = File(...),) -&gt; JSONResponse:\nprint(email)\nprint(file)\nmessage = MessageSchema(\n    subject=&quot;Fastapi mail module&quot;,\n    recipients=email,\n    body=&quot;Simple background task&quot;,\n    subtype=&quot;html&quot;,\n    attachments=file)\n\nfm = FastMail(ConnectionConfig(\n    MAIL_USERNAME=res(&quot;MAIL_USERNAME&quot;),\n    MAIL_PASSWORD=res(&quot;MAIL_PASSWORD&quot;),\n    MAIL_FROM=&quot;admin@acsebs.com&quot;,\n    MAIL_PORT=res(&quot;MAIL_PORT&quot;),\n    MAIL_SERVER=res(&quot;MAIL_SERVER&quot;),\n    MAIL_FROM_NAME=&quot;send attachment email service&quot;,\n    MAIL_TLS=res(&quot;MAIL_TLS&quot;),\n    MAIL_SSL=res(&quot;MAIL_SSL&quot;),\n    USE_CREDENTIALS=res(&quot;USE_CREDENTIALS&quot;),\n    VALIDATE_CERTS=res(&quot;VALIDATE_CERTS&quot;)\n))\n\nbackground_tasks.add_task(fm.send_message, message)\n\nreturn JSONResponse(status_code=200, content={&quot;message&quot;: &quot;email has been sent&quot;})\n</code></pre>\n<h2>Posting data through Swagger UI:</h2>\n<p><a href=\"https://i.stack.imgur.com/Z8YFb.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/Z8YFb.png\" alt=\"enter image description here\" /></a></p>\n<h2>The error:</h2>\n<p><a href=\"https://i.stack.imgur.com/zbTO3.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/zbTO3.png\" alt=\"enter image description here\" /></a></p>\n",
                    "OwnerUserId": "20237088",
                    "LastEditorUserId": "17865804",
                    "LastEditDate": "2022-10-14T11:51:46.720",
                    "LastActivityDate": "2022-10-16T08:45:09.227",
                    "Title": "\"Value is not a valid email address\" when sending multiple email addresses using Pydantic, FastAPI and Swagger UI",
                    "Tags": "<python><swagger><swagger-ui><fastapi><pydantic>",
                    "AnswerCount": "2",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "74175401",
                "ParentRepo": "https://github.com/wandb/wandb/issues/4409",
                "StackOverflow_Post": {
                    "Id": "74175401",
                    "PostTypeId": "1",
                    "CreationDate": "2022-10-23T23:04:20.533",
                    "Score": "1",
                    "ViewCount": "219",
                    "Body": "<p>I am having a weird issue where I change the location of all my code &amp; data to a different location with more disk space, then I soft link my projects &amp; data to those locations with more space. I assume there must be some file handle issue because wandb's logger is throwing me issues. So my questions:</p>\n<ol>\n<li>how do I have wandb only log  online and not locally? (e.g. stop trying to log anything to <code>./wandb</code>[or any secret place it might be logging to]  since it's creating issues). Note my code was running fine after I  stopped logging to wandb so I assume that was the issue. note that the <code>dir=None</code> is the default to wandb's param.</li>\n<li>how do I resolve this issue entirely so that it works seemlessly with all my projects softlinked somewhere else?</li>\n</ol>\n<hr />\n<h1>More details on the error</h1>\n<pre><code>Traceback (most recent call last):\n  File &quot;/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/logging/__init__.py&quot;, line 1087, in emit\n    self.flush()\n  File &quot;/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/logging/__init__.py&quot;, line 1067, in flush\n    self.stream.flush()\nOSError: [Errno 116] Stale file handle\nCall stack:\n  File &quot;/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/threading.py&quot;, line 930, in _bootstrap\n    self._bootstrap_inner()\n  File &quot;/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/threading.py&quot;, line 973, in _bootstrap_inner\n    self.run()\n  File &quot;/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/site-packages/wandb/vendor/watchdog/observers/api.py&quot;, line 199, in run\n    self.dispatch_events(self.event_queue, self.timeout)\n  File &quot;/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/site-packages/wandb/vendor/watchdog/observers/api.py&quot;, line 368, in dispatch_events\n    handler.dispatch(event)\n  File &quot;/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/site-packages/wandb/vendor/watchdog/events.py&quot;, line 454, in dispatch\n    _method_map[event_type](event)\n  File &quot;/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/site-packages/wandb/filesync/dir_watcher.py&quot;, line 275, in _on_file_created\n    logger.info(&quot;file/dir created: %s&quot;, event.src_path)\nMessage: 'file/dir created: %s'\nArguments: ('/shared/rsaas/miranda9/diversity-for-predictive-success-of-meta-learning/wandb/run-20221023_170722-1tfzh49r/files/output.log',)\n--- Logging error ---\nTraceback (most recent call last):\n  File &quot;/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/logging/__init__.py&quot;, line 1087, in emit\n    self.flush()\n  File &quot;/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/logging/__init__.py&quot;, line 1067, in flush\n    self.stream.flush()\nOSError: [Errno 116] Stale file handle\nCall stack:\n  File &quot;/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/threading.py&quot;, line 930, in _bootstrap\n    self._bootstrap_inner()\n  File &quot;/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/threading.py&quot;, line 973, in _bootstrap_inner\n    self.run()\n  File &quot;/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/site-packages/wandb/sdk/internal/internal_util.py&quot;, line 50, in run\n    self._run()\n  File &quot;/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/site-packages/wandb/sdk/internal/internal_util.py&quot;, line 101, in _run\n    self._process(record)\n  File &quot;/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/site-packages/wandb/sdk/internal/internal.py&quot;, line 263, in _process\n    self._hm.handle(record)\n  File &quot;/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/site-packages/wandb/sdk/internal/handler.py&quot;, line 130, in handle\n    handler(record)\n  File &quot;/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/site-packages/wandb/sdk/internal/handler.py&quot;, line 138, in handle_request\n    logger.debug(f&quot;handle_request: {request_type}&quot;)\nMessage: 'handle_request: stop_status'\nArguments: ()\nN/A% (0 of 100000) |      | Elapsed Time: 0:00:00 | ETA:  --:--:-- |   0.0 s/it\n\nTraceback (most recent call last):\n  File &quot;/home/miranda9/diversity-for-predictive-success-of-meta-learning/div_src/diversity_src/experiment_mains/main_dist_maml_l2l.py&quot;, line 1814, in &lt;module&gt;\n    main()\n  File &quot;/home/miranda9/diversity-for-predictive-success-of-meta-learning/div_src/diversity_src/experiment_mains/main_dist_maml_l2l.py&quot;, line 1747, in main\n    train(args=args)\n  File &quot;/home/miranda9/diversity-for-predictive-success-of-meta-learning/div_src/diversity_src/experiment_mains/main_dist_maml_l2l.py&quot;, line 1794, in train\n    meta_train_iterations_ala_l2l(args, args.agent, args.opt, args.scheduler)\n  File &quot;/home/miranda9/ultimate-utils/ultimate-utils-proj-src/uutils/torch_uu/training/meta_training.py&quot;, line 167, in meta_train_iterations_ala_l2l\n    log_zeroth_step(args, meta_learner)\n  File &quot;/home/miranda9/ultimate-utils/ultimate-utils-proj-src/uutils/logging_uu/wandb_logging/meta_learning.py&quot;, line 92, in log_zeroth_step\n    log_train_val_stats(args, args.it, step_name, train_loss, train_acc, training=True)\n  File &quot;/home/miranda9/ultimate-utils/ultimate-utils-proj-src/uutils/logging_uu/wandb_logging/supervised_learning.py&quot;, line 55, in log_train_val_stats\n    _log_train_val_stats(args=args,\n  File &quot;/home/miranda9/ultimate-utils/ultimate-utils-proj-src/uutils/logging_uu/wandb_logging/supervised_learning.py&quot;, line 116, in _log_train_val_stats\n    args.logger.log('\\n')\n  File &quot;/home/miranda9/ultimate-utils/ultimate-utils-proj-src/uutils/logger.py&quot;, line 89, in log\n    print(msg, flush=flush)\n  File &quot;/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/site-packages/wandb/sdk/lib/redirect.py&quot;, line 640, in write\n    self._old_write(data)\nOSError: [Errno 116] Stale file handle\nwandb: Waiting for W&amp;B process to finish... (failed 1). Press Control-C to abort syncing.\nwandb: Synced vit_mi Adam_rfs_cifarfs Adam_cosine_scheduler_rfs_cifarfs 0.001: args.jobid=101161: https://wandb.ai/brando/entire-diversity-spectrum/runs/1tfzh49r\nwandb: Synced 6 W&amp;B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\nwandb: Find logs at: ./wandb/run-20221023_170722-1tfzh49r/logs\n--- Logging error ---\nTraceback (most recent call last):\n  File &quot;/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/site-packages/wandb/sdk/interface/router_sock.py&quot;, line 27, in _read_message\n    resp = self._sock_client.read_server_response(timeout=1)\n  File &quot;/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/site-packages/wandb/sdk/lib/sock_client.py&quot;, line 283, in read_server_response\n    data = self._read_packet_bytes(timeout=timeout)\n  File &quot;/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/site-packages/wandb/sdk/lib/sock_client.py&quot;, line 269, in _read_packet_bytes\n    raise SockClientClosedError()\nwandb.sdk.lib.sock_client.SockClientClosedError\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File &quot;/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/site-packages/wandb/sdk/interface/router.py&quot;, line 70, in message_loop\n    msg = self._read_message()\n  File &quot;/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/site-packages/wandb/sdk/interface/router_sock.py&quot;, line 29, in _read_message\n    raise MessageRouterClosedError\nwandb.sdk.interface.router.MessageRouterClosedError\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File &quot;/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/logging/__init__.py&quot;, line 1087, in emit\n    self.flush()\n  File &quot;/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/logging/__init__.py&quot;, line 1067, in flush\n    self.stream.flush()\nOSError: [Errno 116] Stale file handle\nCall stack:\n  File &quot;/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/threading.py&quot;, line 930, in _bootstrap\n    self._bootstrap_inner()\n  File &quot;/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/threading.py&quot;, line 973, in _bootstrap_inner\n    self.run()\n  File &quot;/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/threading.py&quot;, line 910, in run\n    self._target(*self._args, **self._kwargs)\n  File &quot;/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/site-packages/wandb/sdk/interface/router.py&quot;, line 77, in message_loop\n    logger.warning(&quot;message_loop has been closed&quot;)\nMessage: 'message_loop has been closed'\nArguments: ()\n/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/tempfile.py:817: ResourceWarning: Implicitly cleaning up &lt;TemporaryDirectory '/srv/condor/execute/dir_27749/tmpmvf78q6owandb'&gt;\n  _warnings.warn(warn_message, ResourceWarning)\n/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/tempfile.py:817: ResourceWarning: Implicitly cleaning up &lt;TemporaryDirectory '/srv/condor/execute/dir_27749/tmpt5etqpw_wandb-artifacts'&gt;\n  _warnings.warn(warn_message, ResourceWarning)\n/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/tempfile.py:817: ResourceWarning: Implicitly cleaning up &lt;TemporaryDirectory '/srv/condor/execute/dir_27749/tmp55lzwviywandb-media'&gt;\n  _warnings.warn(warn_message, ResourceWarning)\n/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/tempfile.py:817: ResourceWarning: Implicitly cleaning up &lt;TemporaryDirectory '/srv/condor/execute/dir_27749/tmprmk7lnx4wandb-media'&gt;\n  _warnings.warn(warn_message, ResourceWarning)\n</code></pre>\n<hr />\n<p>Error:</p>\n<pre><code>====&gt; about to start train loop\nStarting training!\nWARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1129)'))': /api/5288891/envelope/\n--- Logging error ---\nTraceback (most recent call last):\n  File &quot;/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/logging/__init__.py&quot;, line 1086, in emit\n    stream.write(msg + self.terminator)\n  File &quot;/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/site-packages/wandb/sdk/lib/redirect.py&quot;, line 640, in write\n    self._old_write(data)\nOSError: [Errno 116] Stale file handle\nCall stack:\n  File &quot;/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/threading.py&quot;, line 930, in _bootstrap\n    self._bootstrap_inner()\n  File &quot;/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/threading.py&quot;, line 973, in _bootstrap_inner\n    self.run()\n  File &quot;/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/threading.py&quot;, line 910, in run\n    self._target(*self._args, **self._kwargs)\n  File &quot;/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/site-packages/sentry_sdk/worker.py&quot;, line 128, in _target\n    callback()\n  File &quot;/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/site-packages/sentry_sdk/transport.py&quot;, line 467, in send_envelope_wrapper\n    self._send_envelope(envelope)\n  File &quot;/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/site-packages/sentry_sdk/transport.py&quot;, line 384, in _send_envelope\n    self._send_request(\n  File &quot;/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/site-packages/sentry_sdk/transport.py&quot;, line 230, in _send_request\n    response = self._pool.request(\n  File &quot;/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/site-packages/urllib3/request.py&quot;, line 78, in request\n    return self.request_encode_body(\n  File &quot;/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/site-packages/urllib3/request.py&quot;, line 170, in request_encode_body\n    return self.urlopen(method, url, **extra_kw)\n  File &quot;/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/site-packages/urllib3/poolmanager.py&quot;, line 375, in urlopen\n    response = conn.urlopen(method, u.request_uri, **kw)\n  File &quot;/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/site-packages/urllib3/connectionpool.py&quot;, line 780, in urlopen\n    log.warning(\nMessage: &quot;Retrying (%r) after connection broken by '%r': %s&quot;\nArguments: (Retry(total=2, connect=None, read=None, redirect=None, status=None), SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1129)')), '/api/5288891/envelope/')\n</code></pre>\n<hr />\n<h1>Bounty</h1>\n<p>My suggestions on what might solve this are:</p>\n<ol>\n<li>Figuring out a way to stop wandb logging locally or minimize the amount of logging wandb is logging locally.</li>\n<li>Figure out what is exactly being logged and minimize the space.</li>\n<li>have the logging work even if all the folders are being symlinked. (imho this should work out of the box)</li>\n<li>figuring out a systematic and simple way to find where the stale file handles are coming from.</li>\n</ol>\n<p>I am surprised moving <strong>everything</strong> to <code>/shared/rsaas/miranda9/</code> and running experiments from there did not solve the issue.</p>\n<hr />\n<p>cross:</p>\n<ul>\n<li><a href=\"https://community.wandb.ai/t/how-to-stop-logging-locally-but-only-save-to-wandbs-servers-and-have-wandb-work-using-soft-links/3305\" rel=\"nofollow noreferrer\">https://community.wandb.ai/t/how-to-stop-logging-locally-but-only-save-to-wandbs-servers-and-have-wandb-work-using-soft-links/3305</a></li>\n<li><a href=\"https://www.reddit.com/r/learnmachinelearning/comments/ybvo73/how_to_stop_logging_locally_but_only_save_to/\" rel=\"nofollow noreferrer\">https://www.reddit.com/r/learnmachinelearning/comments/ybvo73/how_to_stop_logging_locally_but_only_save_to/</a></li>\n<li>gitissue: <a href=\"https://github.com/wandb/wandb/issues/4409\" rel=\"nofollow noreferrer\">https://github.com/wandb/wandb/issues/4409</a></li>\n</ul>\n",
                    "OwnerUserId": "1601580",
                    "LastEditorUserId": "1601580",
                    "LastEditDate": "2022-10-26T17:39:34.157",
                    "LastActivityDate": "2022-11-02T03:33:58.257",
                    "Title": "How to stop logging locally but only save to wandb's servers and have wandb work using soft links?",
                    "Tags": "<python><machine-learning><deep-learning><pytorch><wandb>",
                    "AnswerCount": "2",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "74242722",
                "ParentRepo": "https://github.com/invoke-ai/InvokeAI",
                "StackOverflow_Post": {
                    "Id": "74242722",
                    "PostTypeId": "1",
                    "CreationDate": "2022-10-29T03:58:48.717",
                    "Score": "0",
                    "ViewCount": "36",
                    "Body": "<p>I created a Daemon to wrap around Invoke-AI command line interface <a href=\"https://github.com/invoke-ai/InvokeAI\" rel=\"nofollow noreferrer\">https://github.com/invoke-ai/InvokeAI</a> to generate images for my website.</p>\n<p>My issue is that it keeps failing on some artists names with &quot;\u014d&quot; in their name and I have no idea why. I had the same issue with another interface. Both were ran in an Anaconda Python environment. Both worked fine when I opened the command line directly and entered the name, so I think the issue is in my code.</p>\n<p>For my below tests I used &quot;Art by Bai\u014dken Eishun&quot; and &quot;Art by Gyosh\u016b Hayami&quot;.</p>\n<p>I removed all the irrelevant code for troubleshooting. Running PHP 7.4 on Windows 11.</p>\n<pre class=\"lang-php prettyprint-override\"><code>&lt;?php\n// tell php to automatically flush after every output\n// including lines of output produced by shell commands\ndisable_ob();\nset_time_limit(0);\nchdir('E:\\InvokeAI');\n\n$startEnvCommand = '&quot;C:\\Windows\\System32\\cmd.exe &quot;/K&quot; C:\\Users\\Blake\\anaconda3\\Scripts\\activate.bat invokeai&quot;'.PHP_EOL;\n$invokeCommand = 'python E:\\InvokeAI\\scripts\\invoke.py';\n$logFile = 'error.txt';\n\n// open command line invokeAI environment\n\necho $startEnvCommand.'&lt;br /&gt;';\n\n$process = proc_open($startEnvCommand, array(\n   0 =&gt; array(&quot;pipe&quot;, &quot;r&quot;),\n   1 =&gt; array(&quot;pipe&quot;, &quot;w&quot;),\n   2 =&gt; array(&quot;file&quot;, $logFile, &quot;a&quot;)\n), $pipes, 'E:\\InvokeAI');\n\n$stdin = $pipes[0];\n$stdout = $pipes[1];\n\nstream_set_blocking($stdout, false);\nstream_set_blocking($stdin, true);\n\nwhile ($data = fread($stdout, 8192)) {\n    echo '&quot;'.$data.'&quot;.&lt;br /&gt;';\n    if (substr($data, -12) == &quot;E:\\InvokeAI&gt;&quot;) {\n         echo &quot;Env started...&lt;br /&gt;&quot;;\n        break;\n    }\n}\nusleep(250000);\n\n// start invoke prompt!\nfwrite($stdin, $invokeCommand.PHP_EOL);\nwhile ($data = fread($stdout, 8192)) {\n   echo '&quot;'.$data.'&quot;.&lt;br /&gt;';\n    if (substr($data, -8) == 'invoke&gt; ') {\n      echo 'Prompt started, start generating images...&lt;br /&gt;';\n      break;\n    }\n    \n    if (substr($data, -12) == 'E:\\InvokeAI&gt;') {\n      echo file_get_contents($logFile);\n         exit('Error!');\n        break;\n    }\n}\n\nsleep(1);\n\n// run command to test here\n$command = '&quot;Art by Bai\u014dken Eishun&quot; -s 50 -W 512 -H 512 -C 7 -n 5 -A k_euler_a';\n$command = '&quot;Art by Gyosh\u016b Hayami&quot; -s 50 -W 512 -H 512 -C 7 -n 5 -A k_euler_a';\n\n         echo &quot;Running command: \\&quot;{$command}\\&quot;&lt;br /&gt;&quot;;\n\n         // start invoke prompt!\n         fwrite($stdin, $command.PHP_EOL);\n         while ($data = fread($stdout, 8192)) {\n            echo '&quot;'.$data.'&quot;.&lt;br /&gt;';\n             if (substr($data, -8) == 'invoke&gt; ') {\n               echo 'Images complete...&lt;br /&gt;';\n           exit('done!');\n               break;\n             }\n         }\n\n\n\n\nfunction disable_ob() {\n   // Turn off output buffering\n   ini_set('output_buffering', 'off');\n   // Turn off PHP output compression\n   ini_set('zlib.output_compression', false);\n   // Implicitly flush the buffer(s)\n   ini_set('implicit_flush', true);\n   ob_implicit_flush(true);\n   // Clear, and turn off output buffering\n   while (ob_get_level() &gt; 0) {\n       // Get the curent level\n       $level = ob_get_level();\n       // End the buffering\n       ob_end_clean();\n       // If the current level has not changed, abort\n       if (ob_get_level() == $level) break;\n   }\n   // Disable apache output buffering/compression\n   if (function_exists('apache_setenv')) {\n       apache_setenv('no-gzip', '1');\n       apache_setenv('dont-vary', '1');\n   }\n}\n\n\n\n</code></pre>\n<p>Output:</p>\n<p><strong>&quot;Art by Bai\u014dken Eishun&quot;</strong></p>\n<pre><code>&quot;C:\\Windows\\System32\\cmd.exe &quot;/K&quot; C:\\Users\\Blake\\anaconda3\\Scripts\\activate.bat invokeai&quot;\n&quot; (invokeai) E:\\InvokeAI&gt;&quot;.\nEnv started...\n&quot;python E:\\InvokeAI\\scripts\\invoke.py &quot;.\n&quot;* Initializing, be patient... &gt;&gt; GFPGAN Initialized &gt;&gt; CodeFormer Initialized &gt;&gt; ESRGAN Initialized &gt;&gt; Using device_type cuda &gt;&gt; Loading stable-diffusion-1.4 from models/ldm/stable-diffusion-v1/model.ckpt | LatentDiffusion: Running in eps-prediction mode | DiffusionWrapper has 859.52 M params. | Making attention of type 'vanilla' with 512 in_channels | Working with z of shape (1, 4, 32, 32) = 4096 dimensions. | Making attention of type 'vanilla' with 512 in_channels | Using faster float16 precision &gt;&gt; Model loaded in 14.59s &gt;&gt; Max VRAM used to load the model: 2.17G &gt;&gt; Current VRAM usage:2.17G &gt;&gt; Setting Sampler to k_lms * Initialization done! Awaiting your command (-h for help, 'q' to quit) invoke&gt; &quot;.\nPrompt started, start generating images...\nRunning command: &quot;&quot;Art by Bai\u014dken Eishun&quot; -s 50 -W 512 -H 512 -C 7 -n 5 -A k_euler_a&quot;\n&quot;&gt;&gt; Setting Sampler to k_euler_a &quot;.\n&quot;&gt;&gt; Sampling with k_euler_ancestral starting at step 0 of 50 (50 new sampling steps) &quot;.\n&quot; (invokeai) E:\\InvokeAI&gt;&quot;.\n</code></pre>\n<p><strong>&quot;Art by Gyosh\u016b Hayami&quot;</strong></p>\n<pre><code>&quot;C:\\Windows\\System32\\cmd.exe &quot;/K&quot; C:\\Users\\Blake\\anaconda3\\Scripts\\activate.bat invokeai&quot;\n&quot; (invokeai) E:\\InvokeAI&gt;&quot;.\nEnv started...\n&quot;python E:\\InvokeAI\\scripts\\invoke.py &quot;.\n&quot;* Initializing, be patient... &gt;&gt; GFPGAN Initialized &gt;&gt; CodeFormer Initialized &gt;&gt; ESRGAN Initialized &gt;&gt; Using device_type cuda &gt;&gt; Loading stable-diffusion-1.4 from models/ldm/stable-diffusion-v1/model.ckpt | LatentDiffusion: Running in eps-prediction mode | DiffusionWrapper has 859.52 M params. | Making attention of type 'vanilla' with 512 in_channels | Working with z of shape (1, 4, 32, 32) = 4096 dimensions. | Making attention of type 'vanilla' with 512 in_channels | Using faster float16 precision &gt;&gt; Model loaded in 14.83s &gt;&gt; Max VRAM used to load the model: 2.17G &gt;&gt; Current VRAM usage:2.17G &gt;&gt; Setting Sampler to k_lms * Initialization done! Awaiting your command (-h for help, 'q' to quit) invoke&gt; &quot;.\nPrompt started, start generating images...\nRunning command: &quot;&quot;Art by Gyosh\u016b Hayami&quot; -s 50 -W 512 -H 512 -C 7 -n 5 -A k_euler_a&quot;\n&quot;&gt;&gt; Setting Sampler to k_euler_a &quot;.\n&quot;&gt;&gt; Sampling with k_euler_ancestral starting at step 0 of 50 (50 new sampling steps) &gt;&gt; Sampling with k_euler_ancestral starting at step 0 of 50 (50 new sampling steps) &gt;&gt; Sampling with k_euler_ancestral starting at step 0 of 50 (50 new sampling steps) &gt;&gt; Sampling with k_euler_ancestral starting at step 0 of 50 (50 new sampling steps) &gt;&gt; Sampling with k_euler_ancestral starting at step 0 of 50 (50 new sampling steps) &gt;&gt; Usage stats: &gt;&gt; 5 image(s) generated in 31.76s &gt;&gt; Max VRAM used for this generation: 3.35G. Current VRAM utilization: 2.21G &gt;&gt; Max VRAM used since script start: 3.35G Outputs: [1.1] outputs/img-samples\\000001.259883587.png: &quot;Art by Gyosh\u016b Hayami&quot; -s 50 -S 259883587 -W 512 -H 512 -C 7.0 -A k_euler_a [1.2] outputs/img-samples\\000001.3608423195.png: &quot;Art by Gyosh\u016b Hayami&quot; -s 50 -S 3608423195 -W 512 -H 512 -C 7.0 -A k_euler_a [1.3] outputs/img-samples\\000001.1094619114.png: &quot;Art by Gyosh\u016b Hayami&quot; -s 50 -S 1094619114 -W 512 -H 512 -C 7.0 -A k_euler_a [1.4] outputs/img-samples\\000001.1779765255.png: &quot;Art by Gyosh\u016b Hayami&quot; -s 50 -S 1779765255 -W 512 -H 512 -C 7.0 -A k_euler_a [1.5] outputs/img-samples\\000001.37246202.png: &quot;Art by Gyosh\u016b Hayami&quot; -s 50 -S 37246202 -W 512 -H 512 -C 7.0 -A k_euler_a invoke&gt; &quot;.\nImages complete...\ndone!\n</code></pre>\n<p>It must be an encoding issue but I haven't been able to find out what encoding it wants. Currently it's in UTF-8. I tried changing the encoding in the proc_open $env_vars but it gave encoding errors when I tried to make it UTF-8. I tried using mb_convert_encoding($command, &quot;pass&quot;, &quot;auto&quot;) as well, but this returns an empty string.</p>\n",
                    "OwnerUserId": "156839",
                    "LastActivityDate": "2022-10-29T05:47:10.070",
                    "Title": "PHP fwrite to proc_open to Python failing with \u014d character but not others in text2image Daemon",
                    "Tags": "<python><php><cmd><proc-open>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "74250904",
                "ParentRepo": "https://github.com/RedisAI/RedisAI",
                "StackOverflow_Post": {
                    "Id": "74250904",
                    "PostTypeId": "2",
                    "ParentId": "10137857",
                    "CreationDate": "2022-10-30T06:09:22.697",
                    "Score": "1",
                    "Body": "<p>As an addition, Redis has capabilities beside caching purpose. Based on latest Redis Documentation (<a href=\"https://redis.io/docs/modules/\" rel=\"nofollow noreferrer\">https://redis.io/docs/modules/</a>), Redis has some external modules that support different kind of tasks such as:</p>\n<ul>\n<li><a href=\"https://github.com/RediSearch/RediSearch\" rel=\"nofollow noreferrer\">Redis Search</a>, full-text search capability</li>\n<li><a href=\"https://github.com/RedisGraph/RedisGraph\" rel=\"nofollow noreferrer\">Redis Graph</a>, graph database on top of Redis</li>\n<li><a href=\"https://github.com/RedisTimeSeries/RedisTimeSeries\" rel=\"nofollow noreferrer\">Redis Time Series</a>, module that adds a time series data structure to Redis.</li>\n<li><a href=\"https://github.com/RedisAI/RedisAI\" rel=\"nofollow noreferrer\">Redis AI</a>,</li>\n<li><a href=\"https://github.com/antirez/neural-redis\" rel=\"nofollow noreferrer\">Neural Network for Redis</a>, neural networks module for Redis</li>\n<li>etc.</li>\n</ul>\n<p>Personally, I used Redis for message queue by utilize Celery for Django REST Framework application beside caching at production.</p>\n",
                    "OwnerUserId": "20369391",
                    "LastEditorUserId": "20369391",
                    "LastEditDate": "2022-10-30T06:16:43.197",
                    "LastActivityDate": "2022-10-30T06:16:43.197",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "74322122",
                "ParentRepo": "https://github.com/Ce11an/spacy-cleaner",
                "StackOverflow_Post": {
                    "Id": "74322122",
                    "PostTypeId": "2",
                    "ParentId": "45605946",
                    "CreationDate": "2022-11-04T19:32:06.757",
                    "Score": "0",
                    "Body": "<p>I developed a package for this exact situation. Check out <a href=\"https://github.com/Ce11an/spacy-cleaner\" rel=\"nofollow noreferrer\">spacy-cleaner</a>:</p>\n<pre class=\"lang-py prettyprint-override\"><code>import spacy\nimport spacy_cleaner\nfrom spacy_cleaner.processing import removers, mutators\n\n\nmodel = spacy.load(&quot;en_core_web_sm&quot;)\n\npipeline = spacy_cleaner.Pipeline(\n    model,\n    removers.remove_stopword_token,\n    removers.remove_punctuation_token,\n    mutators.mutate_lemma_token,\n)\n\ntexts = [&quot;Hello, my name is Cellan!&quot;]\n\npipeline.clean(texts)\n\n# ['hello Cellan']\n</code></pre>\n<p>Check out our <a href=\"https://ce11an.github.io/spacy-cleaner/\" rel=\"nofollow noreferrer\">docs</a> for more information. Hope it helps! :)</p>\n",
                    "OwnerUserId": "12675367",
                    "LastActivityDate": "2022-11-04T19:32:06.757",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "74424468",
                "ParentRepo": "https://github.com/oxsecurity/megalinter",
                "StackOverflow_Post": {
                    "Id": "74424468",
                    "PostTypeId": "2",
                    "ParentId": "58734176",
                    "CreationDate": "2022-11-13T20:22:41.833",
                    "Score": "0",
                    "Body": "<p>I improved and packaged all the answers in a python command line utility <a href=\"https://github.com/nvuillam/github-dependents-info\" rel=\"nofollow noreferrer\">github-dependents-info</a></p>\n<pre><code>pip install github-dependents-info\ngithub-dependents-info --repo nvuillam/npm-groovy-lint --markdownfile ./package-usage.md --sort stars --verbose\n</code></pre>\n<p>In addition to already eisting features, it can:</p>\n<ul>\n<li>Output as text, JSON or markdown file</li>\n<li>Manage multiple packages in a single repo (ex: <a href=\"https://github.com/oxsecurity/megalinter\" rel=\"nofollow noreferrer\">megalinter</a>)</li>\n<li>Retry HTTP requests when failing</li>\n<li>Generate shields.io badges</li>\n</ul>\n<p><a href=\"https://i.stack.imgur.com/996Wv.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/996Wv.png\" alt=\"enter image description here\" /></a></p>\n<p><a href=\"https://github.com/oxsecurity/megalinter/blob/main/docs/used-by-stats.md\" rel=\"nofollow noreferrer\">Example result</a></p>\n",
                    "OwnerUserId": "7113625",
                    "LastActivityDate": "2022-11-13T20:22:41.833",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "74435545",
                "ParentRepo": "https://github.com/gimlet-io/onechart/issues/35",
                "StackOverflow_Post": {
                    "Id": "74435545",
                    "PostTypeId": "2",
                    "ParentId": "67791967",
                    "CreationDate": "2022-11-14T17:22:09.270",
                    "Score": "0",
                    "Body": "<p>Latest update from this <a href=\"https://github.com/gimlet-io/onechart/issues/35\" rel=\"nofollow noreferrer\">issue</a> works</p>\n<pre><code>  strategy:\n    rollingUpdate: null\n    type: Recreate\n</code></pre>\n",
                    "OwnerUserId": "8412926",
                    "LastActivityDate": "2022-11-14T17:22:09.270",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "74487794",
                "ParentRepo": "https://github.com/pyomeca/pyomeca",
                "StackOverflow_Post": {
                    "Id": "74487794",
                    "PostTypeId": "2",
                    "ParentId": "72137839",
                    "CreationDate": "2022-11-18T09:52:23.773",
                    "Score": "0",
                    "Body": "<p>try <a href=\"https://pypi.org/project/c3d/\" rel=\"nofollow noreferrer\">https://pypi.org/project/c3d/</a></p>\n<p>or <a href=\"https://github.com/pyomeca/pyomeca\" rel=\"nofollow noreferrer\">https://github.com/pyomeca/pyomeca</a></p>\n<p>its easier with them than with btk toolkit. You will need to see docs to get it done. I am using those to read only, then switch to numpy or pandas.</p>\n",
                    "OwnerUserId": "11559034",
                    "LastActivityDate": "2022-11-18T09:52:23.773",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "74512363",
                "ParentRepo": "https://github.com/zehengl/ez-address-parser",
                "StackOverflow_Post": {
                    "Id": "74512363",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "74512440",
                    "CreationDate": "2022-11-20T22:03:45.507",
                    "Score": "1",
                    "ViewCount": "46",
                    "Body": "<p>I am an R User that is trying to learn more about Python.</p>\n<p>I found this Python library that I would like to use for address parsing: <a href=\"https://github.com/zehengl/ez-address-parser\" rel=\"nofollow noreferrer\">https://github.com/zehengl/ez-address-parser</a></p>\n<p>I was able to try an example over here:</p>\n<pre><code>from ez_address_parser import AddressParser\n\nap = AddressParser()\n\nresult = ap.parse(&quot;290 Bremner Blvd, Toronto, ON M5V 3L9&quot;)\nprint(results)\n[('290', 'StreetNumber'), ('Bremner', 'StreetName'), ('Blvd', 'StreetType'), ('Toronto', 'Municipality'), ('ON', 'Province'), ('M5V', 'PostalCode'), ('3L9', 'PostalCode')]\n</code></pre>\n<p>I have the following file that I imported:</p>\n<pre><code>df = pd.read_csv(r'C:/Users/me/OneDrive/Documents/my_file.csv',  encoding='latin-1')\n\n   name                               address\n1 name1 290 Bremner Blvd, Toronto, ON M5V 3L9\n2 name2 291 Bremner Blvd, Toronto, ON M5V 3L9\n3 name3 292 Bremner Blvd, Toronto, ON M5V 3L9\n</code></pre>\n<p>I tried to apply the above function and export the file:</p>\n<pre><code>df['Address_Parse'] = df['ADDRESS'].apply(ap.parse)\n\ndf = pd.DataFrame(df)\ndf.to_csv(r'C:/Users/me/OneDrive/Documents/python_file.csv', index=False, header=True)\n</code></pre>\n<p>This seems to have worked - but everything appears to be in one line!</p>\n<pre><code>[('290', 'StreetNumber'), ('Bremner', 'StreetName'), ('Blvd', 'StreetType'), ('Toronto', 'Municipality'), ('ON', 'Province'), ('M5V', 'PostalCode'), ('3L9', 'PostalCode')]\n</code></pre>\n<p>Is there a way in Python to make each of these &quot;elements&quot; (e.g. StreetNumber, StreetName, etc.) into a separate column?</p>\n<p>Thank you!</p>\n",
                    "OwnerUserId": "13203841",
                    "LastEditorUserId": "10760768",
                    "LastEditDate": "2022-11-20T22:27:26.567",
                    "LastActivityDate": "2022-11-20T22:56:59.700",
                    "Title": "Applying Functions in Python",
                    "Tags": "<python><pandas><data-manipulation>",
                    "AnswerCount": "2",
                    "CommentCount": "3",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            }
        ],
        "Type": 2
    },
    "https://github.com/nameko/nameko": {
        "CVE Description": [
            "Nameko through 2.13.0 can be tricked into performing arbitrary code execution when deserializing the config file."
        ],
        "Edges": [
            {
                "ParentSID": "48201370",
                "ParentRepo": "https://github.com/onefinestay/nameko-sqlalchemy",
                "StackOverflow_Post": {
                    "Id": "48201370",
                    "PostTypeId": "2",
                    "ParentId": "48200075",
                    "CreationDate": "2018-01-11T06:57:24.950",
                    "Score": "1",
                    "Body": "<p>You should be using a DependencyProvider such as <a href=\"https://github.com/onefinestay/nameko-sqlalchemy\" rel=\"nofollow noreferrer\">nameko-sqlalchemy</a> to be connecting to a database.</p>\n\n<p>Instantiating the MySQL connection inside <code>__init__</code> means you'll create a new connection every time the RPC method fires, probably means you're running out of connections.</p>\n",
                    "OwnerUserId": "128749",
                    "LastActivityDate": "2018-01-11T06:57:24.950",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "48806710",
                "ParentRepo": "https://github.com/graphql-python/graphene-sqlalchemy/issues/112",
                "StackOverflow_Post": {
                    "Id": "48806710",
                    "PostTypeId": "1",
                    "CreationDate": "2018-02-15T11:56:38.310",
                    "Score": "3",
                    "ViewCount": "1546",
                    "Body": "<p>I currently have the following mutation defined for my project:</p>\n\n<p>My class <code>PlanetAttribute</code>  is used to define Graphene Fields used as inputs of my mutations</p>\n\n<pre><code>class PlanetAttribute:\n    name = graphene.String(required=True, description=\"Name of the planet.\")\n    rotation_period = graphene.String(default_value=\"unknown\", description=\"Rotation period of the planet.\")\n    orbital_period = graphene.String(default_value=\"unknown\", description=\"Orbital period of the planet.\")\n    diameter = graphene.String(default_value=\"unknown\", description=\"Diameter of the planet.\")\n    climate = graphene.String(default_value=\"unknown\", description=\"Climate period of the planet.\")\n    gravity = graphene.String(default_value=\"unknown\", description=\"Gravity of the planet.\")\n    terrain = graphene.String(default_value=\"unknown\", description=\"Terrain of the planet.\")\n    surface_water = graphene.String(default_value=\"unknown\", description=\"Surface water of the planet.\")\n    population = graphene.String(default_value=\"unknown\", description=\"Population of the planet.\")\n    url = graphene.String(default_value=\"unknown\", description=\"URL of the planet in the Star Wars API.\")\n</code></pre>\n\n<p>My class <code>CreatePlanetInput</code> is used to define the Graphene input object type. Note that it inherits its attributes from the <code>PlanetAttribute</code> class defined above.</p>\n\n<pre><code>class CreatePlanetInput(graphene.InputObjectType, PlanetAttribute):\n    \"\"\"Arguments to create a planet.\"\"\"\n    pass\n</code></pre>\n\n<p>My class <code>CreatePlanet</code> is my Graphene mutation class which takes the <code>CreatePlanetInput</code> class as arguments.</p>\n\n<pre><code>class CreatePlanet(graphene.Mutation):\n    \"\"\"Create a planet.\"\"\"\n    planet = graphene.Field(lambda: Planet, description=\"Planet created by this mutation.\")\n\n    class Arguments:\n        input = CreatePlanetInput(required=True)\n\n    def mutate(self, info, input):\n        data = utils.input_to_dictionary(input)\n        data['created'] = datetime.utcnow()\n        data['edited'] = datetime.utcnow()\n\n        planet = ModelPlanet(**data)\n        db_session.add(planet)\n        db_session.commit()\n\n        return CreatePlanet(planet=planet)\n</code></pre>\n\n<p>Instead of declaring mutation inputs manually in the <code>PlanetAttribute</code> class, I would rather generate them dynamically from my SQLALchemy class <code>ModelPlanet</code> which is defined as below:</p>\n\n<pre><code>class ModelPlanet(Base):\n    \"\"\"Planet model.\"\"\"\n\n    __tablename__ = 'planet'\n\n    id = Column('id', Integer, primary_key=True, doc=\"Id of the person.\")\n    name = Column('name', String, doc=\"Name of the planet.\")\n    rotation_period = Column('rotation_period', String, doc=\"Rotation period of the planet.\")\n    orbital_period = Column('orbital_period', String, doc=\"Orbital period of the planet.\")\n    diameter = Column('diameter', String, doc=\"Diameter of the planet.\")\n    climate = Column('climate', String, doc=\"Climate period of the planet.\")\n    gravity = Column('gravity', String, doc=\"Gravity of the planet.\")\n    terrain = Column('terrain', String, doc=\"Terrain of the planet.\")\n    surface_water = Column('surface_water', String, doc=\"Surface water of the planet.\")\n    population = Column('population', String, doc=\"Population of the planet.\")\n    created = Column('created', String, doc=\"Record created date.\")\n    edited = Column('edited', String, doc=\"Record last updated date.\")\n    url = Column('url', String, doc=\"URL of the planet in the Star Wars API.\")\n\n    peopleList = relationship(ModelPeople, backref='planet')\n</code></pre>\n\n<p>How would you proceed?</p>\n\n<p>Note that I have also posted the question here: <a href=\"https://github.com/graphql-python/graphene-sqlalchemy/issues/112\" rel=\"nofollow noreferrer\">https://github.com/graphql-python/graphene-sqlalchemy/issues/112</a></p>\n",
                    "OwnerUserId": "6283849",
                    "LastActivityDate": "2020-12-22T16:14:29.643",
                    "Title": "Generate Graphene Mutation Inputs from SQLAlchemy Class Attributes",
                    "Tags": "<python><sqlalchemy><graphene-python>",
                    "AnswerCount": "1",
                    "CommentCount": "1",
                    "FavoriteCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "55225685",
                "ParentRepo": "https://github.com/nameko/nameko-grpc",
                "StackOverflow_Post": {
                    "Id": "55225685",
                    "PostTypeId": "2",
                    "ParentId": "55101067",
                    "CreationDate": "2019-03-18T16:14:46.930",
                    "Score": "1",
                    "Body": "<p>Unfortunately currently there isn't swagger like tool for documenting Nameko's RPC interface. </p>\n\n<p>As Nameko's RPC implementation is AMQP based, you will most likely control both Client and Server side in which case regular Python documentation tools like <code>sphinx-doc</code> are available for you. </p>\n\n<p>If you'd like to expose API to external clients and share service definition with them you could take a look at Nameko's GRPC implementation <a href=\"https://github.com/nameko/nameko-grpc\" rel=\"nofollow noreferrer\">https://github.com/nameko/nameko-grpc</a> (and examples: <a href=\"https://github.com/nameko/nameko-examples-grpc\" rel=\"nofollow noreferrer\">https://github.com/nameko/nameko-examples-grpc</a>). </p>\n\n<p>gRPC is based on Protocol Buffers service definitions which are effectively documenting you API interface and can be used to generate client libraries.  </p>\n",
                    "OwnerUserId": "177209",
                    "LastActivityDate": "2019-03-18T16:14:46.930",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "58715651",
                "ParentRepo": "https://github.com/sivabudh/djanko/blob/master/services.py",
                "StackOverflow_Post": {
                    "Id": "58715651",
                    "PostTypeId": "2",
                    "ParentId": "58686004",
                    "CreationDate": "2019-11-05T16:31:43.760",
                    "Score": "1",
                    "Body": "<p>This is how:</p>\n\n<p><a href=\"https://github.com/sivabudh/djanko/blob/master/services.py\" rel=\"nofollow noreferrer\">https://github.com/sivabudh/djanko/blob/master/services.py</a></p>\n\n<p>See: django-nameko-standalone</p>\n\n<p>Update: If you want to do microservices with Django, just use Celery. Works like a charm.</p>\n",
                    "OwnerUserId": "65313",
                    "LastEditorUserId": "65313",
                    "LastEditDate": "2019-11-11T01:40:47.900",
                    "LastActivityDate": "2019-11-11T01:40:47.900",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "60565168",
                "ParentRepo": "https://github.com/signalpillar/nameko-injector",
                "StackOverflow_Post": {
                    "Id": "60565168",
                    "PostTypeId": "1",
                    "CreationDate": "2020-03-06T13:33:50.797",
                    "Score": "2",
                    "ViewCount": "86",
                    "Body": "<p>I am busy programming a microservice backend in Python using Nameko. While searching for a good dependency injection package I came a across Injector. I really liked it and wanted to use it together with Nameko. Then I noticed a small problem: Nameko instantiates the workers and doesn't work with dependency injection packages out of the box. After trying to get it to work using the documentation I stumbled upon the package <a href=\"https://github.com/signalpillar/nameko-injector\" rel=\"nofollow noreferrer\">nameko-injector</a>. I liked the concept and tried to implement it but i get the error:</p>\n\n<blockquote>\n  <p>Parameter 'bindings' unfilled</p>\n</blockquote>\n\n<p>Using the example code from the git repository (shown below) the problem occurred at the initialization of the NamekoInjector class.</p>\n\n<p>The microservice worker class:</p>\n\n<pre><code>from nameko.rpc import rpc\nfrom services.order_service import OrderService\nfrom nameko_injector.core import NamekoInjector\n\nINJECTOR = NamekoInjector()\n\n\n@INJECTOR.decorate_service\nclass OrderWorker:\n\n    # Mandatory field for service discovery\n    name = \"order_worker\"\n\n    def __init__(self, service: OrderService):\n        self.service = service\n\n    @rpc\n    def get_orders(self):\n        return self.service.orders()\n\n</code></pre>\n\n<p>The OrderService class:</p>\n\n<pre><code>from models.order.order import Order\n\n\nclass OrderService(object):\n\n    def __init__(self):\n        self.orders = [Order(1), Order(2)]\n\n    def get_users(self):\n        return self.orders\n</code></pre>\n\n<p>The Order class:</p>\n\n<pre><code>class Order:\n    def __init__(self, orderid):\n        self.orderid = orderid\n\n    def __str__(self):\n        return str(self.orderid)\n\n</code></pre>\n\n<p>When looking in the NamekoInjector class I couldn't find out what the binding exactly does and when it's used. In the first place I don't even need it but when I delete the binding fields and other usages in the NamekoInjector class, it still won't work. Can anybody please help me? Thanks!</p>\n",
                    "OwnerUserId": "13019057",
                    "LastActivityDate": "2022-01-06T18:58:29.740",
                    "Title": "Unable to get nameko-injector Python package to work",
                    "Tags": "<python><dependency-injection><microservices><nameko>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "FavoriteCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "70155213",
                "ParentRepo": "https://github.com/jorzel/opentable",
                "StackOverflow_Post": {
                    "Id": "70155213",
                    "PostTypeId": "2",
                    "ParentId": "59021614",
                    "CreationDate": "2021-11-29T13:09:25.113",
                    "Score": "0",
                    "Body": "<p>To create separated SQLAlchemy model for domain and persistance you should use <code>mapper</code>, instead of declarative mapping style. Example:</p>\n<pre><code># entities.py\nclass Table:\n    def __init__(self, table_id: int):\n        self.id = table_id\n\nclass Restaurant:\n    def __init__(self, restaurant_id: int, tables: List[Table]):\n        self.id = restaurant_id\n        self.tables = tables\n\n# orm.py\nfrom sqlalchemy import Boolean, Column, ForeignKey, Integer, MetaData, create_engine\nfrom sqlalchemy import Table as sa_Table\nfrom sqlalchemy.ext.declarative import declarative_base\nfrom sqlalchemy.orm import mapper, relationship\nfrom entities import Restaurant, Table\n\nSQLALCHEMY_DATABASE_URI = &quot;sqlite:///&quot; # your db uri\n\nengine = create_engine(SQLALCHEMY_DATABASE_URI)\nmetadata = MetaData(bind=engine)\nBase = declarative_base(metadata=metadata)\n\nrestaurant = sa_Table(\n    &quot;restaurant&quot;,\n    metadata,\n    Column(&quot;id&quot;, Integer, primary_key=True, autoincrement=True),\n)\n\ntable = sa_Table(\n    &quot;table&quot;,\n    metadata,\n    Column(&quot;id&quot;, Integer, primary_key=True, autoincrement=True),\n    Column(&quot;restaurant_id&quot;, Integer, ForeignKey(&quot;restaurant.id&quot;))\n)\n\ndef run_mappers():\n    &quot;&quot;&quot;\n    Provides mapping between db tables and domain models.\n    &quot;&quot;&quot;\n    mapper(\n        Restaurant,\n        restaurant,\n        properties={&quot;tables&quot;: relationship(Table, backref=&quot;restaurant&quot;)},\n    )\n    mapper(Table, table)\n\nrun_mappers() # it should be executed in the app runtime\n</code></pre>\n<p>If you need more context, here is my repo implementing full python project in DDD style (using Port and adapters architecture): <a href=\"https://github.com/jorzel/opentable\" rel=\"nofollow noreferrer\">https://github.com/jorzel/opentable</a>\nI have recently written a blog post about it: <a href=\"https://jorzel.hashnode.dev/persistence-and-domain-model-separation-using-sqlalchemy-orm\" rel=\"nofollow noreferrer\">https://jorzel.hashnode.dev/persistence-and-domain-model-separation-using-sqlalchemy-orm</a>.\nThere is also a great book (in python) covering this topic: <a href=\"https://github.com/cosmicpython/book\" rel=\"nofollow noreferrer\">https://github.com/cosmicpython/book</a></p>\n",
                    "OwnerUserId": "7938435",
                    "LastEditorUserId": "7938435",
                    "LastEditDate": "2021-11-29T13:30:16.120",
                    "LastActivityDate": "2021-11-29T13:30:16.120",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "70277354",
                "ParentRepo": "https://github.com/nameko/nameko-sqlalchemy",
                "StackOverflow_Post": {
                    "Id": "70277354",
                    "PostTypeId": "1",
                    "CreationDate": "2021-12-08T15:15:38.973",
                    "Score": "4",
                    "ViewCount": "168",
                    "Body": "<p>We are building a Python microservices application with Posgresql as service datastore.  At first glance Nameko seems a good starting point.  However the <a href=\"https://nameko.readthedocs.io/en/stable/key_concepts.html#concurrency\" rel=\"nofollow noreferrer\">Nameko documentation section on Concurrency includes this statement</a>:</p>\n<blockquote>\n<p>Nameko is built on top of the eventlet library, which provides concurrency via \u201cgreenthreads\u201d. The concurrency model is co-routines with implicit yielding.<br />\nImplicit yielding relies on monkey patching the standard library, to trigger a yield when a thread waits on I/O. If your host services with nameko run on the command line, Nameko will apply the monkey patch for you.<br />\nEach worker executes in its own greenthread. The maximum number of concurrent workers can be tweaked based on the amount of time each worker will spend waiting on I/O.<br />\nWorkers are stateless so are inherently thread safe, but dependencies should ensure they are unique per worker or otherwise safe to be accessed concurrently by multiple workers.<br />\n<strong>Note that many C-extensions that are using sockets and that would normally be considered thread-safe may not work with greenthreads. Among them are librabbitmq, MySQLdb and others.</strong></p>\n</blockquote>\n<p>Our architect is suggesting Nameko is therefore not going to fly - because although the pyscopg2 Postgresql driver is advertised as thread safe:</p>\n<blockquote>\n<p>Its main features are the complete implementation of the Python DB API 2.0 specification and the thread safety (several threads can share the same connection). It was designed for heavily multi-threaded applications</p>\n</blockquote>\n<p><a href=\"https://www.psycopg.org/docs/usage.html#thread-and-process-safety\" rel=\"nofollow noreferrer\">It is clarified</a>:</p>\n<blockquote>\n<p>The above observations are only valid for regular threads: they don\u2019t apply to forked processes nor to green threads. libpqconnections shouldn\u2019t be used by a forked processes, so when using a module such as multiprocessingor a forking web deploy method such as FastCGI make sure to create the connections after the fork.\nConnections shouldn\u2019t be shared either by different green threads: see Support for coroutine librariesfor further details.</p>\n</blockquote>\n<p><a href=\"https://www.psycopg.org/docs/advanced.html#green-support\" rel=\"nofollow noreferrer\">With a link clarifying</a>:</p>\n<blockquote>\n<p>Warning Psycopg connections are not green thread safe and can\u2019t be used concurrently by different green threads. Trying to execute more than one command at time using one cursor per thread will result in an error (or a deadlock on versions before 2.4.2).\nTherefore, programmers are advised to either avoid sharing connections between coroutines or to use a library-friendly lock to synchronize shared connections, e.g. for pooling.</p>\n</blockquote>\n<p>The normal service configuration would have the service hold a repository with a connection shared by threads, with repository access methods using sessions on that connection scoped to the method.</p>\n<p>Our architect suggest that even if we were to go with a connection+session per thread because of how the greenthreads work in terms of implicit yielding on a given session if we do other I/O operations between data access calls on the session e.g. file write via logging then we might suffer an implicite context switch - which then could cause issues on the session post the logging.</p>\n<p>Is there any reasonable way we can use Nameko in this context or is it doomed as our architect suggests?\nIs there any way we can make this work without having to write our own microservice code e.g. using <a href=\"https://docs.celeryproject.org/projects/kombu/en/latest/introduction.html#about\" rel=\"nofollow noreferrer\">Kombu</a>?</p>\n<p>Additional note: A comment <a href=\"https://github.com/nameko/nameko-sqlalchemy\" rel=\"nofollow noreferrer\">on this page suggests</a> regarding Database drivers states:</p>\n<blockquote>\n<p>You may use any database driver compatible with SQLAlchemy provided it is safe to use with eventlet. <strong>This will include all pure-python drivers</strong>.</p>\n</blockquote>\n<p>It goes on to list pysqlite &amp; pymysql.</p>\n<p>Would using either pg8000 or py-postgresql pure Python drivers put us in the clear threading wise - is the issue here greenthreads in combination with pyscopg2/3 driver that uses C-code or is it fundamentally Namekos use of greenthreads?</p>\n",
                    "OwnerUserId": "159361",
                    "LastEditorUserId": "159361",
                    "LastEditDate": "2021-12-10T14:36:20.600",
                    "LastActivityDate": "2021-12-10T15:47:08.203",
                    "Title": "Potential Nameko consurrency issues with pyscopg2 driver for Postgresql",
                    "Tags": "<python><postgresql><thread-safety><kombu><nameko>",
                    "AnswerCount": "0",
                    "CommentCount": "4",
                    "FavoriteCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "72930721",
                "ParentRepo": "https://github.com/morganjbruce/microservices-in-action/tree/master/chapter-7/feature/statsd",
                "StackOverflow_Post": {
                    "Id": "72930721",
                    "PostTypeId": "1",
                    "CreationDate": "2022-07-10T18:00:43.690",
                    "Score": "0",
                    "ViewCount": "92",
                    "Body": "<p>I am having a problem starting a docker container with statsd sevice with some ruby script. It is a simple container from this github page - <a href=\"https://github.com/morganjbruce/microservices-in-action/tree/master/chapter-7/feature/statsd\" rel=\"nofollow noreferrer\">https://github.com/morganjbruce/microservices-in-action/tree/master/chapter-7/feature/statsd</a></p>\n<p>Already tried playing around with COPY and CMD command where I think might be the problem, but without success.</p>\n<p>Here is the Dockerfile:</p>\n<pre><code>FROM alpine:3.6\n\nMAINTAINER simplebank &lt;engineering@simplebenak.book&gt;\n\nARG port=&quot;8125&quot;\nARG home=&quot;/root/&quot;\nARG app_root=&quot;/var/code/simplebank/&quot;\nARG app_name=&quot;statsd-agent&quot;\n\nENV TERM xterm\nENV LANG=en_GB.UTF-8\nENV HOME $home\n\nENV REFRESHED_AT 2016-11-25\n\nCOPY . $app_root$app_name\n\nRUN apk update &amp;&amp; apk --update add \\\n      ruby \\\n      ruby-irb \\\n      ruby-json \\\n      ruby-rake \\\n      ruby-bigdecimal \\\n      ruby-io-console \\\n      libstdc++ \\\n      tzdata \\\n      ca-certificates \\\n      bash\n\nRUN gem install bundler --no-ri --no-rdoc \\\n    &amp;&amp; cd $app_root$app_name ; bundle install \\\n    &amp;&amp; rm -rf /var/cache/apk/*\n\nRUN chown -R nobody:nogroup $app_root$app_name\nRUN chmod +x $app_root$app_name/statsd-agent.rb\n\nUSER nobody\n\nEXPOSE $port/udp\n\nWORKDIR $app_root$app_name\n\nCMD ./$app_root$app_name/statsd-agent.rb\n</code></pre>\n<p>The Gemfile:</p>\n<pre><code>source &quot;https://www.rubygems.org&quot;\n\ngem &quot;term-ansicolor&quot;\n</code></pre>\n<p>The statsd-agent.rb script</p>\n<pre><code>#!/usr/bin/env ruby\n#\n# This script is found in this post by Lee Hambley\n# http://lee.hambley.name/2013/01/26/dirt-simple-statsd-server-for-local-development.html\n#\nrequire 'socket'\nrequire 'term/ansicolor'\n\ninclude Term::ANSIColor\n\n$stdout.sync = true\n\nc = Term::ANSIColor\ns = UDPSocket.new\ns.bind(&quot;0.0.0.0&quot;, 8125)\nwhile blob = s.recvfrom(1024)\n  metric, value = blob.first.split(':')\n  puts &quot;StatsD Metric: #{c.blue(metric)} #{c.green(value)}&quot;\nend\n</code></pre>\n<p>From the folder with dockerfile I build Image:</p>\n<pre><code>docker build -t statsd_service .\n</code></pre>\n<p>And run it:</p>\n<pre><code>docker run -dp 8125:8125 statsd_service\n</code></pre>\n<p>Now the container wont start and in Logs I see this:</p>\n<pre><code>': No such file or directory\n</code></pre>\n<p>Can you help me out please?\nThx</p>\n",
                    "OwnerUserId": "2412626",
                    "LastActivityDate": "2022-07-10T18:27:26.320",
                    "Title": "Docker wont start, Exited with ': No such file or directory",
                    "Tags": "<ruby><docker><statsd>",
                    "AnswerCount": "1",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            }
        ],
        "Type": 2
    },
    "https://github.com/ElementsProject/lightning": {
        "CVE Description": [
            "Blockstream c-lightning through 0.10.1 allows loss of funds because of dust HTLC exposure."
        ],
        "Edges": [
            {
                "SID": "49097763",
                "StackOverflow_Post": {
                    "Id": "49097763",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "49109611",
                    "CreationDate": "2018-03-04T16:44:41.810",
                    "Score": "1",
                    "ViewCount": "481",
                    "Body": "<p>I am playing around with the lightning implementation from <a href=\"https://github.com/ElementsProject/lightning\" rel=\"nofollow noreferrer\">https://github.com/ElementsProject/lightning</a> and after the following steps the cli-client cannot list funds which I deposited at the generated address from the internal wallet</p>\n\n<ol>\n<li>I installed bitcoind-0.16 and fully synced the mainnet-blockchain</li>\n<li>I installed c-lightning and synced with the local full node</li>\n<li>I generated a new address with <code>./lightning-cli newaddr</code></li>\n<li>I funded this address from my Electrum wallet (not from the local node wallet) and saw the incoming transaction with <code>./lightning-cli listfunds</code></li>\n<li>Then I accidentally deleted the file <code>.lightning/lightningd.sqlite3</code></li>\n<li>After restart the lightningd recreated the file but now <code>./lightning-cli listfunds</code> is showing empty results but the funds have to be there because the funding transaction is visible in the blockchain.</li>\n</ol>\n\n<p>I investigated <code>./lightning-cli dev-listaddrs</code> which shows all addresses of the internal wallet and there is my funding address. So I think I need to re-sync the lightningd with the bitcoin blockchain, but a <code>./lightning-cli dev-rescan-outputs</code> had no success.</p>\n\n<p>What can I do to be able to see and spend the funds again? Or, how can I get the seed/private key of the internal (lightning) wallet?</p>\n",
                    "OwnerUserId": "8265284",
                    "LastActivityDate": "2018-03-08T12:25:23.210",
                    "Title": "How to re-sync c-lightning with mainnet blockchain?",
                    "Tags": "<bitcoin><lightning>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "49097763",
                "ParentRepo": "https://github.com/ElementsProject/lightning",
                "StackOverflow_Post": {
                    "Id": "49097763",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "49109611",
                    "CreationDate": "2018-03-04T16:44:41.810",
                    "Score": "1",
                    "ViewCount": "481",
                    "Body": "<p>I am playing around with the lightning implementation from <a href=\"https://github.com/ElementsProject/lightning\" rel=\"nofollow noreferrer\">https://github.com/ElementsProject/lightning</a> and after the following steps the cli-client cannot list funds which I deposited at the generated address from the internal wallet</p>\n\n<ol>\n<li>I installed bitcoind-0.16 and fully synced the mainnet-blockchain</li>\n<li>I installed c-lightning and synced with the local full node</li>\n<li>I generated a new address with <code>./lightning-cli newaddr</code></li>\n<li>I funded this address from my Electrum wallet (not from the local node wallet) and saw the incoming transaction with <code>./lightning-cli listfunds</code></li>\n<li>Then I accidentally deleted the file <code>.lightning/lightningd.sqlite3</code></li>\n<li>After restart the lightningd recreated the file but now <code>./lightning-cli listfunds</code> is showing empty results but the funds have to be there because the funding transaction is visible in the blockchain.</li>\n</ol>\n\n<p>I investigated <code>./lightning-cli dev-listaddrs</code> which shows all addresses of the internal wallet and there is my funding address. So I think I need to re-sync the lightningd with the bitcoin blockchain, but a <code>./lightning-cli dev-rescan-outputs</code> had no success.</p>\n\n<p>What can I do to be able to see and spend the funds again? Or, how can I get the seed/private key of the internal (lightning) wallet?</p>\n",
                    "OwnerUserId": "8265284",
                    "LastActivityDate": "2018-03-08T12:25:23.210",
                    "Title": "How to re-sync c-lightning with mainnet blockchain?",
                    "Tags": "<bitcoin><lightning>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            }
        ],
        "Type": 1
    },
    "https://github.com/streamaserver/streama": {
        "CVE Description": [
            "A cross-site request forgery (CSRF) vulnerability exists in Streama up to and including v1.10.3. The application does not have CSRF checks in place when performing actions such as uploading local files. As a result, attackers could make a logged-in administrator upload arbitrary local files via a CSRF attack and send them to the attacker."
        ],
        "Edges": [
            {
                "SID": "58155456",
                "StackOverflow_Post": {
                    "Id": "58155456",
                    "PostTypeId": "1",
                    "CreationDate": "2019-09-29T13:02:00.240",
                    "Score": "1",
                    "ViewCount": "200",
                    "Body": "<p>I am relatively new to Java, Gradle, Spring and Docker, and i need to perform some modifications on an open source project: <a href=\"https://github.com/streamaserver/streama\" rel=\"nofollow noreferrer\">https://github.com/streamaserver/streama</a> written in Java.</p>\n\n<p>I have set up a dev environment but i don't believe that this is the optimal approach, can this be done more efficiently without the need to rebuild with Gradle and rebuild docker containers on every code change?</p>\n\n<p>This is what i run at the moment to get Docker up listening on localhost  with a fresh build </p>\n\n<pre><code>./gradlew build \ndocker-compose build --no-cache\ndocker-compose up\n</code></pre>\n\n<p>Does the gradle project have to be compiled in to a jar file?</p>\n\n<p>Can the docker container sync with filesystem and listen to changed to the jar?</p>\n",
                    "OwnerUserId": "12138537",
                    "LastEditorUserId": "12138537",
                    "LastEditDate": "2019-09-29T13:06:20.267",
                    "LastActivityDate": "2019-09-29T13:06:20.267",
                    "Title": "Development environment Gradle & Docker without compiling jar's and rebuilding containers",
                    "Tags": "<java><spring><docker><gradle>",
                    "AnswerCount": "0",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            }
        ],
        "Type":0
    },
    "https://github.com/encode/httpx": {
        "CVE Description": [
            "Encode OSS httpx < 0.23.0 is affected by improper input validation in `httpx.URL`, `httpx.Client` and some functions using `httpx.URL.copy_with`."
        ],
        "Edges": [
            {
                "ParentSID": "12044852",
                "ParentRepo": "https://github.com/rthalley/dnspython",
                "StackOverflow_Post": {
                    "Id": "12044852",
                    "PostTypeId": "1",
                    "CreationDate": "2012-08-20T20:45:49.700",
                    "Score": "2",
                    "ViewCount": "1860",
                    "Body": "<p>Is there an existing/standard algorithm for mapping an email address onto a RNAME field of a SOA record (and its inverse)?  I'm using the <a href=\"https://github.com/rthalley/dnspython\" rel=\"nofollow noreferrer\">dnspython</a> package but I don't see anything in their source tree to handle this.  I ran into the edge case of having a period '.' in the username that needs to be escaped and wondering if there are any other edge cases that I am missing.  <a href=\"https://www.rfc-editor.org/rfc/rfc1035#section-3.3.13\" rel=\"nofollow noreferrer\">RFC 1035</a> simply states:</p>\n<blockquote>\n<p>A &lt;domain-name&gt; which specifies the mailbox of the person responsible for this zone.</p>\n</blockquote>\n<p>None of the RFCs that update 1035 expand upon RNAME field aside from a brief mention in <a href=\"https://www.rfc-editor.org/rfc/rfc1183#section-2.2\" rel=\"nofollow noreferrer\">RFC 1183</a>.</p>\n",
                    "OwnerUserId": "182365",
                    "LastEditorUserId": "-1",
                    "LastEditDate": "2021-10-07T10:55:51.000",
                    "LastActivityDate": "2012-08-21T18:07:26.793",
                    "Title": "How do you map an email address onto a SOA RNAME field?",
                    "Tags": "<python><dns><dnspython>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "14823029",
                "ParentRepo": "https://github.com/mozilla/servo/blob/master/src/servo/platform/osmain.rs#L340",
                "StackOverflow_Post": {
                    "Id": "14823029",
                    "PostTypeId": "2",
                    "ParentId": "14804256",
                    "CreationDate": "2013-02-11T23:41:40.783",
                    "Score": "2",
                    "Body": "<p>This problem is likely related to the thread you are running the code on. Some libraries have an affinity for the actual main thread the process began execution on, and this is often the case with graphics libraries and calls into the windowing system. The main Rust task does not execute on the main thread, but the Rust library does have a way to execute a task on the main thread. See an <a href=\"https://github.com/mozilla/servo/blob/master/src/servo/platform/osmain.rs#L340\" rel=\"nofollow\">example from servo</a>.</p>\n\n<p>If that doesn't get you unstuck then you may need to create a .app folder to run your OS X application. I'm not entirely familiar with the details but I'm lead to believe that coca API's don't entirely work without one.</p>\n",
                    "OwnerUserId": "1204536",
                    "LastActivityDate": "2013-02-11T23:41:40.783",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "15529393",
                "ParentRepo": "https://github.com/jupyter/jupyterhub",
                "StackOverflow_Post": {
                    "Id": "15529393",
                    "PostTypeId": "2",
                    "ParentId": "15527069",
                    "CreationDate": "2013-03-20T16:34:30.500",
                    "Score": "5",
                    "Body": "<p>[Edit Feb 2015]</p>\n\n<p>The relevant project to run multi-user IPython notebook is to use <a href=\"https://github.com/jupyter/jupyterhub\" rel=\"nofollow\">JupyterHub</a> (Note: IPython has been partially renamed Jupyter). JupyterHub has a pluggable architecture that handle various auth, and remote spawning of process, as well as user redirection.</p>\n\n<hr>\n\n<p>[This part is not relevant anymore]</p>\n\n<p>Not baked in IPython (yet), is is in the roadmap for the next 2 years.\nYou can start one notebook instance per user (but then you don't share notebook), each on a different port. You can have a look at <a href=\"https://github.com/cni/ipython-hydra\" rel=\"nofollow\">IPython-Hydra</a> that more or less does it automatically. If you have issues with multiple port, you can host multiple notebook server using prefix and <a href=\"https://npmjs.org/package/ipython-notebook-proxy\" rel=\"nofollow\">ipython notebook proxy</a> I didn't had time to have it support https yet, but it is recommended if you host it on public ip.</p>\n",
                    "OwnerUserId": "137794",
                    "LastEditorUserId": "137794",
                    "LastEditDate": "2015-02-26T06:17:40.677",
                    "LastActivityDate": "2015-02-26T06:17:40.677",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "22113627",
                "ParentRepo": "https://github.com/openstack/requirements/blob/master/global-requirements.txt",
                "StackOverflow_Post": {
                    "Id": "22113627",
                    "PostTypeId": "2",
                    "ParentId": "20075574",
                    "CreationDate": "2014-03-01T11:15:38.053",
                    "Score": "4",
                    "Body": "<p>Just use this:\n<a href=\"https://pypi.python.org/pypi/caniusepython3/\" rel=\"nofollow\">https://pypi.python.org/pypi/caniusepython3/</a></p>\n\n<p>For the sake of statistics, this is openstack list of deps (161 in total):\n<a href=\"https://github.com/openstack/requirements/blob/master/global-requirements.txt\" rel=\"nofollow\">https://github.com/openstack/requirements/blob/master/global-requirements.txt</a></p>\n\n<p>And this is what's holding them back:</p>\n\n<pre><code>  giampaolo@UX32VD:/tmp$ caniusepython3 -r requirements.txt \n  Finding and checking dependencies ...\n\n  You need 67 projects to transition to Python 3.\n  Of those 67 projects, 65 have no direct dependencies blocking their transition:\n\n  boto\n  cmd2\n  coinor.pulp\n  croniter\n  ddt\n  diskimage-builder\n  django-bootstrap-form\n  django-compressor\n  django-openstack-auth\n  dnspython\n  eventlet\n  extras\n  gear\n  hacking\n  thrift (which is blocking happybase)\n  jsonrpclib\n  mysql-python\n  netifaces\n  nose-exclude\n  nosehtmloutput\n  nosexcover\n  openstack-doc-tools\n  openstack.nose-plugin\n  os-apply-config\n  os-collect-config\n  os-refresh-config\n  oslo.config\n  oslo.messaging\n  oslo.rootwrap\n  oslo.sphinx\n  oslosphinx\n  pam\n  ecdsa (which is blocking paramiko)\n  paste\n  posix-ipc\n  proboscis\n  pycadf\n  pyghmi\n  python-ceilometerclient\n  python-cinderclient\n  python-designateclient\n  python-glanceclient\n  python-heatclient\n  python-ldap\n  python-neutronclient\n  python-openstackclient\n  python-savannaclient\n  python-seamicroclient\n  python-swiftclient\n  python-troveclient\n  qpid-python\n  rtslib-fb\n  sockjs-tornado\n  sphinxcontrib-docbookrestapi\n  sphinxcontrib-httpdomain\n  sphinxcontrib-pecanwsme\n  sqlalchemy-migrate\n  suds\n  swift\n  taskflow\n  tripleo-image-elements\n  warlock\n  websockify\n  xenapi\n  zake\n</code></pre>\n",
                    "OwnerUserId": "376587",
                    "LastEditorUserId": "376587",
                    "LastEditDate": "2014-03-01T11:22:12.127",
                    "LastActivityDate": "2014-03-01T11:22:12.127",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "22789161",
                "ParentRepo": "https://github.com/timothycrosley/isort",
                "StackOverflow_Post": {
                    "Id": "22789161",
                    "PostTypeId": "2",
                    "ParentId": "22722976",
                    "CreationDate": "2014-04-01T14:39:37.687",
                    "Score": "28",
                    "Body": "<p>Have a look at <a href=\"https://pypi.python.org/pypi/isort\" rel=\"noreferrer\">https://pypi.python.org/pypi/isort</a> or <a href=\"https://github.com/timothycrosley/isort\" rel=\"noreferrer\">https://github.com/timothycrosley/isort</a></p>\n\n<blockquote>\n  <p>isort parses specified files for global level import lines (imports outside of try / excepts blocks, functions, etc..) and puts them all at the top of the file grouped together by the type of import:</p>\n  \n  <ul>\n  <li>Future </li>\n  <li>Python Standard Library </li>\n  <li>Third Party </li>\n  <li>Current Python Project </li>\n  <li>Explicitly Local (. before import, as in: from . import x) </li>\n  </ul>\n  \n  <p>Custom Separate Sections (Defined by forced_separate list in configuration file) \n  Inside of each section the imports are sorted alphabetically. isort automatically removes duplicate python imports, and wraps long from imports to the specified line length (defaults to 80).</p>\n</blockquote>\n\n<p><a href=\"https://pypi.python.org/pypi/flake8-isort\" rel=\"noreferrer\">https://pypi.python.org/pypi/flake8-isort</a> plugs this functionality into flake8</p>\n",
                    "OwnerUserId": "674447",
                    "LastEditorUserId": "674447",
                    "LastEditDate": "2016-02-16T10:58:09.310",
                    "LastActivityDate": "2016-02-16T10:58:09.310",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "23436125",
                "ParentRepo": "https://github.com/servo/servo/wiki/Design",
                "StackOverflow_Post": {
                    "Id": "23436125",
                    "PostTypeId": "2",
                    "ParentId": "1934715",
                    "CreationDate": "2014-05-02T20:07:06.090",
                    "Score": "307",
                    "Body": "<p><strong>First read:</strong> <a href=\"https://stackoverflow.com/questions/1050222/concurrency-vs-parallelism-what-is-the-difference\">Concurrency vs Parallelism - What is the difference?</a> </p>\n\n<blockquote>\n  <p>Concurrency is the separation of tasks to provide interleaved\n  execution. Parallelism is the simultaneous execution of multiple\n  pieces of work in order to increase speed. \u2014<a href=\"https://github.com/servo/servo/wiki/Design\" rel=\"noreferrer\">https://github.com/servo/servo/wiki/Design</a></p>\n</blockquote>\n\n<p><strong>Short answer:</strong> With threads, the operating system switches running threads preemptively according to its scheduler, which is an algorithm in the operating system kernel. With coroutines, the programmer and programming language determine when to switch coroutines; in other words, tasks are cooperatively multitasked by pausing and resuming functions at set points, typically (but not necessarily) within a single thread.</p>\n\n<p><strong>Long answer:</strong> In contrast to threads, which are pre-emptively scheduled by the operating system, coroutine switches are cooperative, meaning the programmer (and possibly the programming language and its runtime) controls when a switch will happen. </p>\n\n<blockquote>\n  <p>In contrast to threads, which are pre-emptive, coroutine switches are\n  cooperative (programmer controls when a switch will happen). The\n  kernel is not involved in the coroutine switches.\n  \u2014<a href=\"http://www.boost.org/doc/libs/1_55_0/libs/coroutine/doc/html/coroutine/overview.html\" rel=\"noreferrer\">http://www.boost.org/doc/libs/1_55_0/libs/coroutine/doc/html/coroutine/overview.html</a></p>\n</blockquote>\n\n<p>A language that supports <strong>native threads</strong> can execute its threads (user threads) onto the operating system's threads (<strong>kernel threads</strong>). Every process has at least one kernel thread. Kernel threads are like processes, except that they share memory space in their owning process with all other threads in that process. A process \"owns\" all its assigned resources, like memory, file handles, sockets, device handles, etc., and these resources are all shared among its kernel threads.</p>\n\n<p>The operating system scheduler is part of the kernel that runs each thread for a certain amount time (on a single processor machine). The scheduler allocates time (timeslicing) to each thread, and if the thread isn't finished within that time, the scheduler pre-empts it (interrupts it and switches to another thread).  Multiple threads can run in parallel on a multi-processor machine, as each thread can be (but doesn't necessarily have to be) scheduled onto a separate processor.</p>\n\n<p>On a single processor machine, threads are timesliced and preempted (switched between) quickly (on Linux the default timeslice is 100ms) which makes them concurrent. However, they can't be run in parallel (simultaneously), since a single-core processor can only run one thing at a time.</p>\n\n<p><strong>Coroutines</strong> and/or <strong>generators</strong> can be used to implement cooperative functions. Instead of being run on kernel threads and scheduled by the operating system, they run in a single thread until they yield or finish, yielding to other functions as determined by the programmer. Languages with <strong>generators</strong>, such as Python and ECMAScript 6, can be used to build coroutines. Async/await (seen in C#, Python, ECMAscript 7, Rust) is an abstraction built on top of generator functions that yield futures/promises.</p>\n\n<p>In some contexts, <strong>coroutines</strong> may refer to stackful functions while <strong>generators</strong> may refer to stackless functions.</p>\n\n<p><strong>Fibers</strong>, <strong>lightweight threads</strong>, and <strong>green threads</strong> are other names for coroutines or coroutine-like things. They may sometimes look (typically on purpose) more like operating system threads in the programming language, but they do not run in parallel like real threads and work instead like coroutines. (There may be more specific technical particularities or differences among these concepts depending on the language or implementation.)</p>\n\n<p>For example, Java had \"<strong>green threads</strong>\"; these were threads that were scheduled by the Java virtual machine (JVM) instead of natively on the underlying operating system's kernel threads. These did not run in parallel or take advantage of multiple processors/cores--since that would require a native thread! Since they were not scheduled by the OS, they were more like coroutines than kernel threads. Green threads are what Java used until native threads were introduced into Java 1.2.</p>\n\n<p>Threads consume resources. In the JVM, each thread has its own stack, typically 1MB in size. 64k is the least amount of stack space allowed per thread in the JVM. The thread stack size can be configured on the command line for the JVM. Despite the name, threads are not free, due to their use resources like each thread needing its own stack, thread-local storage (if any), and the cost of thread scheduling/context-switching/CPU cache invalidation. This is part of the reason why coroutines have become popular for performance critical, highly-concurrent applications.</p>\n\n<p>Mac OS will only allow a process to allocate about 2000 threads, and Linux allocates 8MB stack per thread and will only allow as many threads that will fit in physical RAM.</p>\n\n<p>Hence, threads are the heaviest weight (in terms of memory usage and context-switching time), then coroutines, and finally generators are the lightest weight.</p>\n",
                    "OwnerUserId": "3417109",
                    "LastEditorUserId": "3417109",
                    "LastEditDate": "2017-09-01T22:50:25.263",
                    "LastActivityDate": "2017-09-01T22:50:25.263",
                    "CommentCount": "3",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "23914464",
                "ParentRepo": "https://github.com/lundberg/respx",
                "StackOverflow_Post": {
                    "Id": "23914464",
                    "PostTypeId": "2",
                    "ParentId": "15753390",
                    "CreationDate": "2014-05-28T14:29:26.087",
                    "Score": "246",
                    "Body": "<p>Try using the <a href=\"https://github.com/getsentry/responses\" rel=\"noreferrer\">responses library</a>. Here is an example from <a href=\"https://github.com/getsentry/responses#basics\" rel=\"noreferrer\">their documentation</a>:</p>\n<pre class=\"lang-py prettyprint-override\"><code>import responses\nimport requests\n\n@responses.activate\ndef test_simple():\n    responses.add(responses.GET, 'http://twitter.com/api/1/foobar',\n                  json={'error': 'not found'}, status=404)\n\n    resp = requests.get('http://twitter.com/api/1/foobar')\n\n    assert resp.json() == {&quot;error&quot;: &quot;not found&quot;}\n\n    assert len(responses.calls) == 1\n    assert responses.calls[0].request.url == 'http://twitter.com/api/1/foobar'\n    assert responses.calls[0].response.text == '{&quot;error&quot;: &quot;not found&quot;}'\n</code></pre>\n<p>It provides quite a nice convenience over setting up all the mocking yourself.</p>\n<p>There's also <a href=\"https://github.com/gabrielfalcao/HTTPretty\" rel=\"noreferrer\">HTTPretty</a>:</p>\n<p>It's not specific to <code>requests</code> library, more powerful in some ways though I found it doesn't lend itself so well to inspecting the requests that it intercepted, which <code>responses</code> does quite easily</p>\n<p>There's also <a href=\"https://github.com/patrys/httmock\" rel=\"noreferrer\">httmock</a>.</p>\n<p>A new library gaining popularity recently over the venerable <code>requests</code> is <a href=\"https://www.python-httpx.org/\" rel=\"noreferrer\"><code>httpx</code></a>, which adds first-class support for async. A mocking library for httpx is: <a href=\"https://github.com/lundberg/respx\" rel=\"noreferrer\">https://github.com/lundberg/respx</a></p>\n",
                    "OwnerUserId": "202168",
                    "LastEditorUserId": "202168",
                    "LastEditDate": "2022-06-23T11:51:57.123",
                    "LastActivityDate": "2022-06-23T11:51:57.123",
                    "CommentCount": "7",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "25588020",
                "ParentRepo": "https://github.com/pylast/pylast",
                "StackOverflow_Post": {
                    "Id": "25588020",
                    "PostTypeId": "2",
                    "ParentId": "25587992",
                    "CreationDate": "2014-08-31T00:47:34.627",
                    "Score": "4",
                    "Body": "<p>You are trying to call the <strong>documentation URL</strong>; the returned page explains how to use the API&lt; it is not the actual API method itself. Call the actual API at:</p>\n\n<pre><code>http://ws.audioscrobbler.com/2.0/\n</code></pre>\n\n<p>and give the method as a <em>parameter</em>:</p>\n\n<pre><code>params = {\n    \"method\": \"track.getSimilar\",\n    \"track\": \"Believe\",\n    \"artist\": \"Cher\",\n    \"limit\": \"5\",\n    \"api_key\":\"#my_api_key\"\n}\nr = request.get('http://ws.audioscrobbler.com/2.0/', params=params)\n</code></pre>\n\n<p>See the <a href=\"http://www.last.fm/api/intro\" rel=\"nofollow\">API introduction</a>:</p>\n\n<blockquote>\n  <p>The API root URL is located at <a href=\"http://ws.audioscrobbler.com/2.0/\" rel=\"nofollow\">http://ws.audioscrobbler.com/2.0/</a></p>\n</blockquote>\n\n<p>and the <a href=\"http://www.last.fm/api/rest\" rel=\"nofollow\">REST requests documentation</a>:</p>\n\n<blockquote>\n  <p>Generally speaking, you will send a method parameter expressed as 'package.method' along with method specific arguments to the root URL. The following parameters are required for all calls:</p>\n  \n  <p><strong><em>api_key</em></strong> : A Last.fm API Key.<br>\n  <strong><em>method</em></strong> : An API method expressed as package.method, corresponding to a documented last.fm API method name. </p>\n</blockquote>\n\n<p>Demo:</p>\n\n<pre><code>&gt;&gt;&gt; import requests\n&gt;&gt;&gt; params = {\n...     \"method\": \"track.getSimilar\",\n...     \"track\": \"Believe\",\n...     \"artist\": \"Cher\",\n...     \"limit\": \"5\",\n...     'api_key': '#a valid api key#',\n... }\n&gt;&gt;&gt; r = requests.get('http://ws.audioscrobbler.com/2.0/', params=params)\n&gt;&gt;&gt; r\n&lt;Response [200]&gt;\n&gt;&gt;&gt; r.headers['content-type']\n'text/xml; charset=utf-8;'\n&gt;&gt;&gt; r.content.splitlines()[1:3]\n['&lt;lfm status=\"ok\"&gt;', '&lt;similartracks track=\"Believe\" artist=\"Cher\"&gt;']\n</code></pre>\n\n<p>If you are using <code>requests</code> it may be easier to set the <code>format</code> parameter to <code>json</code>:</p>\n\n<pre><code>&gt;&gt;&gt; params['format']= 'json'\n&gt;&gt;&gt; r = requests.get('http://ws.audioscrobbler.com/2.0/', params=params)\n&gt;&gt;&gt; r.json()['similartracks']['@attr']\n{u'track': u'Believe', u'artist': u'Cher'}\n</code></pre>\n\n<p>However, rather than re-invent the wheel, you could use the <a href=\"https://github.com/pylast/pylast\" rel=\"nofollow\"><code>pyLast</code> module</a> instead:</p>\n\n<pre><code>import pylast\nfrom itertools import islice\n\n\nlast = pylast.LastFMNetwork(api_key=\"#your_api_key\", api_secret=\"#your_api_secret\")\ntrack = last.get_track('Cher', 'Believe')\nfor similar in islice(track.get_similar(), 5):\n    # limited to the first 5 similar tracks\n    print similar.item\n</code></pre>\n",
                    "OwnerUserId": "100297",
                    "LastEditorUserId": "896802",
                    "LastEditDate": "2015-04-30T04:08:07.440",
                    "LastActivityDate": "2015-04-30T04:08:07.440",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "29805400",
                "ParentRepo": "https://github.com/rollbar/pyrollbar",
                "StackOverflow_Post": {
                    "Id": "29805400",
                    "PostTypeId": "1",
                    "CreationDate": "2015-04-22T17:54:28.470",
                    "Score": "4",
                    "ViewCount": "1336",
                    "Body": "<p><strong>Technologies and Applications used</strong>: Rollbar, Django 1.7, Python 3.4</p>\n\n<p>So, I'm following the official documentation found here for integrating Rollbar into a python and Django based application: <a href=\"https://github.com/rollbar/pyrollbar\" rel=\"nofollow\">https://github.com/rollbar/pyrollbar</a>. Which includes: pip installing rollbar, adding the middleware class and creating the Rollbar dictionary configuration in a settings file, etc.</p>\n\n<p>Just to test things out I added the example they provided in their docs to one of my views, and Rollbar/Django works fine (i.e. Rollbar registers the exception and the exception is sent to my Rollbar account in the cloud):</p>\n\n<pre><code>try:\n    main_app_loop()\nexcept IOError:\n    rollbar.report_message('Got an IOError in the main loop', 'warning')\nexcept:\n   # catch-all\n   rollbar.report_exc_info()\n</code></pre>\n\n<p>But, for example, in one of my template files I misspell a block tag and get an error via Django's default error logging system. However, Rollbar doesn't record the error and/or it isn't sent to my Rollbar account in the cloud. Is that because Rollbar has to be integrated manually via some kind of try, catch scenario? Or can Rollbar just grab errors by default without having to write a try, catch? </p>\n\n<p>There is no other documentation I kind find for integrating Rollbar into a Django project other than what is found on the above link, so I'm not sure what to do next. Anyone else run into this or know what the issue might be?</p>\n",
                    "OwnerUserId": "2241614",
                    "LastEditorUserId": "2577852",
                    "LastEditDate": "2016-05-14T08:59:58.423",
                    "LastActivityDate": "2016-05-14T08:59:58.423",
                    "Title": "Why isn't Rollbar catching my exceptions in my Django/Python app?",
                    "Tags": "<python><django><logging><error-handling><rollbar>",
                    "AnswerCount": "0",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "30018904",
                "ParentRepo": "https://github.com/w3c/web-platform-tests/blob/master/webdriver/navigation/auth_tests.py",
                "StackOverflow_Post": {
                    "Id": "30018904",
                    "PostTypeId": "2",
                    "ParentId": "5672407",
                    "CreationDate": "2015-05-03T20:17:13.547",
                    "Score": "3",
                    "Body": "<p>For more portability, this can be handled by stub API and using <a href=\"http://seleniumhq.github.io/selenium/docs/api/java/org/openqa/selenium/Alert.html\" rel=\"nofollow noreferrer\">Alert</a>.</p>\n\n<p>Example Java code (<a href=\"https://github.com/alkedr/yama-test-staging/blob/727dfb566bb99c2537bca5f97c748e107c571694/webdriver-allure-wrapper/src/main/java/ru/yandex/autotests/market/frontend/AlertAllureAdapter.java\" rel=\"nofollow noreferrer\">sample</a>):</p>\n\n<pre><code>import org.openqa.selenium.Alert;\nimport org.openqa.selenium.security.Credentials;\npublic void authenticateUsing(Credentials credentials) {\n    private final Alert alert;\n    alert.authenticateUsing(credentials);\n}\n</code></pre>\n\n<p>See also: <a href=\"https://github.com/w3c/web-platform-tests/blob/master/webdriver/navigation/auth_tests.py\" rel=\"nofollow noreferrer\">auth_tests.py</a></p>\n\n<p>Or by sending keys manually like:</p>\n\n<pre><code>SendKeys(\"user\");\nSendKeys(\"{TAB}\");\nSendKeys(\"password\");\nSendKeys(\"~\"); // Enter\n</code></pre>\n\n<p>See also the following feature request: <a href=\"https://github.com/SeleniumHQ/selenium/issues/453\" rel=\"nofollow noreferrer\">#453 Portable BASIC Auth at GitHub</a></p>\n\n<p>Related:</p>\n\n<ul>\n<li><a href=\"https://sqa.stackexchange.com/q/12892/2840\">How to send Basic Authentication headers in Selenium?</a> at QA SE</li>\n</ul>\n",
                    "OwnerUserId": "55075",
                    "LastEditorUserId": "-1",
                    "LastEditDate": "2017-04-13T12:41:46.237",
                    "LastActivityDate": "2015-05-03T20:17:13.547",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "30064664",
                "ParentRepo": "https://github.com/miketheman/pytest-socket",
                "StackOverflow_Post": {
                    "Id": "30064664",
                    "PostTypeId": "2",
                    "ParentId": "18601828",
                    "CreationDate": "2015-05-05T23:01:37.610",
                    "Score": "23",
                    "Body": "<p><strong>Update</strong>: There is now a pytest plugin that does the same thing as this answer! You can read the answer just to see how things work, but I <strong>strongly</strong> recommend using the plugin instead of copying-pasting my answer :-) See here: <a href=\"https://github.com/miketheman/pytest-socket\" rel=\"nofollow noreferrer\">https://github.com/miketheman/pytest-socket</a></p>\n<hr />\n<p>I found Thomas Orozco's answer to be very helpful. Following on keflavich, this is how I integrated into my unit test suite. This works for me with thousands of very different unit test-cases (&lt;100 that need socket though) ... and in and out of doctests.</p>\n<p>I posted it <a href=\"https://gist.github.com/hangtwenty/9200597e3be274c79896\" rel=\"nofollow noreferrer\">here</a>. Including below for convenience. Tested with Python 2.7.5, pytest==2.7.0. (To test for yourself, run <code>py.test --doctest-modules</code> in directory with all 3 files cloned.)</p>\n<p><strong>_socket_toggle.py</strong></p>\n<pre><code>from __future__ import print_function\nimport socket\nimport sys\n\n_module = sys.modules[__name__]\n\ndef disable_socket():\n    &quot;&quot;&quot; disable socket.socket to disable the Internet. useful in testing.\n\n    .. doctest::\n        &gt;&gt;&gt; enable_socket()\n        [!] socket.socket is enabled.\n        &gt;&gt;&gt; disable_socket()\n        [!] socket.socket is disabled. Welcome to the desert of the real.\n        &gt;&gt;&gt; socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        Traceback (most recent call last):\n        ...\n        RuntimeError: I told you not to use the Internet!\n        &gt;&gt;&gt; enable_socket()\n        [!] socket.socket is enabled.\n        &gt;&gt;&gt; enable_socket()\n        [!] socket.socket is enabled.\n        &gt;&gt;&gt; disable_socket()\n        [!] socket.socket is disabled. Welcome to the desert of the real.\n        &gt;&gt;&gt; socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        Traceback (most recent call last):\n        ...\n        RuntimeError: I told you not to use the Internet!\n        &gt;&gt;&gt; enable_socket()\n        [!] socket.socket is enabled.\n    &quot;&quot;&quot;\n    setattr(_module, '_socket_disabled', True)\n\n    def guarded(*args, **kwargs):\n        if getattr(_module, '_socket_disabled', False):\n            raise RuntimeError(&quot;I told you not to use the Internet!&quot;)\n        else:\n            # SocketType is a valid public alias of socket.socket,\n            # we use it here to avoid namespace collisions\n            return socket.SocketType(*args, **kwargs)\n\n    socket.socket = guarded\n\n    print(u'[!] socket.socket is disabled. Welcome to the desert of the real.')\n\n\ndef enable_socket():\n    &quot;&quot;&quot; re-enable socket.socket to enable the Internet. useful in testing.\n    &quot;&quot;&quot;\n    setattr(_module, '_socket_disabled', False)\n    print(u'[!] socket.socket is enabled.')\n</code></pre>\n<p><strong>conftest.py</strong></p>\n<pre><code># Put this in the conftest.py at the top of your unit tests folder,\n# so it's available to all unit tests\nimport pytest\nimport _socket_toggle\n\n\ndef pytest_runtest_setup():\n    &quot;&quot;&quot; disable the interet. test-cases can explicitly re-enable &quot;&quot;&quot;\n    _socket_toggle.disable_socket()\n\n\n@pytest.fixture(scope='function')\ndef enable_socket(request):\n    &quot;&quot;&quot; re-enable socket.socket for duration of this test function &quot;&quot;&quot;\n    _socket_toggle.enable_socket()\n    request.addfinalizer(_socket_toggle.disable_socket)\n</code></pre>\n<p><strong>test_example.py</strong></p>\n<pre><code># Example usage of the py.test fixture in tests\nimport socket\nimport pytest\n\ntry:\n    from urllib2 import urlopen\nexcept ImportError:\n    import urllib3\n    urlopen = urllib.request.urlopen\n\n\ndef test_socket_disabled_by_default():\n    # default behavior: socket.socket is unusable\n    with pytest.raises(RuntimeError):\n        urlopen(u'https://www.python.org/')\n\n\ndef test_explicitly_enable_socket(enable_socket):\n    # socket is enabled by pytest fixture from conftest. disabled in finalizer\n    assert socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n</code></pre>\n",
                    "OwnerUserId": "884640",
                    "LastEditorUserId": "884640",
                    "LastEditDate": "2022-08-29T21:22:13.603",
                    "LastActivityDate": "2022-08-29T21:22:13.603",
                    "CommentCount": "5",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "30949557",
                "ParentRepo": "https://github.com/thomas-xin/Miza/blob/dabf27408effa1d5a44e09f73b1ad7dddc2a1452/misc/page_tokens.txt",
                "StackOverflow_Post": {
                    "Id": "30949557",
                    "PostTypeId": "2",
                    "ParentId": "30949556",
                    "CreationDate": "2015-06-20T02:08:52.407",
                    "Score": "13",
                    "Body": "<p>A YouTube pageToken is six characters long. Here's what I've been able to determine about the format:</p>\n<p>char 1: Always 'C' that I've seen.\nchar 2-3: Encoded start position\nchar 4-5: Always 'QA' that I've seen.\nchar 6: 'A' means list items in a position greater than or equal to the start position. 'Q' means list items before the start position.</p>\n<p>Due to the nature of character 6, there are two different ways to represent the same page. Given maxResults=1, page 2 can be reached by setting the page token to either &quot;CAEQAA&quot; or &quot;CAIQAQ&quot;. The first one means to start at result number 2 (represented by characters 2-3 &quot;AE&quot;) and list 1 item. The second means to return one item before result number 3 (represented by characters 2-3 &quot;AI&quot;.</p>\n<p>Characters 2-3 are a strange base 16 encoding.</p>\n<p>Character 3 uses a list from A-Z, then a-z, then 0-9 and increments by 4 in the list for each increase of 1. The series is A,E,I,M,Q,U,Y,c,g,k,o,s,w,0,4,8. Character 2 goes from A to B to C to D and so on. For my purposes, I'm not working with large result sets, so I haven't bothered to see what happens to the second character beyond a couple hundred results. Perhaps someone working with larger sets will provide an update as to how character 2 behaves after that.</p>\n<p>Since the string only contains a start position and an option for &quot;&gt;=&quot; or &quot;&lt;&quot;, the same string is used in multiple cases. For instance, with 2 results per page, the start position of the second page is result 3. The pageToken for this is &quot;CAIQAA&quot;. This is identical to the token for the third page with one result per page.</p>\n<p>Since I'm primarily a php person, here's the function I'm using to get the pageToken for a given page:</p>\n<pre><code>function token($limit, $page) {\n    $start = 1 + ($page - 1) * $limit;\n    $third_chars = array_merge(\n            range(&quot;A&quot;,&quot;Z&quot;,4),\n            range(&quot;c&quot;,&quot;z&quot;,4),\n            range(0,9,4));\n    return 'C'.\n           chr(ord('A') + floor($start / 16)).\n           $third_chars[($start % 16) - 1].\n           'QAA';\n}\n$limit = 1;\necho &quot;With $limit result(s) per page...&quot;.PHP_EOL;\nfor ($i = 1; $i &lt; 6; ++$i) {\n    echo &quot;The token for page $i is &quot;.token($limit, $i).PHP_EOL;\n}\n</code></pre>\n<p>Please test this function in your project and update the rest of us if you find a flaw or an enhancement since YouTube hasn't provided us with an easy way to do this.</p>\n<p>Edit: The page token sequence for YouTube API v3 has been changed, and this system will no longer work. For an example of the most up-to-date and working page tokens, see <a href=\"https://github.com/thomas-xin/Miza/blob/dabf27408effa1d5a44e09f73b1ad7dddc2a1452/misc/page_tokens.txt\" rel=\"nofollow noreferrer\">this page</a>.</p>\n",
                    "OwnerUserId": "2001325",
                    "LastEditorUserId": "1526321",
                    "LastEditDate": "2021-10-25T19:35:05.273",
                    "LastActivityDate": "2021-10-25T19:35:05.273",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "31368818",
                "ParentRepo": "https://github.com/leandrotoledo/python-telegram-bot",
                "StackOverflow_Post": {
                    "Id": "31368818",
                    "PostTypeId": "2",
                    "ParentId": "30156609",
                    "CreationDate": "2015-07-12T14:26:31.557",
                    "Score": "1",
                    "Body": "<p>The Telegram Bot API is now officially available.</p>\n\n<p>Resources:</p>\n\n<ul>\n<li><a href=\"https://core.telegram.org/bots/\" rel=\"nofollow\">Introduction</a></li>\n<li><a href=\"https://core.telegram.org/bots/api\" rel=\"nofollow\">API</a></li>\n<li><a href=\"https://github.com/leandrotoledo/python-telegram-bot\" rel=\"nofollow\">Python wrapper</a></li>\n<li><a href=\"https://www.npmjs.com/search?q=telegram+bot\" rel=\"nofollow\">Node.js wrappers</a></li>\n<li><a href=\"https://github.com/bennesp/telegramAPI\" rel=\"nofollow\">Ruby wrapper</a> - <a href=\"https://github.com/eljojo/telegram_bot\" rel=\"nofollow\">Another one</a></li>\n<li><a href=\"https://github.com/pathetic/tgbot-php\" rel=\"nofollow\">PHP wrapper</a></li>\n</ul>\n",
                    "OwnerUserId": "1633924",
                    "LastActivityDate": "2015-07-12T14:26:31.557",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "31930347",
                "ParentRepo": "https://github.com/python-telegram-bot/python-telegram-bot",
                "StackOverflow_Post": {
                    "Id": "31930347",
                    "PostTypeId": "5",
                    "CreationDate": "2015-08-10T22:40:34.967",
                    "Score": "0",
                    "Body": "<p>This is a <a href=\"/questions/tagged/python\" class=\"post-tag\" title=\"show questions tagged &#39;python&#39;\" rel=\"tag\">python</a> library that wraps around the <a href=\"/questions/tagged/telegram\" class=\"post-tag\" title=\"show questions tagged &#39;telegram&#39;\" rel=\"tag\">telegram</a> bot HTTP API. It is compatible with <a href=\"/questions/tagged/python-3.x\" class=\"post-tag\" title=\"show questions tagged &#39;python-3.x&#39;\" rel=\"tag\">python-3.x</a> only (please check the PyPi/GitHub page for detailed info).</p>\n<p><strong>Telegram Bot API</strong></p>\n<p>The <a href=\"https://core.telegram.org/bots\" rel=\"nofollow noreferrer\">Telegram Bot API</a> is an HTTP-based interface created for developers keen on building bots for Telegram.</p>\n<ul>\n<li><a href=\"https://pypi.python.org/pypi/python-telegram-bot/\" rel=\"nofollow noreferrer\">Python package index page</a></li>\n<li><a href=\"https://github.com/python-telegram-bot/python-telegram-bot\" rel=\"nofollow noreferrer\">Source code on Github</a></li>\n<li><a href=\"https://github.com/python-telegram-bot/python-telegram-bot/wiki\" rel=\"nofollow noreferrer\">Library Wiki</a></li>\n<li><a href=\"https://python-telegram-bot.readthedocs.io/en/stable/\" rel=\"nofollow noreferrer\">Official Documentation</a></li>\n<li><a href=\"http://t.me/pythontelegrambotgroup\" rel=\"nofollow noreferrer\">Library Official Telegram Help Group</a></li>\n</ul>\n",
                    "OwnerUserId": "5113242",
                    "LastEditorUserId": "10606962",
                    "LastEditDate": "2021-08-01T08:47:21.807",
                    "LastActivityDate": "2021-08-01T08:47:21.807",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "32262484",
                "ParentRepo": "https://github.com/zalando/connexion",
                "StackOverflow_Post": {
                    "Id": "32262484",
                    "PostTypeId": "2",
                    "ParentId": "32253883",
                    "CreationDate": "2015-08-28T02:33:17.733",
                    "Score": "4",
                    "Body": "<p>Take a look at <a href=\"https://github.com/zalando/connexion\" rel=\"nofollow\">https://github.com/zalando/connexion</a>.  This gives a swagger-first way to build out your app.  Similar to <code>swagger-node</code> and <code>swagger-inflector</code> in the <a href=\"https://github.com/swagger-api\" rel=\"nofollow\">https://github.com/swagger-api</a> repository</p>\n",
                    "OwnerUserId": "420797",
                    "LastActivityDate": "2015-08-28T02:33:17.733",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "33557530",
                "ParentRepo": "https://github.com/biolab/orange3/wiki/Installation-on-openSUSE-13.2",
                "StackOverflow_Post": {
                    "Id": "33557530",
                    "PostTypeId": "1",
                    "CreationDate": "2015-11-06T00:41:44.217",
                    "Score": "0",
                    "ViewCount": "145",
                    "Body": "<p>I am having trouble installing Orange3 from github on openSUSE 13.1.</p>\n\n<p>I have all requirements installed: gcc, g++, python 3-devel, pysci, pyqt4devel etc.</p>\n\n<p>I followed <a href=\"https://github.com/biolab/orange3/wiki/Installation-on-openSUSE-13.2\" rel=\"nofollow\">these</a> instructions, everything seems to work (with many warnings when compiling), however when entering in <code>Orange.canvas</code>, there are no widgets at all. It seems they have been missing on installation/compilation.</p>\n\n<p>Any idea about what I did miss in the install or requirements?</p>\n",
                    "OwnerUserId": "4243578",
                    "LastEditorUserId": "2675154",
                    "LastEditDate": "2015-11-07T13:12:41.357",
                    "LastActivityDate": "2015-11-07T18:29:38.363",
                    "Title": "Orange 3 - openSUSE 13.1 installation - No widgets",
                    "Tags": "<opensuse><orange>",
                    "AnswerCount": "1",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "35650664",
                "ParentRepo": "https://github.com/ets-labs/python-dependency-injector",
                "StackOverflow_Post": {
                    "Id": "35650664",
                    "PostTypeId": "2",
                    "ParentId": "31678827",
                    "CreationDate": "2016-02-26T11:35:17.563",
                    "Score": "17",
                    "Body": "<p>Some time ago I wrote dependency injection microframework with a ambition to make it Pythonic - <a href=\"https://github.com/ets-labs/python-dependency-injector\" rel=\"noreferrer\">Dependency Injector</a>. That's how your code can look like in case of its usage:</p>\n\n<pre><code>\"\"\"Example of dependency injection in Python.\"\"\"\n\nimport logging\nimport sqlite3\n\nimport boto.s3.connection\n\nimport example.main\nimport example.services\n\nimport dependency_injector.containers as containers\nimport dependency_injector.providers as providers\n\n\nclass Platform(containers.DeclarativeContainer):\n    \"\"\"IoC container of platform service providers.\"\"\"\n\n    logger = providers.Singleton(logging.Logger, name='example')\n\n    database = providers.Singleton(sqlite3.connect, ':memory:')\n\n    s3 = providers.Singleton(boto.s3.connection.S3Connection,\n                             aws_access_key_id='KEY',\n                             aws_secret_access_key='SECRET')\n\n\nclass Services(containers.DeclarativeContainer):\n    \"\"\"IoC container of business service providers.\"\"\"\n\n    users = providers.Factory(example.services.UsersService,\n                              logger=Platform.logger,\n                              db=Platform.database)\n\n    auth = providers.Factory(example.services.AuthService,\n                             logger=Platform.logger,\n                             db=Platform.database,\n                             token_ttl=3600)\n\n    photos = providers.Factory(example.services.PhotosService,\n                               logger=Platform.logger,\n                               db=Platform.database,\n                               s3=Platform.s3)\n\n\nclass Application(containers.DeclarativeContainer):\n    \"\"\"IoC container of application component providers.\"\"\"\n\n    main = providers.Callable(example.main.main,\n                              users_service=Services.users,\n                              auth_service=Services.auth,\n                              photos_service=Services.photos)\n</code></pre>\n\n<p>Here is a link to more extensive description of this example - <a href=\"http://python-dependency-injector.ets-labs.org/examples/services_miniapp.html\" rel=\"noreferrer\">http://python-dependency-injector.ets-labs.org/examples/services_miniapp.html</a></p>\n\n<p>Hope it can help a bit. For more information please visit:</p>\n\n<ul>\n<li>GitHub <a href=\"https://github.com/ets-labs/python-dependency-injector\" rel=\"noreferrer\">https://github.com/ets-labs/python-dependency-injector</a></li>\n<li>Docs <a href=\"http://python-dependency-injector.ets-labs.org/\" rel=\"noreferrer\">http://python-dependency-injector.ets-labs.org/</a></li>\n</ul>\n",
                    "OwnerUserId": "4224605",
                    "LastEditorUserId": "4224605",
                    "LastEditDate": "2017-01-26T13:05:28.710",
                    "LastActivityDate": "2017-01-26T13:05:28.710",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "36752767",
                "ParentRepo": "https://github.com/DonJayamanne/pythonVSCode/wiki/Python-Path-and-Version",
                "StackOverflow_Post": {
                    "Id": "36752767",
                    "PostTypeId": "2",
                    "ParentId": "36705579",
                    "CreationDate": "2016-04-20T18:57:12.010",
                    "Score": "1",
                    "Body": "<p>This is working for me, but only for local files. See screenshot below:</p>\n\n<p><a href=\"https://i.stack.imgur.com/LTwmP.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/LTwmP.png\" alt=\"enter image description here\"></a></p>\n\n<p>I am using <a href=\"https://code.visualstudio.com/docs?dv=winzip\" rel=\"nofollow noreferrer\">portable 1.0.0 zip</a> on windows 7. I installed <a href=\"https://marketplace.visualstudio.com/items?itemName=donjayamanne.python\" rel=\"nofollow noreferrer\">Don Jayamanne's Python extension</a>. Maybe you need it for it to work? Haven't tried without it. </p>\n\n<p>In case you are unfamiliar with the extension, there are some configuration changes to make after you install it if python is not in your PATH.</p>\n\n<p>You will have to tell it where your python lives using these <a href=\"https://github.com/DonJayamanne/pythonVSCode/wiki/Python-Path-and-Version\" rel=\"nofollow noreferrer\">config updates</a>:</p>\n\n<blockquote>\n  <p>Configure the path to the python interpreter in the User Settings file\n  (settings.json) as follows. Ensure to specify the fully qualified name\n  of the python executable. \n  \"python.pythonPath\":\"c:/python27/python.exe\"</p>\n</blockquote>\n\n<p>I also updated the <a href=\"https://github.com/DonJayamanne/pythonVSCode/wiki/Python-Path-and-Version#python-version-used-for-debugging\" rel=\"nofollow noreferrer\">debugging setting too</a>, not sure if that has any impact.</p>\n\n<pre><code>Simply provide the fully qualified path to the python executable in the \"python\" setting within the configuration settings in the launch.json file as follows:\n\n{\n    \"name\": \"Python\",\n    \"type\": \"python\",\n    \"request\": \"launch\",\n    \"stopOnEntry\": true,\n    \"program\": \"${file}\",\n    \"pythonPath\": \"c:/python27/python.exe\",\n    \"debugOptions\": [\n        \"WaitOnAbnormalExit\",\n        \"WaitOnNormalExit\",\n        \"RedirectOutput\"\n    ]\n}\n</code></pre>\n",
                    "OwnerUserId": "1519290",
                    "LastEditorUserId": "1519290",
                    "LastEditDate": "2016-04-23T15:58:02.133",
                    "LastActivityDate": "2016-04-23T15:58:02.133",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "36802211",
                "ParentRepo": "https://github.com/jupyterhub/jupyterhub/wiki/Using-sudo-to-run-JupyterHub-without-root-privileges",
                "StackOverflow_Post": {
                    "Id": "36802211",
                    "PostTypeId": "1",
                    "CreationDate": "2016-04-22T19:49:16.713",
                    "Score": "2",
                    "ViewCount": "1102",
                    "Body": "<p>Getting Python right on Mac seems a constant challenge.  I'm working with a Homebrew implementation, and now have difficulty running Jupyter except with sudo:</p>\n\n<pre><code>$ which python\n/usr/local/bin/python\n$ which pip\n/Users/username/bin/pip\n$ which jupyter\n/usr/local/bin/jupyter\n$ jupyter notebook\nTraceback (most recent call last):\n  File \"/usr/local/bin/jupyter\", line 7, in &lt;module&gt;\n    from jupyter_core.command import main\nImportError: No module named jupyter_core.command\n$ sudo jupyter notebook\nThe Jupyter Notebook is running at: http://localhost:8888/\n</code></pre>\n\n<p>Once running, Jupyter fails to import pandas (installed via <code>pip install pandas</code>):</p>\n\n<pre><code>import pandas\nImportError                               Traceback (most recent call last)\n&lt;ipython-input-18-d6ac987968b6&gt; in &lt;module&gt;()\n----&gt; 1 import pandas\nImportError: No module named pandas\n</code></pre>\n\n<p>.. even though pandas is available (<code>python -s 'import pandas'</code> works fine).  Guessing its path isn't available to root.</p>\n\n<p>I'm wondering if Jupyter is <a href=\"https://github.com/jupyterhub/jupyterhub/wiki/Using-sudo-to-run-JupyterHub-without-root-privileges\" rel=\"nofollow\">particularly problematic</a> or if this is just my setup..?</p>\n\n<p>Grateful for assistance as this is becoming very tiresome.  Any guidance on wiping python and reinstalling 'properly' from scratch would be handy.</p>\n\n<hr>\n\n<p>Edit:</p>\n\n<pre><code>$ which virtualenv\n/usr/local/bin/virtualenv\n21:16 $ virtualenv\nTraceback (most recent call last):\n  File \"/usr/local/bin/virtualenv\", line 7, in &lt;module&gt;\n    from virtualenv import main\nImportError: No module named virtualenv\n</code></pre>\n",
                    "OwnerUserId": "1156245",
                    "LastEditorUserId": "1156245",
                    "LastEditDate": "2016-04-22T20:17:23.770",
                    "LastActivityDate": "2016-04-22T20:17:23.770",
                    "Title": "Fixing Python on Mac",
                    "Tags": "<python><macos><jupyter>",
                    "AnswerCount": "2",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "36883703",
                "ParentRepo": "https://github.com/biolab/orange3-text/issues",
                "StackOverflow_Post": {
                    "Id": "36883703",
                    "PostTypeId": "2",
                    "ParentId": "36870011",
                    "CreationDate": "2016-04-27T07:56:32.847",
                    "Score": "1",
                    "Body": "<p>We are well aware of this problem and are currently trying to resolve it with authors of <a href=\"https://github.com/piskvorky/smart_open\" rel=\"nofollow\">smart_open</a> (which we require through <a href=\"https://github.com/piskvorky/gensim\" rel=\"nofollow\">gensim</a> - one of our dependencies). The problem occurs since <a href=\"https://github.com/piskvorky/smart_open/issues/40\" rel=\"nofollow\">gensim cannot be installed</a> with environment variable <code>LC_ALL=C</code> which is how we install add-ons. Currently, I would suggest to install it through the terminal. On a Mac this can be done by going to Orange's installation folder and running the <code>pip install</code>:</p>\n\n<pre><code>cd /Applications/Orange3.app/Contents/MacOS\n./pip install Orange3-Text\n</code></pre>\n\n<p>Beware that Orange3-Text is still in development and some major changes are coming through the summer. So if you encounter any issues, please report them on our <a href=\"https://github.com/biolab/orange3-text/issues\" rel=\"nofollow\">issue tracker</a>.</p>\n",
                    "OwnerUserId": "892987",
                    "LastActivityDate": "2016-04-27T07:56:32.847",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "37451775",
                "ParentRepo": "https://github.com/abhinavsingh/proxy.py",
                "StackOverflow_Post": {
                    "Id": "37451775",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "37451821",
                    "CreationDate": "2016-05-26T04:44:04.783",
                    "Score": "0",
                    "ViewCount": "134",
                    "Body": "<p>I am trying to set up an HTTP proxy using Python. I found this library on GitHub: <a href=\"https://github.com/abhinavsingh/proxy.py\" rel=\"nofollow\">https://github.com/abhinavsingh/proxy.py</a>. However, I noticed that it is a generic proxy--it extracts the target server from the original HTTP request, and uses that to construct it's own HTTP request.</p>\n\n<p>What I'd like to make is a proxy that points to only one server, www.targetserver.com. How can I go about this?</p>\n",
                    "OwnerUserId": "58109",
                    "LastActivityDate": "2016-05-26T04:49:12.387",
                    "Title": "How to make an HTTP proxy that points to a specific server",
                    "Tags": "<python><proxy>",
                    "AnswerCount": "1",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "43310169",
                "ParentRepo": "https://github.com/microsoftgraph/msgraph-sdk-python",
                "StackOverflow_Post": {
                    "Id": "43310169",
                    "PostTypeId": "2",
                    "ParentId": "43300979",
                    "CreationDate": "2017-04-09T18:09:11.257",
                    "Score": "1",
                    "Body": "<p>There is a create folder operation, although it seems <a href=\"https://msdn.microsoft.com/en-us/office/office365/api/mail-rest-operations#CreateFolders\" rel=\"nofollow noreferrer\">specific to Mail folders</a> and doesn't take any parameters that can specify a folder type.  It's possible it may take on the same item type as the parent folder, but I'm  not certain.</p>\n\n<p>Otherwise there is a create method specific for Contact folders in the Graph API; see <a href=\"https://developer.microsoft.com/en-us/graph/docs/api-reference/v1.0/api/contactfolder_post_childfolders\" rel=\"nofollow noreferrer\">https://developer.microsoft.com/en-us/graph/docs/api-reference/v1.0/api/contactfolder_post_childfolders</a>.</p>\n\n<p>If you want a Python specific SDK, see: <a href=\"https://github.com/microsoftgraph/msgraph-sdk-python\" rel=\"nofollow noreferrer\">https://github.com/microsoftgraph/msgraph-sdk-python</a>. Code samples: <a href=\"https://github.com/search?q=python+sample+user:microsoftgraph&amp;type=Repositories\" rel=\"nofollow noreferrer\">https://github.com/search?q=python+sample+user:microsoftgraph&amp;type=Repositories</a></p>\n\n<p>FYI, you can use any code platform to work with the Office 365 or Graph APIs, as long as they support REST.</p>\n",
                    "OwnerUserId": "519226",
                    "LastActivityDate": "2017-04-09T18:09:11.257",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "43344319",
                "ParentRepo": "https://github.com/microsoft/vscode-python/blob/master/CHANGELOG.md#2019100-8-october-2019",
                "StackOverflow_Post": {
                    "Id": "43344319",
                    "PostTypeId": "2",
                    "ParentId": "40831593",
                    "CreationDate": "2017-04-11T11:13:44.147",
                    "Score": "84",
                    "Body": "<p>Either use setup.cfg for single project or change your user settings for all py files.</p>\n\n<pre class=\"lang-js prettyprint-override\"><code>{\n    \"python.linting.pycodestyleEnabled\": true,\n    \"python.linting.pycodestyleArgs\": [\n        \"--ignore=E501\" \n    ]\n}\n</code></pre>\n\n<p>Before <a href=\"https://github.com/microsoft/vscode-python/blob/master/CHANGELOG.md#2019100-8-october-2019\" rel=\"noreferrer\">October 2019</a> all <code>pycodestyle</code> settings  were named <code>pep8</code>:</p>\n\n<pre class=\"lang-js prettyprint-override\"><code>{\n    \"python.linting.pep8Enabled\": true,\n    \"python.linting.pep8Args\": [\n        \"--ignore=E501\" \n    ]\n}\n</code></pre>\n",
                    "OwnerUserId": "997977",
                    "LastEditorUserId": "405017",
                    "LastEditDate": "2019-11-12T20:08:48.533",
                    "LastActivityDate": "2019-11-12T20:08:48.533",
                    "CommentCount": "4",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "44257741",
                "ParentRepo": "https://github.com/RasaHQ/rasa_nlu",
                "StackOverflow_Post": {
                    "Id": "44257741",
                    "PostTypeId": "2",
                    "ParentId": "44253194",
                    "CreationDate": "2017-05-30T08:56:48.217",
                    "Score": "3",
                    "Body": "<p>This is called \"intent analysis\". There are such libraries, for example <a href=\"https://github.com/RasaHQ/rasa_nlu\" rel=\"nofollow noreferrer\">RASA</a></p>\n\n<p>For example you input is \"show me chinese restaurants\". The output would be</p>\n\n<pre><code>{\n  \"text\": \"show me chinese restaurants\",\n  \"intent\": \"restaurant_search\",\n  \"entities\": [\n    {\n      \"start\": 8,\n      \"end\": 15,\n      \"value\": \"chinese\",\n      \"entity\": \"cuisine\"\n    }\n  ]\n}\n</code></pre>\n\n<p>Overall it is pretty advanced NLU.</p>\n",
                    "OwnerUserId": "432021",
                    "LastActivityDate": "2017-05-30T08:56:48.217",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "44421113",
                "ParentRepo": "https://github.com/python273/telegraph/blob/master/telegraph/api.py",
                "StackOverflow_Post": {
                    "Id": "44421113",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "44423745",
                    "CreationDate": "2017-06-07T19:19:10.407",
                    "Score": "3",
                    "ViewCount": "3979",
                    "Body": "<p>I am using the <code>telegra.ph</code> <a href=\"https://github.com/python273/telegraph/blob/master/telegraph/api.py\" rel=\"nofollow noreferrer\">api</a> to edit the page I have made. I want to format the text that I have on the page to align to the right of the page. Right now the content that I am sending through a Python request is:</p>\n\n<pre><code>from telegraph import Telegraph\ntel = Telegraph(my_access_token)\n\ncontent = [{\"tag\": \"h4\",\n            \"children\": [\"Hello, World!\"]},\n            \"attrs\": {\"dir\": \"rtl\"}\n            }]\n\npage = tel.edit_page(path='/url',\n                     title='testing',\n                     content=content,\n                     )\n</code></pre>\n\n<p>However the request completely ignores the <code>\"dir\": \"rtl\"</code> attribute, since \"dir\" is not one of the attributes that <a href=\"http://telegra.ph/api\" rel=\"nofollow noreferrer\">Telegraph</a> accepts. How can one align the text to the right through <code>telegra.ph</code>?</p>\n",
                    "OwnerUserId": "7992467",
                    "LastEditorUserId": "6375113",
                    "LastEditDate": "2017-07-04T15:03:41.863",
                    "LastActivityDate": "2017-08-03T16:22:07.867",
                    "Title": "How to use HTML formatting with telegra.ph API",
                    "Tags": "<python><html><python-requests><python-telegram-bot>",
                    "AnswerCount": "2",
                    "CommentCount": "1",
                    "FavoriteCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "44556106",
                "ParentRepo": "https://github.com/impredicative/irc-rss-feed-bot/blob/5bcae4a/ircrssfeedbot/util/hashlib.py",
                "StackOverflow_Post": {
                    "Id": "44556106",
                    "PostTypeId": "2",
                    "ParentId": "44556105",
                    "CreationDate": "2017-06-14T23:16:05.680",
                    "Score": "21",
                    "Body": "<h3>Using hash</h3>\n<p>A cryptographic hash is assumably a uniformly distributed integer in the range [0, MAX_HASH]. Accordingly, it can be scaled to a floating-point number in the range [0, 1) by dividing it by MAX_HASH + 1.</p>\n<pre><code>import hashlib\n\nHash = hashlib.sha512\nMAX_HASH_PLUS_ONE = 2**(Hash().digest_size * 8)\n\ndef str_to_probability(in_str):\n    &quot;&quot;&quot;Return a reproducible uniformly random float in the interval [0, 1) for the given string.&quot;&quot;&quot;\n    seed = in_str.encode()\n    hash_digest = Hash(seed).digest()\n    hash_int = int.from_bytes(hash_digest, 'big')  # Uses explicit byteorder for system-agnostic reproducibility\n    return hash_int / MAX_HASH_PLUS_ONE  # Float division\n\n&gt;&gt;&gt; str_to_probability('a3b2Foobar')\n0.3659629991207491\n</code></pre>\n<p>Here is a real world <a href=\"https://github.com/impredicative/irc-rss-feed-bot/blob/5bcae4a/ircrssfeedbot/util/hashlib.py\" rel=\"nofollow noreferrer\">usage example</a>.</p>\n<p>Notes:</p>\n<ul>\n<li>The built-in\n<a href=\"https://docs.python.org/3/reference/datamodel.html#object.__hash__\" rel=\"nofollow noreferrer\"><code>hash</code></a>\nmethod must not be used because it can preserve the input's\ndistribution, e.g. with <code>hash(123)</code>. Alternatively, it can return values that differ when Python is restarted, e.g. with <code>hash('123')</code>.</li>\n<li>Using modulo is not necessary as float division is sufficient.</li>\n</ul>\n<h3>Using random</h3>\n<p>The <a href=\"https://docs.python.org/library/random.html\" rel=\"nofollow noreferrer\"><code>random</code></a> module can be used with <code>in_str</code> as its seed, while addressing concerns surrounding both <a href=\"https://stackoverflow.com/questions/10021882/how-do-i-make-randint-threadsafe-in-python\">thread safety</a> and continuity.</p>\n<p>With this approach, not only is cross-language reproducibility a concern, but reproducibility across multiple future versions of Python could also be a concern. It is therefore not recommended.</p>\n<pre><code>import random\n\ndef str_to_probability(in_str):\n    &quot;&quot;&quot;Return a reproducible uniformly random float in the interval [0, 1) for the given seed.&quot;&quot;&quot;\n    return random.Random(in_str).random()\n\n&gt;&gt;&gt; str_to_probability('a3b2Foobar')\n0.4662507245848473\n</code></pre>\n",
                    "OwnerUserId": "832230",
                    "LastEditorUserId": "832230",
                    "LastEditDate": "2021-01-19T20:21:26.153",
                    "LastActivityDate": "2021-01-19T20:21:26.153",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "45646324",
                "ParentRepo": "https://github.com/fantix/gino",
                "StackOverflow_Post": {
                    "Id": "45646324",
                    "PostTypeId": "2",
                    "ParentId": "10784254",
                    "CreationDate": "2017-08-12T03:50:33.420",
                    "Score": "5",
                    "Body": "<p>It's been 5 years, and a lot changed. We wrote <a href=\"https://github.com/fantix/gino\" rel=\"noreferrer\">GINO</a> to be a lightweight ORM on top of <a href=\"https://magicstack.github.io/asyncpg/current/\" rel=\"noreferrer\">asyncpg</a> and <a href=\"https://docs.sqlalchemy.org/en/rel_1_1/#sqlalchemy-core\" rel=\"noreferrer\">SQLAlchemy core</a>. It is for asyncio and PostgreSQL only. GINO as \"GINO Is Not ORM\", because it applied almost none usual ORM patterns, in order to be explicit and simple.</p>\n",
                    "OwnerUserId": "3316267",
                    "LastActivityDate": "2017-08-12T03:50:33.420",
                    "CommentCount": "3",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "46007722",
                "ParentRepo": "https://github.com/mindflayer/python-mocket",
                "StackOverflow_Post": {
                    "Id": "46007722",
                    "PostTypeId": "2",
                    "ParentId": "44423801",
                    "CreationDate": "2017-09-01T20:41:18.390",
                    "Score": "0",
                    "Body": "<p>I'm the author of <a href=\"https://github.com/mindflayer/python-mocket\" rel=\"nofollow noreferrer\"><strong>mocket</strong></a> and few days ago I released the version <em>2.0.0</em> which fully supports <em>asyncio</em>/<em>aiohttp</em>.</p>\n\n<p>Here is the same example of code mocking a URL on HTTP and on HTTPS:</p>\n\n<pre><code>import aiohttp\nimport asyncio\nimport async_timeout\nfrom unittest import TestCase\n\nfrom mocket.mocket import mocketize\nfrom mocket.mockhttp import Entry\n\n\nclass AioHttpEntryTestCase(TestCase):\n    @mocketize\n    def test_http_session(self):\n        url = 'http://httpbin.org/ip'\n        body = \"asd\" * 100\n        Entry.single_register(Entry.GET, url, body=body, status=404)\n        Entry.single_register(Entry.POST, url, body=body*2, status=201)\n\n        async def main(l):\n            async with aiohttp.ClientSession(loop=l) as session:\n                with async_timeout.timeout(3):\n                    async with session.get(url) as get_response:\n                        assert get_response.status == 404\n                        assert await get_response.text() == body\n\n                with async_timeout.timeout(3):\n                    async with session.post(url, data=body * 6) as post_response:\n                        assert post_response.status == 201\n                        assert await post_response.text() == body * 2\n\n        loop = asyncio.get_event_loop()\n        loop.set_debug(True)\n        loop.run_until_complete(main(loop))\n\n    @mocketize\n    def test_https_session(self):\n        url = 'https://httpbin.org/ip'\n        body = \"asd\" * 100\n        Entry.single_register(Entry.GET, url, body=body, status=404)\n        Entry.single_register(Entry.POST, url, body=body*2, status=201)\n\n        async def main(l):\n            async with aiohttp.ClientSession(loop=l) as session:\n                with async_timeout.timeout(3):\n                    async with session.get(url) as get_response:\n                        assert get_response.status == 404\n                        assert await get_response.text() == body\n\n                with async_timeout.timeout(3):\n                    async with session.post(url, data=body * 6) as post_response:\n                        assert post_response.status == 201\n                        assert await post_response.text() == body * 2\n\n        loop = asyncio.get_event_loop()\n        loop.set_debug(True)\nloop.run_until_complete(main(loop))\n</code></pre>\n\n<p>Source: <a href=\"https://github.com/mindflayer/python-mocket/blob/master/tests/tests35/test_http_aiohttp.py\" rel=\"nofollow noreferrer\">https://github.com/mindflayer/python-mocket/blob/master/tests/tests35/test_http_aiohttp.py</a></p>\n",
                    "OwnerUserId": "1759549",
                    "LastActivityDate": "2017-09-01T20:41:18.390",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "46387129",
                "ParentRepo": "https://github.com/iotaledger/iota.lib.py/blob/85bbc7da14f3ff99e7e0b0fd482e8cbea063a7fd/.travis.yml",
                "StackOverflow_Post": {
                    "Id": "46387129",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "50054594",
                    "CreationDate": "2017-09-24T06:06:15.333",
                    "Score": "7",
                    "ViewCount": "665",
                    "Body": "<p>I'd like Travis CI to build and deploy the following artefacts to PyPI whenever a new commit hits the <code>master</code> branch:</p>\n\n<ul>\n<li>Python 2 wheel</li>\n<li>Python 3 wheel</li>\n<li>Source</li>\n</ul>\n\n<p>To make this happen, I've added the following to <a href=\"https://github.com/iotaledger/iota.lib.py/blob/85bbc7da14f3ff99e7e0b0fd482e8cbea063a7fd/.travis.yml\" rel=\"noreferrer\"><code>.travis.yml</code></a>:</p>\n\n<pre><code>language: python\npython:\n  - '2.7'\n  - '3.5'\n  - '3.6'\ndeploy:\n  on:\n    branch: master\n  provider: pypi\n  distribution: bdist_wheel sdist\n</code></pre>\n\n<p>For normal build/test, the configuration works great.  However, it introduces a race condition <a href=\"https://travis-ci.org/iotaledger/iota.lib.py/jobs/279121774\" rel=\"noreferrer\">when deploying to PyPI</a>:</p>\n\n<pre><code>Uploading distributions to https://upload.pypi.org/legacy/\nUploading PyOTA-2.0.0b1.tar.gz\nHTTPError: 400 Client Error: File already exists. for url: https://upload.pypi.org/legacy/\n</code></pre>\n\n<p>What changes should I make to <code>.travis.yml</code> to get Travis CI to deploy the correct artefacts to PyPI?</p>\n",
                    "OwnerUserId": "5568265",
                    "LastActivityDate": "2018-04-27T03:03:13.517",
                    "Title": "Preventing conflicts when deploying multiple distros to PyPI using Travis-CI",
                    "Tags": "<travis-ci><pypi>",
                    "AnswerCount": "2",
                    "CommentCount": "0",
                    "FavoriteCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "47534219",
                "ParentRepo": "https://github.com/Microsoft/vscode-python",
                "StackOverflow_Post": {
                    "Id": "47534219",
                    "PostTypeId": "1",
                    "CreationDate": "2017-11-28T14:40:29.597",
                    "Score": "0",
                    "ViewCount": "993",
                    "Body": "<p>I am trying to debug python flask app from VSCode using the <a href=\"https://github.com/Microsoft/vscode-python\" rel=\"nofollow noreferrer\">VSCode-Python</a> extension. According two the documentation there are 2 ways to make it work:</p>\n\n<ul>\n<li>Use the <code>\"module\":\"flask.cli\"</code> option in launch.json</li>\n<li>Use a startup script, which imports <code>flask.cli</code> module. Described <a href=\"https://stackoverflow.com/questions/39056448/debug-flaskpython-web-application-in-visual-studio-code\">here</a></li>\n</ul>\n\n<p>For both ways I end up with: <code>OSError: Windows error 1</code>. That seems to be an error indicating that the <code>main</code> function imported from <code>flask.cli</code> does not exists.</p>\n\n<p>I am using virtualenv. If I try to run from command line, the application works fine.</p>\n\n<p>Here is the settings.json content (env is the folder which contains the environment scripts):</p>\n\n<pre><code>{\n  \"python.pythonPath\": \"${workspaceRoot}\\\\backend\\\\env\\\\Scripts\\\\python.exe\"\n}\n</code></pre>\n\n<p>And here is the launch.json:</p>\n\n<pre><code>{\n    \"version\": \"0.2.0\",\n    \"configurations\": [\n        {\n            \"name\": \"Python: Flask (0.11.x or later)\",\n            \"type\": \"python\",\n            \"request\": \"launch\",\n            \"stopOnEntry\": false,\n            \"pythonPath\": \"${config:python.pythonPath}\",\n            \"cwd\": \"${workspaceRoot}\",\n            \"module\":\"flask.cli\",\n            \"env\": {\n                \"FLASK_APP\": \"${workspaceRoot}\\\\backend\\\\app.py\"\n            },\n            \"args\": [\n                \"run\",\n                \"--no-debugger\",\n                \"--no-reload\"\n            ],\n            \"debugOptions\": [\n                \"WaitOnAbnormalExit\",\n                \"WaitOnNormalExit\",\n                \"RedirectOutput\"\n            ]\n        }\n    ]\n}\n</code></pre>\n\n<p>Here is the complete error stack trace:</p>\n\n<pre><code>runpy.py:125: RuntimeWarning: 'flask.cli' found in sys.modules after import of package 'flask', but prior to execution of 'flask.cli'; this may result in unpredictable behaviour\n  warn(RuntimeWarning(msg))\nline 205, in run_module return _run_module_code(code, init_globals, run_name, mod_spec)\nline 96, in _run_module_code mod_name, mod_spec, pkg_name, script_name)\nline 85, in _run_code exec(code, run_globals)\nline 517, in &lt;module&gt; main(as_module=True)\nline 513, in main cli.main(args=args, prog_name=name)\nline 380, in main return AppGroup.main(self, *args, **kwargs)\nline 707, in main e.show()\nline 47, in show echo(self.ctx.get_usage() + '\\n', file=file, color=color)\nline 259, in echo file.write(message)\nline 180, in write return self._text_stream.write(x)\nline 164, in write raise OSError(self._get_error_message(GetLastError()))\nOSError: Windows error 1\n</code></pre>\n",
                    "OwnerUserId": "773692",
                    "LastEditorUserId": "2631715",
                    "LastEditDate": "2018-08-23T10:40:57.553",
                    "LastActivityDate": "2018-08-23T10:40:57.553",
                    "Title": "Debug flask app in visual studio code on windows",
                    "Tags": "<python><flask><visual-studio-code>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "47539344",
                "ParentRepo": "https://github.com/pact-foundation/pact-python/",
                "StackOverflow_Post": {
                    "Id": "47539344",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "47544092",
                    "CreationDate": "2017-11-28T19:22:17.560",
                    "Score": "2",
                    "ViewCount": "2907",
                    "Body": "<p>I'm looking at the <a href=\"https://github.com/pact-foundation/pact-python/\" rel=\"nofollow noreferrer\">Python implementation</a> of Pact and trying to set up provider states.  It seems to say that the way to do it is for the provider to have an endpoint built into the service that is called to put the provider in the correct state.  The issue is I can't find any documentation on what that endpoint is actually supposed to look like. What is the input, what does it return, etc.</p>\n\n<p>I tried looking at the default <a href=\"https://docs.pact.io/documentation/ruby/provider_states.html\" rel=\"nofollow noreferrer\">ruby implementation</a>, and it seems to imply a completely different mechanism for putting the provider into a certain state. This looks like it uses a ruby module that gets <code>require</code>d by the verifier script, with no HTTP requests involved at all.</p>\n\n<p>What is the correct way to set up a provider state?  If it requires setting up additional endpoints, I need to know what that endpoint is supposed to look like. If it requires a class/module to be imported to the verifier script, I need to know how that is implemented in languages other than ruby.</p>\n",
                    "OwnerUserId": "702948",
                    "LastEditorUserId": "665163",
                    "LastEditDate": "2017-11-28T23:54:41.470",
                    "LastActivityDate": "2017-12-02T23:54:55.487",
                    "Title": "Pact: how to set up provider states",
                    "Tags": "<python><pact><pact-python>",
                    "AnswerCount": "2",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "47722697",
                "ParentRepo": "https://github.com/intel-analytics/analytics-zoo/blob/master/apps/fraudDetection/Fraud%20Detction.ipynb",
                "StackOverflow_Post": {
                    "Id": "47722697",
                    "PostTypeId": "2",
                    "ParentId": "41997462",
                    "CreationDate": "2017-12-08T21:52:55.370",
                    "Score": "0",
                    "Body": "<p>I am translating scala program for python. I found smart answer to your problem.\nThe column are named V1 - V28, Time, Amount, Class.\n(I am not Scala pro)\nThe solution looks like this.</p>\n\n<pre><code>// cast all the column to Double type.\nval df = raw.select(((1 to 28).map(i =&gt; \"V\" + i) ++ Array(\"Time\", \"Amount\", \"Class\")).map(s =&gt; col(s).cast(\"Double\")): _*)\n</code></pre>\n\n<p>The link: <a href=\"https://github.com/intel-analytics/analytics-zoo/blob/master/apps/fraudDetection/Fraud%20Detction.ipynb\" rel=\"nofollow noreferrer\">https://github.com/intel-analytics/analytics-zoo/blob/master/apps/fraudDetection/Fraud%20Detction.ipynb</a> </p>\n",
                    "OwnerUserId": "1290338",
                    "LastActivityDate": "2017-12-08T21:52:55.370",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "47849395",
                "ParentRepo": "https://github.com/ssut/py-googletrans/blob/master/translate",
                "StackOverflow_Post": {
                    "Id": "47849395",
                    "PostTypeId": "2",
                    "ParentId": "47849057",
                    "CreationDate": "2017-12-16T19:48:21.727",
                    "Score": "0",
                    "Body": "<p>Oops - I thought this code was your own; it appears to be the <code>translate</code> script from the github, <a href=\"https://github.com/ssut/py-googletrans/blob/master/translate\" rel=\"nofollow noreferrer\">https://github.com/ssut/py-googletrans/blob/master/translate</a></p>\n\n<p>So there isn't another parser.</p>\n\n<p>Still the diagnostics that suggest apply - print the <code>sys.argv</code> to see what the parser is getting, print <code>args</code> after parsing, and skip (for now) the call to <code>Translate</code>.  And run with <code>py3</code> if possible.</p>\n\n<hr>\n\n<p>Your parser with just</p>\n\n<pre><code>parser = argparse.ArgumentParser(\n    description='Python Google Translator as a command-line tool')\nparser.add_argument('text', help='The text you want to translate.')\nparser.add_argument('-d', '--dest', default='en',\n    help='The destination language you want to translate. (Default: en)')\nparser.add_argument('-s', '--src', default='auto',\n    help='The source language you want to translate. (Default: auto)')\nparser.add_argument('-c', '--detect', action='store_true', default=False,\n    help='')\nargs = parser.parse_args()\nprint(args)\n</code></pre>\n\n<p>produces:</p>\n\n<pre><code>1347:~/mypy$ python2 stack47849057.py \nusage: stack47849057.py [-h] [-d DEST] [-s SRC] [-c] text\nstack47849057.py: error: too few arguments\n1144:~/mypy$ python2 stack47849057.py boy\nNamespace(dest='en', detect=False, src='auto', text='boy')\n1144:~/mypy$ python2 stack47849057.py boy -d french\nNamespace(dest='french', detect=False, src='auto', text='boy')\n1145:~/mypy$ python3 stack47849057.py \nusage: stack47849057.py [-h] [-d DEST] [-s SRC] [-c] text\nstack47849057.py: error: the following arguments are required: text\n</code></pre>\n\n<p>In other words it works with your input.  As noted in Py3 the error message is clearer.</p>\n\n<p>I suspect there's a problem with <code>Translator</code>.  It may have its own parser, and maybe even modifies the <code>sys.argv</code>.  You could also <code>print(sys.argv)</code> to check that.</p>\n\n<p>The error message seems to be coming from your parser, since the usage matches.</p>\n",
                    "OwnerUserId": "901925",
                    "LastEditorUserId": "901925",
                    "LastEditDate": "2017-12-16T20:20:09.947",
                    "LastActivityDate": "2017-12-16T20:20:09.947",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "48791965",
                "ParentRepo": "https://github.com/ably/ably-python",
                "StackOverflow_Post": {
                    "Id": "48791965",
                    "PostTypeId": "5",
                    "CreationDate": "2018-02-14T16:31:29.827",
                    "Score": "0",
                    "Body": "<p>Ably is a realtime data delivery platform providing developers everything they need to create, deliver and manage complex realtime functionality. Ably solves the hardest parts of scaling and reliability so they don\u2019t have to.</p>\n\n<p>Ably is the only globally distributed pub/sub platform to provide websocket support and open protocol support, with low latencies (mean 65ms), guaranteed ordering, and continuity of service over unreliable networks.</p>\n\n<p>Useful links:</p>\n\n<ul>\n<li><a href=\"https://www.ably.io/platform\" rel=\"nofollow noreferrer\">Ably platform</a></li>\n<li><a href=\"https://www.ably.io/documentation\" rel=\"nofollow noreferrer\">Documentation</a></li>\n<li><a href=\"https://www.ably.io/tutorials\" rel=\"nofollow noreferrer\">Tutorials</a></li>\n<li><a href=\"https://blog.ably.io/\" rel=\"nofollow noreferrer\">Blog</a></li>\n<li><a href=\"https://www.ably.io/about\" rel=\"nofollow noreferrer\">About Ably</a></li>\n</ul>\n\n<p>Ably provides client libraries for the following platforms:</p>\n\n<ul>\n<li><a href=\"https://github.com/ably/ably-java\" rel=\"nofollow noreferrer\">Android</a></li>\n<li><a href=\"https://github.com/ably/ably-js\" rel=\"nofollow noreferrer\">Cordova / Phonegap</a></li>\n<li><a href=\"https://github.com/ably/ably-go\" rel=\"nofollow noreferrer\">Go</a></li>\n<li><a href=\"https://github.com/ably/ably-ios\" rel=\"nofollow noreferrer\">iOS Objective-C and Swift</a></li>\n<li><a href=\"https://github.com/ably/ably-java\" rel=\"nofollow noreferrer\">Java</a></li>\n<li><a href=\"https://github.com/ably/ably-js\" rel=\"nofollow noreferrer\">Javascript (browsers)</a></li>\n<li><a href=\"https://github.com/ably/ably-php-laravel\" rel=\"nofollow noreferrer\">Laravel</a></li>\n<li><a href=\"https://github.com/ably/ably-dotnet\" rel=\"nofollow noreferrer\">Mono</a></li>\n<li><a href=\"https://github.com/ably/ably-js-nativescript\" rel=\"nofollow noreferrer\">NativeScript</a></li>\n<li><a href=\"https://github.com/ably/ably-dotnet\" rel=\"nofollow noreferrer\">.NET</a></li>\n<li><a href=\"https://github.com/ably/ably-js\" rel=\"nofollow noreferrer\">Node.js</a></li>\n<li><a href=\"https://github.com/ably/ably-php\" rel=\"nofollow noreferrer\">PHP</a></li>\n<li><a href=\"https://github.com/ably/ably-python\" rel=\"nofollow noreferrer\">Python</a></li>\n<li><a href=\"https://github.com/ably/ably-js-react-native\" rel=\"nofollow noreferrer\">React Native</a></li>\n<li><a href=\"https://github.com/ably/ably-ruby\" rel=\"nofollow noreferrer\">Ruby</a></li>\n<li><a href=\"https://github.com/ably/ably-dotnet\" rel=\"nofollow noreferrer\">Xamarin and Xamarin.forms</a></li>\n</ul>\n",
                    "OwnerUserId": "139607",
                    "LastEditorUserId": "139607",
                    "LastEditDate": "2018-02-14T21:43:18.173",
                    "LastActivityDate": "2018-02-14T21:43:18.173",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "49225310",
                "ParentRepo": "https://github.com/lepture/authlib/blob/master/authlib/client/oauth2.py#L155",
                "StackOverflow_Post": {
                    "Id": "49225310",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "49227124",
                    "CreationDate": "2018-03-11T21:30:55.560",
                    "Score": "0",
                    "ViewCount": "1119",
                    "Body": "<p>I'm using authlib in my project. I have a local IDP setup using http atm.\nFor testing, this code is blocking me because my dev environment is http.</p>\n\n<p><a href=\"https://github.com/lepture/authlib/blob/master/authlib/client/oauth2.py#L155\" rel=\"nofollow noreferrer\">https://github.com/lepture/authlib/blob/master/authlib/client/oauth2.py#L155</a></p>\n\n<p>I can carry on by commenting out the line. But, i think having a way to turn of https check is neater.</p>\n\n<p>So, dose anyway know a way to turn off https check in Authlib ?</p>\n",
                    "OwnerUserId": "9476746",
                    "LastActivityDate": "2018-03-12T01:57:06.567",
                    "Title": "how to turn off ssl check in Authlib",
                    "Tags": "<ssl><authlib>",
                    "AnswerCount": "1",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "49796882",
                "ParentRepo": "https://github.com/web-platform-tests/wpt/blob/master/url/resources/urltestdata.json",
                "StackOverflow_Post": {
                    "Id": "49796882",
                    "PostTypeId": "2",
                    "ParentId": "10786042",
                    "CreationDate": "2018-04-12T12:43:06.807",
                    "Score": "10",
                    "Body": "<p>The code</p>\n<pre class=\"lang-java prettyprint-override\"><code>URL url = new URL(&quot;http://example.com/query?q=random word \u00a3500 bank $&quot;);\nURI uri = new URI(url.getProtocol(), url.getUserInfo(), IDN.toASCII(url.getHost()), url.getPort(), url.getPath(), url.getQuery(), url.getRef());\nString correctEncodedURL = uri.toASCIIString();\nSystem.out.println(correctEncodedURL);\n</code></pre>\n<p>Prints</p>\n<pre class=\"lang-none prettyprint-override\"><code>http://example.com/query?q=random%20word%20%C2%A3500%20bank%20$\n</code></pre>\n<p>What is happening here?</p>\n<p><strong>1.</strong> Split URL into structural parts. Use <code>java.net.URL</code> for it.</p>\n<p><strong>2.</strong>  Encode each structural part properly!</p>\n<p><strong>3.</strong> Use <code>IDN.toASCII(putDomainNameHere)</code> to <a href=\"https://en.wikipedia.org/wiki/Punycode\" rel=\"nofollow noreferrer\">Punycode</a> encode the hostname!</p>\n<p><strong>4.</strong> Use <code>java.net.URI.toASCIIString()</code> to <a href=\"https://en.wikipedia.org/wiki/Percent-encoding\" rel=\"nofollow noreferrer\">percent-encode</a>, NFC encoded Unicode - (better would be NFKC!). For more information, see: <em><a href=\"https://stackoverflow.com/questions/49768599/how-to-encode-properly-this-url/49778055#49778055\">How to encode properly this URL</a></em></p>\n<p>In some cases it is advisable to <a href=\"https://stackoverflow.com/a/53776285/1485527\">check if the URL is already encoded</a>. Also replace '+' encoded spaces with '%20' encoded spaces.</p>\n<p>Here are some examples that will also work properly</p>\n<pre><code>{\n      &quot;in&quot; : &quot;http://\u0646\u0627\u0645\u0647\u200c\u0627\u06cc.com/&quot;,\n     &quot;out&quot; : &quot;http://xn--mgba3gch31f.com/&quot;\n},{\n     &quot;in&quot; : &quot;http://www.example.com/\u2025/foo&quot;,\n     &quot;out&quot; : &quot;http://www.example.com/%E2%80%A5/foo&quot;\n},{\n     &quot;in&quot; : &quot;http://search.barnesandnoble.com/booksearch/first book.pdf&quot;,\n     &quot;out&quot; : &quot;http://search.barnesandnoble.com/booksearch/first%20book.pdf&quot;\n}, {\n     &quot;in&quot; : &quot;http://example.com/query?q=random word \u00a3500 bank $&quot;,\n     &quot;out&quot; : &quot;http://example.com/query?q=random%20word%20%C2%A3500%20bank%20$&quot;\n}\n</code></pre>\n<p>The solution passes around 100 of the test cases provided by <a href=\"https://github.com/web-platform-tests/wpt/blob/master/url/resources/urltestdata.json\" rel=\"nofollow noreferrer\">Web Platform Tests</a>.</p>\n",
                    "OwnerUserId": "1485527",
                    "LastEditorUserId": "63550",
                    "LastEditDate": "2022-11-30T23:07:24.257",
                    "LastActivityDate": "2022-11-30T23:07:24.257",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "50787361",
                "ParentRepo": "https://github.com/mxmaslin/Test-tasks/tree/removeme/tests_python/my-project",
                "StackOverflow_Post": {
                    "Id": "50787361",
                    "PostTypeId": "1",
                    "CreationDate": "2018-06-10T19:35:20.190",
                    "Score": "0",
                    "ViewCount": "65",
                    "Body": "<p>As a result of <code>make html</code> command, Sphinx generates documentation only for some modules. Other modules remain undocumented.</p>\n\n<p>Project structure:</p>\n\n<pre><code>|- my-project\n|--| my_project\n|--| docs\n|----| _build\n|------| ...\n|----| _static\n|------| ...\n|----| _templates\n|------| ...\n|---- conf.py\n|---- index.rst\n|---- Makefile\n|---- source\n|-----| modules.rst\n|-----| ...\n</code></pre>\n\n<p><code>conf.py</code>:</p>\n\n<pre><code>import os\nimport sys\nsys.path.insert(0, os.path.abspath('../'))\nextensions = [\n    'sphinx.ext.autodoc',\n    'sphinx.ext.autosummary',\n    'sphinx.ext.viewcode',\n    'sphinx.ext.napoleon',\n]\nautosummary_generate=True\nsource_suffix = '.rst'\n</code></pre>\n\n<p><code>index.rst</code>:</p>\n\n<pre><code>.. toctree::\n   :maxdepth: 2\n   :caption: Contents:\n\n   ./source/modules\n\n\nIndices and tables\n==================\n\n* :ref:`genindex`\n* :ref:`modindex`\n* :ref:`search`\n</code></pre>\n\n<p><code>source/modules.rst</code>:</p>\n\n<pre><code>my_project\n==========\n\n.. toctree::\n   :maxdepth: 4\n\n   my_project\n</code></pre>\n\n<p>Please consider to look at the sources at github: <a href=\"https://github.com/mxmaslin/Test-tasks/tree/removeme/tests_python/my-project\" rel=\"nofollow noreferrer\">https://github.com/mxmaslin/Test-tasks/tree/removeme/tests_python/my-project</a></p>\n",
                    "OwnerUserId": "2564698",
                    "LastEditorUserId": "65548",
                    "LastEditDate": "2018-06-10T19:50:27.147",
                    "LastActivityDate": "2018-06-11T10:13:54.963",
                    "Title": "Sphinx generates documentation partially",
                    "Tags": "<python><python-sphinx><autodoc>",
                    "AnswerCount": "1",
                    "CommentCount": "5",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "50876864",
                "ParentRepo": "https://github.com/encode/uvicorn/issues/68#issuecomment-384943732",
                "StackOverflow_Post": {
                    "Id": "50876864",
                    "PostTypeId": "2",
                    "ParentId": "50835054",
                    "CreationDate": "2018-06-15T13:43:58.217",
                    "Score": "1",
                    "Body": "<p>Nginx closes connections after a predefined time. If you want to have long lived connections, you need to set custom timeout. I also had <a href=\"https://github.com/encode/uvicorn/issues/68#issuecomment-384943732\" rel=\"nofollow noreferrer\">same issue</a> and got fixed after setting <code>proxy_read_timeout</code> to <code>86400</code>.</p>\n\n<pre><code>  location / {\n        proxy_pass http://0.0.0.0:8001;\n        proxy_http_version 1.1;\n        proxy_set_header Upgrade $http_upgrade;\n        proxy_set_header Connection \"upgrade\";\n\n        proxy_read_timeout 86400;\n}\n</code></pre>\n",
                    "OwnerUserId": "2698552",
                    "LastActivityDate": "2018-06-15T13:43:58.217",
                    "CommentCount": "3",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "51795115",
                "ParentRepo": "https://github.com/Vaelor/python-mattermost-driver",
                "StackOverflow_Post": {
                    "Id": "51795115",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "51805514",
                    "CreationDate": "2018-08-10T23:26:18.220",
                    "Score": "0",
                    "ViewCount": "729",
                    "Body": "<p>We're running two mattermost servers.</p>\n\n<p>One we have a python process logging in with <a href=\"https://github.com/Vaelor/python-mattermost-driver\" rel=\"nofollow noreferrer\">https://github.com/Vaelor/python-mattermost-driver</a> using a personal access token with the community Python driver. \nThis process has a session that doesn't time out which is one of the benefits of using a personal access token to login.\n<a href=\"https://docs.mattermost.com/developer/personal-access-tokens.html\" rel=\"nofollow noreferrer\">https://docs.mattermost.com/developer/personal-access-tokens.html</a> .</p>\n\n<p>We log in using a username and password with the client4 go driver and this works however it times out after a while. It appears there is no way of using a personal access token to log in with the official client 4 driver.</p>\n\n<p>The documentation for the Mattermost Client4 code is at\n<a href=\"https://godoc.org/github.com/mattermost/platform/model#Client\" rel=\"nofollow noreferrer\">https://godoc.org/github.com/mattermost/platform/model#Client</a></p>\n\n<p>The source for client4 is at <a href=\"https://github.com/mattermost/mattermost-server/blob/master/model/client4.go\" rel=\"nofollow noreferrer\">https://github.com/mattermost/mattermost-server/blob/master/model/client4.go</a></p>\n\n<p>The closest thing that looks like it would work is logging in under with a username and password and then setting the authentication token via client.MockSession which failed on testing.</p>\n\n<p>What's the official way of logging in with a personal access token using the client4 go driver for mattermost?</p>\n",
                    "OwnerUserId": "162358",
                    "LastEditorUserId": "162358",
                    "LastEditDate": "2018-08-11T03:23:37.650",
                    "LastActivityDate": "2018-08-12T03:45:30.870",
                    "Title": "What's the official way of logging in with a personal access token using the client4 go driver for mattermost?",
                    "Tags": "<go><mattermost>",
                    "AnswerCount": "1",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "52111578",
                "ParentRepo": "https://github.com/OpenXbox/xbox-webapi-python/blob/master/xbox/webapi/authentication/manager.py#L164",
                "StackOverflow_Post": {
                    "Id": "52111578",
                    "PostTypeId": "2",
                    "ParentId": "51853445",
                    "CreationDate": "2018-08-31T08:37:36.367",
                    "Score": "2",
                    "Body": "<p>I have follow the <a href=\"https://github.com/OpenXbox/xbox-webapi-python/blob/master/xbox/webapi/authentication/manager.py#L164\" rel=\"nofollow noreferrer\"><code>authenticate</code></a> of <a href=\"https://github.com/OpenXbox/xbox-webapi-python\" rel=\"nofollow noreferrer\"><code>xbox-webapi-python</code></a> to get the <code>Authorization</code> header(<code>XBL3.0 x=&lt;uhs&gt;,&lt;xsts&gt;</code>). Just add <code>Authorization</code> to each Xbox Live API request beside other required headers, You can get correcttly response. </p>\n\n<p>The value of <code>Authorization</code> also can get by <a href=\"https://learn.microsoft.com/en-us/dotnet/api/microsoft.xbox.services.system.xboxliveuser.gettokenandsignatureasync?view=xboxlive-dotnet-2017.11.20171204.01\" rel=\"nofollow noreferrer\"><code>getTokenAndSignatureAsync</code></a>. This value is apply to all Xbox API endpoint.</p>\n",
                    "OwnerUserId": "2714012",
                    "LastActivityDate": "2018-08-31T08:37:36.367",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "52655008",
                "ParentRepo": "https://github.com/dalibo/temboard/commit/ff98d6740ae11345658508b02052294d6cffd448",
                "StackOverflow_Post": {
                    "Id": "52655008",
                    "PostTypeId": "2",
                    "ParentId": "51033689",
                    "CreationDate": "2018-10-04T20:55:11.297",
                    "Score": "26",
                    "Body": "<p>I had the same problem with my CI build, and I found a workaround creating the folders like @A. Scherbaum mentioned.</p>\n\n<pre><code>sudo mkdir -p /usr/share/man/man1\nsudo mkdir -p /usr/share/man/man7\nsudo apt-get update\nsudo apt-get install postgresql-client\n</code></pre>\n\n<p>I found this solution in this <a href=\"https://github.com/dalibo/temboard/commit/ff98d6740ae11345658508b02052294d6cffd448\" rel=\"noreferrer\">commit</a> through this <a href=\"https://github.com/dalibo/temboard/issues/211\" rel=\"noreferrer\">issue</a></p>\n\n<p>However I also did the test silencing the error like you said and It worked, but I don't know the consequences</p>\n\n<pre><code>sudo apt-get install postgresql-client || true\n</code></pre>\n\n<p>I found something similar in this <a href=\"https://circleci.com/docs/2.0/postgres-config/\" rel=\"noreferrer\">circleci article</a></p>\n",
                    "OwnerUserId": "4788966",
                    "LastActivityDate": "2018-10-04T20:55:11.297",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "53479387",
                "ParentRepo": "https://github.com/tortoise/tortoise-orm",
                "StackOverflow_Post": {
                    "Id": "53479387",
                    "PostTypeId": "2",
                    "ParentId": "10784254",
                    "CreationDate": "2018-11-26T10:43:38.603",
                    "Score": "5",
                    "Body": "<p>Have a look at Tortoise <a href=\"https://github.com/tortoise/tortoise-orm\" rel=\"noreferrer\">ORM</a></p>\n\n<p>Its aiming to be a full-featured <code>ORM</code> inspired by <code>Django syntax</code>, but asycnio only.\nSince <code>Tornado 5.0</code> runs on asyncio, it should just work.</p>\n",
                    "OwnerUserId": "10705811",
                    "LastEditorUserId": "7200297",
                    "LastEditDate": "2018-11-26T11:26:05.860",
                    "LastActivityDate": "2018-11-26T11:26:05.860",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "54545320",
                "ParentRepo": "https://github.com/greenbone/gvm-tools",
                "StackOverflow_Post": {
                    "Id": "54545320",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "54547569",
                    "CreationDate": "2019-02-06T01:05:25.073",
                    "Score": "1",
                    "ViewCount": "1732",
                    "Body": "<p>I have been trying to figure out how I can execute tasks from the command line with OpenVAS (without any interactions with their web gui)</p>\n\n<p>I've tried running this command:</p>\n\n<p><code>omp --port=9392 --host=&lt;IP&gt; --username=admin --password=admin --xml \"&lt;get_results/&gt;\"</code></p>\n\n<p>And it just stalls there, appearing to do nothing. No output, nothing.</p>\n\n<p>After looking around, apparently <code>omp</code> is deprecated and people have said to switch to <code>gvm-cli</code> found <a href=\"https://github.com/greenbone/gvm-tools\" rel=\"nofollow noreferrer\">here</a>. </p>\n\n<p>After switching to <code>gvm-cli</code>, I ran the following command, and got this error..</p>\n\n<pre><code>gvm-cli socket --gmp-username admin --gmp-password admin --xml \"&lt;get_results/&gt;\"\n\nTraceback (most recent call last):\n  File \"/home/phillip/py37/bin/gvm-cli\", line 10, in &lt;module&gt;\n    sys.exit(main())\n  File \"/home/phillip/py37/lib/python3.7/site-packages/gvmtools/cli.py\", line 92, in main\n    gvm.authenticate(args.gmp_username, args.gmp_password)\n  File \"/home/phillip/py37/lib/python3.7/site-packages/gvm/protocols/gmpv7.py\", line 210, in authenticate\n    self._send(cmd.to_string())\n  File \"/home/phillip/py37/lib/python3.7/site-packages/gvm/protocols/base.py\", line 62, in _send\n    self.connect()\n  File \"/home/phillip/py37/lib/python3.7/site-packages/gvm/protocols/base.py\", line 98, in connect\n    self._connection.connect()\n  File \"/home/phillip/py37/lib/python3.7/site-packages/gvm/connections.py\", line 310, in connect\n    self._socket.connect(self.path)\nFileNotFoundError: [Errno 2] No such file or directory\n</code></pre>\n\n<p>I'm not sure what else to do. Could someone steer me in the right direction with this?</p>\n\n<p>What I want to eventually end up doing is create an automated scanning system completely from the command line. I want to be able to:</p>\n\n<ol>\n<li>Create a new target</li>\n<li>Create a new task</li>\n<li>Run the scan</li>\n</ol>\n\n<p><strong>How can I accomplish this?</strong></p>\n\n<p><strong>Extra Info:</strong></p>\n\n<p>When running <code>openvas-check-setup --v9</code> my output is: <code>It seems like your OpenVAS-9 installation is OK</code></p>\n\n<p>OS: CentOS 7</p>\n\n<p>The web gui runs fine, and I executed a task to make sure everything is working ok. </p>\n",
                    "OwnerUserId": "6566820",
                    "LastEditorUserId": "6566820",
                    "LastEditDate": "2019-02-06T01:10:32.613",
                    "LastActivityDate": "2019-05-16T06:17:39.900",
                    "Title": "OpenVAS: CLI Vulnerability Scanning [CentOS]",
                    "Tags": "<security><centos><port-scanning><nessus><openvas>",
                    "AnswerCount": "2",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "55115790",
                "ParentRepo": "https://github.com/rigetti/pyquil/issues/835",
                "StackOverflow_Post": {
                    "Id": "55115790",
                    "PostTypeId": "1",
                    "CreationDate": "2019-03-12T07:02:20.707",
                    "Score": "1",
                    "ViewCount": "147",
                    "Body": "<p>This question has been posted earlier as an issue at <a href=\"https://github.com/rigetti/pyquil/issues/835\" rel=\"nofollow noreferrer\">rigetti/pyquil</a>, where it has been recommended to ask Python experts before considering it a bug in Rigetti's pyquil library:</p>\n\n<p>Consider the following mini application that creates a string containing QASM code in the host application and invokes the Python interpreter:</p>\n\n<pre class=\"lang-cpp prettyprint-override\"><code>#include &lt;Python.h&gt;\n#include &lt;sstream&gt;\n\nstatic void run()\n{\n  std::stringstream ss;\n\n  ss &lt;&lt; \"import pyquil\\n\"\n     &lt;&lt; \"qasm = 'H 0'\\n\"\n     &lt;&lt; \"p = pyquil.Program(qasm)\\n\"\n     &lt;&lt; \"qc = pyquil.get_qc('9q-square-qvm')\\n\"\n     &lt;&lt; \"result = qc.run_and_measure(p, trials=1024)\\n\"\n     &lt;&lt; \"print(result)\\n\";\n\n  Py_Initialize();\n  PyRun_SimpleString(ss.str().c_str());\n  Py_Finalize();\n}\n\nint main()\n{\n  run();\n  run();\n  return 0;\n}\n</code></pre>\n\n<p><em>Remark:</em> In my real program am not using <code>PyRun_SimpleString</code> but, instead, the approach described <a href=\"https://stackoverflow.com/questions/3286448/calling-a-python-method-from-c-c-and-extracting-its-return-value\">here</a> to extract the return value. The problem is the same, so the above program is just meant as illustrating example to keep things as simple as possible.</p>\n\n<p>Compiling the code under macOS 10.13.6 as follows</p>\n\n<pre class=\"lang-sh prettyprint-override\"><code>g++ -I/usr/local//homebrew/Cellar/python/3.7.2_2/Frameworks/Python.framework/Versions/3.7/include/python3.7m -L/usr/local//homebrew/Cellar/python/3.7.2_2/Frameworks/Python.framework/Versions/3.7/lib -lpython3.7m demo.cxx -o demo.exe\n</code></pre>\n\n<p>yields the following error:</p>\n\n<pre class=\"lang-sh prettyprint-override\"><code>{0: array([1, 1, 0, ..., 1, 0, 0]), 1: array([0, 0, 0, ..., 0, 0, 0]), 2: array([0, 0, 0, ..., 0, 0, 0]), 3: array([0, 0, 0, ..., 0, 0, 0]), 4: array([0, 0, 0, ..., 0, 0, 0]), 5: array([0, 0, 0, ..., 0, 0, 0]), 6: array([0, 0, 0, ..., 0, 0, 0]), 7: array([0, 0, 0, ..., 0, 0, 0]), 8: array([0, 0, 0, ..., 0, 0, 0])}\nSegmentation fault: 11\n</code></pre>\n\n<p>Removing the second <code>run()</code> from the <code>main()</code> function, i.e. no second invocation of the Python interpreter, solves the problem.</p>\n\n<p>The segmentation fault occurs already at the <code>import pyquil</code> line. That is, already this code produces a segmentation fault in the second call to <code>run()</code>:</p>\n\n<pre class=\"lang-cpp prettyprint-override\"><code>#include &lt;Python.h&gt;\n#include &lt;sstream&gt;\n\nstatic void run()\n{\n  std::stringstream ss;\n\n  ss &lt;&lt; \"import pyquil\\n\";\n\n  Py_Initialize();\n  PyRun_SimpleString(ss.str().c_str());\n  Py_Finalize();\n}\n\nint main()\n{\n  run();\n  run();\n  return 0;\n}\n</code></pre>\n\n<p>I have been using multiple invocations of the Python interpreter from the same host application with many other Python modules and never encountered this problem. Any help is appreciated.</p>\n",
                    "OwnerUserId": "6906549",
                    "LastActivityDate": "2019-03-12T07:02:20.707",
                    "Title": "Multiple calls to Python interpreter embedded in C++ application yield segmentation fault",
                    "Tags": "<python><c++><segmentation-fault><embed>",
                    "AnswerCount": "0",
                    "CommentCount": "0",
                    "FavoriteCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "55333645",
                "ParentRepo": "https://github.com/census-instrumentation/opencensus-python/tree/master/contrib/opencensus-ext-stackdriver",
                "StackOverflow_Post": {
                    "Id": "55333645",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "55527037",
                    "CreationDate": "2019-03-25T08:18:03.223",
                    "Score": "0",
                    "ViewCount": "618",
                    "Body": "<p>Im trying to install and use <code>stats_exporter</code> from <code>opencensus.ext.stackdriver</code> using the following guide: <a href=\"https://github.com/census-instrumentation/opencensus-python/tree/master/contrib/opencensus-ext-stackdriver\" rel=\"nofollow noreferrer\">opencensus-ext-stackdriver</a></p>\n\n<p>after installing it through pip:</p>\n\n<p><code>pip install opencensus-ext-stackdriver</code> </p>\n\n<p>Im trying to import it and:</p>\n\n<pre><code>from opencensus.ext.stackdriver import stats_exporter as stackdriver\nImportError: cannot import name 'stats_exporter' from 'opencensus.ext.stackdriver'\n</code></pre>\n\n<p>When comparing the Git repo, and my local <code>venv/lib/python3.7/site-packages/...</code>   it seems like the pip version isn't compatible with Github , so i tried to install it though cloning, and using <code>setup.py</code></p>\n\n<pre><code>pip install ../opencensus-python/contrib/opencensus-ext-stackdriver/dist/opencensus-ext-stackdriver-0.2.dev0.tar.gz\n</code></pre>\n\n<p>which gives me the following error:</p>\n\n<pre><code>(venv) Yehoshaphats-MacBook-Pro:present-value yehoshaphatschellekens$ pip install ../opencensus-python/contrib/opencensus-ext-stackdriver/dist/opencensus-ext-stackdriver-0.2.dev0.tar.gz \nProcessing /Users/yehoshaphatschellekens/opencensus-python/contrib/opencensus-ext-stackdriver/dist/opencensus-ext-stackdriver-0.2.dev0.tar.gz\n    Complete output from command python setup.py egg_info:\n    Traceback (most recent call last):\n      File \"&lt;string&gt;\", line 1, in &lt;module&gt;\n      File \"/private/var/folders/s2/y6vcdc1105s8xlpb12slr9z00000gn/T/pip-req-build-7m1ibdpd/setup.py\", line 17, in &lt;module&gt;\n        from version import __version__\n    ModuleNotFoundError: No module named 'version'\n\n    ----------------------------------------\nCommand \"python setup.py egg_info\" failed with error code 1 in /private/var/folders/s2/y6vcdc1105s8xlpb12slr9z00000gn/T/pip-req-build-7m1ibdpd/\n</code></pre>\n\n<p>Similar errors of this type indicated that i need to upgrade <code>setuptools</code>, tried that also :(</p>\n\n<p><a href=\"https://stackoverflow.com/questions/32423793/importerror-no-module-named-version\">This post</a> suggests that it might related to the fact that i'm using python3, which isn't completable with <code>version</code> though i really need to install this package on my python3 venv.</p>\n\n<p>Any Help on this issue would be great!</p>\n",
                    "OwnerUserId": "3386991",
                    "LastActivityDate": "2019-04-05T02:48:28.973",
                    "Title": "Trouble shooting when tring to install and import `stats_exporter` from `opencensus.ext.stackdriver`",
                    "Tags": "<python><opencensus>",
                    "AnswerCount": "1",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "55375349",
                "ParentRepo": "https://github.com/encode/requests-async",
                "StackOverflow_Post": {
                    "Id": "55375349",
                    "PostTypeId": "2",
                    "ParentId": "53318354",
                    "CreationDate": "2019-03-27T10:47:31.630",
                    "Score": "0",
                    "Body": "<p>The <code>requests-async</code> pacakge provides asyncio support for <code>requests</code>... <a href=\"https://github.com/encode/requests-async\" rel=\"nofollow noreferrer\">https://github.com/encode/requests-async</a></p>\n\n<p>Either that or use <code>aiohttp</code>.</p>\n",
                    "OwnerUserId": "596689",
                    "LastActivityDate": "2019-03-27T10:47:31.630",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "55520484",
                "ParentRepo": "https://github.com/zentralopensource/zentral",
                "StackOverflow_Post": {
                    "Id": "55520484",
                    "PostTypeId": "2",
                    "ParentId": "55520047",
                    "CreationDate": "2019-04-04T16:03:39.423",
                    "Score": "5",
                    "Body": "<p>When osquery is running in daemon mode, you can enable the <a href=\"https://osquery.readthedocs.io/en/stable/deployment/remote/\" rel=\"nofollow noreferrer\">distributed query facilities</a>. When this is enabled, osqueryd will periodically check in to a remote server to see whether there are queries for it to execute (typical intervals for this check range from 10 seconds to 1 minute).</p>\n\n<p>Note that due to the nature of the environments that osquery runs in, the osquery agent does not listen for incoming connections. It only ever makes outgoing connections to a remote server to check for queries to execute.</p>\n\n<p>To take advantage of this, you need a server implementing the osquery remote APIs. There are a handful of open-source options available:</p>\n\n<p><a href=\"https://github.com/kolide/fleet\" rel=\"nofollow noreferrer\">Fleet</a> (disclaimer: I build this)</p>\n\n<p><a href=\"https://github.com/zentralopensource/zentral\" rel=\"nofollow noreferrer\">Zentral</a></p>\n\n<p><a href=\"https://github.com/mwielgoszewski/doorman\" rel=\"nofollow noreferrer\">Doorman</a></p>\n\n<p><a href=\"https://github.com/OktaSecurityLabs/sgt\" rel=\"nofollow noreferrer\">SGT</a></p>\n\n<p><strong>Security note</strong>: providing remote execution on an osquery agent can be very dangerous since it can retrieve sensitive information on the device it runs on. If you plan to serve some sort of a web page allowing direct queries on your agent, be aware that since osquery provide an SQL abstraction of your system, it can be vulnerable to <a href=\"https://www.netsparker.com/blog/web-security/osquery-injection/\" rel=\"nofollow noreferrer\">injections</a>. </p>\n",
                    "OwnerUserId": "491710",
                    "LastEditorUserId": "2664350",
                    "LastEditDate": "2019-06-19T11:30:55.480",
                    "LastActivityDate": "2019-06-19T11:30:55.480",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "55593648",
                "ParentRepo": "https://github.com/ijl/orjson",
                "StackOverflow_Post": {
                    "Id": "55593648",
                    "PostTypeId": "2",
                    "ParentId": "27407430",
                    "CreationDate": "2019-04-09T13:05:36.770",
                    "Score": "16",
                    "Body": "<p>swith from</p>\n<pre><code>import json \n</code></pre>\n<p>to</p>\n<pre><code>import ujson\n</code></pre>\n<p><a href=\"https://artem.krylysov.com/blog/2015/09/29/benchmark-python-json-libraries/\" rel=\"noreferrer\">https://artem.krylysov.com/blog/2015/09/29/benchmark-python-json-libraries/</a></p>\n<p>or switch to orjson</p>\n<pre><code>import orjson \n</code></pre>\n<p><a href=\"https://github.com/ijl/orjson\" rel=\"noreferrer\">https://github.com/ijl/orjson</a></p>\n",
                    "OwnerUserId": "6515755",
                    "LastEditorUserId": "6515755",
                    "LastEditDate": "2022-01-15T09:47:34.727",
                    "LastActivityDate": "2022-01-15T09:47:34.727",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "55650766",
                "ParentRepo": "https://github.com/uber/ludwig/",
                "StackOverflow_Post": {
                    "Id": "55650766",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "55834377",
                    "CreationDate": "2019-04-12T11:35:57.487",
                    "Score": "2",
                    "ViewCount": "347",
                    "Body": "<p>I want to install <a href=\"https://github.com/uber/ludwig/\" rel=\"nofollow noreferrer\">ludwig from uber</a> from source on a gpu server I got access to. I don't have admin rights there. </p>\n\n<p>The steps I use are documented in the getting started steps from ludwig:</p>\n\n<pre class=\"lang-sh prettyprint-override\"><code>git clone https://github.com/uber/ludwig.git\ncd ludwig\ngit checkout db6c90a\nvirtualenv -p python3 venv\nsource venv/bin/activate\npip install -r requirements.txt\npython -m spacy download en\npython setup.py install\n</code></pre>\n\n<p>I'm just checking out to a custom branch and change <code>tensorflow</code> to <code>tensorflow-gpu==1.12.0</code> in the <code>requirements.txt</code>.</p>\n\n<p>While running the virtualenv installation step I always ran into this TypeError:</p>\n\n<p><code>TypeError: unsupported operand type(s) for -=: 'Retry' and 'int'</code></p>\n\n<p><code>OSError: Command /data/home/jburkard/ludwig/venv/bin/python3 - setuptools pkg_resources pip wheel failed with error code 2</code></p>\n\n<p>I already tried all of the steps mentioned <a href=\"https://stackoverflow.com/questions/42610545/typeerror-unsupported-operand-types-for-retry-and-int-during-pip\">in this issue.</a> But I neither use a proxy nor did the other tipps help.</p>\n\n<p>It would be really great to get some more tips on what I can try out!</p>\n\n<p>Full traceback:</p>\n\n<pre><code>jtheb@gpu:~/ludwig$ virtualenv -p python3 venv\nAlready using interpreter /usr/bin/python3\nUsing base prefix '/usr'\nNew python executable in /data/home/jtheb/ludwig/venv/bin/python3\nAlso creating executable in /data/home/jtheb/ludwig/venv/bin/python\nInstalling setuptools, pkg_resources, pip, wheel...\n  Complete output from command /data/home/jtheb/ludwig/venv/bin/python3 - setuptools pkg_resources pip wheel:\n  Collecting setuptools\nException:\nTraceback (most recent call last):\n  File \"/data/home/jtheb/ludwig/venv/share/python-wheels/urllib3-1.19.1-py2.py3-none-any.whl/urllib3/connection.py\", line 138, in _new_conn\n    (self.host, self.port), self.timeout, **extra_kw)\n  File \"/data/home/jtheb/ludwig/venv/share/python-wheels/urllib3-1.19.1-py2.py3-none-any.whl/urllib3/util/connection.py\", line 98, in create_connection\n    raise err\n  File \"/data/home/jtheb/ludwig/venv/share/python-wheels/urllib3-1.19.1-py2.py3-none-any.whl/urllib3/util/connection.py\", line 88, in create_connection\n    sock.connect(sa)\nsocket.timeout: timed out\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/data/home/jtheb/ludwig/venv/share/python-wheels/urllib3-1.19.1-py2.py3-none-any.whl/urllib3/connectionpool.py\", line 594, in urlopen\n    chunked=chunked)\n  File \"/data/home/jtheb/ludwig/venv/share/python-wheels/urllib3-1.19.1-py2.py3-none-any.whl/urllib3/connectionpool.py\", line 361, in _make_request\n    conn.request(method, url, **httplib_request_kw)\n  File \"/usr/lib/python3.5/http/client.py\", line 1107, in request\n    self._send_request(method, url, body, headers)\n  File \"/usr/lib/python3.5/http/client.py\", line 1152, in _send_request\n    self.endheaders(body)\n  File \"/usr/lib/python3.5/http/client.py\", line 1103, in endheaders\n    self._send_output(message_body)\n  File \"/usr/lib/python3.5/http/client.py\", line 934, in _send_output\n    self.send(msg)\n  File \"/usr/lib/python3.5/http/client.py\", line 877, in send\n    self.connect()\n  File \"/data/home/jtheb/ludwig/venv/share/python-wheels/urllib3-1.19.1-py2.py3-none-any.whl/urllib3/connection.py\", line 163, in connect\n    conn = self._new_conn()\n  File \"/data/home/jtheb/ludwig/venv/share/python-wheels/urllib3-1.19.1-py2.py3-none-any.whl/urllib3/connection.py\", line 143, in _new_conn\n    (self.host, self.timeout))\npip._vendor.requests.packages.urllib3.exceptions.ConnectTimeoutError: (&lt;pip._vendor.requests.packages.urllib3.connection.HTTPConnection object at 0x7fe436346898&gt;, 'Connection to 192.168.24.3 timed out. (connect timeout=15)')\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/share/python-wheels/pip-9.0.1-py2.py3-none-any.whl/pip/basecommand.py\", line 215, in main\n    status = self.run(options, args)\n  File \"/usr/share/python-wheels/pip-9.0.1-py2.py3-none-any.whl/pip/commands/install.py\", line 353, in run\n    wb.build(autobuilding=True)\n  File \"/usr/share/python-wheels/pip-9.0.1-py2.py3-none-any.whl/pip/wheel.py\", line 749, in build\n    self.requirement_set.prepare_files(self.finder)\n  File \"/usr/share/python-wheels/pip-9.0.1-py2.py3-none-any.whl/pip/req/req_set.py\", line 380, in prepare_files\n    ignore_dependencies=self.ignore_dependencies))\n  File \"/usr/share/python-wheels/pip-9.0.1-py2.py3-none-any.whl/pip/req/req_set.py\", line 554, in _prepare_file\n    require_hashes\n  File \"/usr/share/python-wheels/pip-9.0.1-py2.py3-none-any.whl/pip/req/req_install.py\", line 278, in populate_link\n    self.link = finder.find_requirement(self, upgrade)\n  File \"/usr/share/python-wheels/pip-9.0.1-py2.py3-none-any.whl/pip/index.py\", line 465, in find_requirement\n    all_candidates = self.find_all_candidates(req.name)\n  File \"/usr/share/python-wheels/pip-9.0.1-py2.py3-none-any.whl/pip/index.py\", line 423, in find_all_candidates\n    for page in self._get_pages(url_locations, project_name):\n  File \"/usr/share/python-wheels/pip-9.0.1-py2.py3-none-any.whl/pip/index.py\", line 568, in _get_pages\n    page = self._get_page(location)\n  File \"/usr/share/python-wheels/pip-9.0.1-py2.py3-none-any.whl/pip/index.py\", line 683, in _get_page\n    return HTMLPage.get_page(link, session=self.session)\n  File \"/usr/share/python-wheels/pip-9.0.1-py2.py3-none-any.whl/pip/index.py\", line 792, in get_page\n    \"Cache-Control\": \"max-age=600\",\n  File \"/data/home/jtheb/ludwig/venv/share/python-wheels/requests-2.12.4-py2.py3-none-any.whl/requests/sessions.py\", line 501, in get\n    return self.request('GET', url, **kwargs)\n  File \"/usr/share/python-wheels/pip-9.0.1-py2.py3-none-any.whl/pip/download.py\", line 386, in request\n    return super(PipSession, self).request(method, url, *args, **kwargs)\n  File \"/data/home/jtheb/ludwig/venv/share/python-wheels/requests-2.12.4-py2.py3-none-any.whl/requests/sessions.py\", line 488, in request\n    resp = self.send(prep, **send_kwargs)\n  File \"/data/home/jtheb/ludwig/venv/share/python-wheels/requests-2.12.4-py2.py3-none-any.whl/requests/sessions.py\", line 609, in send\n    r = adapter.send(request, **kwargs)\n  File \"/data/home/jtheb/ludwig/venv/share/python-wheels/requests-2.12.4-py2.py3-none-any.whl/requests/adapters.py\", line 423, in send\n    timeout=timeout\n  File \"/data/home/jtheb/ludwig/venv/share/python-wheels/urllib3-1.19.1-py2.py3-none-any.whl/urllib3/connectionpool.py\", line 643, in urlopen\n    _stacktrace=sys.exc_info()[2])\n  File \"/data/home/jtheb/ludwig/venv/share/python-wheels/urllib3-1.19.1-py2.py3-none-any.whl/urllib3/util/retry.py\", line 315, in increment\n    total -= 1\nTypeError: unsupported operand type(s) for -=: 'Retry' and 'int'\n----------------------------------------\n...Installing setuptools, pkg_resources, pip, wheel...done.\nTraceback (most recent call last):\n  File \"/usr/bin/virtualenv\", line 11, in &lt;module&gt;\n    load_entry_point('virtualenv==15.1.0', 'console_scripts', 'virtualenv')()\n  File \"/usr/lib/python3/dist-packages/virtualenv.py\", line 724, in main\n    symlink=options.symlink)\n  File \"/usr/lib/python3/dist-packages/virtualenv.py\", line 992, in create_environment\n    download=download,\n  File \"/usr/lib/python3/dist-packages/virtualenv.py\", line 922, in install_wheel\n    call_subprocess(cmd, show_stdout=False, extra_env=env, stdin=SCRIPT)\n  File \"/usr/lib/python3/dist-packages/virtualenv.py\", line 817, in call_subprocess\n    % (cmd_desc, proc.returncode))\nOSError: Command /data/home/jtheb/ludwig/venv/bin/python3 - setuptools pkg_resources pip wheel failed with error code 2\n</code></pre>\n",
                    "OwnerUserId": "11171670",
                    "LastEditorUserId": "1466970",
                    "LastEditDate": "2019-07-02T18:49:01.460",
                    "LastActivityDate": "2019-07-02T18:49:01.460",
                    "Title": "While trying to install virtualenv on server without sudo rights I got: `TypeError: unsupported operand type(s) for -=: 'Retry' and 'int'`",
                    "Tags": "<python><tensorflow><virtualenv><ludwig>",
                    "AnswerCount": "1",
                    "CommentCount": "8",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "55655269",
                "ParentRepo": "https://github.com/RasaHQ/rasa_core_sdk/blob/cfffaac0013606f7614ab0f213bc39623ee8b53c/rasa_core_sdk/forms.py#L374",
                "StackOverflow_Post": {
                    "Id": "55655269",
                    "PostTypeId": "2",
                    "ParentId": "55552019",
                    "CreationDate": "2019-04-12T15:44:52.230",
                    "Score": "0",
                    "Body": "<p>I assume you mean how the action sdk determines which template it should use to ask for a requested slot, right? </p>\n\n<p>This logic is actually hardcoded here: <a href=\"https://github.com/RasaHQ/rasa_core_sdk/blob/cfffaac0013606f7614ab0f213bc39623ee8b53c/rasa_core_sdk/forms.py#L374\" rel=\"nofollow noreferrer\">https://github.com/RasaHQ/rasa_core_sdk/blob/cfffaac0013606f7614ab0f213bc39623ee8b53c/rasa_core_sdk/forms.py#L374</a></p>\n\n<p>What it does is simply dispatches an utterance which is <code>utter_ask_{the name of slot which should be requested}</code>.</p>\n\n<p>If the user then sends back his answer, the form action is triggered again and the slot value can be extracted.</p>\n",
                    "OwnerUserId": "3429596",
                    "LastActivityDate": "2019-04-12T15:44:52.230",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "55665510",
                "ParentRepo": "https://github.com/andli/pymkm",
                "StackOverflow_Post": {
                    "Id": "55665510",
                    "PostTypeId": "2",
                    "ParentId": "55659823",
                    "CreationDate": "2019-04-13T12:36:05.470",
                    "Score": "3",
                    "Body": "<blockquote>\n<p><strong>Question</strong>: fetch the stock of specific users</p>\n</blockquote>\n<h3>Cardmarket RESTful API Documentation (Version 2.0)</h3>\n<ul>\n<li><a href=\"https://api.cardmarket.com/ws/documentation/API:Auth_OAuthHeader\" rel=\"nofollow noreferrer\">OAuth Header and Generating a Signature </a></li>\n<li><a href=\"https://www.mkmapi.eu/ws/documentation/API_2.0:Articles\" rel=\"nofollow noreferrer\">Articles</a></li>\n<li><a href=\"https://www.mkmapi.eu/ws/documentation/API_2.0:User_Articles\" rel=\"nofollow noreferrer\">User Articles</a></li>\n</ul>\n<h3>Python wrapper for the cardmarket.com API (version 2.0, using OAuth1)</h3>\n<ul>\n<li><a href=\"https://github.com/andli/pymkm\" rel=\"nofollow noreferrer\"><code>pymkm</code></a></li>\n</ul>\n<h3>Requests-OAuthlib: OAuth for Humans</h3>\n<ul>\n<li><a href=\"https://requests-oauthlib.readthedocs.io/en/latest/index.html\" rel=\"nofollow noreferrer\">Docs \u00bb Requests-OAuthlib</a></li>\n</ul>\n<hr />\n<p>Using <code>OAuth1Session</code>:</p>\n<pre><code>from requests_oauthlib import OAuth1Session\n\n# base_url = 'https://api.cardmarket.com/ws/v2.0/output.json'\nbase_url = 'https://api.cardmarket.com/ws/v2.0'\n\n# product_id = 266361 # Mandatory\n# url = '{}/articles/{}'.format(base_url, product_id)\n\nuser_id = 266361 # Mandatory  Type: integer (ID) or string (name)\nurl = '{}/users/:{}/articles'.format(base_url, user_id)\n\noauth = OAuth1Session('app_token',\n                       client_secret='app_secret',\n                       resource_owner_key='access_token',\n                       resource_owner_secret='access_token_secret',\n                       realm=url\n                      )\n\nparams = {'start':0, 'maxResults':100}\nr = oauth.get(url, params=params)\n</code></pre>\n",
                    "OwnerUserId": "7414759",
                    "LastEditorUserId": "-1",
                    "LastEditDate": "2020-06-20T09:12:55.060",
                    "LastActivityDate": "2019-04-13T13:10:29.227",
                    "CommentCount": "3",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "55921074",
                "ParentRepo": "https://github.com/p1c2u/openapi-core",
                "StackOverflow_Post": {
                    "Id": "55921074",
                    "PostTypeId": "2",
                    "ParentId": "54748710",
                    "CreationDate": "2019-04-30T12:33:53.483",
                    "Score": "2",
                    "Body": "<p>As for <strong>Q1 2019</strong> there is no such tool.\nThe good list of existing tools is <a href=\"https://openapi.tools/#data-validators\" rel=\"nofollow noreferrer\">https://openapi.tools/#data-validators</a></p>\n\n<p>As a workaround one could use one of the existing tools and call binary created with such tool from python.</p>\n\n<p>PS. There is <a href=\"https://github.com/p1c2u/openapi-core\" rel=\"nofollow noreferrer\">https://github.com/p1c2u/openapi-core</a> but it seems not to support full OpenApi 3.</p>\n",
                    "OwnerUserId": "1064544",
                    "LastActivityDate": "2019-04-30T12:33:53.483",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "56010650",
                "ParentRepo": "https://github.com/RasaHQ/rasa/issues/1699",
                "StackOverflow_Post": {
                    "Id": "56010650",
                    "PostTypeId": "2",
                    "ParentId": "55952525",
                    "CreationDate": "2019-05-06T18:35:53.207",
                    "Score": "11",
                    "Body": "<p>If your python 3.5 is version 3.5.3 or below, I believe upgrading should fix it. See a relevant issue <a href=\"https://github.com/RasaHQ/rasa/issues/1699\" rel=\"noreferrer\">here</a></p>\n\n<p>From the relevant error in <a href=\"https://github.com/python/typing/issues/266\" rel=\"noreferrer\">typing</a>:</p>\n\n<blockquote>\n  <p><code>typing</code> will only get upgraded with Python if you are on Python 3.5+. Since this issue was fixed in August 2016, I believe any 3.5 release above 3.5.3 should work.</p>\n</blockquote>\n",
                    "OwnerUserId": "11227100",
                    "LastActivityDate": "2019-05-06T18:35:53.207",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "56596075",
                "ParentRepo": "https://github.com/yunstanford/pytest-sanic",
                "StackOverflow_Post": {
                    "Id": "56596075",
                    "PostTypeId": "2",
                    "ParentId": "56594314",
                    "CreationDate": "2019-06-14T10:15:08.223",
                    "Score": "0",
                    "Body": "<p>I think you can fix your bug by changing this method: </p>\n\n<pre class=\"lang-py prettyprint-override\"><code>@app.listener('after_server_stop')\nasync def finish(app, loop):\n    await app.aiohttp_session.close()\n</code></pre>\n\n<p>That's not your responsibility to close the loop and you should use the fact that <code>finish</code> is called from an asynchronous context (you don't need to start the event loop, it's already running).</p>\n\n<p>If that's not the only problem, then maybe start from a simpler example and add things until it breaks again. Sanic looks to have a well documented <a href=\"https://sanic.readthedocs.io/en/latest/sanic/testing.html#testing\" rel=\"nofollow noreferrer\">test section</a> where they suggest to use <a href=\"https://github.com/yunstanford/pytest-sanic\" rel=\"nofollow noreferrer\">pytest-sanic</a>. A simple example using pytest would look like: </p>\n\n<pre class=\"lang-py prettyprint-override\"><code># file: server.py\nfrom sanic import Sanic\nfrom sanic.response import json\n\napp = Sanic()\n\n@app.route('/')\nasync def test(request):\n    return json({'hello': 'world'})\n\nif __name__ == \"__main__\":\n    app.run(host='0.0.0.0', port=8000)\n</code></pre>\n\n<pre class=\"lang-py prettyprint-override\"><code># file: server_test.py\nimport pytest\nfrom server import app\n\n@pytest.yield_fixture\ndef sanic_app():\n    yield app\n\n@pytest.fixture\ndef test_cli(loop, sanic_app, sanic_client):\n    return loop.run_until_complete(sanic_client(app))\n\nasync def test_index(test_cli):\n    resp = await test_cli.get('/')\n    assert resp.status == 200\n    json = await resp.json()\n    assert json == {'hello': 'world'}\n\nasync def test_index_fail(test_cli):\n    resp = await test_cli.get('/')\n    assert resp.status == 200\n    json = await resp.json()\n    assert json == {'bonjour': 'monde'}\n</code></pre>\n\n<p>You would need to install some packages: </p>\n\n<pre><code>pip install sanic pytest pytest-sanic\n</code></pre>\n\n<p>Then you could just run <code>pytest</code>, you should have the first test passing and the second failing. </p>\n\n<p>In general you shouldn't have to start an event loop yourself, always try to get rid of the <code>loop.run_...</code>.</p>\n",
                    "OwnerUserId": "1720199",
                    "LastActivityDate": "2019-06-14T10:15:08.223",
                    "CommentCount": "3",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "56640234",
                "ParentRepo": "https://github.com/simonw/datasette",
                "StackOverflow_Post": {
                    "Id": "56640234",
                    "PostTypeId": "1",
                    "CreationDate": "2019-06-18T00:09:42.137",
                    "Score": "2",
                    "ViewCount": "248",
                    "Body": "<p>I'm working with a Python-based library called \"<a href=\"https://github.com/simonw/datasette\" rel=\"nofollow noreferrer\">datasette</a>\" that makes it easy to search SQLite databases. I'm trying to push more than 1.5GB worth of SQLite databases, 535MB compressed, to Heroku but I get this error when I run <code>datasette publish heroku</code>.</p>\n\n<pre><code>Compiled slug size: 535.5M is too large (max is 500M).\n</code></pre>\n\n<p>How can I work around the slug size limits?</p>\n",
                    "OwnerUserId": "1435711",
                    "LastEditorUserId": "997358",
                    "LastEditDate": "2019-11-25T19:59:24.240",
                    "LastActivityDate": "2019-11-25T20:01:01.927",
                    "Title": "How to get around Heroku slug size limits?",
                    "Tags": "<sqlite><heroku><datasette>",
                    "AnswerCount": "2",
                    "CommentCount": "2",
                    "FavoriteCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "56656918",
                "ParentRepo": "https://github.com/RasaHQ/rasa-sdk/blob/b18f088446e405608b74193e84c0d82ddfe6af47/rasa_sdk/forms.py#L340",
                "StackOverflow_Post": {
                    "Id": "56656918",
                    "PostTypeId": "2",
                    "ParentId": "56051878",
                    "CreationDate": "2019-06-18T20:55:32.967",
                    "Score": "0",
                    "Body": "<p>here is a Rasa Dev :-) \nYou could overwrite the <code>validate</code> <a href=\"https://github.com/RasaHQ/rasa-sdk/blob/b18f088446e405608b74193e84c0d82ddfe6af47/rasa_sdk/forms.py#L340\" rel=\"nofollow noreferrer\">function here</a>.</p>\n\n<p>Probably something along these lines:</p>\n\n<pre><code>    def validate(self, dispatcher, tracker, domain):\n        # type: (CollectingDispatcher, Tracker, Dict[Text, Any]) -&gt; List[Dict]\n        \"\"\"Extract and validate value of requested slot.\n        If nothing was extracted reject execution of the form action.\n        Subclass this method to add custom validation and rejection logic\n        \"\"\"\n\n        # extract other slots that were not requested\n        # but set by corresponding entity or trigger intent mapping\n        slot_values = self.extract_other_slots(dispatcher, tracker, domain)\n\n        slot_value = slot_values.get(\"slot_name\")\n        events = []\n        if not_is_valid(slot_value):\n           events.append(SlotSet(\"slot_name\", \"slot_value\"))\n\n        # TODO validate others\n\n        return events\n\n</code></pre>\n",
                    "OwnerUserId": "3429596",
                    "LastActivityDate": "2019-06-18T20:55:32.967",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "57379605",
                "ParentRepo": "https://github.com/cloudtools/awacs",
                "StackOverflow_Post": {
                    "Id": "57379605",
                    "PostTypeId": "2",
                    "ParentId": "57376216",
                    "CreationDate": "2019-08-06T15:40:03.397",
                    "Score": "1",
                    "Body": "<p>You might want to look at the <a href=\"https://github.com/cloudtools/awacs\" rel=\"nofollow noreferrer\">awacs</a> project which allows for policy definition.</p>\n\n<p>Also, likely you need to just Ref() your policy to get the name of it.</p>\n",
                    "OwnerUserId": "3845642",
                    "LastActivityDate": "2019-08-06T15:40:03.397",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "57605307",
                "ParentRepo": "https://github.com/SAP/python-pyodata/commit/dd467e6ad58588d8c6edaae6b99967eb8cfe4c7c",
                "StackOverflow_Post": {
                    "Id": "57605307",
                    "PostTypeId": "2",
                    "ParentId": "56396535",
                    "CreationDate": "2019-08-22T08:39:58.310",
                    "Score": "0",
                    "Body": "<p>I maintain the package and we had problems with XML namespaces which we fixed few weeks ago:\n<a href=\"https://github.com/SAP/python-pyodata/commit/dd467e6ad58588d8c6edaae6b99967eb8cfe4c7c\" rel=\"nofollow noreferrer\">https://github.com/SAP/python-pyodata/commit/dd467e6ad58588d8c6edaae6b99967eb8cfe4c7c</a></p>\n\n<p>I would recommend you to upgrade to the latest version of pyodata. If you still have the problems, you can instruct pyodata to use your namespaces:\n<a href=\"https://pyodata.readthedocs.io/en/latest/usage/initialization.html#dealing-with-errors-during-parsing-metadata\" rel=\"nofollow noreferrer\">https://pyodata.readthedocs.io/en/latest/usage/initialization.html#dealing-with-errors-during-parsing-metadata</a></p>\n\n<p>You can the namespace URIs at the begging of $metadata</p>\n\n<pre><code>&lt;edmx:Edmx xmlns:edmx=\"http://schemas.microsoft.com/ado/2007/06/edmx\" Version=\"1.0\"&gt;\n  &lt;edmx:DataServices xmlns:m=\"http://schemas.microsoft.com/ado/2007/08/dataservices/metadata\" m:DataServiceVersion=\"1.0\" m:MaxDataServiceVersion=\"3.0\"&gt;\n     &lt;Schema xmlns=\"http://schemas.microsoft.com/ado/2008/09/edm\" Namespace=\"NorthwindModel\"&gt;\n</code></pre>\n\n<p>The XML fragment above was obtained from the Microsoft's Northwind service which is supported by default and servers here only the demonstration purpose. In your python code, you would write the following:</p>\n\n<pre><code>from pyodata.v2.model import Config\n\nnamespaces = {\n    'edmx': 'http://schemas.microsoft.com/ado/2007/06/edmx',\n    'edm': 'http://schemas.microsoft.com/ado/2008/09/edm'\n}\n\ncustom_config = Config(xml_namespaces=namespaces)\n\nnorthwind = pyodata.Client(SERVICE_URL, requests.Session(), config=custom_config)\n</code></pre>\n",
                    "OwnerUserId": "4973805",
                    "LastActivityDate": "2019-08-22T08:39:58.310",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "SID": "58026695",
                "StackOverflow_Post": {
                    "Id": "58026695",
                    "PostTypeId": "2",
                    "ParentId": "57261619",
                    "CreationDate": "2019-09-20T10:35:45.127",
                    "Score": "2",
                    "Body": "<p>This have support for brotli requests <a href=\"https://github.com/encode/httpx\" rel=\"nofollow noreferrer\">https://github.com/encode/httpx</a>.</p>\n\n<p>Example from unit tests:</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>import brotli\nimport httpx\n\nbody = b\"test 123\"\ncompressed_body = brotli.compress(body)\n\nheaders = [(b\"Content-Encoding\", b\"br\")]\nresponse = httpx.Response(200, headers=headers, content=compressed_body)\n</code></pre>\n",
                    "OwnerUserId": "1643541",
                    "LastActivityDate": "2019-09-20T10:35:45.127",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "58855239",
                "ParentRepo": "https://github.com/williamFalcon/pytorch-lightning/pull/310",
                "StackOverflow_Post": {
                    "Id": "58855239",
                    "PostTypeId": "2",
                    "ParentId": "58115801",
                    "CreationDate": "2019-11-14T11:01:03.677",
                    "Score": "2",
                    "Body": "<p>The support for lbfgs optimizer was added on <a href=\"https://github.com/williamFalcon/pytorch-lightning/pull/310\" rel=\"nofollow noreferrer\">#310</a>, now it is not required to define a closure function.</p>\n",
                    "OwnerUserId": "3513738",
                    "LastActivityDate": "2019-11-14T11:01:03.677",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "59017711",
                "ParentRepo": "https://github.com/elastic/apm-agent-python/issues/293",
                "StackOverflow_Post": {
                    "Id": "59017711",
                    "PostTypeId": "2",
                    "ParentId": "59015424",
                    "CreationDate": "2019-11-24T12:37:14.223",
                    "Score": "2",
                    "Body": "<p>From <a href=\"https://github.com/elastic/apm-agent-python/issues/293\" rel=\"nofollow noreferrer\">here</a>, it looks like <code>functools.partial</code> does not copy the <code>__module__</code> and <code>__name__</code> attributes from the inner function. You can work around it by defining <code>__name__</code> manually:</p>\n\n<pre><code>import tkinter as tk\nfrom functools import partial\n\ndef change_color(color):\n    root.configure(bg=color)\n\nroot = tk.Tk()\n\nc = partial(change_color, 'blue')\nc.__name__ = \"c\"\n\nroot.after(1000, c)\n\nroot.mainloop()\n</code></pre>\n",
                    "OwnerUserId": "9284423",
                    "LastActivityDate": "2019-11-24T12:37:14.223",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "59164798",
                "ParentRepo": "https://github.com/geopython/pygeoapi/blob/b61404d610060361e931e8abbd05b9ba34d9cc00/pygeoapi/provider/geojson.py",
                "StackOverflow_Post": {
                    "Id": "59164798",
                    "PostTypeId": "1",
                    "CreationDate": "2019-12-03T20:25:04.767",
                    "Score": "2",
                    "ViewCount": "125",
                    "Body": "<p>It looks like the <a href=\"https://github.com/geopython/pygeoapi/blob/b61404d610060361e931e8abbd05b9ba34d9cc00/pygeoapi/provider/geojson.py\" rel=\"nofollow noreferrer\">GeoJSON provider</a> is the first, and currently the only, provider to implement <code>create</code>, <code>update</code> and <code>delete</code> operations.</p>\n\n<p>I can't see an example for how to enable these operations in the <code>pygeoapi-config.yml</code> file. Is it possible?</p>\n",
                    "OwnerUserId": "1624894",
                    "LastEditorUserId": "1624894",
                    "LastEditDate": "2020-07-14T09:20:58.660",
                    "LastActivityDate": "2020-07-14T09:20:58.660",
                    "Title": "Create, Update and Delete operations in pygeoapi",
                    "Tags": "<python><geojson><ogc>",
                    "AnswerCount": "1",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "59815441",
                "ParentRepo": "https://github.com/prefecthq/prefect",
                "StackOverflow_Post": {
                    "Id": "59815441",
                    "PostTypeId": "2",
                    "ParentId": "58419203",
                    "CreationDate": "2020-01-19T23:44:42.900",
                    "Score": "4",
                    "Body": "<p>From the knowledge I gained in my attempt to answer this question, I've come to the conclusion that <strong>Airflow is just not the tool for the job.</strong></p>\n\n<p>Airflow is designed for <em>scheduled</em>, idempotent DAGs. A DagRun must also have a unique <code>execution_date</code>; this means running the same DAG at the exact same start time (in the case that we receive two documents at the same time is quite literally impossible. Of course, we can schedule the next DagRun immediately in succession, but this limitation should demonstrate that any attempt to use Airflow in this fashion will always be, to an extent, a hack.</p>\n\n<p>The most viable solution I've found is to instead use <a href=\"https://github.com/prefecthq/prefect\" rel=\"nofollow noreferrer\">Prefect</a>, which was developed with the intention of overcoming some of the limitations of Airflow:</p>\n\n<p>\"Prefect assumes that flows can be run at any time, for any reason.\"</p>\n\n<p>Prefect's equivalent of a DAG is a Flow; one key advantage of a flow that we may take advantage of is the ease of parametriziation. Then, with some threads, we're able to have a Flow run for each element in a stream. Here is an example streaming ETL pipeline:</p>\n\n<pre><code>import time\nfrom prefect import task, Flow, Parameter\nfrom threading import Thread\n\u200b\n\u200b\ndef stream():\n    for x in range(10):\n        yield x\n        time.sleep(1)\n\u200b\n\u200b\n@task\ndef extract(x):\n    # If 'x' referenced a document, in this step we could load that document\n    return x\n\u200b\n\u200b\n@task\ndef transform(x):\n    return x * 2\n\u200b\n\u200b\n@task\ndef load(y):\n    print(\"Received y: {}\".format(y))\n\u200b\n\u200b\nwith Flow(\"ETL\") as flow:\n    x_param = Parameter('x')\n    e = extract(x_param)\n    t = transform(e)\n    l = load(t)\n\u200b\nfor x in stream():\n    thread = Thread(target=flow.run, kwargs={\"x\": x})\n    thread.start()\n</code></pre>\n",
                    "OwnerUserId": "4418475",
                    "LastEditorUserId": "4418475",
                    "LastEditDate": "2020-01-19T23:55:49.883",
                    "LastActivityDate": "2020-01-19T23:55:49.883",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "59840282",
                "ParentRepo": "https://github.com/deezer/spleeter",
                "StackOverflow_Post": {
                    "Id": "59840282",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "59842926",
                    "CreationDate": "2020-01-21T11:34:30.877",
                    "Score": "0",
                    "ViewCount": "185",
                    "Body": "<p>I'm using <a href=\"https://github.com/deezer/spleeter\" rel=\"nofollow noreferrer\">Spleeter</a> to remove music from audios. </p>\n\n<p>My goal is to build a script that automates the process of extracting audio from the video, execute Spleeter on the extracted audio &amp; than merge the manipulated audio back to the video replacing the original one. </p>\n\n<p>The main issue I had is that I don't have enough ram to process the whole extracted audio. I need to split it the into multiple pieces &amp; execute Spleeter upon each piece.</p>\n\n<p>Then concatenate the manipulated pieces together and merge the result to the video.</p>\n\n<p>Here's what I tried:</p>\n\n<pre><code>#!/bin/bash\n\ncd ~/Desktop/Video-convert\n\n# create audio from video\nffmpeg -i *.mp4 output.mp3\n\n# Split the audio into pieces\nffmpeg -i output.mp3 -f segment -segment_time 120 -c copy output_%03d.mp3\n\n\n# Execute Spleeter upon each sample\nFILES=~/Desktop/Video-convert/*.mp3\n\nfor f in $FILES\ndo\n  spleeter separate -i $f -o output_vocal\ndone\n\n# delete unneeded audios\nrm *.mp3\ncd output_vocal\n\n# ===========================================================\n# the problem starts here\n# ===========================================================\n\n# concatenate manipulated audios together\nfind . -name 'vocals.wav' -exec echo {} &gt;&gt; mylist.txt \\;\n\nffmpeg -f concat -safe 0 -i mylist.txt -c copy vocal.mp3\n\nmv vocal.mp3 ../\n\ncd ../\n\n# merge the audio back to video\nffmpeg -i *.mp4 -i vocal.mp3 \\\n-c:v copy -c:a aac -strict experimental \\\n-map 0:v:0 -map 1:a:0 vocal-vid.mp4\n</code></pre>\n\n<p>Everything works well until having to concatenate the audios together. Spleeter outputs the result into <strong>vocal.wav</strong> &amp; <strong>accompaniment.wav</strong> within a sub-folder that is named the same as the audio that was processed.</p>\n\n<p>The File Tree looks like this:</p>\n\n<pre><code>output_vocal\n- output_000\n----- vocal.wav\n----- accompaniment.wav\n- output_001\n----- vocal.wav\n----- accompaniment.wav\n- output_002\n----- vocal.wav\n----- accompaniment.wav\n</code></pre>\n\n<p>As you can see the problem comes with the naming. My objective is to concatenate all <strong>vocal.wav</strong> into one mp3 audio. </p>\n\n<p>And then merge the final <strong>vocal.mp3</strong> audio with the <strong>*.mp4</strong> video.</p>\n\n<p>Only issue is going around the way that Spleeter outputs the result audios.</p>\n",
                    "OwnerUserId": "12067875",
                    "LastActivityDate": "2020-01-21T14:33:42.803",
                    "Title": "Extract AUDIO, manipulate & merge again",
                    "Tags": "<linux><bash><shell><audio><ffmpeg>",
                    "AnswerCount": "1",
                    "CommentCount": "4",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "59956029",
                "ParentRepo": "https://github.com/PrefectHQ/prefect",
                "StackOverflow_Post": {
                    "Id": "59956029",
                    "PostTypeId": "2",
                    "ParentId": "59164875",
                    "CreationDate": "2020-01-28T19:50:01.850",
                    "Score": "3",
                    "Body": "<p>This is now possible on the <a href=\"https://github.com/PrefectHQ/prefect\" rel=\"nofollow noreferrer\">master branch</a> of Prefect and will be released with 0.9.2 next week: the <a href=\"https://docs.prefect.io/core/concepts/schedules.html#clocks\" rel=\"nofollow noreferrer\">Clocks API</a> now allows for providing parameters to each clock that will be passed to each flow run generated from that clock.  In your case, you can do:</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>from prefect import task, Flow, Task, Parameter\nfrom prefect.schedules import clocks, Schedule\n\ndiurnal   = ['rooster', 'dog']\nnocturnal = ['owl', 'hampster']\n\n# Clocks\ndiurnal_clock   = clocks.CronClock(\"50 7 * * mon,wed\", parameter_defaults={\"animals\": diurnal})\nnocturnal_clock = clocks.CronClock(\"15 12 * * tue,thu\", parameter_defaults={\"animals\": nocturnal})\n\n# the full schedule\nschedule = Schedule(clocks=[diurnal_clock, nocturnal_clock])\n\n# Flow is common to both types, though with different schedules.\nwith Flow(name=\"wakuptime\", schedule=schedule) as this_flow:\n    animals = Parameter(\"animals\", default=[])\n    wakeup(animals)\n\n# will run on the schedule with varying parameter values\nthis_flow.run()\n</code></pre>\n",
                    "OwnerUserId": "1617887",
                    "LastActivityDate": "2020-01-28T19:50:01.850",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "59991377",
                "ParentRepo": "https://github.com/klen/aioauth-client",
                "StackOverflow_Post": {
                    "Id": "59991377",
                    "PostTypeId": "1",
                    "CreationDate": "2020-01-30T17:26:02.333",
                    "Score": "1",
                    "ViewCount": "672",
                    "Body": "<p>I have successfully implemented OAuth1 with the regular <code>requests</code> module like this:</p>\n\n<pre><code>import requests\nfrom requests_oauthlib import OAuth1\n\n\noauth = OAuth1(client_key=oauth_cred[\"consumer_key\"], client_secret=oauth_cred[\"consumer_secret\"], resource_owner_key=oauth_cred[\"access_token\"], resource_owner_secret=oauth_cred[\"access_token_secret\"])\n\nsession = requests.Session()\n\nsession.auth = oauth\n</code></pre>\n\n<p>When trying to transfer this to <code>aiohttp</code>, I have not been able to get it to work. Substituting <code>aiohttp.ClientSession()</code> for <code>requests.Session()</code> gives me <code>{'errors': [{'code': 215, 'message': 'Bad Authentication data.'}]}</code>. </p>\n\n<p>I have looked at some solutions on the internet like <a href=\"https://github.com/klen/aioauth-client\" rel=\"nofollow noreferrer\">https://github.com/klen/aioauth-client</a>, but this seems to be a different approach. I just want it to function exactly like in my example above.</p>\n\n<p>I tried </p>\n\n<pre><code>import aiohttp\nfrom aioauth_client import TwitterClient\n\n\noauth = TwitterClient(consumer_key=oauth_cred[\"consumer_key\"], consumer_secret=oauth_cred[\"consumer_secret\"], oauth_token=oauth_cred[\"access_token\"], oauth_token_secret=oauth_cred[\"access_token_secret\"])\n\nsession = aiohttp.ClientSession()\n\nsession.auth = oauth\n</code></pre>\n\n<p>but I got the same error.</p>\n\n<p>How can I get this to work?</p>\n",
                    "OwnerUserId": "9147378",
                    "LastActivityDate": "2021-08-19T05:21:30.093",
                    "Title": "How to use OAuth1 with aiohttp",
                    "Tags": "<python><http><asynchronous><oauth><aiohttp>",
                    "AnswerCount": "1",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "60046853",
                "ParentRepo": "https://github.com/dry-python/returns",
                "StackOverflow_Post": {
                    "Id": "60046853",
                    "PostTypeId": "2",
                    "ParentId": "59908236",
                    "CreationDate": "2020-02-03T20:41:13.050",
                    "Score": "5",
                    "Body": "<p>There are several main goals in Dependency Injection technique, including (but not limited to):</p>\n\n<ul>\n<li>Lowering coupling between parts of your system. This way you can change each part with less effort. See <a href=\"https://enterprisecraftsmanship.com/posts/cohesion-coupling-difference/\" rel=\"noreferrer\">\"High cohesion, low coupling\"</a></li>\n<li>To enforce stricter rules about responsibilities. One entity must do only one thing on its level of abstraction. Other entities must be defined as dependencies to this one. See <a href=\"https://en.wikipedia.org/wiki/Inversion_of_control\" rel=\"noreferrer\">\"IoC\"</a></li>\n<li>Better testing experience. Explicit dependencies allow you to stub different parts of your system with some primitive test behaviour that has the same public API than your production code. See <a href=\"https://martinfowler.com/articles/mocksArentStubs.html\" rel=\"noreferrer\">\"Mocks arent' stubs\"</a></li>\n</ul>\n\n<p>The other thing to keep in mind is that we usually shall rely on abstractions, not implementations. I see a lot of people who use DI to inject only particular implementation. There's a big difference.</p>\n\n<p>Because when you inject and rely on an implementation, there's no difference in what method we use to create objects. It just does not matter. For example, if you inject <code>requests</code> without proper abstractions you would still require anything similar with the same methods, signatures, and return types. You would not be able to replace this implementation at all. But, when you inject <code>fetch_order(order: OrderID) -&gt; Order</code> it means that anything can be inside. <code>requests</code>, database, whatever.</p>\n\n<p>To sum things up:</p>\n\n<blockquote>\n  <p>What are the benefits of using inject?</p>\n</blockquote>\n\n<p>The main benefit is that you don't have to assemble your dependencies manually. However, this comes with a huge cost: you are using complex, even magical, tools to solve problems. One day or another complexity will fight you back.</p>\n\n<blockquote>\n  <p>Is it worth to bother and use inject framework?</p>\n</blockquote>\n\n<p>One more thing about <code>inject</code> framework in particular. I don't like when objects where I inject something knows about it. It is an implementation detail!</p>\n\n<p>How in a world <code>Postcard</code> domain model, for example, knows this thing?</p>\n\n<p>I would recommend to use <a href=\"https://github.com/bobthemighty/punq\" rel=\"noreferrer\"><code>punq</code></a> for simple cases and <a href=\"https://github.com/dry-python/dependencies\" rel=\"noreferrer\"><code>dependencies</code></a> for complex ones.</p>\n\n<p><code>inject</code> also does not enforce a clean separation of \"dependencies\" and object properties. As it was said, one of the main goal of DI is to enforce stricter responsibilities. </p>\n\n<p>In contrast, let me show how <code>punq</code> works:</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>from typing_extensions import final\n\nfrom attr import dataclass\n\n# Note, we import protocols, not implementations:\nfrom project.postcards.repository.protocols import PostcardsForToday\nfrom project.postcards.services.protocols import (\n   SendPostcardsByEmail,\n   CountPostcardsInAnalytics,\n)\n\n@final\n@dataclass(frozen=True, slots=True)\nclass SendTodaysPostcardsUsecase(object):\n    _repository: PostcardsForToday\n    _email: SendPostcardsByEmail\n    _analytics: CountPostcardInAnalytics\n\n    def __call__(self, today: datetime) -&gt; None:\n        postcards = self._repository(today)\n        self._email(postcards)\n        self._analytics(postcards)\n</code></pre>\n\n<p>See? We even don't have a constructor. We declaratively define our dependencies and <code>punq</code> will automatically inject them. And we do not define any specific implementations. Only protocols to follow. This style is called \"functional objects\" or <a href=\"https://en.wikipedia.org/wiki/Single_responsibility_principle\" rel=\"noreferrer\">SRP</a>-styled classes.</p>\n\n<p>Then we define the <code>punq</code> container itself:</p>\n\n<pre class=\"lang-py prettyprint-override\"><code># project/implemented.py\n\nimport punq\n\ncontainer = punq.Container()\n\n# Low level dependencies:\ncontainer.register(Postgres)\ncontainer.register(SendGrid)\ncontainer.register(GoogleAnalytics)\n\n# Intermediate dependencies:\ncontainer.register(PostcardsForToday)\ncontainer.register(SendPostcardsByEmail)\ncontainer.register(CountPostcardInAnalytics)\n\n# End dependencies:\ncontainer.register(SendTodaysPostcardsUsecase)\n</code></pre>\n\n<p>And use it:</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>from project.implemented import container\n\nsend_postcards = container.resolve(SendTodaysPostcardsUsecase)\nsend_postcards(datetime.now())\n</code></pre>\n\n<p>See? Now our classes have no idea who and how creates them. No decorators, no special values.</p>\n\n<p>Read more about SRP-styled classes here:</p>\n\n<ul>\n<li><a href=\"https://sobolevn.me/2019/03/enforcing-srp\" rel=\"noreferrer\">Enforcing Single Responsibility Principle in Python</a></li>\n</ul>\n\n<blockquote>\n  <p>Are there any other better ways of separating the domain from the outside?</p>\n</blockquote>\n\n<p>You can use functional programming concepts instead of imperative ones. The main idea of function dependency injection is that you don't call things that relies on context you don't have. You schedule these calls for later, when the context is present. Here's how you can illustrate dependency injection with just simple functions:</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>from django.conf import settings\nfrom django.http import HttpRequest, HttpResponse\nfrom words_app.logic import calculate_points\n\ndef view(request: HttpRequest) -&gt; HttpResponse:\n    user_word: str = request.POST['word']  # just an example\n    points = calculate_points(user_words)(settings)  # passing the dependencies and calling\n    ...  # later you show the result to user somehow\n\n# Somewhere in your `word_app/logic.py`:\n\nfrom typing import Callable\nfrom typing_extensions import Protocol\n\nclass _Deps(Protocol):  # we rely on abstractions, not direct values or types\n    WORD_THRESHOLD: int\n\ndef calculate_points(word: str) -&gt; Callable[[_Deps], int]:\n    guessed_letters_count = len([letter for letter in word if letter != '.'])\n    return _award_points_for_letters(guessed_letters_count)\n\ndef _award_points_for_letters(guessed: int) -&gt; Callable[[_Deps], int]:\n    def factory(deps: _Deps):\n        return 0 if guessed &lt; deps.WORD_THRESHOLD else guessed\n    return factory\n</code></pre>\n\n<p>The only problem with this pattern is that <code>_award_points_for_letters</code> will be hard to compose.</p>\n\n<p>That's why we made a special wrapper to help the composition (it is a part of the <code>returns</code>:</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>import random\nfrom typing_extensions import Protocol\nfrom returns.context import RequiresContext\n\nclass _Deps(Protocol):  # we rely on abstractions, not direct values or types\n    WORD_THRESHOLD: int\n\ndef calculate_points(word: str) -&gt; RequiresContext[_Deps, int]:\n    guessed_letters_count = len([letter for letter in word if letter != '.'])\n    awarded_points = _award_points_for_letters(guessed_letters_count)\n    return awarded_points.map(_maybe_add_extra_holiday_point)  # it has special methods!\n\ndef _award_points_for_letters(guessed: int) -&gt; RequiresContext[_Deps, int]:\n    def factory(deps: _Deps):\n        return 0 if guessed &lt; deps.WORD_THRESHOLD else guessed\n    return RequiresContext(factory)  # here, we added `RequiresContext` wrapper\n\ndef _maybe_add_extra_holiday_point(awarded_points: int) -&gt; int:\n    return awarded_points + 1 if random.choice([True, False]) else awarded_points\n</code></pre>\n\n<p>For example, <code>RequiresContext</code> has special <code>.map</code> method to compose itself with a pure function. And that's it. As a result you have just simple functions and composition helpers with simple API. No magic, no extra complexity. And as a bonus everything is properly typed and compatible with <code>mypy</code>.</p>\n\n<p>Read more about this approach here:</p>\n\n<ul>\n<li><a href=\"https://sobolevn.me/2020/02/typed-functional-dependency-injection\" rel=\"noreferrer\">Typed functional dependency injection</a></li>\n<li><a href=\"https://github.com/dry-python/returns\" rel=\"noreferrer\">returns docs</a></li>\n</ul>\n",
                    "OwnerUserId": "4842742",
                    "LastActivityDate": "2020-02-03T20:41:13.050",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "60331839",
                "ParentRepo": "https://github.com/kubeflow/kfserving",
                "StackOverflow_Post": {
                    "Id": "60331839",
                    "PostTypeId": "1",
                    "CreationDate": "2020-02-21T03:33:32.320",
                    "Score": "1",
                    "ViewCount": "483",
                    "Body": "<p>Is there a suggested way to serve hundreds of machine learning models in Kubernetes?\nSolutions like <a href=\"https://github.com/kubeflow/kfserving\" rel=\"nofollow noreferrer\">Kfserving</a> seem to be more suitable for cases where there is a single trained model, or a few versions of it, and this model serves all requests. For instance a typeahead model that is universal across all users.</p>\n\n<p>But is there a <strong>suggested way to serve hundreds or thousands of such models?</strong> For example, a typeahead model trained specifically on each user's data.</p>\n\n<p>The most naive way to achieve something like that, would be that each typeahead serving container maintains a local cache of models in memory. But then scaling to multiple pods would be a problem because each cache is local to the pod. So each request would need to get routed to the correct pod that has loaded the model.</p>\n\n<p>Also having to maintain such a registry where we know which pod has loaded which model and perform updates on model eviction seems like a lot of work.</p>\n",
                    "OwnerUserId": "12936151",
                    "LastActivityDate": "2020-05-04T16:28:26.343",
                    "Title": "Kubernetes Machine Learning Model Serving",
                    "Tags": "<machine-learning><kubernetes><knative-serving>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "60434138",
                "ParentRepo": "https://github.com/PyTorchLightning/pytorch-lightning",
                "StackOverflow_Post": {
                    "Id": "60434138",
                    "PostTypeId": "2",
                    "ParentId": "52652214",
                    "CreationDate": "2020-02-27T13:17:24.450",
                    "Score": "4",
                    "Body": "<p>As of today, <a href=\"https://github.com/PyTorchLightning/pytorch-lightning\" rel=\"nofollow noreferrer\">PyTorch Lightning</a> allows to run PyTorch code on TPUs trivially (you will need the XLA library installed).\nFrom their demo notebook on <a href=\"https://colab.research.google.com/drive/1-_LKx4HwAxl5M6xPJmqAAu444LTDQoa3\" rel=\"nofollow noreferrer\">colab</a>:</p>\n\n<pre><code>from pytorch_lightning import Trainer\n\nmodel = CoolSystem()\n\n# most basic trainer, uses good defaults\ntrainer = Trainer(num_tpu_cores=8)\ntrainer.fit(model)\n</code></pre>\n",
                    "OwnerUserId": "2945357",
                    "LastActivityDate": "2020-02-27T13:17:24.450",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "60467878",
                "ParentRepo": "https://github.com/marcosschroh/python-schema-registry-client",
                "StackOverflow_Post": {
                    "Id": "60467878",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "60478201",
                    "CreationDate": "2020-02-29T17:39:13.750",
                    "Score": "3",
                    "ViewCount": "10355",
                    "Body": "<p>As of now i am doing something like this reading avsc file to get schema</p>\n\n<pre><code>value_schema = avro.load('client.avsc')\n</code></pre>\n\n<p>can i do something to get schema from confluent schema registry using topic-name? </p>\n\n<p>i found one way but didn't figure out how to use it.</p>\n\n<p><a href=\"https://github.com/marcosschroh/python-schema-registry-client\" rel=\"nofollow noreferrer\">https://github.com/marcosschroh/python-schema-registry-client</a></p>\n",
                    "OwnerUserId": "6793146",
                    "LastEditorUserId": "7131757",
                    "LastEditDate": "2020-04-09T00:02:03.207",
                    "LastActivityDate": "2021-09-02T16:51:30.887",
                    "Title": "How to programmatically get schema from confluent schema registry in Python",
                    "Tags": "<python><apache-kafka><avro><confluent-schema-registry>",
                    "AnswerCount": "3",
                    "CommentCount": "1",
                    "FavoriteCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "60699273",
                "ParentRepo": "https://github.com/florimondmanca/www/issues/102",
                "StackOverflow_Post": {
                    "Id": "60699273",
                    "PostTypeId": "2",
                    "ParentId": "60699202",
                    "CreationDate": "2020-03-16T01:16:06.770",
                    "Score": "7",
                    "Body": "<p>Well, you can do it by <strike>directly modifying the <code>__dict__</code> member of the instance</strike> modifying the attribute using <code>object.__setattr__(...)</code><sup>1</sup>, but why??? Asking specifically for <em>immutable</em> and then making it mutable is... indecisive. But if you must:</p>\n<pre class=\"lang-python prettyprint-override\"><code>from dataclasses import dataclass\n\n@dataclass(frozen=True)\nclass Foo:\n    id: str\n    name: str\n    def strip_id(self):\n        object.__setattr__(self, 'id', None)\n\nfoo=Foo(10, 'bar')\n\n&gt;&gt;&gt; foo\nFoo(id=10, name='bar')\n&gt;&gt;&gt; foo.strip_id()\n&gt;&gt;&gt; foo\nFoo(id=None, name='bar')\n</code></pre>\n<p>Any way of doing this is probably going to seem hacky... because it requires doing things that are fundamentally the opposite of the design.</p>\n<p>If you're using this as a signal to other programmers that they should not modify the values, the way that is normally done in Python is by prefixing the variable name with a single underscore. If you want to do that, while also making the values accessible, Python has a builtin module called <code>property</code>, where (from the documentation) &quot;typical use is to define a managed attribute&quot;:</p>\n<pre class=\"lang-python prettyprint-override\"><code>from dataclasses import dataclass\n\n@dataclass\nclass Foo:\n    _name: str\n    @property\n    def name(self):\n        return self._name\n    @name.setter\n    def name(self, value):\n        self._name = value\n    @name.deleter\n    def name(self):\n        self._name = None\n</code></pre>\n<p>Then you can use it like this:</p>\n<pre><code>&gt;&gt;&gt; f=Foo()\n&gt;&gt;&gt; f.name = &quot;bar&quot;\n&gt;&gt;&gt; f.name\n'bar'\n&gt;&gt;&gt; f._name\n'bar'\n&gt;&gt;&gt; del f.name\n&gt;&gt;&gt; f.name\n&gt;&gt;&gt; f._name\n</code></pre>\n<p>The decorated methods hide the actual value of <code>_name</code> behind <code>name</code> to control how the user interacts with that value. You can use this to apply transformation rules or validation checks to data before it is stored or returned.</p>\n<p>This doesn't quite accomplish the same thing as using <code>@dataclass(frozen=True)</code>, and if you try declaring it as frozen, you'll get an error. Mixing frozen dataclasses with the property decorator is not straightforward and I have not seen a satisfying solution that is concise and intuitive. @Arne posted <a href=\"https://stackoverflow.com/a/59249252/6689725\">this answer</a>, and I found <a href=\"https://github.com/florimondmanca/www/issues/102\" rel=\"nofollow noreferrer\">this thread</a> on GitHub, but neither approach is very inspiring; if I came across such things in code that I had to maintain, I would not be very happy (but I <em>would</em> be confused, and probably pretty irritated).</p>\n<hr />\n<p><sub>1: Modified as per the answer by @Arne, who observed that the internal use of a dictionary as the data container is not guaranteed.</sub></p>\n",
                    "OwnerUserId": "6689725",
                    "LastEditorUserId": "6689725",
                    "LastEditDate": "2021-11-29T01:29:15.053",
                    "LastActivityDate": "2021-11-29T01:29:15.053",
                    "CommentCount": "10",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "61271970",
                "ParentRepo": "https://github.com/tomwojcik/starlette-context",
                "StackOverflow_Post": {
                    "Id": "61271970",
                    "PostTypeId": "2",
                    "ParentId": "57204499",
                    "CreationDate": "2020-04-17T12:43:04.240",
                    "Score": "21",
                    "Body": "<p>A solution provided <a href=\"https://github.com/encode/starlette/issues/420\" rel=\"nofollow noreferrer\">here</a> defines a context manager, that you can access globally. For each request, you are extracting the relevant information (like headers) &amp; pass it to the context manager.</p>\n<p>Since fastapi is built with <a href=\"https://www.starlette.io/\" rel=\"nofollow noreferrer\">Starlette</a>, you can use the library <a href=\"https://github.com/tomwojcik/starlette-context\" rel=\"nofollow noreferrer\">starlette-context</a>. It is creating a <code>context</code> object that you can use without passing it as argument. The main caveat is that you still need to pass a request object to all your routes.</p>\n<p>EDIT: In <code>starlette-context==0.3.0</code> new middleware has been added. <code>Starlette</code> team started to discourage (<a href=\"https://github.com/encode/starlette/issues/919#issuecomment-672908610\" rel=\"nofollow noreferrer\">here</a>) the use of their <code>BaseHTTPMiddleware</code>, in particulary for StreamingResponse/FileResponse endpoints. You might want to use <code>RawContextMiddleware</code> which also doesn't require the request object but it's experimental as there is no documentation in <code>Starlette</code> for writing custom middleware without the interface. But it seems to be working.</p>\n<p>Sample code from this lib to illustrate:</p>\n<pre class=\"lang-py prettyprint-override\"><code>import uvicorn\nfrom fastapi import FastAPI\nfrom starlette.requests import Request\nfrom starlette.responses import JSONResponse\nfrom starlette.middleware import Middleware\n\nfrom starlette_context import context, plugins\nfrom starlette_context.middleware import RawContextMiddleware\n\nmiddleware = [\n    Middleware(\n        RawContextMiddleware,\n        plugins=(\n            plugins.RequestIdPlugin(),\n            plugins.CorrelationIdPlugin()\n        )\n    )\n]\n\napp = FastAPI(debug=True, middleware=middleware)\n\n\n@app.route('/')\nasync def index(request: Request):  # This argument is still needed here\n    return JSONResponse(context.data)  # Your context data\n\n\nuvicorn.run(app, host=&quot;0.0.0.0&quot;)\n</code></pre>\n",
                    "OwnerUserId": "10816458",
                    "LastEditorUserId": "10816458",
                    "LastEditDate": "2022-07-26T15:29:02.053",
                    "LastActivityDate": "2022-07-26T15:29:02.053",
                    "CommentCount": "4",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "61582102",
                "ParentRepo": "https://github.com/fiduswriter/fiduswriter",
                "StackOverflow_Post": {
                    "Id": "61582102",
                    "PostTypeId": "1",
                    "CreationDate": "2020-05-03T21:50:36.537",
                    "Score": "0",
                    "ViewCount": "305",
                    "Body": "<p>I am currently trying to setup the Django web app from <a href=\"https://github.com/fiduswriter/fiduswriter\" rel=\"nofollow noreferrer\">https://github.com/fiduswriter/fiduswriter</a>.</p>\n\n<p>When I run <code>python manage.py runserver localhost:8000</code> I do not receive any errors. The ouptput of the console looks as follows:</p>\n\n<pre><code>python manage.py runserver localhost:8000\nOperations to perform:\n  Apply all migrations: account, admin, auth, avatar, bibliography, contenttypes, document, feedback, flatpages, sessions, sites, socialaccount, style, user, usermedia\nRunning migrations:\n  No migrations to apply.\nTranspiling...\nMay 03, 2020 - 21:32:04\nDjango version 2.2.10, using settings None\nDjango tornado server is running at http://localhost:8000/\nQuit the server with CONTROL-C.\n</code></pre>\n\n<p>When accessing localhost:8000, there is no page coming up.</p>\n\n<p>However, when I build the Docker image resp. pull the one from <a href=\"https://hub.docker.com/r/moritzf/fiduswriter/\" rel=\"nofollow noreferrer\">https://hub.docker.com/r/moritzf/fiduswriter/</a>, I can start it and it shows the starting page.</p>\n\n<p>How is this phenomenon explicable?</p>\n",
                    "OwnerUserId": "2386605",
                    "LastEditorUserId": "2386605",
                    "LastEditDate": "2020-05-04T06:21:42.423",
                    "LastActivityDate": "2020-05-04T06:21:42.423",
                    "Title": "Django runserver shows just blank page",
                    "Tags": "<python><django><web><django-models>",
                    "AnswerCount": "0",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "61582102",
                "ParentRepo": "https://github.com/fiduswriter/fiduswriter",
                "StackOverflow_Post": {
                    "Id": "61582102",
                    "PostTypeId": "1",
                    "CreationDate": "2020-05-03T21:50:36.537",
                    "Score": "0",
                    "ViewCount": "305",
                    "Body": "<p>I am currently trying to setup the Django web app from <a href=\"https://github.com/fiduswriter/fiduswriter\" rel=\"nofollow noreferrer\">https://github.com/fiduswriter/fiduswriter</a>.</p>\n\n<p>When I run <code>python manage.py runserver localhost:8000</code> I do not receive any errors. The ouptput of the console looks as follows:</p>\n\n<pre><code>python manage.py runserver localhost:8000\nOperations to perform:\n  Apply all migrations: account, admin, auth, avatar, bibliography, contenttypes, document, feedback, flatpages, sessions, sites, socialaccount, style, user, usermedia\nRunning migrations:\n  No migrations to apply.\nTranspiling...\nMay 03, 2020 - 21:32:04\nDjango version 2.2.10, using settings None\nDjango tornado server is running at http://localhost:8000/\nQuit the server with CONTROL-C.\n</code></pre>\n\n<p>When accessing localhost:8000, there is no page coming up.</p>\n\n<p>However, when I build the Docker image resp. pull the one from <a href=\"https://hub.docker.com/r/moritzf/fiduswriter/\" rel=\"nofollow noreferrer\">https://hub.docker.com/r/moritzf/fiduswriter/</a>, I can start it and it shows the starting page.</p>\n\n<p>How is this phenomenon explicable?</p>\n",
                    "OwnerUserId": "2386605",
                    "LastEditorUserId": "2386605",
                    "LastEditDate": "2020-05-04T06:21:42.423",
                    "LastActivityDate": "2020-05-04T06:21:42.423",
                    "Title": "Django runserver shows just blank page",
                    "Tags": "<python><django><web><django-models>",
                    "AnswerCount": "0",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "61812370",
                "ParentRepo": "https://github.com/trainindata/deploying-machine-learning-models/commits/master",
                "StackOverflow_Post": {
                    "Id": "61812370",
                    "PostTypeId": "1",
                    "CreationDate": "2020-05-15T05:31:22.757",
                    "Score": "1",
                    "ViewCount": "1843",
                    "Body": "<p>I am new to github and when i tried to checkout initial <code>6.2</code> from the link mentioned below i am getting below error.</p>\n\n<p>link: <a href=\"https://github.com/trainindata/deploying-machine-learning-models/commits/master\" rel=\"nofollow noreferrer\">https://github.com/trainindata/deploying-machine-learning-models/commits/master</a></p>\n\n<pre><code>error :  fatal : reference is not a tree 75b48f55a9b6dd94c40846f5a66c7f217a1f580b\n</code></pre>\n\n<p>can anyone help me to solve this error.</p>\n",
                    "OwnerUserId": "11814008",
                    "LastEditorUserId": "6779252",
                    "LastEditDate": "2020-05-15T17:43:37.647",
                    "LastActivityDate": "2020-05-16T02:02:27.413",
                    "Title": "Not able to perfrom git checkout . Facing error- Fatal: Reference is not a tree error is triggering",
                    "Tags": "<github><fatal-error><git-checkout>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "FavoriteCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "61817602",
                "ParentRepo": "https://github.com/yaph/geonamescache/blob/master/geonamescache/__init__.py#L63",
                "StackOverflow_Post": {
                    "Id": "61817602",
                    "PostTypeId": "2",
                    "ParentId": "60396125",
                    "CreationDate": "2020-05-15T10:57:47.323",
                    "Score": "0",
                    "Body": "<p>I don't know if this is still relevant but I'm also working with geonamescache at the moment so I was able to come across this question. But for anyone who's looking for this as well, unfortunately, they don't have a feature like that where you can pass along a list for the get_cities_by_name() method as it expects a single name based on the <a href=\"https://github.com/yaph/geonamescache/blob/master/geonamescache/__init__.py#L63\" rel=\"nofollow noreferrer\">definition</a> You would have to invoke this method in a for loop or something alike in order to use it for the whole column.</p>\n",
                    "OwnerUserId": "11882013",
                    "LastActivityDate": "2020-05-15T10:57:47.323",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "61857845",
                "ParentRepo": "https://github.com/drmikehenry/romt",
                "StackOverflow_Post": {
                    "Id": "61857845",
                    "PostTypeId": "2",
                    "ParentId": "32267233",
                    "CreationDate": "2020-05-17T19:46:54.087",
                    "Score": "4",
                    "Body": "<p>Check out <a href=\"https://github.com/drmikehenry/romt\" rel=\"nofollow noreferrer\"><code>romt</code> - Rust Offline Mirror Tool</a>.</p>\n<p>Romt (Rust Offline Mirror Tool) aids in using the Rust programming language in an offline context. Instructions and tooling are provided for:</p>\n<ul>\n<li>Mirroring of Rust ecosystem artifacts:\n<ul>\n<li>Toolchains (Rustc, Cargo, libraries, etc.)</li>\n<li>Rustup (toolchain multiplexer)</li>\n<li>Crates.io (community-supplied Crates)</li>\n</ul>\n</li>\n<li>Incremental artifact downloading.</li>\n<li>Incremental artifact transfer to offline network.</li>\n<li>Artifact serving in offline context (offline computer, disconnected network).</li>\n</ul>\n",
                    "OwnerUserId": "1398841",
                    "LastEditorUserId": "1398841",
                    "LastEditDate": "2022-09-28T17:49:46.347",
                    "LastActivityDate": "2022-09-28T17:49:46.347",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "62066645",
                "ParentRepo": "https://github.com/alexgolec/tda-api/blob/autodoc-bysource-not-working/tda/streaming.py#L328",
                "StackOverflow_Post": {
                    "Id": "62066645",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "62078196",
                    "CreationDate": "2020-05-28T14:02:22.697",
                    "Score": "2",
                    "ViewCount": "473",
                    "Body": "<p>I'm trying to document a module I'm maintaining, and I'm finding it very difficult to get my enum classes documented properly. For instance, here's one that I'd like to document properly (<a href=\"https://github.com/alexgolec/tda-api/blob/autodoc-bysource-not-working/tda/streaming.py#L328\" rel=\"nofollow noreferrer\">source</a>): </p>\n\n<pre><code>class QOSLevel(Enum):\n    '''Quality of service levels'''\n\n    #: 500ms (fastest available)\n    EXPRESS = '0'                  \n\n    #: 750ms                       \n    REAL_TIME = '1'                \n\n    #: 1000ms                      \n    FAST = '2'                     \n\n    #: 1500ms                      \n    MODERATE = '3'                 \n\n    #: 3000ms                      \n    SLOW = '4'                     \n\n    #: 5000ms                      \n    DELAYED = '5'                  \n</code></pre>\n\n<p>My documentation for this is here (<a href=\"https://github.com/alexgolec/tda-api/blob/autodoc-bysource-not-working/docs/streaming.rst\" rel=\"nofollow noreferrer\">source</a>): </p>\n\n<pre><code>.. autoclass:: tda.streaming.StreamClient.QOSLevel \n  :members:                                        \n  :undoc-members:                                  \n  :member-order: bysource                          \n</code></pre>\n\n<p>The output looks like this: </p>\n\n<p><a href=\"https://i.stack.imgur.com/pSNtl.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/pSNtl.png\" alt=\"enter image description here\"></a></p>\n\n<p>Two things are immediately wrong here: </p>\n\n<ul>\n<li><p>First off, the documentation strings I set are not rendering. I've attempted to follow <a href=\"https://stackoverflow.com/questions/61314181/when-using-sphinx-how-can-i-document-members-that-dont-have-docstrings\">some advice I've received before</a> that worked for generic attributes, but it seems enums are somehow handled differently? </p></li>\n<li><p>Secondly, it seems the <code>:member-order: bysource</code> directive is being ignored. I tried setting this both here and in <code>conf.py</code>, and neither place seems to allow the fields to be emitted in the proper order. </p></li>\n</ul>\n\n<p>I'm using sphinx v3.0.4 for what it's worth. You can try to replicate the error by copy-pasting the following into your terminal: </p>\n\n<pre><code>git clone https://github.com/alexgolec/tda-api.git\ncd tda-api\ngit checkout remotes/origin/autodoc-bysource-not-working\nvirtualenv -v virtualenv\nsource virtualenv/bin/activate\npip install -r requirements.txt\nmake -f Makefile.sphinx html\nopen docs-build/html/streaming.html  # Only works on Mac OS    \n</code></pre>\n",
                    "OwnerUserId": "265629",
                    "LastEditorUserId": "10794031",
                    "LastEditDate": "2020-05-29T06:41:11.477",
                    "LastActivityDate": "2020-05-29T06:41:11.477",
                    "Title": "Difficulties documenting enum classes?",
                    "Tags": "<python><python-sphinx><inner-classes><autodoc>",
                    "AnswerCount": "1",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "62133305",
                "ParentRepo": "https://github.com/jborean93/pypsrp",
                "StackOverflow_Post": {
                    "Id": "62133305",
                    "PostTypeId": "2",
                    "ParentId": "18961213",
                    "CreationDate": "2020-06-01T13:25:53.920",
                    "Score": "0",
                    "Body": "<p>pypsrp - Python PowerShell Remoting Protocol Client library</p>\n\n<pre><code>At a basic level, you can use this library to;\n\nExecute a cmd command\nRun another executable\nExecute PowerShell scripts\nCopy a file from the localhost to the remote Windows host\nFetch a file from the remote Windows host to the localhost\nCreate a Runspace Pool that contains one or multiple PowerShell pipelines and execute them asynchronously\nSupport for a reference host base implementation of PSRP for interactive scripts\n</code></pre>\n\n<p>REF: <a href=\"https://github.com/jborean93/pypsrp\" rel=\"nofollow noreferrer\">https://github.com/jborean93/pypsrp</a></p>\n",
                    "OwnerUserId": "8352968",
                    "LastActivityDate": "2020-06-01T13:25:53.920",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "62269264",
                "ParentRepo": "https://github.com/koxudaxi/datamodel-code-generator",
                "StackOverflow_Post": {
                    "Id": "62269264",
                    "PostTypeId": "2",
                    "ParentId": "62267544",
                    "CreationDate": "2020-06-08T18:52:29.840",
                    "Score": "5",
                    "Body": "<p>There's no method for exactly that, but you can use <a href=\"https://pydantic-docs.helpmanual.io/usage/models/#dynamic-model-creation\" rel=\"noreferrer\"><code>create_model()</code></a> to create a model if you know the field types.</p>\n\n<p>Or there's <a href=\"https://github.com/koxudaxi/datamodel-code-generator\" rel=\"noreferrer\">datamodel-code-generator</a> (separate package) which allows you to generate models from schema definitions.</p>\n",
                    "OwnerUserId": "949890",
                    "LastActivityDate": "2020-06-08T18:52:29.840",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "62366091",
                "ParentRepo": "https://github.com/luissilva1044894/Pyrez/blob/1.1.x/pyrez/models/Mixin/Dict.py",
                "StackOverflow_Post": {
                    "Id": "62366091",
                    "PostTypeId": "2",
                    "ParentId": "62365997",
                    "CreationDate": "2020-06-13T22:05:01.623",
                    "Score": "0",
                    "Body": "<p>Looks like this PyRez library uses some kind of custom Dict object for API responses, and the <code>__str__</code> method is already doing a <code>json.dump</code> of the args. So try <code>str(the_obj)</code>. See <a href=\"https://github.com/luissilva1044894/Pyrez/blob/1.1.x/pyrez/models/Mixin/Dict.py\" rel=\"nofollow noreferrer\">here</a>.</p>\n",
                    "OwnerUserId": "257465",
                    "LastActivityDate": "2020-06-13T22:05:01.623",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "62514890",
                "ParentRepo": "https://github.com/taizan-hokuto/pytchat",
                "StackOverflow_Post": {
                    "Id": "62514890",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "62546391",
                    "CreationDate": "2020-06-22T12:51:04.847",
                    "Score": "1",
                    "ViewCount": "4548",
                    "Body": "<p>I have this python code:</p>\n<pre><code>from pytchat import LiveChat\nimport time\nimport requests\nimport threading\n\nvideo_id = None\nliveChat = None\n\ndef runChat():\n  global liveChat\n  liveChat = LiveChat(video_id)\n  while liveChat.is_alive():\n    try:\n      chatdata = liveChat.get()\n      for c in chatdata.items:\n          print(f&quot;{c.datetime} [{c.author.channelId}]- {c.message}&quot;)\n          chatdata.tick()\n    except KeyboardInterrupt:\n      liveChat.terminate()\n      break\n\ndef checkId():\n  threading.Timer(1.0, checkId).start()\n  global video_id\n  req = requests.get(&quot;http://localhost/getId&quot;)\n  if req.status_code == 200:\n    vidId = req.text\n    if vidId != &quot;null&quot; and vidId != video_id:\n        video_id = vidId\n        print(f&quot;got id: {video_id}&quot;)\n        if liveChat is not None:\n          liveChat.terminate()\n        runChat()\n\ndef main():\n  checkId()\n\nif __name__ == '__main__':\n  main()\n</code></pre>\n<p>That utilizes the pytchat library (<a href=\"https://github.com/taizan-hokuto/pytchat\" rel=\"nofollow noreferrer\">https://github.com/taizan-hokuto/pytchat</a>).\nAs you can see, I want to dynamically change the videoId that the chat is bundled to, but with the code above this is the result:</p>\n<pre><code>root@vps:~# python3 liveChat.py\ngot id: a10TAdVZmOq # First id, the library works, we can capture chat messages.\ngot id: NMre6IAPoLI # After second id appears, there is this exception:\nException in thread Thread-52:\nTraceback (most recent call last):\n  File &quot;/usr/local/lib/python3.6/threading.py&quot;, line 916, in _bootstrap_inner\n    self.run()\n  File &quot;/usr/local/lib/python3.6/threading.py&quot;, line 1182, in run\n    self.function(*self.args, **self.kwargs)\n  File &quot;liveChat.py&quot;, line 36, in checkId\n    runChat()\n  File &quot;liveChat.py&quot;, line 11, in runChat\n    liveChat = LiveChat(video_id)\n  File &quot;/usr/local/lib/python3.6/site-packages/pytchat/core_multithread/livechat.py&quot;, line 110, in __init__\n    signal.signal(signal.SIGINT, lambda a, b: self.terminate())\n  File &quot;/usr/local/lib/python3.6/signal.py&quot;, line 47, in signal\n    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))\nValueError: signal only works in main thread\n</code></pre>\n<p>How can this be solved since signals only work in main thread?</p>\n",
                    "OwnerUserId": "10369389",
                    "LastActivityDate": "2022-08-17T22:45:42.477",
                    "Title": "Python signals: ValueError: signal only works in main thread",
                    "Tags": "<python>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "FavoriteCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "62603967",
                "ParentRepo": "https://github.com/hyroai/gamla",
                "StackOverflow_Post": {
                    "Id": "62603967",
                    "PostTypeId": "2",
                    "ParentId": "9110593",
                    "CreationDate": "2020-06-26T22:59:10.460",
                    "Score": "15",
                    "Body": "<p>You can use <code>httpx</code> for that.</p>\n<pre class=\"lang-py prettyprint-override\"><code>import httpx\n\nasync def get_async(url):\n    async with httpx.AsyncClient() as client:\n        return await client.get(url)\n\nurls = [&quot;http://google.com&quot;, &quot;http://wikipedia.org&quot;]\n\n# Note that you need an async context to use `await`.\nawait asyncio.gather(*map(get_async, urls))\n</code></pre>\n<p>if you want a functional syntax, the <a href=\"https://github.com/hyroai/gamla\" rel=\"noreferrer\">gamla</a> lib wraps this into <code>get_async</code>.</p>\n<p>Then you can do</p>\n<pre class=\"lang-py prettyprint-override\"><code>\nawait gamla.map(gamla.get_async(10))([&quot;http://google.com&quot;, &quot;http://wikipedia.org&quot;])\n</code></pre>\n<p>The <code>10</code> is the timeout in seconds.</p>\n<p>(disclaimer: I am its author)</p>\n",
                    "OwnerUserId": "378594",
                    "LastEditorUserId": "378594",
                    "LastEditDate": "2020-11-15T14:34:09.093",
                    "LastActivityDate": "2020-11-15T14:34:09.093",
                    "CommentCount": "3",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "62677080",
                "ParentRepo": "https://github.com/strawberry-graphql/strawberry",
                "StackOverflow_Post": {
                    "Id": "62677080",
                    "PostTypeId": "5",
                    "CreationDate": "2020-07-01T12:39:44.757",
                    "Score": "0",
                    "Body": "<p><strong>GraphQL</strong> is a query language for APIs created by Facebook. It's specification is currently public and can be checked <a href=\"https://github.com/graphql/graphql-spec\" rel=\"nofollow noreferrer\">here</a>.</p>\n<p>There are well known implementations for servers to support this query language, allowing them to build the typed schema or serve queries against that schema. Some of them are:</p>\n<ul>\n<li><a href=\"https://github.com/graphql-python/graphql-core\" rel=\"nofollow noreferrer\">graphql-core-next</a></li>\n<li><a href=\"http://graphene-python.org/\" rel=\"nofollow noreferrer\">graphene</a></li>\n<li><a href=\"https://github.com/strawberry-graphql/strawberry\" rel=\"nofollow noreferrer\">strawberry</a></li>\n<li><a href=\"https://github.com/mirumee/ariadne\" rel=\"nofollow noreferrer\">ariadne</a></li>\n</ul>\n<p>Use this tag to make questions about any of these, to ask something of one library compared to the other, to get best practices for implementing these, or others.</p>\n",
                    "OwnerUserId": "10322652",
                    "LastEditorUserId": "10322652",
                    "LastEditDate": "2020-07-06T23:02:59.680",
                    "LastActivityDate": "2020-07-06T23:02:59.680",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "62712173",
                "ParentRepo": "https://github.com/ephes/django_async/blob/master/request_in_sync_view.md",
                "StackOverflow_Post": {
                    "Id": "62712173",
                    "PostTypeId": "1",
                    "CreationDate": "2020-07-03T09:10:38.380",
                    "Score": "3",
                    "ViewCount": "439",
                    "Body": "<p>Got an issue trying to connect from an async view in Django 3.1 to a sync view served by the same  asgi server. Doing this in normal wsgi development server works, but not in an asgi server. Which seems kind of weird. Probably I misunderstood on how asgi works :). Here's a link on how to reproduce this:</p>\n<p><a href=\"https://github.com/ephes/django_async/blob/master/request_in_sync_view.md\" rel=\"nofollow noreferrer\">All steps to reproduce this.</a></p>\n<p>Here are just the views causing the problem. Maybe someone is able to tell immediately what I'm doing wrong by just looking at those:</p>\n<pre class=\"lang-py prettyprint-override\"><code>import httpx\n\nfrom django.http import JsonResponse\n\n\ndef sync_api_view(request):\n    payload = {&quot;foo&quot;: &quot;bar&quot;}\n    return JsonResponse(payload)\n\n\ndef sync_aggregation_view(request):\n    responses = []\n    r = httpx.get(&quot;http://127.0.0.1:8000/sync_api_view/&quot;)\n    responses.append(r.json())\n    result = {&quot;responses&quot;: responses}\n    return JsonResponse(result)\n</code></pre>\n<p>The &quot;sync_aggregation_view&quot; is the one that works in wsgi but not via asgi.</p>\n",
                    "OwnerUserId": "199248",
                    "LastActivityDate": "2020-07-03T10:35:01.270",
                    "Title": "Django 3.1 asgi server timeout connecting to itself inside async view",
                    "Tags": "<python><django><asynchronous><wsgi><asgi>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "62791628",
                "ParentRepo": "https://github.com/dmontagu/fastapi-utils",
                "StackOverflow_Post": {
                    "Id": "62791628",
                    "PostTypeId": "1",
                    "CreationDate": "2020-07-08T09:25:38.280",
                    "Score": "5",
                    "ViewCount": "6501",
                    "Body": "<p>We are using <a href=\"https://github.com/dmontagu/fastapi-utils\" rel=\"noreferrer\">fastapi-utils</a> to have a scheduled task in the background. We check all 5 seconds if new data is available in the DB, if yes we process it (takes up to 5 minutes)</p>\n<p>During this time, the couroutine should be blocking so that its only triggered once.</p>\n<p>We noticed that our data is sometimes processed 3x, we assume that the scheduler continues to run, even though the function has been triggered.</p>\n<p>Therefore we tried  to circumvent it with the <code>IsRunningQuery</code> variable.</p>\n<p>We tried a solution with a while True loop without <code>@repeat_every</code> to make it run once at startup, but Azure Webapps does not allow running this.</p>\n<pre><code>@app.on_event(&quot;startup&quot;) \n@repeat_every(wait_first=True,seconds=int(10))\ndef scheduled_task() -&gt; None:\n    global IsRunningQuery\n    global LastCheck\n    if IsRunningQuery == False:\n        IsRunningQuery = True\n        gunicorn_logger.info(&quot;status='checkforleads'&quot;)\n        OurProccessingClass.processDataBaseData() # can take up 5 minutes\n        LastCheck=Utils.datetime()\n        IsRunningQuery = False\n\n</code></pre>\n<p>This variante works in our DEV environment, but not on Azure</p>\n<pre><code>@app.on_event(&quot;startup&quot;) \nasync def scheduled_task() -&gt; None:\n    while True:\n        gunicorn_logger.info(&quot;status='checkforleads'&quot;)\n        OurProccessingClass.processDataBaseData() # can take up 5 minutes\n        time.sleep(int(os.environ[&quot;CRM_SLEEP&quot;]))\n</code></pre>\n",
                    "OwnerUserId": "670186",
                    "LastEditorUserId": "670186",
                    "LastEditDate": "2020-07-08T09:34:03.837",
                    "LastActivityDate": "2022-01-11T02:19:11.823",
                    "Title": "FastAPI @repeat_every how to prevent parallel def scheduled_task() instances",
                    "Tags": "<fastapi>",
                    "AnswerCount": "2",
                    "CommentCount": "0",
                    "FavoriteCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "62817008",
                "ParentRepo": "https://github.com/sysid/sse-starlette",
                "StackOverflow_Post": {
                    "Id": "62817008",
                    "PostTypeId": "2",
                    "ParentId": "58895486",
                    "CreationDate": "2020-07-09T14:19:48.843",
                    "Score": "19",
                    "Body": "<p>FastAPI is based on Starlette and <a href=\"https://github.com/sysid/sse-starlette\" rel=\"noreferrer\">Server-Sent Events</a> plugin is available for Starlette</p>\n<pre><code>import asyncio\nimport uvicorn\nfrom fastapi import FastAPI, Request\nfrom sse_starlette.sse import EventSourceResponse\n\nMESSAGE_STREAM_DELAY = 1  # second\nMESSAGE_STREAM_RETRY_TIMEOUT = 15000  # milisecond\napp = FastAPI()\n\n\n@app.get('/stream')\nasync def message_stream(request: Request):\n    def new_messages(): ...\n    async def event_generator():\n        while True:\n            # If client was closed the connection\n            if await request.is_disconnected():\n                break\n\n            # Checks for new messages and return them to client if any\n            if new_messages():\n                yield {\n                        &quot;event&quot;: &quot;new_message&quot;,\n                        &quot;id&quot;: &quot;message_id&quot;,\n                        &quot;retry&quot;: MESSAGE_STREAM_RETRY_TIMEOUT,\n                        &quot;data&quot;: &quot;message_content&quot;\n                }\n\n            await asyncio.sleep(MESSAGE_STREAM_DELAY)\n\n    return EventSourceResponse(event_generator())\n\n\nif __name__ == &quot;__main__&quot;:\n    uvicorn.run(app, host=&quot;127.0.0.1&quot;, port=8000)\n\n</code></pre>\n",
                    "OwnerUserId": "11392333",
                    "LastActivityDate": "2020-07-09T14:19:48.843",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "62845801",
                "ParentRepo": "https://github.com/alexmercerind/youtube-search-python",
                "StackOverflow_Post": {
                    "Id": "62845801",
                    "PostTypeId": "2",
                    "ParentId": "62779030",
                    "CreationDate": "2020-07-11T06:06:37.600",
                    "Score": "4",
                    "Body": "<p>There is a similar module for your requirement (supports both async &amp; sync):</p>\n<p><a href=\"https://github.com/alexmercerind/youtube-search-python\" rel=\"nofollow noreferrer\">https://github.com/alexmercerind/youtube-search-python</a></p>\n<p>You can use it in following way:</p>\n<h3>Example</h3>\n<pre class=\"lang-py prettyprint-override\"><code>from youtubesearchpython import VideosSearch\n\nvideosSearch = VideosSearch('NoCopyrightSounds', limit = 2)\n\nprint(videosSearch.result())\n</code></pre>\n<h3>Result</h3>\n<pre class=\"lang-json prettyprint-override\"><code>{\n    &quot;result&quot;: [\n        {\n            &quot;type&quot;: &quot;video&quot;,\n            &quot;id&quot;: &quot;K4DyBUG242c&quot;,\n            &quot;title&quot;: &quot;Cartoon - On &amp; On (feat. Daniel Levi) [NCS Release]&quot;,\n            &quot;publishedTime&quot;: &quot;5 years ago&quot;,\n            &quot;duration&quot;: &quot;3:28&quot;,\n            &quot;viewCount&quot;: {\n                &quot;text&quot;: &quot;389,673,774 views&quot;,\n                &quot;short&quot;: &quot;389M views&quot;\n            },\n            &quot;thumbnails&quot;: [\n                {\n                    &quot;url&quot;: &quot;https://i.ytimg.com/vi/K4DyBUG242c/hqdefault.jpg?sqp=-oaymwEjCOADEI4CSFryq4qpAxUIARUAAAAAGAElAADIQj0AgKJDeAE=&amp;rs=AOn4CLBkTusCwcZQlmVAaRQ5rH-mvBuA1g&quot;,\n                    &quot;width&quot;: 480,\n                    &quot;height&quot;: 270\n                }\n            ],\n            &quot;descriptionSnippet&quot;: [\n                {\n                    &quot;text&quot;: &quot;NCS: Music Without Limitations NCS Spotify: http://spoti.fi/NCS Free Download / Stream: http://ncs.io/onandon \\u25bd Connect with\\u00a0...&quot;\n                }\n            ],\n            &quot;channel&quot;: {\n                &quot;name&quot;: &quot;NoCopyrightSounds&quot;,\n                &quot;id&quot;: &quot;UC_aEa8K-EOJ3D6gOs7HcyNg&quot;,\n                &quot;thumbnails&quot;: [\n                    {\n                        &quot;url&quot;: &quot;https://yt3.ggpht.com/a-/AOh14GhS0G5FwV8rMhVCUWSDp36vWEvnNs5Vl97Zww=s68-c-k-c0x00ffffff-no-rj-mo&quot;,\n                        &quot;width&quot;: 68,\n                        &quot;height&quot;: 68\n                    }\n                ],\n                &quot;link&quot;: &quot;https://www.youtube.com/channel/UC_aEa8K-EOJ3D6gOs7HcyNg&quot;\n            },\n            &quot;accessibility&quot;: {\n                &quot;title&quot;: &quot;Cartoon - On &amp; On (feat. Daniel Levi) [NCS Release] by NoCopyrightSounds 5 years ago 3 minutes, 28 seconds 389,673,774 views&quot;,\n                &quot;duration&quot;: &quot;3 minutes, 28 seconds&quot;\n            },\n            &quot;link&quot;: &quot;https://www.youtube.com/watch?v=K4DyBUG242c&quot;,\n            &quot;shelfTitle&quot;: null\n        },\n        {\n            &quot;type&quot;: &quot;video&quot;,\n            &quot;id&quot;: &quot;yJg-Y5byMMw&quot;,\n            &quot;title&quot;: &quot;Warriyo - Mortals (feat. Laura Brehm) [NCS Release]&quot;,\n            &quot;publishedTime&quot;: &quot;3 years ago&quot;,\n            &quot;duration&quot;: &quot;3:50&quot;,\n            &quot;viewCount&quot;: {\n                &quot;text&quot;: &quot;153,353,801 views&quot;,\n                &quot;short&quot;: &quot;153M views&quot;\n            },\n            &quot;thumbnails&quot;: [\n                {\n                    &quot;url&quot;: &quot;https://i.ytimg.com/vi/yJg-Y5byMMw/hqdefault.jpg?sqp=-oaymwEjCOADEI4CSFryq4qpAxUIARUAAAAAGAElAADIQj0AgKJDeAE=&amp;rs=AOn4CLDY-mve79IweErMo-71AsKEIB1m0A&quot;,\n                    &quot;width&quot;: 480,\n                    &quot;height&quot;: 270\n                }\n            ],\n            &quot;descriptionSnippet&quot;: [\n                {\n                    &quot;text&quot;: &quot;NCS: Music Without Limitations NCS Spotify: http://spoti.fi/NCS Free Download / Stream: http://ncs.io/mortals Connect with NCS:\\u00a0...&quot;\n                }\n            ],\n            &quot;channel&quot;: {\n                &quot;name&quot;: &quot;NoCopyrightSounds&quot;,\n                &quot;id&quot;: &quot;UC_aEa8K-EOJ3D6gOs7HcyNg&quot;,\n                &quot;thumbnails&quot;: [\n                    {\n                        &quot;url&quot;: &quot;https://yt3.ggpht.com/a-/AOh14GhS0G5FwV8rMhVCUWSDp36vWEvnNs5Vl97Zww=s68-c-k-c0x00ffffff-no-rj-mo&quot;,\n                        &quot;width&quot;: 68,\n                        &quot;height&quot;: 68\n                    }\n                ],\n                &quot;link&quot;: &quot;https://www.youtube.com/channel/UC_aEa8K-EOJ3D6gOs7HcyNg&quot;\n            },\n            &quot;accessibility&quot;: {\n                &quot;title&quot;: &quot;Warriyo - Mortals (feat. Laura Brehm) [NCS Release] by NoCopyrightSounds 3 years ago 3 minutes, 50 seconds 153,353,801 views&quot;,\n                &quot;duration&quot;: &quot;3 minutes, 50 seconds&quot;\n            },\n            &quot;link&quot;: &quot;https://www.youtube.com/watch?v=yJg-Y5byMMw&quot;,\n            &quot;shelfTitle&quot;: null\n        }\n    ]\n}\n</code></pre>\n<p>The search result from this library is very detailed.</p>\n",
                    "OwnerUserId": "12825435",
                    "LastEditorUserId": "12825435",
                    "LastEditDate": "2021-03-03T11:14:05.017",
                    "LastActivityDate": "2021-03-03T11:14:05.017",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "62916420",
                "ParentRepo": "https://github.com/GoogleCloudPlatform/django-demo-app-unicodex",
                "StackOverflow_Post": {
                    "Id": "62916420",
                    "PostTypeId": "2",
                    "ParentId": "62907431",
                    "CreationDate": "2020-07-15T13:48:00.377",
                    "Score": "5",
                    "Body": "<p>I recommend <a href=\"http://whitenoise.evans.io/en/stable/django.html\" rel=\"noreferrer\">Whitenoise</a> for static files.</p>\n<p><a href=\"https://github.com/GoogleCloudPlatform/django-demo-app-unicodex\" rel=\"noreferrer\">https://github.com/GoogleCloudPlatform/django-demo-app-unicodex</a> is an excellent starting point for running Django (and therefore Wagtail) on Google Cloud Run. It includes a <a href=\"https://github.com/GoogleCloudPlatform/django-demo-app-unicodex/blob/master/docs/30-setup-bucket.md\" rel=\"noreferrer\">section on configuring Cloud Storage Buckets</a>.</p>\n",
                    "OwnerUserId": "181793",
                    "LastActivityDate": "2020-07-15T13:48:00.377",
                    "CommentCount": "3",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "62929311",
                "ParentRepo": "https://github.com/felix-hilden/tekore/blob/master/tekore/_auth/util.py#L55",
                "StackOverflow_Post": {
                    "Id": "62929311",
                    "PostTypeId": "2",
                    "ParentId": "62870699",
                    "CreationDate": "2020-07-16T07:06:11.343",
                    "Score": "2",
                    "Body": "<h3>Set up a web server.</h3>\n<p>To programmatially extract the access tokens you need a web server to handle the redirection after the user logs in on Spotify (which you redirected them to). Now this server <em>can</em> be the user pasting the URI to an input field on a terminal, but obviously this isn't ideal for user experience. It leaves room for lots of mistakes.</p>\n<p>I've authored a Spotify Web API client, whose internals might be useful for you to examine. <a href=\"https://tekore.readthedocs.io/en/stable/examples/auth_server.html\" rel=\"nofollow noreferrer\">For example</a>, you can use Flask to construct the server. The main principle is using one endpoint (i.e. <code>/login</code>) to redirect (code <code>307</code> worked for me browsers won't remember it) the user to a callback (i.e. <code>/callback</code>) which recieves the <code>code</code> parameter with which you can request an access token.</p>\n<p>OAuth2 can be a bit of a pain to implement locally, I know. In my library I also made a <a href=\"https://github.com/felix-hilden/tekore/blob/master/tekore/_auth/util.py#L55\" rel=\"nofollow noreferrer\">similar function</a> that you are constructing using <code>webbrowser</code>, but it does have the manual copy-pasting quirk. To use functions you can define yourself for brevity, the gist of it is:</p>\n<pre><code>verifier = secrets.token_urlsafe(32)  # for PKCE, not in my library yet\nurl = user_authorisation_url(scope, state, verifier)\n\n# Communicate with the user\nprint('Opening browser for Spotify login...')\nwebbrowser.open(url)\nredirected = input('Please paste redirect URL: ').strip()\n\ncode = parse_code_from_url(redirected)\nstate_back = parse_state_from_url(redirected)\nassert state == state_back  # For that added security juice\ntoken = request_user_token(code, verifier)\n</code></pre>\n",
                    "OwnerUserId": "7089239",
                    "LastActivityDate": "2020-07-16T07:06:11.343",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "62949317",
                "ParentRepo": "https://github.com/rasahq/rasa",
                "StackOverflow_Post": {
                    "Id": "62949317",
                    "PostTypeId": "2",
                    "ParentId": "62934606",
                    "CreationDate": "2020-07-17T07:39:18.113",
                    "Score": "0",
                    "Body": "<p>Rasa NLU was deprecated 1.5 years ago in favor of <a href=\"https://github.com/rasahq/rasa\" rel=\"nofollow noreferrer\">https://github.com/rasahq/rasa</a> . I highly recommend you to switch to the maintained version as you will an up to date documentation and lot of new features which make it easier to interact with it.</p>\n",
                    "OwnerUserId": "3429596",
                    "LastActivityDate": "2020-07-17T07:39:18.113",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "63083415",
                "ParentRepo": "https://github.com/mfleader/snappyCLI",
                "StackOverflow_Post": {
                    "Id": "63083415",
                    "PostTypeId": "1",
                    "CreationDate": "2020-07-25T01:38:15.153",
                    "Score": "0",
                    "ViewCount": "161",
                    "Body": "<p>I created a command line interface with <a href=\"https://typer.tiangolo.com/\" rel=\"nofollow noreferrer\">Typer</a> to a <a href=\"https://github.com/mfleader/snappyCLI\" rel=\"nofollow noreferrer\">client</a> for an http <a href=\"https://github.com/openshift-scale/snappy-data-server\" rel=\"nofollow noreferrer\">server</a>.</p>\n<p>This starts an interactive login that displays prompts for username, and then password. If valid, it echoes the authorization token to standard output.</p>\n<pre class=\"lang-sh prettyprint-override\"><code>$ snappy login\n</code></pre>\n<pre class=\"lang-sh prettyprint-override\"><code>Username:\nPassword:\n</code></pre>\n<p>How does one capture the last output in a shell script? I've tried a basic subshell:</p>\n<pre class=\"lang-sh prettyprint-override\"><code>token=$(snappy login)\n</code></pre>\n<p>But then <code>token</code> captures <code>Username: Password: &lt;authorization token&gt;</code>, and no text is displayed to standard output.</p>\n<p>My current choice:</p>\n<pre class=\"lang-sh prettyprint-override\"><code>script -qc 'snappy login'\ntoken=$(tail -1 typescript)\nrm typescript\n</code></pre>\n<p>Bottom 13 lines removed because they only contained the token characters:</p>\n<pre class=\"lang-sh prettyprint-override\"><code>$ snappy login 2&gt;&amp;1 | hexdump -C\nmyemail@mail.com\n00000000  55 73 65 72 6e 61 6d 65  3a 20 50 61 73 73 77 6f  |Username: Passwo|\n\n00000010  72 64 3a 20 65 79 4a 30  65 58 41 69 4f 69 4a 4b  |rd: eyJ0eXAiOiJK|\n</code></pre>\n",
                    "OwnerUserId": "13771512",
                    "LastEditorUserId": "13771512",
                    "LastEditDate": "2020-07-25T15:39:44.937",
                    "LastActivityDate": "2020-07-25T15:39:44.937",
                    "Title": "How to capture final output of an interactive python script within a bash script?",
                    "Tags": "<bash><shell><variable-assignment><python-interactive>",
                    "AnswerCount": "1",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "63110233",
                "ParentRepo": "https://github.com/lovvskillz/python-discord-webhook",
                "StackOverflow_Post": {
                    "Id": "63110233",
                    "PostTypeId": "2",
                    "ParentId": "54973413",
                    "CreationDate": "2020-07-27T07:01:52.747",
                    "Score": "0",
                    "Body": "<p>you can use discord webhooks:</p>\n<ul>\n<li>first, see this video tutorial on <a href=\"https://www.youtube.com/watch?reload=9&amp;v=hS_981bBG-8\" rel=\"nofollow noreferrer\">youtube</a></li>\n<li>then use <a href=\"https://github.com/lovvskillz/python-discord-webhook\" rel=\"nofollow noreferrer\">python-discord-webhook</a></li>\n</ul>\n",
                    "OwnerUserId": "4626394",
                    "LastActivityDate": "2020-07-27T07:01:52.747",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "63288886",
                "ParentRepo": "https://github.com/awslabs/aws-lambda-powertools-python/blob/f5d14e3279276192c6fed0907b84b1dfa23c7b3c/aws_lambda_powertools/tracing/tracer.py",
                "StackOverflow_Post": {
                    "Id": "63288886",
                    "PostTypeId": "1",
                    "CreationDate": "2020-08-06T17:30:56.050",
                    "Score": "-1",
                    "ViewCount": "1229",
                    "Body": "<p>I have a lambda function and I am using aws_lambda_powertools in it. Lambda function project structure is like below-</p>\n<pre><code>source-&gt;Folder\n   - handler.py\nlibs\n   - aws-lambda-powertools\n   - aws-xray-sdk\n   - other libs which aws-lambda-powertools need\n\nhandler.py\nfrom libs.aws_lambda_powertools import Logger, Tracer\n</code></pre>\n<p>When I run the lambda, it gives me an error &quot;No Module found aws_xray_sdk&quot; even though the module(used by aws-powertools) is there under the libs folder.</p>\n<p>Source of Tracer which I am using in my lambda.\n<a href=\"https://github.com/awslabs/aws-lambda-powertools-python/blob/f5d14e3279276192c6fed0907b84b1dfa23c7b3c/aws_lambda_powertools/tracing/tracer.py\" rel=\"nofollow noreferrer\">https://github.com/awslabs/aws-lambda-powertools-python/blob/f5d14e3279276192c6fed0907b84b1dfa23c7b3c/aws_lambda_powertools/tracing/tracer.py</a></p>\n",
                    "OwnerUserId": "11740470",
                    "LastEditorUserId": "11740470",
                    "LastEditDate": "2020-08-06T18:07:26.397",
                    "LastActivityDate": "2020-08-08T10:38:26.810",
                    "Title": "Python not able to find modules",
                    "Tags": "<python><aws-lambda><python-3.6><aws-xray>",
                    "AnswerCount": "2",
                    "CommentCount": "4",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "63348643",
                "ParentRepo": "https://github.com/ihabunek/twitch-dl/",
                "StackOverflow_Post": {
                    "Id": "63348643",
                    "PostTypeId": "2",
                    "ParentId": "63348225",
                    "CreationDate": "2020-08-10T22:05:43.713",
                    "Score": "1",
                    "Body": "<p>You can do this multiple ways.</p>\n<p>Way 1.\nUse the twitch api V5</p>\n<pre><code>import requests\nimport json\n\nr = requests.get(&quot;https://api.twitch.tv/kraken/channels/&lt;channel ID&gt;/videos\n\n&quot;, headers={&quot;Client-ID&quot;:&quot;CLIENTID&quot;})\nj = json.loads(r.text)\n\nj['url']\n</code></pre>\n<p>to gather all videos and download then execute a command via python or whatever language you choose. To execute either of two options. <a href=\"https://github.com/ytdl-org/youtube-dl\" rel=\"nofollow noreferrer\">Youtube-DL</a> which the command would be as follows</p>\n<pre><code>youtube-dl twitchVideoURL\n</code></pre>\n<p>or using <a href=\"https://github.com/ihabunek/twitch-dl/\" rel=\"nofollow noreferrer\">twitch-dl</a></p>\n<p>which you could execute a command like</p>\n<pre><code>twitch-dl download twitchVideoURL\n</code></pre>\n<p>Way 2\nuse purely <a href=\"https://github.com/ihabunek/twitch-dl/\" rel=\"nofollow noreferrer\">twitch-dl</a></p>\n<p>This way you would end up running\n<code>twitch-dl videos twitchChannelName</code>\nwhich would give you an output as follows (this just grabbed off his github readme)</p>\n<pre><code>Found 33 videos\n\n221837124\nSUPER MARIO ODYSSSEY - Stream #2 / 600,000,000\nBananasaurus_Rex playing Super Mario Odyssey\nPublished 2018-01-24 @ 12:05:25  Length: 3h 40min\n\n221418913\nDead Space and then SUPER MARIO ODYSSEY PogChamp\nBananasaurus_Rex playing Dead Space\nPublished 2018-01-23 @ 02:40:58  Length: 6h 2min\n</code></pre>\n<p>From there you could grab the first line of each new video. Finally putting that id into\n<code>twitch-dl download VideoID</code></p>\n<p>Hopefully this gives you some ideas as to how to do this. As you never specified a language I tried to for the most part be as generic as possible.</p>\n",
                    "OwnerUserId": "7490788",
                    "LastActivityDate": "2020-08-10T22:05:43.713",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "63645786",
                "ParentRepo": "https://github.com/scholarly-python-package/scholarly",
                "StackOverflow_Post": {
                    "Id": "63645786",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "63645804",
                    "CreationDate": "2020-08-29T10:09:17.597",
                    "Score": "0",
                    "ViewCount": "72",
                    "Body": "<p>i am new to python and Django. I am trying the python library &quot;<a href=\"https://github.com/scholarly-python-package/scholarly\" rel=\"nofollow noreferrer\">scholarly.py</a>&quot; to gather article url (to pdf or to eprint) on a django webpage.</p>\n<p>Here's what the sample input looks like:</p>\n<pre><code>&gt;&gt;&gt; search_query = scholarly.search_pubs('Perception of physical stability and center of mass of 3D objects')\n&gt;&gt;&gt; print(next(search_query))\n</code></pre>\n<p>Here's what the output looks like:</p>\n<pre><code>{'bib': {'abstract': 'Humans can judge from vision alone whether an object is '\n                 'physically stable or not. Such judgments allow observers '\n                 'to predict the physical behavior of objects, and hence '\n                 'to guide their motor actions. We investigated the visual '\n                 'estimation of physical stability of 3-D objects (shown '\n                 'in stereoscopically viewed rendered scenes) and how it '\n                 'relates to visual estimates of their center of mass '\n                 '(COM). In Experiment 1, observers viewed an object near '\n                 'the edge of a table and adjusted its tilt to the '\n                 'perceived critical angle, ie, the tilt angle at which '\n                 'the object',\n     'author': ['SA Cholewiak', 'RW Fleming', 'M Singh'],\n     'cites': '23',\n     'eprint': 'https://jov.arvojournals.org/article.aspx?articleID=2213254',\n     'gsrank': '1',\n     'title': 'Perception of physical stability and center of mass of 3-D '\n              'objects',\n     'url': 'https://jov.arvojournals.org/article.aspx?articleID=2213254',\n     'venue': 'Journal of vision',\n     'year': '2015'},\n 'citations_link': '/scholar?cites=15736880631888070187&amp;as_sdt=5,33&amp;sciodt=0,33&amp;hl=en',\n 'filled': False,\n 'source': 'scholar',\n 'url_add_sclib': '/citations?hl=en&amp;xsrf=&amp;continue=/scholar%3Fq%3DPerception%2Bof%2Bphysical%2Bstability%2Band%2Bcenter%2Bof%2Bmass%2Bof%2B3D%2Bobjects%26hl%3Den%26as_sdt%3D0,33&amp;citilm=1&amp;json=&amp;update_op=library_add&amp;info=K8ZpoI6hZNoJ&amp;ei=ewEtX7_JOIvrmQHcvJqoDA',\n 'url_scholarbib': '/scholar?q=info:K8ZpoI6hZNoJ:scholar.google.com/&amp;output=cite&amp;scirp=0&amp;hl=en'}\n</code></pre>\n<p>As you can see this output looks like JSON but it is not JSON.\nWhat do I have to do if I want to get only &quot;url&quot; value from that output.</p>\n<p>Thank you.</p>\n",
                    "OwnerUserId": "14186749",
                    "LastActivityDate": "2022-07-19T20:03:51.333",
                    "Title": "Get Specific attribute value from python library sholarly.py output",
                    "Tags": "<python><python-3.x>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "63983404",
                "ParentRepo": "https://github.com/schemathesis/schemathesis",
                "StackOverflow_Post": {
                    "Id": "63983404",
                    "PostTypeId": "2",
                    "ParentId": "53156494",
                    "CreationDate": "2020-09-20T20:35:38.443",
                    "Score": "0",
                    "Body": "<p>There is also <a href=\"https://github.com/schemathesis/schemathesis\" rel=\"nofollow noreferrer\">Schemathesis</a>, which utilizes property-based testing and generates and runs tests for Open API 2/3 schemas. It requires no configuration by default and works as a CLI tool. It also verifies all examples specified in the schema, which overlaps with some <a href=\"https://github.com/apiaryio/dredd\" rel=\"nofollow noreferrer\">Dredd</a> functionality - but you don't have to specify all examples; the tool will generate everything that is missing.</p>\n",
                    "OwnerUserId": "1779619",
                    "LastActivityDate": "2020-09-20T20:35:38.443",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "64233248",
                "ParentRepo": "https://github.com/jugmac00/hibpcli",
                "StackOverflow_Post": {
                    "Id": "64233248",
                    "PostTypeId": "2",
                    "ParentId": "63011201",
                    "CreationDate": "2020-10-06T20:17:51.627",
                    "Score": "1",
                    "Body": "<p>In your <code>testenv</code> section, you have to set either</p>\n<pre><code>setenv = PY_IGNORE_IMPORTMISMATCH=1\n</code></pre>\n<p>or</p>\n<pre><code>usedevelop = true\n</code></pre>\n<p>You can read more about the problem on the pytest bugtracker, see here <a href=\"https://github.com/pytest-dev/pytest/issues/2042\" rel=\"nofollow noreferrer\">https://github.com/pytest-dev/pytest/issues/2042</a></p>\n<p>While I have not spend a lot of time on this, I am pretty sure it has to do with the naming of your packages.</p>\n<p>The main source folder is called <code>tfields</code> and your package is called <code>tfields</code>. The problem is that now both the installed package and the folder is available for Python under the same namespace.</p>\n<p>When I remember correctly, I had the very same problem for my <a href=\"https://github.com/jugmac00/hibpcli\" rel=\"nofollow noreferrer\">https://github.com/jugmac00/hibpcli</a> project - and the problem went away, once I put my sourcecode in a <code>src</code> directory, and not longer call the top level folder the same as the package name.</p>\n<p>If you want to dig deeper, I highly recommend the article by Hynek Schlawack on why to use a <code>src</code> layout:</p>\n<p><a href=\"https://hynek.me/articles/testing-packaging/\" rel=\"nofollow noreferrer\">https://hynek.me/articles/testing-packaging/</a></p>\n",
                    "OwnerUserId": "672833",
                    "LastActivityDate": "2020-10-06T20:17:51.627",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "64262075",
                "ParentRepo": "https://github.com/mkb79/Audible/issues/3#issuecomment-705262614",
                "StackOverflow_Post": {
                    "Id": "64262075",
                    "PostTypeId": "2",
                    "ParentId": "63067071",
                    "CreationDate": "2020-10-08T12:00:15.633",
                    "Score": "3",
                    "Body": "<p>Following information from <a href=\"https://patchwork.ffmpeg.org/project/ffmpeg/patch/17559601585196510@sas2-2fa759678732.qloud-c.yandex.net/\" rel=\"nofollow noreferrer\">this</a> patch to ffmpeg, you need a key/iv pair, which is unique for each book, to decrypt aaxc files. This key/iv, pair is provided by a special license request to the audible api.</p>\n<p>The key/iv pair have to be decrypted from the license request response. Please take a look on <a href=\"https://github.com/mkb79/Audible/issues/3#issuecomment-705262614\" rel=\"nofollow noreferrer\">this</a> issue in my audible github package for more informations how to obtain the key/iv pair.</p>\n",
                    "OwnerUserId": "14413195",
                    "LastActivityDate": "2020-10-08T12:00:15.633",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "64476829",
                "ParentRepo": "https://github.com/earthobservations/wetterdienst",
                "StackOverflow_Post": {
                    "Id": "64476829",
                    "PostTypeId": "1",
                    "CreationDate": "2020-10-22T06:55:38.923",
                    "Score": "1",
                    "ViewCount": "299",
                    "Body": "<p>I really don't know how to help myself, being unfamiliar with this kind of error, and not finding anything on the Google landscape really. My last hope is one of you guys since I don't know where else to go with this. I tried reinstalling all libraries and setting up a new venv. For more action I don't trust myself enough in these kinds of things.</p>\n<p>The code triggering the error:</p>\n<pre><code>from wetterdienst import DWDObservationData\n\nobservations_daily = DWDObservationData(\n    station_ids=station_ids_d,\n    parameter=params_daily,\n    time_resolution=TimeResolution.DAILY,\n    start_date=&quot;2015-01-01&quot;,\n    end_date=&quot;2020-10-10&quot;,\n    tidy_data=True,\n    humanize_column_names=True,\n)\n\nfor df in observations_hourly.collect_data():\n    name = str(df.STATION_ID.iloc[0]).strip(&quot;.0&quot;)\n    df.to_csv('./data/hourly/{}.csv'.format(name))\n    print('{} done'.format(name))\n</code></pre>\n<p>API is found here: <a href=\"https://github.com/earthobservations/wetterdienst\" rel=\"nofollow noreferrer\">https://github.com/earthobservations/wetterdienst</a></p>\n<p>Error:</p>\n<pre><code>Traceback (most recent call last):\n  File &quot;/Users/sashakaun/PycharmProjects/wetter2.0/main.py&quot;, line 83, in &lt;module&gt;\n    for df in observations_hourly.collect_data():\n  File &quot;/Users/sashakaun/PycharmProjects/wetter2.0/venv/lib/python3.8/site-packages/wetterdienst/dwd/observations/api.py&quot;, line 178, in collect_data\n    df_parameter = self._collect_parameter_from_station(\n  File &quot;/Users/sashakaun/PycharmProjects/wetter2.0/venv/lib/python3.8/site-packages/wetterdienst/dwd/observations/api.py&quot;, line 243, in _collect_parameter_from_station\n    df_period = collect_climate_observations_data(\n  File &quot;/Users/sashakaun/PycharmProjects/wetter2.0/venv/lib/python3.8/site-packages/wetterdienst/dwd/observations/access.py&quot;, line 82, in collect_climate_observations_data\n    filenames_and_files = download_climate_observations_data_parallel(remote_files)\n  File &quot;/Users/sashakaun/PycharmProjects/wetter2.0/venv/lib/python3.8/site-packages/wetterdienst/dwd/observations/access.py&quot;, line 106, in download_climate_observations_data_parallel\n    return list(zip(remote_files, files_in_bytes))\n  File &quot;/usr/local/Cellar/python@3.8/3.8.5/Frameworks/Python.framework/Versions/3.8/lib/python3.8/concurrent/futures/_base.py&quot;, line 611, in result_iterator\n    yield fs.pop().result()\n  File &quot;/usr/local/Cellar/python@3.8/3.8.5/Frameworks/Python.framework/Versions/3.8/lib/python3.8/concurrent/futures/_base.py&quot;, line 432, in result\n    return self.__get_result()\n  File &quot;/usr/local/Cellar/python@3.8/3.8.5/Frameworks/Python.framework/Versions/3.8/lib/python3.8/concurrent/futures/_base.py&quot;, line 388, in __get_result\n    raise self._exception\n  File &quot;/usr/local/Cellar/python@3.8/3.8.5/Frameworks/Python.framework/Versions/3.8/lib/python3.8/concurrent/futures/thread.py&quot;, line 57, in run\n    result = self.fn(*self.args, **self.kwargs)\n  File &quot;/Users/sashakaun/PycharmProjects/wetter2.0/venv/lib/python3.8/site-packages/wetterdienst/dwd/observations/access.py&quot;, line 124, in _download_climate_observations_data\n    return BytesIO(__download_climate_observations_data(remote_file=remote_file))\n  File &quot;&lt;decorator-gen-2&gt;&quot;, line 2, in __download_climate_observations_data\n  File &quot;/Users/sashakaun/PycharmProjects/wetter2.0/venv/lib/python3.8/site-packages/dogpile/cache/region.py&quot;, line 1356, in get_or_create_for_user_func\n    return self.get_or_create(\n  File &quot;/Users/sashakaun/PycharmProjects/wetter2.0/venv/lib/python3.8/site-packages/dogpile/cache/region.py&quot;, line 954, in get_or_create\n    with Lock(\n  File &quot;/Users/sashakaun/PycharmProjects/wetter2.0/venv/lib/python3.8/site-packages/dogpile/lock.py&quot;, line 185, in __enter__\n    return self._enter()\n  File &quot;/Users/sashakaun/PycharmProjects/wetter2.0/venv/lib/python3.8/site-packages/dogpile/lock.py&quot;, line 94, in _enter\n    generated = self._enter_create(value, createdtime)\n  File &quot;/Users/sashakaun/PycharmProjects/wetter2.0/venv/lib/python3.8/site-packages/dogpile/lock.py&quot;, line 178, in _enter_create\n    return self.creator()\n  File &quot;/Users/sashakaun/PycharmProjects/wetter2.0/venv/lib/python3.8/site-packages/dogpile/cache/region.py&quot;, line 920, in gen_value\n    self.backend.set(key, value)\n  File &quot;/Users/sashakaun/PycharmProjects/wetter2.0/venv/lib/python3.8/site-packages/dogpile/cache/backends/file.py&quot;, line 239, in set\n    dbm[key] = pickle.dumps(value, pickle.HIGHEST_PROTOCOL)\n_gdbm.error: Database needs recovery\n</code></pre>\n<p>Thanks a lot!!</p>\n",
                    "OwnerUserId": "14474261",
                    "LastEditorUserId": "14474261",
                    "LastEditDate": "2020-10-22T07:35:10.887",
                    "LastActivityDate": "2020-11-18T18:16:15.203",
                    "Title": "_gdbm.error: Database needs recovery -- after running out of storage while fetching api data",
                    "Tags": "<python><database><pickle><gnu>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "64720717",
                "ParentRepo": "https://github.com/uriyyo/fastapi-pagination/blob/main/examples/pagination_sqlalchemy.py",
                "StackOverflow_Post": {
                    "Id": "64720717",
                    "PostTypeId": "2",
                    "ParentId": "60152442",
                    "CreationDate": "2020-11-06T19:42:46.540",
                    "Score": "11",
                    "Body": "<p>You can use <code>fastapi-pagination</code> module, it currently has integration with <code>sqlalchemy</code> and <code>gino</code>.</p>\n<p>The usage will look like:</p>\n<pre class=\"lang-py prettyprint-override\"><code>from fastapi_pagination import Page, PaginationParams\nfrom fastapi_pagination.ext.sqlalchemy import paginate\n\n\nclass User(Base):\n    __tablename__ = &quot;users&quot;\n\n    id = Column(Integer, primary_key=True, autoincrement=True)\n    name = Column(String, nullable=False)\n    email = Column(String, nullable=False)\n\n\nclass UserModel(BaseModel):\n    id: int\n    name: str\n    email: str\n\n    class Config:\n        orm_mode = True\n\n\napp = FastAPI()\n\n@app.get('/users', response_model=Page[UserModel])\ndef get_users(db: Session = Depends(get_db), params: PaginationParams = Depends()):\n    return paginate(db.query(User), params)\n</code></pre>\n<p>Please notice, the purpose of this code is to show <code>fastapi-pagination</code> API.\nYou can find a fully working example here: <a href=\"https://github.com/uriyyo/fastapi-pagination/blob/main/examples/pagination_sqlalchemy.py\" rel=\"noreferrer\">https://github.com/uriyyo/fastapi-pagination/blob/main/examples/pagination_sqlalchemy.py</a></p>\n",
                    "OwnerUserId": "12243670",
                    "LastEditorUserId": "12243670",
                    "LastEditDate": "2021-11-12T14:05:38.093",
                    "LastActivityDate": "2021-11-12T14:05:38.093",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "64769646",
                "ParentRepo": "https://github.com/PyCQA/isort/blob/5.6.4/isort/place.py#L63-L95",
                "StackOverflow_Post": {
                    "Id": "64769646",
                    "PostTypeId": "2",
                    "ParentId": "63583880",
                    "CreationDate": "2020-11-10T13:14:33.377",
                    "Score": "4",
                    "Body": "<p>You can use <code>src_paths</code> option to specify the project folder. You are do not need to maintain <code>known_first_party</code> list. Related source code (<a href=\"https://github.com/PyCQA/isort/blob/5.6.4/isort/place.py#L63-L95\" rel=\"nofollow noreferrer\">https://github.com/PyCQA/isort/blob/5.6.4/isort/place.py#L63-L95</a>) :</p>\n<pre><code>if (\n    _is_module(module_path)\n    or _is_package(module_path)\n    or _src_path_is_module(src_path, root_module_name)\n):\n    return (sections.FIRSTPARTY, f&quot;Found in one of the configured src_paths: {src_path}.&quot;)\n</code></pre>\n",
                    "OwnerUserId": "3096304",
                    "LastActivityDate": "2020-11-10T13:14:33.377",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "64837516",
                "ParentRepo": "https://github.com/strictdoc-project/strictdoc/blob/e66f52f498db82d804137856c576a7357c1370fa/strictdoc/helpers/parallelizer.py",
                "StackOverflow_Post": {
                    "Id": "64837516",
                    "PostTypeId": "2",
                    "ParentId": "50168647",
                    "CreationDate": "2020-11-14T18:57:17.930",
                    "Score": "1",
                    "Body": "<p>The solution that works for me without <code>OBJC_DISABLE_INITIALIZE_FORK_SAFETY</code> flag in the environment involves initializing the <code>multiprocessing.Pool</code> class right after the <code>main()</code> program starts.</p>\n<p>This is most likely not the fastest solution possible and I am not sure if it works in all situations, however, pre-heating the worker processes early enough before my programs starts does not result in any <code>... may have been in progress in another thread when fork() was called</code> errors and I do get a significant performance boost compared to what I get with non-parallelized code.</p>\n<p>I have created a convenience class <code>Parallelizer</code> which I am starting very early and then using throughout the lifecycle of my program. The full version can be found <a href=\"https://github.com/strictdoc-project/strictdoc/blob/e66f52f498db82d804137856c576a7357c1370fa/strictdoc/helpers/parallelizer.py\" rel=\"nofollow noreferrer\">here</a>.</p>\n<pre><code># entry point to my program\ndef main():\n    parallelizer = Parallelizer()\n    ...\n</code></pre>\n<p>Then whenever you want to have parallelization:</p>\n<pre><code># this function is parallelized. it is run by each child process.\ndef processing_function(input):\n    ...\n    return output\n\n...\ninputs = [...]\nresults = parallelizer.map(\n    inputs,\n    processing_function\n)\n</code></pre>\n<p>And the parallelizer class:</p>\n<pre><code>class Parallelizer:\n    def __init__(self):\n        self.input_queue = multiprocessing.Queue()\n        self.output_queue = multiprocessing.Queue()\n        self.pool = multiprocessing.Pool(multiprocessing.cpu_count(),\n                                         Parallelizer._run,\n                                         (self.input_queue, self.output_queue,))\n\n    def map(self, contents, processing_func):\n        size = 0\n        for content in contents:\n            self.input_queue.put((content, processing_func))\n            size += 1\n        results = []\n        while size &gt; 0:\n            result = self.output_queue.get(block=True)\n            results.append(result)\n            size -= 1\n        return results\n\n    @staticmethod\n    def _run(input_queue, output_queue):\n        while True:\n            content, processing_func = input_queue.get(block=True)\n            result = processing_func(content)\n            output_queue.put(result)\n</code></pre>\n<p>One caveat: the parallelized code might be difficult to debug so I have also prepared a non-parallelizing version of my class which I enable when something goes wrong in the child processes:</p>\n<pre><code>class NullParallelizer:\n    @staticmethod\n    def map(contents, processing_func):\n        results = []\n        for content in contents:\n            results.append(processing_func(content))\n        return results\n</code></pre>\n",
                    "OwnerUserId": "598057",
                    "LastEditorUserId": "598057",
                    "LastEditDate": "2021-11-01T13:28:49.707",
                    "LastActivityDate": "2021-11-01T13:28:49.707",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "64954575",
                "ParentRepo": "https://github.com/wandb/client",
                "StackOverflow_Post": {
                    "Id": "64954575",
                    "PostTypeId": "2",
                    "ParentId": "53356846",
                    "CreationDate": "2020-11-22T13:16:04.263",
                    "Score": "0",
                    "Body": "<p>Recently found this <a href=\"https://github.com/wandb/client\" rel=\"nofollow noreferrer\">Weights and Biases</a> framework that seems to nail the job. It's a more comprehensive solution, and they've got a nicer dashboard.</p>\n",
                    "OwnerUserId": "5989906",
                    "LastActivityDate": "2020-11-22T13:16:04.263",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "64990517",
                "ParentRepo": "https://github.com/koxudaxi/fastapi-code-generator",
                "StackOverflow_Post": {
                    "Id": "64990517",
                    "PostTypeId": "2",
                    "ParentId": "64986431",
                    "CreationDate": "2020-11-24T16:19:27.060",
                    "Score": "3",
                    "Body": "<p>After resolving the issue with <a href=\"https://github.com/koxudaxi/fastapi-code-generator\" rel=\"nofollow noreferrer\">fastapi-code-generator</a>, I've opted to use it.</p>\n<p>For future readers, who use <strong>Python 3.7</strong>, the issue was a missing import in the generated <code>models.py</code> file:</p>\n<pre><code>from __future__ import annotations\n</code></pre>\n<p>Adding it at the top of <code>models.py</code> resolved the issue.</p>\n",
                    "OwnerUserId": "499721",
                    "LastEditorUserId": "499721",
                    "LastEditDate": "2020-11-24T17:05:51.310",
                    "LastActivityDate": "2020-11-24T17:05:51.310",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "65047366",
                "ParentRepo": "https://github.com/Ludo915/DroughtWatch",
                "StackOverflow_Post": {
                    "Id": "65047366",
                    "PostTypeId": "1",
                    "CreationDate": "2020-11-28T07:23:34.350",
                    "Score": "0",
                    "ViewCount": "230",
                    "Body": "<p>The whole function beneath gives me the error below, the function works fine if I take away</p>\n<pre class=\"lang-py prettyprint-override\"><code>with tf.Session() as sess:\n        sess.run(tf.global_variables_initializer())\n        result = image.eval(session = sess)\n        print(result)\n</code></pre>\n<p>but I need to convert image from a Tensor to a numpy array to evaluate if it's a blank image with low .std() to then decide not to have it in the train data...</p>\n<p>Using the with tf.Session() function above seems to impact an other function call:</p>\n<pre class=\"lang-py prettyprint-override\"><code> tfrecord_dataset = tfrecord_dataset.map(lambda x:_parse_(x)).shuffle(buffer_size).repeat(-1).batch(batch_size) \n</code></pre>\n<p>why? Whole function:</p>\n<pre class=\"lang-py prettyprint-override\"><code>def parse_tfrecords(filelist, batch_size, buffer_size, include_viz=False):\n  # try a subset of possible bands\n  def _parse_(serialized_example, keylist=['B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8']):\n    example = tf.io.parse_single_example(serialized_example, features)\n    \n    def getband(example_key):\n      img = tf.io.decode_raw(example_key, tf.uint8)\n      return tf.reshape(img[:IMG_DIM**2], shape=(IMG_DIM, IMG_DIM, 1))\n    \n    bandlist = [getband(example[key]) for key in keylist]\n    # combine bands into tensor\n    image = tf.concat(bandlist, -1)\n    with tf.Session() as sess:\n        sess.run(tf.global_variables_initializer())\n        result = image.eval(session = sess)\n        print(result)\n        \n    # one-hot encode ground truth labels \n    label = tf.cast(example['label'], tf.int32)\n    label = tf.one_hot(label, NUM_CLASSES)\n   \n    # if logging RGB images as examples, generate RGB image from 11-channel satellite image\n    if include_viz:\n      image = get_img_from_example(example)\n      return {'image' : image, 'label': example['label']}, label\n    return {'image': image}, label\n    \n  tfrecord_dataset = tf.data.TFRecordDataset(filelist)\n  tfrecord_dataset = tfrecord_dataset.map(lambda x:_parse_(x)).shuffle(buffer_size).repeat(-1).batch(batch_size)\n  tfrecord_iterator = tfrecord_dataset.make_one_shot_iterator()\n  image, label = tfrecord_iterator.get_next()\n  return image, label\n</code></pre>\n<pre><code>---------------------------------------------------------------------------\nOperatorNotAllowedInGraphError            Traceback (most recent call last)\n&lt;ipython-input-66-12dadabe7ed2&gt; in &lt;module&gt;\n----&gt; 1 train_images, train_labels = parse_tfrecords(train_tfrecords, TOTAL_TRAIN, TOTAL_TRAIN)\n      2 val_images, val_labels = parse_tfrecords(val_tfrecords, TOTAL_VAL, TOTAL_VAL)\n      3 \n\n&lt;ipython-input-65-2c2c4cfc0bc1&gt; in parse_tfrecords(filelist, batch_size, buffer_size, include_viz)\n     27 \n     28   tfrecord_dataset = tf.data.TFRecordDataset(filelist)\n---&gt; 29   tfrecord_dataset = tfrecord_dataset.map(lambda x:_parse_(x)).shuffle(buffer_size).repeat(-1).batch(batch_size)\n     30   tfrecord_iterator = tfrecord_dataset.make_one_shot_iterator()\n     31   image, label = tfrecord_iterator.get_next()\n\n~/.pyenv/versions/lewagon/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py in map(self, map_func, num_parallel_calls, deterministic)\n   2507     if num_parallel_calls is None:\n   2508       return DatasetV1Adapter(\n-&gt; 2509           MapDataset(self, map_func, preserve_cardinality=False))\n   2510     else:\n   2511       return DatasetV1Adapter(\n\n~/.pyenv/versions/lewagon/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py in __init__(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function)\n   4039     self._use_inter_op_parallelism = use_inter_op_parallelism\n   4040     self._preserve_cardinality = preserve_cardinality\n-&gt; 4041     self._map_func = StructuredFunctionWrapper(\n   4042         map_func,\n   4043         self._transformation_name(),\n\n~/.pyenv/versions/lewagon/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py in __init__(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\n   3369       with tracking.resource_tracker_scope(resource_tracker):\n   3370         # TODO(b/141462134): Switch to using garbage collection.\n-&gt; 3371         self._function = wrapper_fn.get_concrete_function()\n   3372         if add_to_graph:\n   3373           self._function.add_to_graph(ops.get_default_graph())\n\n~/.pyenv/versions/lewagon/lib/python3.8/site-packages/tensorflow/python/eager/function.py in get_concrete_function(self, *args, **kwargs)\n   2936       **kwargs: inputs to specialize on.\n   2937     &quot;&quot;&quot;\n-&gt; 2938     graph_function = self._get_concrete_function_garbage_collected(\n   2939         *args, **kwargs)\n   2940     graph_function._garbage_collector.release()  # pylint: disable=protected-access\n\n~/.pyenv/versions/lewagon/lib/python3.8/site-packages/tensorflow/python/eager/function.py in _get_concrete_function_garbage_collected(self, *args, **kwargs)\n   2904       args, kwargs = None, None\n   2905     with self._lock:\n-&gt; 2906       graph_function, args, kwargs = self._maybe_define_function(args, kwargs)\n   2907       seen_names = set()\n   2908       captured = object_identity.ObjectIdentitySet(\n\n~/.pyenv/versions/lewagon/lib/python3.8/site-packages/tensorflow/python/eager/function.py in _maybe_define_function(self, args, kwargs)\n   3211 \n   3212       self._function_cache.missed.add(call_context_key)\n-&gt; 3213       graph_function = self._create_graph_function(args, kwargs)\n   3214       self._function_cache.primary[cache_key] = graph_function\n   3215       return graph_function, args, kwargs\n\n~/.pyenv/versions/lewagon/lib/python3.8/site-packages/tensorflow/python/eager/function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)\n   3063     arg_names = base_arg_names + missing_arg_names\n   3064     graph_function = ConcreteFunction(\n-&gt; 3065         func_graph_module.func_graph_from_py_func(\n   3066             self._name,\n   3067             self._python_function,\n\n~/.pyenv/versions/lewagon/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\n    984         _, original_func = tf_decorator.unwrap(python_func)\n    985 \n--&gt; 986       func_outputs = python_func(*func_args, **func_kwargs)\n    987 \n    988       # invariant: `func_outputs` contains only Tensors, CompositeTensors,\n\n~/.pyenv/versions/lewagon/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py in wrapper_fn(*args)\n   3362           attributes=defun_kwargs)\n   3363       def wrapper_fn(*args):  # pylint: disable=missing-docstring\n-&gt; 3364         ret = _wrapper_helper(*args)\n   3365         ret = structure.to_tensor_list(self._output_structure, ret)\n   3366         return [ops.convert_to_tensor(t) for t in ret]\n\n~/.pyenv/versions/lewagon/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py in _wrapper_helper(*args)\n   3297         nested_args = (nested_args,)\n   3298 \n-&gt; 3299       ret = autograph.tf_convert(func, ag_ctx)(*nested_args)\n   3300       # If `func` returns a list of tensors, `nest.flatten()` and\n   3301       # `ops.convert_to_tensor()` would conspire to attempt to stack\n\n~/.pyenv/versions/lewagon/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py in wrapper(*args, **kwargs)\n    256       except Exception as e:  # pylint:disable=broad-except\n    257         if hasattr(e, 'ag_error_metadata'):\n--&gt; 258           raise e.ag_error_metadata.to_exception(e)\n    259         else:\n    260           raise\n\nOperatorNotAllowedInGraphError: in user code:\n\n    &lt;ipython-input-65-2c2c4cfc0bc1&gt;:29 None  *\n        tfrecord_dataset = tfrecord_dataset.map(lambda x:_parse_(x)).shuffle(buffer_size).repeat(-1).batch(batch_size)\n    &lt;ipython-input-65-2c2c4cfc0bc1&gt;:15 _parse_  *\n        result = image.eval(image)\n    /home/ludo915/.pyenv/versions/lewagon/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:913 eval  **\n        return _eval_using_default_session(self, feed_dict, self.graph, session)\n    /home/ludo915/.pyenv/versions/lewagon/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:5512 _eval_using_default_session\n        return session.run(tensors, feed_dict)\n    /home/ludo915/.pyenv/versions/lewagon/lib/python3.8/site-packages/tensorflow/python/client/session.py:957 run\n        result = self._run(None, fetches, feed_dict, options_ptr,\n    /home/ludo915/.pyenv/versions/lewagon/lib/python3.8/site-packages/tensorflow/python/client/session.py:1115 _run\n        if feed_dict:\n    /home/ludo915/.pyenv/versions/lewagon/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:877 __bool__\n        self._disallow_bool_casting()\n    /home/ludo915/.pyenv/versions/lewagon/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:490 _disallow_bool_casting\n        self._disallow_in_graph_mode(&quot;using a `tf.Tensor` as a Python `bool`&quot;)\n    /home/ludo915/.pyenv/versions/lewagon/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:477 _disallow_in_graph_mode\n        raise errors.OperatorNotAllowedInGraphError(\n\n    OperatorNotAllowedInGraphError: using a `tf.Tensor` as a Python `bool` is not allowed in Graph execution. Use Eager execution or decorate this function with @tf.function.\n\n</code></pre>\n<p>Here is the complete jupyter notebook Explore_Images_lg.ipynb:\n<a href=\"https://github.com/Ludo915/DroughtWatch\" rel=\"nofollow noreferrer\">GitHubRepo</a></p>\n<p>From this repo you can also follow the readme instructions to download the data.</p>\n<p>Thanks for your help!</p>\n",
                    "OwnerUserId": "14687074",
                    "LastActivityDate": "2020-12-11T09:45:32.570",
                    "Title": "How to convert a tensor from import tensorflow.compat.v1 as tf to a numpy array?",
                    "Tags": "<python><tensorflow>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "65193369",
                "ParentRepo": "https://github.com/microsoftgraph/msgraph-sdk-python-core",
                "StackOverflow_Post": {
                    "Id": "65193369",
                    "PostTypeId": "2",
                    "ParentId": "65185666",
                    "CreationDate": "2020-12-08T05:04:43.440",
                    "Score": "0",
                    "Body": "<p>Unfortunately, the Python SDK doesn't have any method to achieve your requirement.</p>\n<p>However, the other alternative would be to make use of the GRAPH.</p>\n<p>You could use the below GRAPH Endpoint :</p>\n<pre><code>https://graph.microsoft.com/beta/roleManagement/directory/roleAssignments?$filter=roleDefinitionId eq '62e90394-69f5-4237-9190-012177145e10'&amp;$expand=principal\n</code></pre>\n<p>ID : 62e90394-69f5-4237-9190-012177145e10 -- <strong>Company Administrator</strong> (Global Administrator)</p>\n<p>For other roles/role id you could refer to this <a href=\"https://www.easy365manager.com/azure-administrator-roles/\" rel=\"nofollow noreferrer\">blog</a> or Run a powershell command <code>Get-MsolRole | Sort-Object Name | ft Name,ObjectID,description</code></p>\n<p>The response is a  returns User Collections who are the Company Administrator(Global Administrator)</p>\n<p><strong>Sample Response :</strong></p>\n<p><a href=\"https://i.stack.imgur.com/Bc4uw.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/Bc4uw.png\" alt=\"enter image description here\" /></a></p>\n<p>You could Python to invoke the Graph Endpoint. You can invoke it directly using the <code>requests</code> library or you can use the below library which is a <strong>wrapper of the Graph APIs</strong></p>\n<p><a href=\"https://github.com/microsoftgraph/msgraph-sdk-python-core\" rel=\"nofollow noreferrer\">https://github.com/microsoftgraph/msgraph-sdk-python-core</a></p>\n<p>Also, <strong>Note</strong> : You will have to register an Azure app with the below permission</p>\n<p><a href=\"https://i.stack.imgur.com/Wtu8k.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/Wtu8k.png\" alt=\"enter image description here\" /></a></p>\n<p><a href=\"https://learn.microsoft.com/en-us/graph/api/rbacapplication-list-roleassignments?view=graph-rest-beta&amp;tabs=http\" rel=\"nofollow noreferrer\">Reference</a></p>\n",
                    "OwnerUserId": "13755246",
                    "LastActivityDate": "2020-12-08T05:04:43.440",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "65491442",
                "ParentRepo": "https://github.com/laurentS/slowapi",
                "StackOverflow_Post": {
                    "Id": "65491442",
                    "PostTypeId": "2",
                    "ParentId": "65491184",
                    "CreationDate": "2020-12-29T11:31:42.747",
                    "Score": "25",
                    "Body": "<p>Best option is using a library since FastAPI does not provide this functionality out-of-box.</p>\n<p><a href=\"https://github.com/laurentS/slowapi\" rel=\"noreferrer\">slowapi</a> is great, and easy to use.</p>\n<p>You can use ut like this.</p>\n<pre><code>from fastapi import FastAPI\nfrom slowapi.errors import RateLimitExceeded\nfrom slowapi import Limiter, _rate_limit_exceeded_handler\nfrom slowapi.util import get_remote_address\n\n\nlimiter = Limiter(key_func=get_remote_address)\napp = FastAPI()\napp.state.limiter = limiter\napp.add_exception_handler(RateLimitExceeded, _rate_limit_exceeded_handler)\n\n@app.get(&quot;/home&quot;)\n@limiter.limit(&quot;5/minute&quot;)\nasync def homepage(request: Request):\n    return PlainTextResponse(&quot;test&quot;)\n\n@app.get(&quot;/mars&quot;)\n@limiter.limit(&quot;5/minute&quot;)\nasync def homepage(request: Request, response: Response):\n    return {&quot;key&quot;: &quot;value&quot;}\n</code></pre>\n",
                    "OwnerUserId": "13161155",
                    "LastEditorUserId": "13161155",
                    "LastEditDate": "2022-04-09T11:56:56.427",
                    "LastActivityDate": "2022-04-09T11:56:56.427",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "66472800",
                "ParentRepo": "https://github.com/pypa/hatch/commit/eef7d0c#diff-846792860efe35ffaa63db526fa381c4f16f2caaa482ef3a8886e62d3454f5ce",
                "StackOverflow_Post": {
                    "Id": "66472800",
                    "PostTypeId": "2",
                    "ParentId": "62983756",
                    "CreationDate": "2021-03-04T10:05:29.583",
                    "Score": "61",
                    "Body": "<h3>What is it for?</h3>\n<p>Currently there are multiple packaging tools being popular in Python community and while <code>setuptools</code> still seems to be prevalent it's not a de\u00a0facto standard anymore. This situation creates a number of hassles for both end\u00a0users and developers:</p>\n<ol>\n<li>For <code>setuptools</code>-based packages installation from source / build of a distribution can fail if one doesn't have <code>setuptools</code> installed;</li>\n<li><code>pip</code> doesn't support the installation of packages based on other packaging tools from source, so these tools had to generate a <code>setup.py</code> file to produce a compatible package. To build a distribution package one has to install the packaging tool first and then use tool-specific commands;</li>\n<li>If package author decides to change the packaging tool, workflows must be changed as\u00a0well to use different tool-specific commands.</li>\n</ol>\n<p><code>pyproject.toml</code> is a new configuration file introduced by <a href=\"https://peps.python.org/pep-0517/\" rel=\"noreferrer\">PEP\u00a0517</a> and <a href=\"https://peps.python.org/pep-0518/\" rel=\"noreferrer\">PEP\u00a0518</a> to solve these problems:</p>\n<blockquote>\n<p>... think of the (rough) steps required to produce a built artifact for a project:</p>\n<ol>\n<li>The source checkout of the project.</li>\n<li>Installation of the build system.</li>\n<li>Execute the build system.</li>\n</ol>\n<p>This PEP [518] covers step #2. <a href=\"https://peps.python.org/pep-0517/\" rel=\"noreferrer\">PEP\u00a0517</a> covers step #3 ...</p>\n</blockquote>\n<p>Any tool can also extend this file with its own section (table) to accept tool-specific options, but it's up to them and not required.</p>\n<p><a href=\"https://peps.python.org/pep-0621/\" rel=\"noreferrer\">PEP\u00a0621</a> suggests using <code>pyproject.toml</code> to specify package core\u00a0metadata in static, tool-agnostic way. Which backends currently support this is shown in the following table:</p>\n<div class=\"s-table-container\">\n<table class=\"s-table\">\n<thead>\n<tr>\n<th style=\"text-align: center;\"><a href=\"https://packaging.python.org/en/latest/key_projects/#enscons\" rel=\"noreferrer\"><code>enscons</code></a></th>\n<th style=\"text-align: center;\"><a href=\"https://packaging.python.org/en/latest/key_projects/#flit\" rel=\"noreferrer\"><code>flit_core</code></a></th>\n<th style=\"text-align: center;\"><a href=\"https://packaging.python.org/en/latest/key_projects/#hatch\" rel=\"noreferrer\"><code>hatchling</code></a></th>\n<th style=\"text-align: center;\"><a href=\"https://packaging.python.org/en/latest/key_projects/#pdm\" rel=\"noreferrer\"><code>pdm-pep517</code></a></th>\n<th style=\"text-align: center;\"><a href=\"https://packaging.python.org/en/latest/key_projects/#poetry\" rel=\"noreferrer\"><code>poetry-core</code></a></th>\n<th style=\"text-align: center;\"><a href=\"https://packaging.python.org/en/latest/key_projects/#easy-install\" rel=\"noreferrer\"><code>setuptools</code></a></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align: center;\"><img src=\"https://i.stack.imgur.com/L0WLX.png\" alt=\"Supports\" /><br><a href=\"https://github.com/dholth/enscons/blob/master/CHANGES#:%7E:text=Support%20PEP%20621%20metadata\" rel=\"noreferrer\" title=\"Apr\u00a024,\u00a02021\">0.26.0+</a></td>\n<td style=\"text-align: center;\"><img src=\"https://i.stack.imgur.com/L0WLX.png\" alt=\"Supports\" /><br><a href=\"https://flit.pypa.io/en/latest/history.html#version-3-3\" rel=\"noreferrer\" title=\"Mar\u00a021,\u00a02021\">3.2+</a></td>\n<td style=\"text-align: center;\"><img src=\"https://i.stack.imgur.com/L0WLX.png\" alt=\"Supports\" /><br><a href=\"https://github.com/pypa/hatch/commit/eef7d0c#diff-846792860efe35ffaa63db526fa381c4f16f2caaa482ef3a8886e62d3454f5ce\" rel=\"noreferrer\" title=\"Dec\u00a029,\u00a02021\">0.3+</a></td>\n<td style=\"text-align: center;\"><img src=\"https://i.stack.imgur.com/L0WLX.png\" alt=\"Supports\" /><br><a href=\"https://github.com/pdm-project/pdm-pep517/blob/master/CHANGELOG.md#release-v030-2020-12-21\" rel=\"noreferrer\" title=\"Dec\u00a021,\u00a02020\">0.3.0+</a></td>\n<td style=\"text-align: center;\"><img src=\"https://i.stack.imgur.com/RfN2j.png\" alt=\"Doesn't support\" /><br><a href=\"https://github.com/python-poetry/poetry/issues/3332\" rel=\"noreferrer\">Issue\u00a0#3332</a></td>\n<td style=\"text-align: center;\"><img src=\"https://i.stack.imgur.com/L0WLX.png\" alt=\"Supports\" /><br><a href=\"https://setuptools.pypa.io/en/latest/history.html#v61-0-0\" rel=\"noreferrer\" title=\"Mar\u00a024,\u00a02022\">61.0.0+</a></td>\n</tr>\n</tbody>\n</table>\n</div><h3>Does it replace <code>setup.py</code>?</h3>\n<p>For <code>setuptools</code>-based packages <code>pyproject.toml</code> is not strictly meant to replace <code>setup.py</code>, but rather to ensure its correct execution if it's still needed. For other packaging tools \u2013 yes, it is:</p>\n<blockquote>\n<p>Where the <code>build-backend</code> key exists, this takes precedence and the source tree follows the format and conventions of the specified backend (as such no <code>setup.py</code> is needed <strong>unless the backend requires it</strong>). Projects may still wish to include a <code>setup.py</code> for compatibility with tools that do not use this spec.</p>\n</blockquote>\n<h3>How to install a package in editable mode?</h3>\n<p>Originally &quot;editable install&quot; was a <code>setuptools</code>-specific feature and as such it was not supported by PEP\u00a0517. Later\u00a0on <a href=\"https://peps.python.org/pep-0660/\" rel=\"noreferrer\">PEP\u00a0660</a> extended this concept to packages using <code>pyproject.toml</code>.</p>\n<p>There are two possible conditions for installing a package in editable mode using <code>pip</code>:</p>\n<ul>\n<li><strong>Modern:</strong><br />\nBoth the frontend (<code>pip</code>) and a backend must support PEP\u00a0660.<br />\n<code>pip</code> supports it <a href=\"https://pip.pypa.io/en/latest/news/#v21-3\" rel=\"noreferrer\" title=\"Oct\u00a011,\u00a02021\">since version\u00a021.3</a>;</li>\n<li><strong>Legacy:</strong><br />\nPackaging tool must provide a <code>setup.py</code> file which supports the <code>develop</code> command.<br />\n<a href=\"https://pip.pypa.io/en/latest/news/#v21-1\" rel=\"noreferrer\" title=\"Apr\u00a024,\u00a02021\">Since version\u00a021.1</a> <code>pip</code> can also install packages using only <code>setup.cfg</code> file in editable mode.</li>\n</ul>\n<p>The following table describes the support of editable installs by various backends:</p>\n<div class=\"s-table-container\">\n<table class=\"s-table\">\n<thead>\n<tr>\n<th style=\"text-align: center;\"><a href=\"https://packaging.python.org/en/latest/key_projects/#enscons\" rel=\"noreferrer\"><code>enscons</code></a></th>\n<th style=\"text-align: center;\"><a href=\"https://packaging.python.org/en/latest/key_projects/#flit\" rel=\"noreferrer\"><code>flit_core</code></a></th>\n<th style=\"text-align: center;\"><a href=\"https://packaging.python.org/en/latest/key_projects/#hatch\" rel=\"noreferrer\"><code>hatchling</code></a></th>\n<th style=\"text-align: center;\"><a href=\"https://packaging.python.org/en/latest/key_projects/#pdm\" rel=\"noreferrer\"><code>pdm-pep517</code></a></th>\n<th style=\"text-align: center;\"><a href=\"https://packaging.python.org/en/latest/key_projects/#poetry\" rel=\"noreferrer\"><code>poetry-core</code></a></th>\n<th style=\"text-align: center;\"><a href=\"https://packaging.python.org/en/latest/key_projects/#easy-install\" rel=\"noreferrer\"><code>setuptools</code></a></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align: center;\"><img src=\"https://i.stack.imgur.com/L0WLX.png\" alt=\"Supports\" /><br><a href=\"https://github.com/dholth/enscons/blob/master/CHANGES#:%7E:text=Update%20editables%20for,660\" rel=\"noreferrer\" title=\"Aug\u00a017,\u00a02021\">0.28.0+</a></td>\n<td style=\"text-align: center;\"><img src=\"https://i.stack.imgur.com/L0WLX.png\" alt=\"Supports\" /><br><a href=\"https://flit.pypa.io/en/latest/history.html#version-3-4\" rel=\"noreferrer\" title=\"Oct\u00a010,\u00a02021\">3.4+</a></td>\n<td style=\"text-align: center;\"><img src=\"https://i.stack.imgur.com/L0WLX.png\" alt=\"Supports\" /><br><a href=\"https://github.com/pypa/hatch/commit/eef7d0c#diff-349bd6b94a1514449b8e77147675ad04398507e47265ad1c176b718347208c55R42-R61\" rel=\"noreferrer\" title=\"Dec\u00a029,\u00a02021\">0.3+</a></td>\n<td style=\"text-align: center;\"><img src=\"https://i.stack.imgur.com/L0WLX.png\" alt=\"Supports\" /><br><a href=\"https://github.com/pdm-project/pdm-pep517/blob/master/CHANGELOG.md#release-v080-2021-06-29\" rel=\"noreferrer\" title=\"Jun\u00a029,\u00a02021\">0.8.0+</a></td>\n<td style=\"text-align: center;\"><img src=\"https://i.stack.imgur.com/L0WLX.png\" alt=\"Supports\" /><br><a href=\"https://github.com/python-poetry/poetry-core/releases/tag/1.0.8\" rel=\"noreferrer\" title=\"Feb\u00a028,\u00a02022\">1.0.8+</a></td>\n<td style=\"text-align: center;\"><img src=\"https://i.stack.imgur.com/L0WLX.png\" alt=\"Supports\" /><br><a href=\"https://setuptools.pypa.io/en/latest/history.html#v64-0-0\" rel=\"noreferrer\" title=\"Aug\u00a011,\u00a02022\">64.0.0+</a></td>\n</tr>\n</tbody>\n</table>\n</div>",
                    "OwnerUserId": "11725753",
                    "LastEditorUserId": "11725753",
                    "LastEditDate": "2022-08-13T15:06:30.817",
                    "LastActivityDate": "2022-08-13T15:06:30.817",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "66488187",
                "ParentRepo": "https://github.com/open-telemetry/opentelemetry-python-contrib/issues/365",
                "StackOverflow_Post": {
                    "Id": "66488187",
                    "PostTypeId": "2",
                    "ParentId": "66357827",
                    "CreationDate": "2021-03-05T07:07:55.233",
                    "Score": "3",
                    "Body": "<p>After hours of debugging turns out it was bad documentation on the Python gRPC Client Instrumentation. For insecure (localhost) channels, the documentation works and the client is instrumented. For secure channels (as required for Google Cloud Run) you need to pass in <code>channel_type='secure'</code>. I'm not sure why it was designed this way and raised an issue on the module: <a href=\"https://github.com/open-telemetry/opentelemetry-python-contrib/issues/365\" rel=\"nofollow noreferrer\">https://github.com/open-telemetry/opentelemetry-python-contrib/issues/365</a></p>\n<p>In addition, you need to use the <code>X-Cloud-Trace-Context</code> header to ensure your traces use the same trace ID as the load balancer and AppServer on Google Cloud run and all link up in Google Trace, but the default implementation of their propagator uses upper case letters that can't be used in gRPC metadata keys so throws a validation error. I took the class below and made it all lowercase and it all works perfectly now:</p>\n<p><a href=\"https://github.com/GoogleCloudPlatform/opentelemetry-operations-python/blob/master/opentelemetry-tools-google-cloud/src/opentelemetry/tools/cloud_trace_propagator.py\" rel=\"nofollow noreferrer\">https://github.com/GoogleCloudPlatform/opentelemetry-operations-python/blob/master/opentelemetry-tools-google-cloud/src/opentelemetry/tools/cloud_trace_propagator.py</a></p>\n<p>Finally I had a long standing issue with linking my logs to traces on Google Cloud logs, the documentation says use a Hex Trace ID and Hex Span ID, but they didn't work as I was using the wrong OpenTelemetry functions to format them. However this code works and I can now see my logs alongside my traces in Google Trace's Trace List view now!</p>\n<pre><code>from opentelemetry import trace\nfrom opentelemetry.trace.span import get_hexadecimal_trace_id, get_hexadecimal_span_id\n\n        current_span = trace.get_current_span()\n        if current_span:\n            trace_id = current_span.get_span_context().trace_id\n            span_id = current_span.get_span_context().span_id\n            if trace_id and span_id:\n                logging_fields['logging.googleapis.com/trace'] = f&quot;projects/{self.gce_project}/traces/{get_hexadecimal_trace_id(trace_id)}&quot;\n                logging_fields['logging.googleapis.com/spanId'] = f&quot;{get_hexadecimal_span_id(span_id)}&quot;\n                logging_fields['logging.googleapis.com/trace_sampled'] = True\n</code></pre>\n<p>It took a while, but I guess its my fault for picking an Alpha (just turned Beta) framework (OpenTelemetry) on a new, not very well documented (in this area) Google Cloud service. But with those fixes it all works now and much easier to debug issues and see the total end to end request!</p>\n",
                    "OwnerUserId": "1508568",
                    "LastActivityDate": "2021-03-05T07:07:55.233",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "66617411",
                "ParentRepo": "https://github.com/nsidnev/fastapi-realworld-example-app/tree/master/app",
                "StackOverflow_Post": {
                    "Id": "66617411",
                    "PostTypeId": "2",
                    "ParentId": "65930477",
                    "CreationDate": "2021-03-13T18:56:49.067",
                    "Score": "1",
                    "Body": "<p>I don't think my solution is complete or correct, but I figured I'd post it in case it inspires any ideas, I'm stumped. I have run into the exact dilemma, almost seems like a design flaw..</p>\n<p>I followed this <a href=\"https://frankie567.github.io/fastapi-users/configuration/full_example\" rel=\"nofollow noreferrer\">MongoDB full example</a> and named it <code>main.py</code></p>\n<p>At this point my app does not work. The server starts up but result results in the aforementioned &quot;attached to a different loop&quot; whenever trying to query the DB.</p>\n<p>Looking for guidance, I stumbled upon the same &quot;real world&quot; <a href=\"https://github.com/nsidnev/fastapi-realworld-example-app/tree/master/app\" rel=\"nofollow noreferrer\">example</a></p>\n<p>In <code>main.py</code> added the startup and shudown event handlers</p>\n<pre><code># Event handlers\napp.add_event_handler(&quot;startup&quot;, create_start_app_handler(app=app))\napp.add_event_handler(&quot;shutdown&quot;, create_stop_app_handler(app=app))\n</code></pre>\n<p>In <code>dlw_api.db.events.py</code> this:</p>\n<pre><code>import logging\n\nfrom dlw_api.user import UserDB\nfrom fastapi import FastAPI\nfrom fastapi_users.db.mongodb import MongoDBUserDatabase\nfrom motor.motor_asyncio import AsyncIOMotorClient\n\n\nLOG = logging.getLogger(__name__)\nDB_NAME = &quot;dlwLocal&quot;\nUSERS_COLLECTION = &quot;users&quot;\nDATABASE_URI = &quot;mongodb://dlw-mongodb:27017&quot;  # protocol://container_name:port\n\n\n_client: AsyncIOMotorClient = None\n_users_db: MongoDBUserDatabase = None\n\n\ndef get_users_db() -&gt; MongoDBUserDatabase:\n    return _users_db\n\n\nasync def connect_to_db() -&gt; None:\n    global _users_db\n    # logger.info(&quot;Connecting to {0}&quot;, repr(DATABASE_URL))\n    client = AsyncIOMotorClient(DATABASE_URI)\n    db = client[DB_NAME]\n    collection = db[USERS_COLLECTION]\n    _users_db = MongoDBUserDatabase(UserDB, collection)\n    LOG.info(f&quot;Connected to {DATABASE_URI}&quot;)\n\n\nasync def close_db_connection(app: FastAPI) -&gt; None:\n    _client.close()\n    LOG.info(&quot;Connection closed&quot;)\n</code></pre>\n<p>And <code>dlw_api.events.py</code>:</p>\n<pre><code>from typing import Callable\nfrom fastapi import FastAPI\nfrom dlw_api.db.events import close_db_connection, connect_to_db\nfrom dlw_api.user import configure_user_auth_routes\nfrom fastapi_users.authentication import CookieAuthentication\nfrom dlw_api.db.events import get_users_db\n\n\nCOOKIE_SECRET = &quot;THIS_NEEDS_TO_BE_SET_CORRECTLY&quot; # TODO: &lt;--|\nCOOKIE_LIFETIME_SECONDS: int = 3_600\nCOOKIE_NAME = &quot;c-is-for-cookie&quot;\n\n# Auth stuff:\n_cookie_authentication = CookieAuthentication(\n    secret=COOKIE_SECRET,\n    lifetime_seconds=COOKIE_LIFETIME_SECONDS,\n    name=COOKIE_NAME,\n)\n\nauth_backends = [\n    _cookie_authentication,\n]\n\n\ndef create_start_app_handler(app: FastAPI) -&gt; Callable:\n    async def start_app() -&gt; None:\n        await connect_to_db(app)\n        configure_user_auth_routes(\n            app=app,\n            auth_backends=auth_backends,\n            user_db=get_users_db(),\n            secret=COOKIE_SECRET,\n        )\n\n    return start_app\n\n\ndef create_stop_app_handler(app: FastAPI) -&gt; Callable:\n    async def stop_app() -&gt; None:\n        await close_db_connection(app)\n\n    return stop_app\n</code></pre>\n<p>This doesn't feel correct to me, does this mean all routes that use <code>Depends</code> for user-auth have to be included on the server startup event handler??</p>\n",
                    "OwnerUserId": "15389030",
                    "LastActivityDate": "2021-03-13T18:56:49.067",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "66627306",
                "ParentRepo": "https://github.com/testdrivenio/fastapi-tdd-docker/issues/5#issuecomment-798435535",
                "StackOverflow_Post": {
                    "Id": "66627306",
                    "PostTypeId": "2",
                    "ParentId": "66119608",
                    "CreationDate": "2021-03-14T17:08:51.247",
                    "Score": "3",
                    "Body": "<p>Try updating the following dependencies:</p>\n<pre><code>asyncpg==0.22.0\nfastapi==0.63.0\nrequests==2.25.1\ntortoise-orm==0.16.21\n</code></pre>\n<p><a href=\"https://github.com/testdrivenio/fastapi-tdd-docker/issues/5#issuecomment-798435535\" rel=\"nofollow noreferrer\">https://github.com/testdrivenio/fastapi-tdd-docker/issues/5#issuecomment-798435535</a></p>\n",
                    "OwnerUserId": "1799408",
                    "LastActivityDate": "2021-03-14T17:08:51.247",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "66999513",
                "ParentRepo": "https://github.com/sigolo/geofiles-api",
                "StackOverflow_Post": {
                    "Id": "66999513",
                    "PostTypeId": "2",
                    "ParentId": "39214367",
                    "CreationDate": "2021-04-08T07:50:28.423",
                    "Score": "4",
                    "Body": "<p>Even if <a href=\"https://gdal.org/\" rel=\"nofollow noreferrer\">GDAL</a> is a good and working solution for <a href=\"https://en.wikipedia.org/wiki/AutoCAD_DXF\" rel=\"nofollow noreferrer\">DXF</a> file (which are CAD files too)</p>\n<p>Since the OOP asks about <a href=\"https://en.wikipedia.org/wiki/.dwg\" rel=\"nofollow noreferrer\">DWG</a> file, I would suggest to use the <a href=\"https://github.com/LibreDWG/libredwg\" rel=\"nofollow noreferrer\">LibreDWG</a> library that support conversion from DWG to GeoJSON files and has very good performance.</p>\n<p>You can use it like so :</p>\n<pre><code>dwgread &lt;input_file_path&gt; -O GeoJSON -o &lt;output_file_path&gt;\n</code></pre>\n<p>There are also many other commands provided by this fantastic library.\nI am also currently work on an open source project <a href=\"https://github.com/sigolo/geofiles-api\" rel=\"nofollow noreferrer\">Geofiles-convertor Rest API</a> which is a REST API that aims to make popular geofiles format conversion easier.\nIt is also based on both GDAL and LibreDWG and there is a Docker image ready to run.</p>\n<h3>Windows Users</h3>\n<p>For Windows users, you can download the <a href=\"https://github.com/LibreDWG/libredwg/releases\" rel=\"nofollow noreferrer\">latest release from GitHub</a> <em>(win32.zip or win64.zip)</em>, which has <code>dwgread.exe</code> file.</p>\n<p>You can then open a terminal in the downloaded folder location and run the command <code>dwgread.exe &quot;D:\\path\\to\\file.dwg&quot; -O GeoJSON -o &quot;D:\\path\\to\\output.json&quot;</code></p>\n",
                    "OwnerUserId": "13000695",
                    "LastEditorUserId": "6908282",
                    "LastEditDate": "2022-09-13T11:37:30.027",
                    "LastActivityDate": "2022-09-13T11:37:30.027",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "67252812",
                "ParentRepo": "https://github.com/talmago/spacy_crfsuite",
                "StackOverflow_Post": {
                    "Id": "67252812",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "67267091",
                    "CreationDate": "2021-04-25T11:22:47.007",
                    "Score": "1",
                    "ViewCount": "394",
                    "Body": "<p>I'm trying to load a custom pre-trained model with custom pipeline from disk as a pipeline in spacy 3.0:</p>\n<p>The code of the factory is like this:</p>\n<pre><code>@CustomEng.factory(&quot;ner-crf&quot;)\ndef create_my_component(nlp, name):\n    crf_extractor = CRFExtractor().from_disk(&quot;path-to-model&quot;)\n    return CRFEntityExtractor(nlp, crf_extractor=crf_extractor)\n</code></pre>\n<p>Then I added to 'ner-crf' to my Language class like this:</p>\n<pre><code>    nlp = spacy.blank('custom-eng')\n    nlp.add_pipe('ner-crf')\n    nlp.to_disk('../model')\n</code></pre>\n<p>There's a thing I think may be relevant: When I use <code>to_disk</code> in order to save the <code>nlp</code> object there is no <code>ner-crf</code> package (the pipeline I just added)  in the saved object.</p>\n<p>Then I run this CLI command to evaluate the NER pipeline:</p>\n<pre><code>python -m spacy evaluate ../model/ ../corpus/dev.spacy --output ../model/metrics.json --gpu-id 0 --code ../../../spacy_utils/custom-eng/__init__.py\n</code></pre>\n<p>But I get this error :</p>\n<pre><code>Traceback (most recent call last):\n  File &quot;/home/marzi/anaconda3/envs/spacy-tutorial/lib/python3.8/runpy.py&quot;, line 194, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File &quot;/home/marzi/anaconda3/envs/spacy-tutorial/lib/python3.8/runpy.py&quot;, line 87, in _run_code\n    exec(code, run_globals)\n  File &quot;/home/marzi/anaconda3/envs/spacy-tutorial/lib/python3.8/site-packages/spacy/__main__.py&quot;, line 4, in &lt;module&gt;\n    setup_cli()\n  File &quot;/home/marzi/anaconda3/envs/spacy-tutorial/lib/python3.8/site-packages/spacy/cli/_util.py&quot;, line 69, in setup_cli\n    command(prog_name=COMMAND)\n  File &quot;/home/marzi/anaconda3/envs/spacy-tutorial/lib/python3.8/site-packages/click/core.py&quot;, line 829, in __call__\n    return self.main(*args, **kwargs)\n  File &quot;/home/marzi/anaconda3/envs/spacy-tutorial/lib/python3.8/site-packages/click/core.py&quot;, line 782, in main\n    rv = self.invoke(ctx)\n  File &quot;/home/marzi/anaconda3/envs/spacy-tutorial/lib/python3.8/site-packages/click/core.py&quot;, line 1259, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File &quot;/home/marzi/anaconda3/envs/spacy-tutorial/lib/python3.8/site-packages/click/core.py&quot;, line 1066, in invoke\n    return ctx.invoke(self.callback, **ctx.params)\n  File &quot;/home/marzi/anaconda3/envs/spacy-tutorial/lib/python3.8/site-packages/click/core.py&quot;, line 610, in invoke\n    return callback(*args, **kwargs)\n  File &quot;/home/marzi/anaconda3/envs/spacy-tutorial/lib/python3.8/site-packages/typer/main.py&quot;, line 497, in wrapper\n    return callback(**use_params)  # type: ignore\n  File &quot;/home/marzi/anaconda3/envs/spacy-tutorial/lib/python3.8/site-packages/spacy/cli/evaluate.py&quot;, line 42, in evaluate_cli\n    evaluate(\n  File &quot;/home/marzi/anaconda3/envs/spacy-tutorial/lib/python3.8/site-packages/spacy/cli/evaluate.py&quot;, line 75, in evaluate\n    nlp = util.load_model(model)\n  File &quot;/home/marzi/anaconda3/envs/spacy-tutorial/lib/python3.8/site-packages/spacy/util.py&quot;, line 326, in load_model\n    return load_model_from_path(Path(name), **kwargs)\n  File &quot;/home/marzi/anaconda3/envs/spacy-tutorial/lib/python3.8/site-packages/spacy/util.py&quot;, line 392, in load_model_from_path\n    return nlp.from_disk(model_path, exclude=exclude)\n  File &quot;/home/marzi/anaconda3/envs/spacy-tutorial/lib/python3.8/site-packages/spacy/language.py&quot;, line 1883, in from_disk\n    util.from_disk(path, deserializers, exclude)\n  File &quot;/home/marzi/anaconda3/envs/spacy-tutorial/lib/python3.8/site-packages/spacy/util.py&quot;, line 1176, in from_disk\n    reader(path / key)\n  File &quot;/home/marzi/anaconda3/envs/spacy-tutorial/lib/python3.8/site-packages/spacy/language.py&quot;, line 1877, in &lt;lambda&gt;\n    deserializers[name] = lambda p, proc=proc: proc.from_disk(\nTypeError: from_disk() got an unexpected keyword argument 'exclude'\n\n</code></pre>\n<p>The custom NER classes that I used belong to <a href=\"https://github.com/talmago/spacy_crfsuite\" rel=\"nofollow noreferrer\">spacy-crfsuite</a> library which works fine in spacy 2 but they have no sample code for Spacy 3 yet so I'm trying to make it work in spacy 3.0 myself.</p>\n",
                    "OwnerUserId": "5516760",
                    "LastEditorUserId": "5516760",
                    "LastEditDate": "2021-04-26T04:44:15.550",
                    "LastActivityDate": "2021-04-26T12:57:58.950",
                    "Title": "Can't evaluate custom ner in spacy 3.0 using CLI",
                    "Tags": "<python><spacy><spacy-3>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "67334629",
                "ParentRepo": "https://github.com/cogeotiff/rio-tiler/blob/ccf8418e49146a64ba27a43d99f727e38c60ccbd/rio_tiler/io/cogeo.py#L103",
                "StackOverflow_Post": {
                    "Id": "67334629",
                    "PostTypeId": "2",
                    "ParentId": "67334225",
                    "CreationDate": "2021-04-30T13:18:03.887",
                    "Score": "0",
                    "Body": "<p>Your dataset <code>test_img_msk</code> has a projected coordinate system, <a href=\"https://epsg.io/32620\" rel=\"nofollow noreferrer\">EPSG:32620</a> to be specific which uses coordinate units of meters.</p>\n<p>The second bounding box seems to be in a different coordinate system, likely a geographic coordinate system, where the coordinate units are decimal degrees.</p>\n<p>So in the end, your <code>left</code> boundary is the same location, just in a different coordinate system.</p>\n<p>For more info on projected vs geographic coordinate system, <a href=\"https://www.esri.com/arcgis-blog/products/arcgis-pro/mapping/gcs_vs_pcs/\" rel=\"nofollow noreferrer\">check this article</a>.</p>\n<p><strong>Edit</strong>:</p>\n<p>Looking at the <a href=\"https://github.com/cogeotiff/rio-tiler/blob/ccf8418e49146a64ba27a43d99f727e38c60ccbd/rio_tiler/io/cogeo.py#L103\" rel=\"nofollow noreferrer\">source code of <code>COGReader.info</code></a> reveals that the bounding box coordinates are transformed from the native projection to the GCS WGS84 using <code>transform_bounds</code>.</p>\n",
                    "OwnerUserId": "5997555",
                    "LastEditorUserId": "5997555",
                    "LastEditDate": "2021-04-30T13:51:33.217",
                    "LastActivityDate": "2021-04-30T13:51:33.217",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "67799112",
                "ParentRepo": "https://github.com/fluentpython/example-code-2e/blob/master/13-protocol-abc/tombolist.py",
                "StackOverflow_Post": {
                    "Id": "67799112",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "67799330",
                    "CreationDate": "2021-06-02T04:52:19.740",
                    "Score": "3",
                    "ViewCount": "68",
                    "Body": "<p>I am currently reading through Luciano Ramalho's excellent book <a href=\"https://www.goodreads.com/en/book/show/22800567\" rel=\"nofollow noreferrer\">Fluent Python</a>. In a chapter about interfaces and inheritance we build a subclass of a list (see <a href=\"https://github.com/fluentpython/example-code-2e/blob/master/13-protocol-abc/tombolist.py\" rel=\"nofollow noreferrer\">github</a> for the original code) and I am confused about the way we define one of the instance methods. For a simlified example my confusion is caused by a situation as follows:</p>\n<pre><code>class ListWithLoadMethod(list):\n    load = list.extend\n</code></pre>\n<p>which generates a new subclass of list which has an alias for the <code>extend</code> method as <code>load</code>. We can test the class by writing</p>\n<pre><code>loaded_list = ListWithLoadMethod(range(4))\nprint(loaded_list)\nloaded_list.extend(range(3))\nprint(loaded_list)\nloaded_list.load(range(3))\nprint(loaded_list) \n</code></pre>\n<p>which produces, as expected:</p>\n<pre><code>[0, 1, 2, 3]\n[0, 1, 2, 3, 0, 1, 2]\n[0, 1, 2, 3, 0, 1, 2, 0, 1, 2]\n</code></pre>\n<p>My confusion arises from on the difference of class methods and static methods. When the new instance of <code>ListWithLoadedMethod</code> is created, it is a subclass of <code>list</code>, but when we initialize the instance we point <code>load</code> to <code>list.extend</code>; how does Python know that by <code>list.extend</code> we do not mean that <code>load</code> should point to a class method of the <code>list</code> class but to actually (apparently?) inherit the instance method of the superclass list?</p>\n",
                    "OwnerUserId": "4605309",
                    "LastActivityDate": "2021-06-02T05:31:19.033",
                    "Title": "Using superclass methods as instance methods",
                    "Tags": "<python><inheritance><class-method><instance-methods>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "67877204",
                "ParentRepo": "https://github.com/dalf/pyhttp-benchmark",
                "StackOverflow_Post": {
                    "Id": "67877204",
                    "PostTypeId": "2",
                    "ParentId": "67822235",
                    "CreationDate": "2021-06-07T18:49:55.963",
                    "Score": "0",
                    "Body": "<p><a href=\"https://github.com/dalf/pyhttp-benchmark\" rel=\"nofollow noreferrer\">https://github.com/dalf/pyhttp-benchmark</a> might help in a way or another.</p>\n<p>See:</p>\n<ul>\n<li><a href=\"https://github.com/dalf/pyhttp-benchmark/blob/master/results/output.md\" rel=\"nofollow noreferrer\">results for httpx 0.18.1</a></li>\n<li><a href=\"https://github.com/dalf/pyhttp-benchmark/blob/027fc353ba1157000de5bff9077c71514298cbcc/results/output.md\" rel=\"nofollow noreferrer\">results for httpx 0.16.1</a></li>\n<li>Labels:\n<ul>\n<li>httpx_uvloop_True = httpx, using uvloop and http2</li>\n<li>httpx_uvloop_False = httpx, using uvloop and http1 only</li>\n</ul>\n</li>\n</ul>\n<p>TLDR: with httpx, when using http2</p>\n<ul>\n<li>avoid large content (&gt;64kb).</li>\n<li>avoid sequential requests</li>\n<li>prefer parallel requests</li>\n</ul>\n",
                    "OwnerUserId": "13239091",
                    "LastEditorUserId": "13239091",
                    "LastEditDate": "2021-06-07T20:29:21.930",
                    "LastActivityDate": "2021-06-07T20:29:21.930",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "68003255",
                "ParentRepo": "https://github.com/freqtrade/freqtrade/blob/develop/Dockerfile",
                "StackOverflow_Post": {
                    "Id": "68003255",
                    "PostTypeId": "2",
                    "ParentId": "68002640",
                    "CreationDate": "2021-06-16T13:05:59.723",
                    "Score": "0",
                    "Body": "<p>The way to get our Python code running in a container is to pack it as a Docker image and then run a container based on it.\n<a href=\"https://i.stack.imgur.com/91v98.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/91v98.png\" alt=\"enter image description here\" /></a></p>\n<p>To generate a Docker image we need to create a Dockerfile that contains instructions needed to build the image. The Dockerfile is then processed by the Docker builder which generates the Docker image. Then, with a simple docker run command, we create and run a container with the Python service.</p>\n<p>An example of a Dockerfile containing instructions for assembling a Docker image for Python service installing <code>finta</code> is the following</p>\n<pre><code># set base image (host OS)\nFROM python:3.8\n\n# install dependencies\nRUN pip install finta\n\n# command to run on container start\nCMD [ &quot;python&quot;, &quot;-V&quot; ]\n</code></pre>\n<p>For each instruction or command from the Dockerfile, the Docker builder generates an image layer and stacks it upon the previous ones. Therefore, the Docker image resulting from the process is simply a read-only stack of different layers.</p>\n<pre><code>docker build -t myimage .\n</code></pre>\n<p>Then, we can check the image is in the local image store:</p>\n<pre><code>docker images\n</code></pre>\n<p>Please refer to the freqtrade DockerFile <a href=\"https://github.com/freqtrade/freqtrade/blob/develop/Dockerfile\" rel=\"nofollow noreferrer\">https://github.com/freqtrade/freqtrade/blob/develop/Dockerfile</a></p>\n",
                    "OwnerUserId": "2025086",
                    "LastActivityDate": "2021-06-16T13:05:59.723",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "68233266",
                "ParentRepo": "https://github.com/averagephotographer/wiki-solver",
                "StackOverflow_Post": {
                    "Id": "68233266",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "68239980",
                    "CreationDate": "2021-07-03T04:32:46.050",
                    "Score": "0",
                    "ViewCount": "159",
                    "Body": "<p>I'm requesting the viewcount for 50 articles and I'm using a loop to resend the request if the Wiki API returns a 'continue' json object. Is there a way I can speed this up, or a faster way to get the view count for the 50 articles?</p>\n<p><a href=\"https://en.wikipedia.org/w/api.php?action=query&amp;prop=pageviews&amp;format=json&amp;pvipcontinue&amp;titles=Armor%20(Marvel%20Comics%20character)%7CCassandra%20Lang%7CCopperhead%20(Marvel%20Comics)%7CAlternative%20versions%20of%20Venom%7CAmphibion%7CChaste%20(Marvel%20Comics)%7CCenturius%7CAmadeus%20Cho%7CAgents%20of%20S.H.I.E.L.D.%7CClint%20Barton%20(Marvel%20Cinematic%20Universe)%7CCorsair%20(comics)%7CCarlos%20Pacheco%7CAnaconda%20(character)%7CBlade%20(film)%7CAnti-Venom%20(Marvel%20Comics)%7CBlack%20Swan%20(comics)%7CAvengers%20Forever%7CBadoon%7CAlternative%20versions%20of%20Spider-Man%7CCaptain%20Marvel%20(Mar-Vell)%7CChameleon%20(Marvel%20Comics)%7CAttuma%7CAtlantis%20Attacks%7CAlan%20Davis%7CBruce%20Banner%20(Marvel%20Cinematic%20Universe)%7CBig%20Man%20(comics)%7CArmor%20Wars%7CBrute%20(Reed%20Richards)%7CBrent%20Jackson%7CBig%20Hero%206%20(comics)%7CBeast%20(comics)%7CBetsy%20Ross%20(character)%7CAvengers%20Unplugged%7CCivil%20War:%20Young%20Avengers/Runaways%7CAgent%20Carter:%20S.H.I.E.L.D.%2050th%20Anniversary%7CCobalt%20Man%7CBlack%20Fox%20(Raul%20Chalmers)%7CAvengers%20Disassembled%7CBattlestar%20(character)%7CAl%20Milgrom%7CCaptain%20Marvel%20(Marvel%20Comics)%7CAchebe%20(character)%7CBloodaxe%20(character)%7CDaimon%20Hellstrom%7CByrrah%7CCaptain%20America:%20Reborn%7CAgents%20of%20Atlas%7CAir-Walker%7CBrothers%20Grimm%20(comics)%20left.child.title=%27Agents%20of%20S.H.I.E.L.D.%27\" rel=\"nofollow noreferrer\">Here's an example call</a></p>\n<p>Here's my code that loops until the continue object is gone</p>\n<pre><code>while 'continue' in json_object:\n            json_object = _request_json(api) \n</code></pre>\n<p>here's the project repository if it helps:\n<a href=\"https://github.com/averagephotographer/wiki-solver\" rel=\"nofollow noreferrer\">https://github.com/averagephotographer/wiki-solver</a></p>\n",
                    "OwnerUserId": "16369768",
                    "LastEditorUserId": "16369768",
                    "LastEditDate": "2021-07-03T05:19:06.157",
                    "LastActivityDate": "2021-07-03T21:10:09.117",
                    "Title": "Is there a faster way to get Wikipedia API information than using continue?",
                    "Tags": "<python-requests><request><wikipedia-api>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "68360229",
                "ParentRepo": "https://github.com/p0lygun/astounding-arapaimas/tree/feature/api/games/api",
                "StackOverflow_Post": {
                    "Id": "68360229",
                    "PostTypeId": "1",
                    "CreationDate": "2021-07-13T09:55:35.490",
                    "Score": "3",
                    "ViewCount": "205",
                    "Body": "<h3 id=\"description-ocdu\">Description</h3>\n<p>I am writing a FastAPI app for making multiplayer chess games. But unfortunately I am stuck on a circular import problem (or so I am guessing) and I'm not able to move forward. Basically I have a socket manager variable in the <code>api/main.py</code> which needs to be imported in <code>api/endpoints/game.py</code>, but in <code>api/main.py</code> I also include the API routers. So whenever I include the API routers it would call that module, which would then call <code>api/main.py</code> which would again call <code>game.py</code> to include the router, therefore creating a circular imports problem. This is the complete python traceback: <a href=\"https://paste.pythondiscord.com/pitalutuva.py\" rel=\"nofollow noreferrer\">here</a>.</p>\n<h3 id=\"code-nckw\">Code</h3>\n<p>The code can be seen on GitHub, here it the repository link <a href=\"https://github.com/p0lygun/astounding-arapaimas/tree/feature/api/games/api\" rel=\"nofollow noreferrer\">https://github.com/p0lygun/astounding-arapaimas/tree/feature/api/games/api</a>.</p>\n<h3 id=\"my-tries-goja\">My Tries</h3>\n<p>I tried all the &quot;hacks&quot; of injecting the module using <code>sys</code> and <code>os</code> but nope they too caused the same problem. I tried moving the <code>socket_manager</code> into a completely different file too but that would too cause the same problem.</p>\n<p>If any other information is required let me know, posting a question for the first time so not so sure what all is needed. Thanks!</p>\n<h2 id=\"edits-69xo\">Edits</h2>\n<h4 id=\"edit-1-9cvr\">Edit 1</h4>\n<p><code>codemation#0324</code> on discord suggested a better way to access the socket manager like this:</p>\n<p><a href=\"https://i.stack.imgur.com/nW1sd.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/nW1sd.png\" alt=\"enter image description here\" /></a></p>\n<p>Interestingly I get the <a href=\"https://paste.pythondiscord.com/ezujutowav.py\" rel=\"nofollow noreferrer\">same error</a> afterwards too.</p>\n<h4 id=\"edit-2-1cye\">Edit 2</h4>\n<p>The problem is happening along the lines where I add JWT Auth depend into the API Router and then use <code>Depend(get_db)</code> in the endpoint definition function. An alternative would be not <code>Depend</code> the <code>get_db()</code> and just call it normally and pass it on to the CRUD functions for the timing.</p>\n<p>To be clear, when I remove <code>, dependencies=[Depends(auth.JWTBearer())]</code> it works perfectly.</p>\n",
                    "OwnerUserId": "14863850",
                    "LastEditorUserId": "14863850",
                    "LastEditDate": "2021-07-13T12:04:53.347",
                    "LastActivityDate": "2021-07-13T12:04:53.347",
                    "Title": "API Router Depends Not Compatible with Depend()",
                    "Tags": "<python><import><socket.io><fastapi>",
                    "AnswerCount": "0",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "68404064",
                "ParentRepo": "https://github.com/aws/aws-mwaa-local-runner",
                "StackOverflow_Post": {
                    "Id": "68404064",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "68404287",
                    "CreationDate": "2021-07-16T05:55:30.463",
                    "Score": "3",
                    "ViewCount": "1411",
                    "Body": "<p>I want to load data from Google Storage to S3</p>\n<p>To do this I want to use <strong>GoogleCloudStorageToS3Operator</strong>, which requires <strong>gcp_conn_id</strong></p>\n<p>So, I need to set up Google Cloud connection type</p>\n<p>To do this, I added</p>\n<blockquote>\n<p>apache-airflow[google]==2.0.2</p>\n</blockquote>\n<p>to requirements.txt</p>\n<p>but Google Cloud connection type is still not in Dropdown list of connections in MWAA\n<a href=\"https://i.stack.imgur.com/qL7gc.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/qL7gc.png\" alt=\"enter image description here\" /></a></p>\n<p>Same approach works well with mwaa local runner</p>\n<p><a href=\"https://github.com/aws/aws-mwaa-local-runner\" rel=\"nofollow noreferrer\">https://github.com/aws/aws-mwaa-local-runner</a></p>\n<p>I guess it does not work in MWAA because of security reasons discussed here\n<a href=\"https://lists.apache.org/thread.html/r67dca5845c48cec4c0b3c34c3584f7c759a0b010172b94d75b3188a3%40%3Cdev.airflow.apache.org%3E\" rel=\"nofollow noreferrer\">https://lists.apache.org/thread.html/r67dca5845c48cec4c0b3c34c3584f7c759a0b010172b94d75b3188a3%40%3Cdev.airflow.apache.org%3E</a></p>\n<p>But still, is there any workaround to add Google Cloud connection type in MWAA?</p>\n",
                    "OwnerUserId": "16292438",
                    "LastActivityDate": "2021-08-13T09:31:38.847",
                    "Title": "AWS Airflow v2.0.2 doesn't show Google Cloud connection type",
                    "Tags": "<amazon-web-services><google-cloud-storage><airflow><mwaa>",
                    "AnswerCount": "3",
                    "CommentCount": "0",
                    "FavoriteCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "68415525",
                "ParentRepo": "https://github.com/westandskif/convtools",
                "StackOverflow_Post": {
                    "Id": "68415525",
                    "PostTypeId": "2",
                    "ParentId": "3749512",
                    "CreationDate": "2021-07-16T21:42:52.713",
                    "Score": "0",
                    "Body": "<p>You could use <a href=\"https://github.com/westandskif/convtools\" rel=\"nofollow noreferrer\">convtools</a> library which generates ad-hoc code for your exact task and allows for dynamic code generation.</p>\n<pre class=\"lang-py prettyprint-override\"><code>from convtools import conversion as c\n\n# grouping by second elements of tuples;\n# aggregate defines the schema of the expected output elements\nconverter = c.group_by(c.item(1)).aggregate({\n    &quot;type&quot;: c.item(1),\n    &quot;items&quot;: c.ReduceFuncs.Array(c.item(0)),\n}).gen_converter()\n\n# now you have a function which does what you asked,\n# store it somewhere for further reuse\nconverter(input_data)\n</code></pre>\n",
                    "OwnerUserId": "5387738",
                    "LastEditorUserId": "5387738",
                    "LastEditDate": "2021-11-12T10:22:55.007",
                    "LastActivityDate": "2021-11-12T10:22:55.007",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "68457420",
                "ParentRepo": "https://github.com/nschloe/deadlink",
                "StackOverflow_Post": {
                    "Id": "68457420",
                    "PostTypeId": "2",
                    "ParentId": "25135347",
                    "CreationDate": "2021-07-20T15:19:22.920",
                    "Score": "1",
                    "Body": "<p>I recently released <a href=\"https://github.com/nschloe/deadlink\" rel=\"nofollow noreferrer\">deadlink</a>, a command-line tool for finding broken links in files. Install with</p>\n<pre><code>pip install deadlink\n</code></pre>\n<p>and use as</p>\n<pre><code>deadlink check /path/to/file/or/directory\n</code></pre>\n<p>or</p>\n<pre><code>deadlink replace-redirects /path/to/file/or/directory\n</code></pre>\n<p>The latter will replace permanent redirects (301) in the specified files.</p>\n<p>Example output:</p>\n<p><a href=\"https://i.stack.imgur.com/q2XF0.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/q2XF0.png\" alt=\"enter image description here\" /></a></p>\n",
                    "OwnerUserId": "353337",
                    "LastEditorUserId": "353337",
                    "LastEditDate": "2022-01-31T11:02:08.280",
                    "LastActivityDate": "2022-01-31T11:02:08.280",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "68582844",
                "ParentRepo": "https://github.com/lmmx/range-streams/blob/master/src/range_streams/codecs/tar/stream.py",
                "StackOverflow_Post": {
                    "Id": "68582844",
                    "PostTypeId": "2",
                    "ParentId": "54657387",
                    "CreationDate": "2021-07-29T21:13:11.677",
                    "Score": "0",
                    "Body": "<p>Yes, it\u2019s possible for an uncompressed tarball, the <a href=\"https://en.wikipedia.org/wiki/Tar_(computing)#File_format\" rel=\"nofollow noreferrer\">file format</a> has header records about the files you can use to check its contents.</p>\n<p>I'm more of a Python than a Java guy, but take a look at my implementation of tarball range requests <a href=\"https://github.com/lmmx/range-streams/blob/master/src/range_streams/codecs/tar/stream.py\" rel=\"nofollow noreferrer\">here</a> and <a href=\"https://range-streams.readthedocs.io/en/latest/api.html#range_streams.codecs.tar.TarStream\" rel=\"nofollow noreferrer\">docs here</a>.</p>\n<p>In short, you can check the header (the file name always comes first, and is padded to 512 byte blocks with NULL <code>b&quot;\\x00&quot;</code> bytes), get the range corresponding to the file length to determine the variable length, get the remainder of that file length of 512 to determine the end-of-file padding, and then iterate up to 1024 before the end of the file (you can send a HEAD request to get the total bytes, or it's sent back when you execute a range request, AKA partial content request). The 1024-before-the-end part is because there are at least 2 empty blocks of 512 bytes at the end of a tar archive.</p>\n<p>When iterating, it's probably sensible to check if the filename of each new block you expect to find a file header in is actually all NULL bytes, as this indicates you've actually entered one of the end-of-file blocks (the spec seems to say &quot;at least 2 empty blocks&quot; so there may be more). But if you control the tar files being generated maybe you wouldn't need to bother.</p>\n",
                    "OwnerUserId": "2668831",
                    "LastActivityDate": "2021-07-29T21:13:11.677",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "68616624",
                "ParentRepo": "https://github.com/supabase/supabase-py",
                "StackOverflow_Post": {
                    "Id": "68616624",
                    "PostTypeId": "1",
                    "CreationDate": "2021-08-02T05:11:44.750",
                    "Score": "0",
                    "ViewCount": "784",
                    "Body": "<p>I'm attempting to connect to the Supabase API for my database. I've attempted to connect using <a href=\"https://github.com/supabase/supabase-py\" rel=\"nofollow noreferrer\">Python client for Supabase</a> and also using Insomnia. Both are giving me an SSL error of sorts.</p>\n<p>I upgraded my openssl using Homebrew but seem to be still having the same error.</p>\n<p>When I try and connect with the Insomnia client, here is the error I get:</p>\n<p><code>Error: SSL connect error</code></p>\n<p>and</p>\n<pre><code> * Preparing request to https://***.supabase.co/rest/v1/asset\n * Current time is 2021-08-02T05:01:29.605Z\n * Using libcurl/7.73.0 OpenSSL/1.1.1k zlib/1.2.11 brotli/1.0.9 zstd/1.4.9 libidn2/2.1.1 libssh2/1.9.0 nghttp2/1.42.0\n * Using default HTTP version\n * Disable timeout\n * Enable automatic URL encoding\n * Enable SSL validation\n * Enable cookie sending with jar of 0 cookies\n * Hostname in DNS cache was stale, zapped\n *   Trying 54.236.241.56:443...\n * Connected to qsnjdsplxqjlclaopkjc.supabase.co (54.236.241.56) port 443 (#10)\n * ALPN, offering h2\n * ALPN, offering http/1.1\n * successfully set certificate verify locations:\n *  CAfile: /var/folders/p_/9mjzfvts4ln1c9cvh32jpt_r0000gn/T/insomnia_2021.4.1/ca-certs.pem\n *  CApath: none\n * TLSv1.3 (OUT), TLS handshake, Client hello (1):\n * error:1408F10B:SSL routines:ssl3_get_record:wrong version number\n * Closing connection 10\n</code></pre>\n<p>When I try to connect using code, the error I receive is the following:</p>\n<pre><code>Traceback (most recent call last):\n  File &quot;/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/urllib3/connectionpool.py&quot;, line 699, in urlopen\n    httplib_response = self._make_request(\n  File &quot;/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/urllib3/connectionpool.py&quot;, line 382, in _make_request\n    self._validate_conn(conn)\n  File &quot;/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/urllib3/connectionpool.py&quot;, line 1010, in _validate_conn\n    conn.connect()\n  File &quot;/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/urllib3/connection.py&quot;, line 411, in connect\n    self.sock = ssl_wrap_socket(\n  File &quot;/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/urllib3/util/ssl_.py&quot;, line 449, in ssl_wrap_socket\n    ssl_sock = _ssl_wrap_socket_impl(\n  File &quot;/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/urllib3/util/ssl_.py&quot;, line 493, in _ssl_wrap_socket_impl\n    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)\n  File &quot;/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/ssl.py&quot;, line 500, in wrap_socket\n    return self.sslsocket_class._create(\n  File &quot;/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/ssl.py&quot;, line 1040, in _create\n    self.do_handshake()\n  File &quot;/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/ssl.py&quot;, line 1309, in do_handshake\n    self._sslobj.do_handshake()\nssl.SSLError: [SSL: WRONG_VERSION_NUMBER] wrong version number (_ssl.c:1123)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File &quot;/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/requests/adapters.py&quot;, line 439, in send\n    resp = conn.urlopen(\n  File &quot;/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/urllib3/connectionpool.py&quot;, line 755, in urlopen\n    retries = retries.increment(\n  File &quot;/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/urllib3/util/retry.py&quot;, line 574, in increment\n    raise MaxRetryError(_pool, url, error or ResponseError(cause))\nurllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='****.supabase.co', port=443): Max retries exceeded with url: /rest/v1/asset (Caused by SSLError(SSLError(1, '[SSL: WRONG_VERSION_NUMBER] wrong version number (_ssl.c:1123)')))\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File &quot;/Users/mitchellwright/Desktop/scraper.py&quot;, line 23, in &lt;module&gt;\n    data = supabase.table(&quot;asset&quot;).insert(\n  File &quot;/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/supabase_py/lib/query_builder.py&quot;, line 31, in _execute_monkey_patch\n    response = func(f&quot;{url}?{query}&quot;, headers=self.session.headers, **additional_kwargs)\n  File &quot;/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/requests/api.py&quot;, line 119, in post\n    return request('post', url, data=data, json=json, **kwargs)\n  File &quot;/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/requests/api.py&quot;, line 61, in request\n    return session.request(method=method, url=url, **kwargs)\n  File &quot;/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/requests/sessions.py&quot;, line 542, in request\n    resp = self.send(prep, **send_kwargs)\n  File &quot;/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/requests/sessions.py&quot;, line 655, in send\n    r = adapter.send(request, **kwargs)\n  File &quot;/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/requests/adapters.py&quot;, line 514, in send\n    raise SSLError(e, request=request)\nrequests.exceptions.SSLError: HTTPSConnectionPool(host='****.supabase.co', port=443): Max retries exceeded with url: /rest/v1/asset (Caused by SSLError(SSLError(1, '[SSL: WRONG_VERSION_NUMBER] wrong version number (_ssl.c:1123)')))\n</code></pre>\n<p>I'm at a bit of a loss on how to proceed here.</p>\n",
                    "OwnerUserId": "432014",
                    "LastEditorUserId": "432014",
                    "LastEditDate": "2021-08-02T17:00:29.033",
                    "LastActivityDate": "2022-03-11T20:07:33.700",
                    "Title": "Receiving SSL wrong version number error when connecting to API",
                    "Tags": "<python><rest><ssl><insomnia><supabase>",
                    "AnswerCount": "0",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "68705324",
                "ParentRepo": "https://github.com/claws/aioprometheus/blob/d6dec47b05cab04901ffb8d2016d659927e02311/examples/frameworks/aiohttp-example.py",
                "StackOverflow_Post": {
                    "Id": "68705324",
                    "PostTypeId": "2",
                    "ParentId": "68697932",
                    "CreationDate": "2021-08-08T23:02:57.010",
                    "Score": "0",
                    "Body": "<p>There are at least two python modules that does that.</p>\n<p>The first one is <a href=\"https://pypi.org/project/aiohttp-prometheus-monitoring/\" rel=\"nofollow noreferrer\">aiohttp-prometheus</a></p>\n<blockquote>\n<p>This package allows to monitor availability of your aiohttp-application components and exports the metrics for prometheus scraper.</p>\n</blockquote>\n<p>It natively export three metrics (<code>request_latency_seconds</code>, <code>requests_total</code>, <code>requests_in_progress_total</code>) but you can add your own metrics. It is explained with more details by the maintainer of the module in his <a href=\"https://www.cloudbees.com/blog/monitoring-your-asynchronous-python-web-applications-using-prometheus\" rel=\"nofollow noreferrer\">blog post</a>, and the <a href=\"https://github.com/amitsaha/aiohttp-prometheus/tree/master/examples/webapp1\" rel=\"nofollow noreferrer\">example file</a> shows a basic aiohttp app, with the corresponding scrape configuration file.<br />\nNote that it hasn't been updated since december 2018, so it doesn't support the <a href=\"https://prometheus.io/docs/concepts/metric_types/#summary\" rel=\"nofollow noreferrer\">Summary</a> metric type and it might not work on the latest versions of aiohttp or prometheus.</p>\n<p>The second one is <a href=\"https://www.cloudbees.com/blog/monitoring-your-asynchronous-python-web-applications-using-prometheus\" rel=\"nofollow noreferrer\">aioprometheus</a>, it's made for the asyncio library, but you can easily use it for aiohttp.</p>\n<blockquote>\n<p>Examples in the examples/frameworks directory show how aioprometheus can be used within various web application frameworks without needing to create a separate aioprometheus.Service endpoint to handle metrics.</p>\n</blockquote>\n<p><a href=\"https://github.com/claws/aioprometheus/blob/d6dec47b05cab04901ffb8d2016d659927e02311/examples/frameworks/aiohttp-example.py\" rel=\"nofollow noreferrer\">This file</a> shows a basic example of its use with aiohttp.</p>\n",
                    "OwnerUserId": "11774715",
                    "LastActivityDate": "2021-08-08T23:02:57.010",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "68866920",
                "ParentRepo": "https://github.com/elimintz/justpy/blob/master/justpy/templates/main.html",
                "StackOverflow_Post": {
                    "Id": "68866920",
                    "PostTypeId": "1",
                    "CreationDate": "2021-08-20T18:54:57.793",
                    "Score": "1",
                    "ViewCount": "487",
                    "Body": "<p>I have an extremely simple flask app that works perfectly with gunicorn and nginx over https with a domain. This shows me that all other configurations are working (IP, ports, https, etc.), but when I try and use it with the justpy library, which uses uvicorn, there is no interaction. The strange thing is that when I run it over the public ip of the GCP with the open port, it works just fine, so I am assuming it is a problem with my configuration of nginx.</p>\n<p>The configuration and examples are below, along with the documentation I could find on this. This is running on a GCP VM instance, (e2 micro) with Ubuntu 21.04 installed. The public IP has been made static and I am using letsencrypt for HTTPS with the domain.</p>\n<p>This might just be because the justpy library is so new, but I wanted to make sure it was not because of configuring nginx incorrectly.</p>\n<p>So, using the simple flask app:</p>\n<pre><code>from flask import Flask\napp = Flask(__name__)\n\n@app.route('/')\ndef hello_world():\n    return 'Hello World from flaskapp 1!'\n\n</code></pre>\n<p>We get what we wanted when we go to <a href=\"https://test1.domain.com\" rel=\"nofollow noreferrer\">https://test1.domain.com</a> (test1.domain.com being just an example) which is &quot;Hello World from flaskapp 1!&quot; using the command</p>\n<p><code>gunicorn fl1:app -b 0.0.0.0:5000</code></p>\n<p>and using the following nginx config:</p>\n<pre><code>server {                                                                                                                   \n        listen 80; \n        listen 443 ssl http2;\n        server_name test1.domain.com;\n        ssl_certificate /etc/letsencrypt/live/domain.com/fullchain.pem;\n        ssl_certificate_key /etc/letsencrypt/live/domain.com/privkey.pem;\n        ssl_protocols TLSv1.3;\n\n        location / {\n            include proxy_params;\n            proxy_pass http://0.0.0.0:5000;                     \n    }   \n}\n\n</code></pre>\n<p>As well, if we use the code for justpy (which comes directly from their documentation <a href=\"https://justpy.io/tutorial/handling_events/\" rel=\"nofollow noreferrer\">here</a>, and <a href=\"https://justpy.io/tutorial/deployment/\" rel=\"nofollow noreferrer\">here</a>) this also gives us what we want without any errors <em><strong>if I run it over the public IP with the open port</strong></em> and using a slight modification to the gunicorn command above:</p>\n<pre><code>gunicorn -k uvicorn.workers.UvicornWorker fl1:app -b 0.0.0.0:5000\n</code></pre>\n<pre><code>import justpy as jp\napp = jp.app\n\ndef my_click(self, msg):\n    self.text = 'I was clicked'\n    self.set_class('bg-blue-500')\n\ndef my_mouseenter(self, msg):\n    self.text = 'Mouse entered'\n    self.set_class('bg-red-500')\n\ndef my_mouseleave(self, msg):\n    self.text = 'Mouse left'\n    self.set_class('bg-teal-500')\n\n\ndef event_demo():\n    wp = jp.WebPage()\n    d = jp.Div(text='Not clicked yet', a=wp, classes='w-64 text-2xl m-2 p-2 bg-blue-500 text-white',\n             click=my_click, mouseenter=my_mouseenter, mouseleave=my_mouseleave)\n    return wp\n\njp.justpy(\n  event_demo,\n  start_server=False\n  )\n</code></pre>\n<p>This will give us a box that turns red with &quot;Mouse entered&quot; when the mouse is inside the box, green with &quot;Mouse left&quot; when the mouse is not in the box, and blue with &quot;I was clicked&quot; when we click on the box.</p>\n<p>All that works, but, when I start using nginx (with the config above) to use https and the domain, that is when it starts to fail and the app constantly says &quot;<em><strong>Page needs to be reloaded, click OK to reload</strong></em>&quot; and it just keeps on reloading each time you click on OK. I suppose it has to do with the nginx config with uvicorn, but I have yet to figure it out.</p>\n<p>The uvicorn <a href=\"https://www.uvicorn.org/deployment/\" rel=\"nofollow noreferrer\">documentation</a> does not help much, and justpy has something in its <a href=\"https://github.com/elimintz/justpy/blob/master/justpy/templates/main.html\" rel=\"nofollow noreferrer\">main.html</a> file for websockets from line 65, but I don't know how that would affect nginx. Any help would be appreciated.</p>\n",
                    "OwnerUserId": "6597821",
                    "LastEditorUserId": "6597821",
                    "LastEditDate": "2021-08-20T20:48:14.990",
                    "LastActivityDate": "2021-09-04T23:24:44.663",
                    "Title": "How to configure uvicorn in nginx for justpy",
                    "Tags": "<nginx><uvicorn><starlette><justpy>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "68979550",
                "ParentRepo": "https://github.com/michalc/sqlite-s3-query/blob/main/sqlite_s3_query.py",
                "StackOverflow_Post": {
                    "Id": "68979550",
                    "PostTypeId": "2",
                    "ParentId": "68879290",
                    "CreationDate": "2021-08-30T06:05:43.703",
                    "Score": "0",
                    "Body": "<p>There doesn't seem to be anything built in, but you can define a function so most of the code doesn't have to make a class directly</p>\n<pre class=\"lang-py prettyprint-override\"><code>def make_struct(fields):\n    class Struct(Structure):\n        _fields_ = [(field_name, field_type) for (field_name, field_type, _) in fields]\n    return Struct(*tuple(value for (_, _, value) in fields))\n</code></pre>\n<p>with example usage</p>\n<pre class=\"lang-py prettyprint-override\"><code>my_struct = make_struct((\n    ('my_first_field', c_int, 1),\n    ('my_second_field', c_double, 1.0),\n))\n</code></pre>\n<p>(This is done at <a href=\"https://github.com/michalc/sqlite-s3-query/blob/main/sqlite_s3_query.py\" rel=\"nofollow noreferrer\">https://github.com/michalc/sqlite-s3-query/blob/main/sqlite_s3_query.py</a>)</p>\n",
                    "OwnerUserId": "1319998",
                    "LastActivityDate": "2021-08-30T06:05:43.703",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "69021077",
                "ParentRepo": "https://github.com/arseniiarsenii/mastodon-meter",
                "StackOverflow_Post": {
                    "Id": "69021077",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "69028229",
                    "CreationDate": "2021-09-01T22:10:16.143",
                    "Score": "10",
                    "ViewCount": "3787",
                    "Body": "<p>I'm building an async backend for an analytics system using FastAPI. The thing is it has to: a) listen for API calls and be available at all times; b) periodically perform a data-gathering task (parsing data and saving it into the DB).</p>\n<p>I wrote this function to act as a daemon:</p>\n<pre><code>    async def start_metering_daemon(self) -&gt; None:\n        &quot;&quot;&quot;sets a never ending task for metering&quot;&quot;&quot;\n        while True:\n            delay: int = self._get_delay()  # delay in seconds until next execution\n            await asyncio.sleep(delay)\n            await self.gather_meterings()  # perfom data gathering\n</code></pre>\n<p>What I'm trying to achieve is so that when app starts it also adds this daemon function into the main event loop and execute it when it has time. However, I haven't been able to find a suitable solution which is adequate to the scale of the task (adding Celery and similar stuff is an overkill).</p>\n<p>I have tried following ways to achieve this but none of them worked:</p>\n<pre><code>@app.on_event(&quot;startup&quot;)\nasync def startup_event() -&gt; None:\n    &quot;&quot;&quot;tasks to do at server startup&quot;&quot;&quot;\n    await Gatherer().start_metering_daemon()\n</code></pre>\n<p>Result: server can't start up since the thread is blocked</p>\n<pre><code>@app.on_event(&quot;startup&quot;)\nasync def startup_event() -&gt; None:\n    &quot;&quot;&quot;tasks to do at server startup&quot;&quot;&quot;\n    fastapi.BackgroundTasks().add_task(Gatherer().start_metering_daemon)\n</code></pre>\n<p>Result: task is never executed as observed in logs</p>\n<pre><code>@app.on_event(&quot;startup&quot;)\nasync def startup_event() -&gt; None:\n    &quot;&quot;&quot;tasks to do at server startup&quot;&quot;&quot;\n    fastapi.BackgroundTasks().add_task(asyncio.run, Gatherer().start_metering_daemon())\n</code></pre>\n<p>Result: same as previous one</p>\n<pre><code>@app.on_event(&quot;startup&quot;)\nasync def startup_event() -&gt; None:\n    &quot;&quot;&quot;tasks to do at server startup&quot;&quot;&quot;\n    threading.Thread(target=asyncio.run, args=(Gatherer().start_metering_daemon(),)).start()\n</code></pre>\n<p>Result: this one works but a) makes no sence; b) spawns N identical threads for N Uvicorn workers which all write same data N times into the DB.</p>\n<p>I am out of solutions by now. I am pretty sure there must be a solution to my problem since is looks pretty trivial to me but I couldn't find one.</p>\n<p>If you want more context here is the <a href=\"https://github.com/arseniiarsenii/mastodon-meter\" rel=\"noreferrer\">repo</a> of the project I reffer to.</p>\n",
                    "OwnerUserId": "16808577",
                    "LastActivityDate": "2021-09-02T10:28:27.000",
                    "Title": "Start an async background daemon in a Python FastAPI app",
                    "Tags": "<python><async-await><python-asyncio><fastapi>",
                    "AnswerCount": "1",
                    "CommentCount": "2",
                    "FavoriteCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "69152440",
                "ParentRepo": "https://github.com/anmol098/waka-readme-stats",
                "StackOverflow_Post": {
                    "Id": "69152440",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "69565082",
                    "CreationDate": "2021-09-12T14:42:50.413",
                    "Score": "1",
                    "ViewCount": "528",
                    "Body": "<p>So I wanted to add the Wakatime Section in my Github profile README.md but it always drop the same error. Firstly, he doesn't work as I would like to because my flags (into the .yml file) aren't working, here is my .yml file :</p>\n<pre><code>    name: Waka Readme\n\non:\n  workflow_dispatch:\n  schedule:\n    # Runs at 05:00PM UTC = 00:00AM +7\n    - cron: '0 */4 * * *'\n\njobs:\n  update-readme:\n    name: Update this repo's README\n    runs-on: ubuntu-latest\n    steps:\n      - uses: anmol098/waka-readme-stats@master\n        with:\n          WAKATIME_API_KEY: ${{ secrets.WAKATIME_API_KEY }}\n          GH_TOKEN: ${{ secrets.GH_TOKEN }}\n          SHOW_LINES_OF_CODE: &quot;True&quot;\n          SHOW_PROFILE_VIEWS: &quot;False&quot;\n          SHOW_COMMIT: &quot;False&quot;\n          SHOW_EDITORS: &quot;True&quot;\n          SHOW_DAYS_OF_WEEK: &quot;False&quot;\n          SHOW_LANGUAGE: &quot;True&quot;\n          SHOW_OS: &quot;True&quot;\n          SHOW_PROJECTS: &quot;False&quot;\n          SHOW_TIMEZONE: &quot;False&quot;\n          SHOW_LANGUAGE_PER_REPO: &quot;False&quot;\n          SHOW_SHORT_INFO: &quot;False&quot;\n          SHOW_LOC_CHART: &quot;False&quot;\n          LOCALE: en\n</code></pre>\n<p>You can find the gh repo here : <a href=\"https://github.com/anmol098/waka-readme-stats\" rel=\"nofollow noreferrer\">https://github.com/anmol098/waka-readme-stats</a></p>\n<p>Here is the error that I'm having when I run the .yml file :</p>\n<pre><code>Traceback (most recent call last):\nException Occurred Query failed to run by returning code of 401. \n  File &quot;/main.py&quot;, line 497, in &lt;module&gt;\n{\n    user_data = run_query(userInfoQuery)  # Execute the query\n    viewer {\n  File &quot;/main.py&quot;, line 156, in run_query\n      login\n    raise Exception(&quot;Query failed to run by returning code of {}. {}&quot;.format(request.status_code, query))\n      email\nException: Query failed to run by returning code of 401. \n      id\n{\n    }\n    viewer {\n  }\n      login\n\n      email\n      id\n    }\n  }\n</code></pre>\n<p>PS: my Wakatime profile is working, I have no problem with the API Key, you can even find my stats here : <a href=\"https://wakatime.com/api/v1/users/branlito/stats/last_7_days\" rel=\"nofollow noreferrer\">https://wakatime.com/api/v1/users/branlito/stats/last_7_days</a></p>\n",
                    "OwnerUserId": "15870510",
                    "LastActivityDate": "2022-01-12T19:04:04.143",
                    "Title": "Wakatime Stats Tracker doesn't work in my GitHub profile README.md",
                    "Tags": "<github><readme><wakatime>",
                    "AnswerCount": "2",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "69332488",
                "ParentRepo": "https://github.com/jdb78/pytorch-forecasting/issues/665",
                "StackOverflow_Post": {
                    "Id": "69332488",
                    "PostTypeId": "2",
                    "ParentId": "69056300",
                    "CreationDate": "2021-09-26T06:49:33.880",
                    "Score": "0",
                    "Body": "<p>I think I've found the solution, thanks to <a href=\"https://github.com/jdb78/pytorch-forecasting/issues/665\" rel=\"nofollow noreferrer\">this</a> github thread. What you need are the two specific versions of the following libs:</p>\n<pre><code>pip install pandas==1.2.5\npip install torchmetrics==0.5.0\n</code></pre>\n<p>I tried installing <code>pandas==1.2.5</code> in python 3.6 but couldn't do it. It was stuck at <code>pandas==1.1.5</code>. So, I had to use python 3.8. The complete set of relevant packages are:</p>\n<pre><code>pytorch-forecasting==0.9.0\npytorch-lightning==1.4.8\ntorch==1.9.1\ntorchmetrics==0.5.0\npandas==1.2.5\n</code></pre>\n",
                    "OwnerUserId": "4245859",
                    "LastEditorUserId": "4245859",
                    "LastEditDate": "2021-09-26T12:05:14.547",
                    "LastActivityDate": "2021-09-26T12:05:14.547",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "69472246",
                "ParentRepo": "https://github.com/michaelhly/solana-py/blob/a366253a3f043979bc6f61869ee8faad98292dc2/solana/keypair.py#L46",
                "StackOverflow_Post": {
                    "Id": "69472246",
                    "PostTypeId": "2",
                    "ParentId": "69448716",
                    "CreationDate": "2021-10-06T20:20:27.827",
                    "Score": "0",
                    "Body": "<p>There's a couple of things you can try.  First, you can use the <code>Keypair</code> type instead, since <code>Account</code> is deprecated, specifically using <code>from_secret_key</code>: <a href=\"https://github.com/michaelhly/solana-py/blob/a366253a3f043979bc6f61869ee8faad98292dc2/solana/keypair.py#L46\" rel=\"nofollow noreferrer\">https://github.com/michaelhly/solana-py/blob/a366253a3f043979bc6f61869ee8faad98292dc2/solana/keypair.py#L46</a></p>\n<p>If that still doesn't work, the format of the private key is likely incorrect. Phantom generates private keys as base-64 strings, whereas these functions are expecting byte arrays.  You can convert between the two using some of the answers at <a href=\"https://stackoverflow.com/questions/69245982/import-phantom-wallet-private-key-into-solana-cli/69256259#69256259\">Import phantom wallet private key into solana CLI</a></p>\n",
                    "OwnerUserId": "16310679",
                    "LastActivityDate": "2021-10-06T20:20:27.827",
                    "CommentCount": "3",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "69492265",
                "ParentRepo": "https://github.com/iliadmitriev/fastapi-sqlalchemy-pytest/blob/master/requirements.txt",
                "StackOverflow_Post": {
                    "Id": "69492265",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "69492610",
                    "CreationDate": "2021-10-08T07:44:17.847",
                    "Score": "6",
                    "ViewCount": "1184",
                    "Body": "<p>I'm trying to build <code>FastAPI</code> application fully covered with test using <code>python 3.9</code>\nFor this purpose I've chosen stack:\nFastAPI, uvicorn, SQLAlchemy, asyncpg, pytest (+ async, cov plugins), coverage and httpx AsyncClient</p>\n<p>Here is my minimal <a href=\"https://github.com/iliadmitriev/fastapi-sqlalchemy-pytest/blob/master/requirements.txt\" rel=\"noreferrer\">requirements.txt</a></p>\n<p>All tests run smoothly and I get the expected results.\nBut I've faced the problem, coverage doesn't properly collected. It breaks after a first <code>await</code> keyword, when coroutine returns control back to the event loop</p>\n<p>Here is a minimal set on how to reproduce this behavior (<a href=\"https://github.com/iliadmitriev/fastapi-sqlalchemy-pytest\" rel=\"noreferrer\">it's also available on a GitHub</a>).</p>\n<p>Appliaction code <code>main.py</code>:</p>\n<pre class=\"lang-py prettyprint-override\"><code>import sqlalchemy as sa\nfrom fastapi import FastAPI\nfrom sqlalchemy.ext.asyncio import AsyncSession, create_async_engine\nfrom starlette.requests import Request\n\napp = FastAPI()\nDATABASE_URL = 'sqlite+aiosqlite://?cache=shared'\n\n\n@app.on_event('startup')\nasync def startup_event():\n    engine = create_async_engine(DATABASE_URL, future=True)\n    app.state.session = AsyncSession(engine, expire_on_commit=False)\n    app.state.engine = engine\n\n\n@app.on_event('shutdown')\nasync def shutdown_event():\n    await app.state.session.close()\n\n\n@app.get('/', name=&quot;home&quot;)\nasync def get_home(request: Request):\n    res = await request.app.state.session.execute(sa.text('SELECT 1'))\n    # after this line coverage breaks\n    row = res.first()\n    assert str(row[0]) == '1'\n    return {&quot;message&quot;: &quot;OK&quot;}\n</code></pre>\n<p>test setup <code>conftest.py</code> looks like this:</p>\n<pre class=\"lang-py prettyprint-override\"><code>import asyncio\n\nimport pytest\nfrom asgi_lifespan import LifespanManager\nfrom httpx import AsyncClient\n\n\n@pytest.fixture(scope='session')\nasync def get_app():\n    from main import app\n    async with LifespanManager(app):\n        yield app\n\n\n@pytest.fixture(scope='session')\nasync def get_client(get_app):\n    async with AsyncClient(app=get_app, base_url=&quot;http://testserver&quot;) as client:\n        yield client\n\n\n@pytest.fixture(scope=&quot;session&quot;)\ndef event_loop():\n    loop = asyncio.new_event_loop()\n    yield loop\n    loop.close()\n</code></pre>\n<p>test is simple as it is (just check status code is 200) <code>test_main.py</code>:</p>\n<pre class=\"lang-py prettyprint-override\"><code>import pytest\nfrom starlette import status\n\n\n@pytest.mark.asyncio\nasync def test_view_health_check_200_ok(get_client):\n    res = await get_client.get('/')\n    assert res.status_code == status.HTTP_200_OK\n</code></pre>\n<pre class=\"lang-sh prettyprint-override\"><code>pytest -vv --cov=. --cov-report term-missing --cov-report html\n</code></pre>\n<p>As a result coverage I get:</p>\n<pre><code>Name           Stmts   Miss  Cover   Missing\n--------------------------------------------\nconftest.py       18      0   100%\nmain.py           20      3    85%   26-28\ntest_main.py       6      0   100%\n--------------------------------------------\nTOTAL             44      3    93%\n</code></pre>\n<p><a href=\"https://i.stack.imgur.com/KvKRh.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/KvKRh.png\" alt=\"enter image description here\" /></a></p>\n<ol>\n<li>Example code above uses <code>aiosqlite</code> instead of <code>asyncpg</code> but coverage failure also reproduces persistently</li>\n<li>I've concluded this problem is with <code>SQLAlchemy</code>, because this example with <code>asyncpg</code> without using the <code>SQLAlchemy</code> works like charm</li>\n</ol>\n",
                    "OwnerUserId": "13369876",
                    "LastActivityDate": "2021-10-08T08:15:29.210",
                    "Title": "FastAPI, SQLAlchemy, pytest, unable to get 100% coverage, it doesn't properly collected",
                    "Tags": "<python><sqlalchemy><python-asyncio><fastapi><pytest-asyncio>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "69573357",
                "ParentRepo": "https://github.com/supabase-community/supabase-py",
                "StackOverflow_Post": {
                    "Id": "69573357",
                    "PostTypeId": "2",
                    "ParentId": "69154258",
                    "CreationDate": "2021-10-14T15:23:53.183",
                    "Score": "2",
                    "Body": "<p>There is a community-supported Python library for Supabase that has support for Supabase Storage, which you can try:</p>\n<p><a href=\"https://github.com/supabase-community/supabase-py\" rel=\"nofollow noreferrer\">https://github.com/supabase-community/supabase-py</a></p>\n<p>see the storage code here:</p>\n<p><a href=\"https://github.com/supabase-community/supabase-py/tree/develop/supabase/lib/storage\" rel=\"nofollow noreferrer\">https://github.com/supabase-community/supabase-py/tree/develop/supabase/lib/storage</a></p>\n",
                    "OwnerUserId": "17151109",
                    "LastEditorUserId": "729785",
                    "LastEditDate": "2021-10-15T08:20:48.873",
                    "LastActivityDate": "2021-10-15T08:20:48.873",
                    "CommentCount": "3",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "69576463",
                "ParentRepo": "https://github.com/marcosschroh/dataclasses-avroschema",
                "StackOverflow_Post": {
                    "Id": "69576463",
                    "PostTypeId": "1",
                    "CreationDate": "2021-10-14T19:39:11.650",
                    "Score": "0",
                    "ViewCount": "433",
                    "Body": "<p>I searched quite a lot before asking this question and looks like I am stuck and therefore asking question here. I know such type of errors are encountered when Schema and object are not a match, maybe some datatype is missing or have other type of value for a field.</p>\n<p>However, I believe my case is different.\nMy application is simple, which only serialize and deserialize an object into avro</p>\n<p>My DataClass:</p>\n<pre class=\"lang-py prettyprint-override\"><code>\nfrom time import time\nfrom faker import Faker\nfrom dataclasses import dataclass, field\n\nfrom dataclasses_avroschema import AvroModel\n\nFaker.seed(0)\nfake = Faker()\n\n\n@dataclass\nclass Head(AvroModel):\n    msgId: str = field()\n    msgCode: str = field()\n\n    @staticmethod\n    def fakeMe():\n        return Head(fake.md5(),\n                fake.pystr(min_chars=5, max_chars=5)\n            )\n\n\n@dataclass\nclass Message(AvroModel):\n    head: Head = field()\n    status: bool = field()\n\n    class Meta:\n        namespace = &quot;me.com.Message.v1&quot;\n\n    def fakeMe(self):\n        self.head = Head.fakeMe()\n        self.bool = fake.pybool()\n\n\n</code></pre>\n<p>Now the script that runs the serialization:</p>\n<pre class=\"lang-py prettyprint-override\"><code>import json, io as mainio\nfrom dto.temp_schema import Message\nfrom avro import schema, datafile, io as avroio\n\nobj = Message(None, True)\nobj.fakeMe()\n\nschema_obj = schema.parse(json.dumps(Message.avro_schema_to_python()))\n\nbuf = mainio.BytesIO()\nwriter = datafile.DataFileWriter(buf, avroio.DatumWriter(), schema_obj)\nwriter.append(obj)\nwriter.flush()\nbuf.seek(0)\ndata = buf.read()\n\nprint(&quot;serialized avro: &quot;, data)\n\n</code></pre>\n<p>When I run this I get following error:</p>\n<pre class=\"lang-sh prettyprint-override\"><code>\nTraceback (most recent call last):\n  File &quot;/Users/office/Documents/projects/msg-bench/scrib.py&quot;, line 28, in &lt;module&gt;\n    writer.append(obj)\n  File &quot;/Users/office/opt/anaconda3/envs/benchenv/lib/python3.9/site-packages/avro/datafile.py&quot;, line 329, in append\n    self.datum_writer.write(datum, self.buffer_encoder)\n  File &quot;/Users/office/opt/anaconda3/envs/benchenv/lib/python3.9/site-packages/avro/io.py&quot;, line 771, in write\n    raise AvroTypeException(self.writer_schema, datum)\n\n\navro.io.AvroTypeException: The datum Message(head=Head(msgId='f112d652ecf13dacd9c78c11e1e7f987', msgCode='cYzVR'), status=True) is not an example of the schema {\n  &quot;type&quot;: &quot;record&quot;,\n  &quot;name&quot;: &quot;Message&quot;,\n  &quot;namespace&quot;: &quot;me.com.Message.v1&quot;,\n  &quot;fields&quot;: [\n    {\n      &quot;type&quot;: {\n        &quot;type&quot;: &quot;record&quot;,\n        &quot;name&quot;: &quot;Head&quot;,\n        &quot;namespace&quot;: &quot;me.com.Message.v1&quot;,\n        &quot;fields&quot;: [\n          {\n            &quot;type&quot;: &quot;string&quot;,\n            &quot;name&quot;: &quot;msgId&quot;\n          },\n          {\n            &quot;type&quot;: &quot;string&quot;,\n            &quot;name&quot;: &quot;msgCode&quot;\n          }\n        ],\n        &quot;doc&quot;: &quot;Head(msgId: str, msgCode: str)&quot;\n      },\n      &quot;name&quot;: &quot;head&quot;\n    },\n    {\n      &quot;type&quot;: &quot;boolean&quot;,\n      &quot;name&quot;: &quot;status&quot;\n    }\n  ],\n  &quot;doc&quot;: &quot;Message(head: dto.temp_schema.Head, status: bool)&quot;\n}\n\n\n</code></pre>\n<p>Please note I am generating the schema using Dataclass Object with help of a python library:\n<a href=\"https://github.com/marcosschroh/dataclasses-avroschema\" rel=\"nofollow noreferrer\">dataclasses-avroschema</a></p>\n<p>And still after using the same schema I am not able to serialize data to Avro.</p>\n<p>Currently I am not sure where I am going wrong and I am new to avro. Why this won't compile?</p>\n<p>System and Library stats:</p>\n<pre class=\"lang-sh prettyprint-override\"><code>\nPython==3.9.7\navro==1.10.2\navro-python3==1.10.2\ndataclasses-avroschema==0.25.1\nFaker==9.3.1\nfastavro==1.4.5\n\n\n</code></pre>\n",
                    "OwnerUserId": "681790",
                    "LastActivityDate": "2021-10-19T02:57:06.583",
                    "Title": "Python Avro avro.io.AvroTypeException The datum is not an example of schema",
                    "Tags": "<python><python-3.x><serialization><avro>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "69580503",
                "ParentRepo": "https://github.com/Programmer-RD-AI/Stackoverflow-Questions/tree/main/Is%20there%20a%20way%20to%20do%20string%20removing%20in%20html%20tags%3F",
                "StackOverflow_Post": {
                    "Id": "69580503",
                    "PostTypeId": "2",
                    "ParentId": "69580380",
                    "CreationDate": "2021-10-15T06:00:27.447",
                    "Score": "0",
                    "Body": "<p>If you want to show without the '', you will need to show this as an element of the list.</p>\n<pre><code>  a = ['1','2']\n  So you will need to do like\n  &lt;h1&gt;\n  {{a[0]}}\n  &lt;/h1&gt;\n</code></pre>\n<p>Or you can do something like below. It is not the best way but this does work to remove the ''. From the list, the code is:</p>\n<p><a href=\"https://github.com/Programmer-RD-AI/Stackoverflow-Questions/tree/main/Is%20there%20a%20way%20to%20do%20string%20removing%20in%20html%20tags%3F\" rel=\"nofollow noreferrer\">https://github.com/Programmer-RD-AI/Stackoverflow-Questions/tree/main/Is%20there%20a%20way%20to%20do%20string%20removing%20in%20html%20tags%3F</a></p>\n<p>Check the above link. You can get the code from there.</p>\n",
                    "OwnerUserId": "13542203",
                    "LastEditorUserId": "1839439",
                    "LastEditDate": "2021-10-15T09:49:27.770",
                    "LastActivityDate": "2021-10-15T09:49:27.770",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "69808678",
                "ParentRepo": "https://github.com/mindee/doctr",
                "StackOverflow_Post": {
                    "Id": "69808678",
                    "PostTypeId": "1",
                    "CreationDate": "2021-11-02T10:15:44.980",
                    "Score": "-1",
                    "ViewCount": "516",
                    "Body": "<p>I am using this repo to <a href=\"https://github.com/mindee/doctr\" rel=\"nofollow noreferrer\">https://github.com/mindee/doctr</a> for OCR\nI get the inference on the following image.</p>\n<p><a href=\"https://i.stack.imgur.com/5RV0r.jpg\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/5RV0r.jpg\" alt=\"Input Image\" /></a></p>\n<p>The following predicted image is shown below\n<a href=\"https://i.stack.imgur.com/yz7zG.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/yz7zG.png\" alt=\"Predicted image \" /></a></p>\n<pre><code>import json\n\nfrom doctr.io import DocumentFile\n\nfrom doctr.models import ocr_predictor\n\n\n\nmodel = ocr_predictor(pretrained=True)\n\n# PDF\n\ndoc = DocumentFile.from_images(&quot;/content/passbook_82_0.jpeg&quot;)\n\n# Analyze\n\nresult = model(doc)\n\n# Export results in json\n\nwith open(&quot;/content/preds.json&quot;, &quot;w&quot;) as f:\n\n    json.dump(result.export(), f)\n</code></pre>\n<p>The following JSON file saved the coordinates and confidence value. Each word has a geometry that gives [[xmin, ymin], [xmax, ymax]] in relative coordinates format.</p>\n<pre><code>{&quot;pages&quot;: [{&quot;page_idx&quot;: 0, &quot;dimensions&quot;: [294, 632], &quot;orientation&quot;: {&quot;value&quot;: null, &quot;confidence&quot;: null}, &quot;language&quot;: {&quot;value&quot;: null, &quot;confidence&quot;: null}, &quot;blocks&quot;: [{&quot;geometry&quot;: [[0.0341796875, 0.169921875], [0.9775390625, 0.8896484375]], &quot;lines&quot;: [{&quot;geometry&quot;: [[0.0341796875, 0.169921875], [0.9775390625, 0.8896484375]], &quot;words&quot;: [{&quot;value&quot;: &quot;anrdla&quot;, &quot;confidence&quot;: 0.2445085644721985, &quot;geometry&quot;: [[0.11328125, 0.1708984375], [0.1923828125, 0.212890625]]}, {&quot;value&quot;: &quot;veedas&quot;, &quot;confidence&quot;: 0.16714346408843994, &quot;geometry&quot;: [[0.1845703125, 0.169921875], [0.2744140625, 0.2158203125]]}, {&quot;value&quot;: &quot;State&quot;, &quot;confidence&quot;: 0.9990315437316895, &quot;geometry&quot;: [[0.642578125, 0.1748046875], [0.6982421875, 0.2236328125]]}, {&quot;value&quot;: &quot;Bank&quot;, &quot;confidence&quot;: 0.999847412109375, &quot;geometry&quot;: [[0.6982421875, 0.1767578125], [0.7529296875, 0.2236328125]]}, {&quot;value&quot;: &quot;of&quot;, &quot;confidence&quot;: 0.9996934533119202, &quot;geometry&quot;: [[0.7548828125, 0.1796875], [0.783203125, 0.22265625]]}, {&quot;value&quot;: &quot;India&quot;, &quot;confidence&quot;: 0.9772151708602905, &quot;geometry&quot;: [[0.78125, 0.177734375], [0.8388671875, 0.2236328125]]}, {&quot;value&quot;: &quot;REGULAR&quot;, &quot;confidence&quot;: 0.8577464818954468, &quot;geometry&quot;: [[0.0380859375, 0.2744140625], [0.1318359375, 0.310546875]]}, {&quot;value&quot;: &quot;SAVINGS&quot;, &quot;confidence&quot;: 0.994958758354187, &quot;geometry&quot;: [[0.140625, 0.27734375], [0.2314453125, 0.310546875]]}, {&quot;value&quot;: &quot;BANK&quot;, &quot;confidence&quot;: 0.9993945956230164, &quot;geometry&quot;: [[0.240234375, 0.27734375], [0.296875, 0.3134765625]]}, {&quot;value&quot;: &quot;ACCOUNT&quot;, &quot;confidence&quot;: 0.9985705018043518, &quot;geometry&quot;: [[0.3056640625, 0.279296875], [0.39453125, 0.3125]]}, {&quot;value&quot;: &quot;DARANGAMELA&quot;, &quot;confidence&quot;: 0.4595634639263153, &quot;geometry&quot;: [[0.73046875, 0.283203125], [0.8720703125, 0.314453125]]}, {&quot;value&quot;: &quot;No&quot;, &quot;confidence&quot;: 0.9307771921157837, &quot;geometry&quot;: [[0.0869140625, 0.322265625], [0.1201171875, 0.3564453125]]}, {&quot;value&quot;: &quot;CIF&quot;, &quot;confidence&quot;: 0.9934298992156982, &quot;geometry&quot;: [[0.03515625, 0.3212890625], [0.083984375, 0.3583984375]]}, {&quot;value&quot;: &quot;88537466750&quot;, &quot;confidence&quot;: 0.9332917332649231, &quot;geometry&quot;: [[0.3037109375, 0.3232421875], [0.4443359375, 0.361328125]]}, {&quot;value&quot;: &quot;DARANGAMELA&quot;, &quot;confidence&quot;: 0.5046369433403015, &quot;geometry&quot;: [[0.7294921875, 0.328125], [0.87109375, 0.359375]]}, {&quot;value&quot;: &quot;-&quot;, &quot;confidence&quot;: 0.9411769509315491, &quot;geometry&quot;: [[0.1826171875, 0.361328125], [0.1923828125, 0.3740234375]]}, {&quot;value&quot;: &quot;Account&quot;, &quot;confidence&quot;: 0.9907050728797913, &quot;geometry&quot;: [[0.0390625, 0.3564453125], [0.130859375, 0.3896484375]]}, {&quot;value&quot;: &quot;No&quot;, &quot;confidence&quot;: 0.9819487929344177, &quot;geometry&quot;: [[0.138671875, 0.3544921875], [0.1796875, 0.390625]]}, {&quot;value&quot;: &quot;20306950151&quot;, &quot;confidence&quot;: 0.23563283681869507, &quot;geometry&quot;: [[0.3076171875, 0.35546875], [0.4404296875, 0.3876953125]]}, {&quot;value&quot;: &quot;Customer&quot;, &quot;confidence&quot;: 0.9558802843093872, &quot;geometry&quot;: [[0.0380859375, 0.38671875], [0.1435546875, 0.4189453125]]}, {&quot;value&quot;: &quot;Name:&quot;, &quot;confidence&quot;: 0.9982724785804749, &quot;geometry&quot;: [[0.15234375, 0.3876953125], [0.2177734375, 0.421875]]}, {&quot;value&quot;: &quot;RASHO&quot;, &quot;confidence&quot;: 0.6698806285858154, &quot;geometry&quot;: [[0.2783203125, 0.388671875], [0.3466796875, 0.4228515625]]}, {&quot;value&quot;: &quot;Ms.&quot;, &quot;confidence&quot;: 0.9627761840820312, &quot;geometry&quot;: [[0.2265625, 0.388671875], [0.2685546875, 0.423828125]]}, {&quot;value&quot;: &quot;MANDAL&quot;, &quot;confidence&quot;: 0.998543381690979, &quot;geometry&quot;: [[0.353515625, 0.3916015625], [0.4326171875, 0.4248046875]]}, {&quot;value&quot;: &quot;S/D/W/H/O:BISWAMITRA&quot;, &quot;confidence&quot;: 0.8553118705749512, &quot;geometry&quot;: [[0.04296875, 0.4755859375], [0.296875, 0.5126953125]]}, {&quot;value&quot;: &quot;MANDAL&quot;, &quot;confidence&quot;: 0.9796141386032104, &quot;geometry&quot;: [[0.3056640625, 0.4794921875], [0.3828125, 0.51171875]]}, {&quot;value&quot;: &quot;Address:VILL-&quot;, &quot;confidence&quot;: 0.7488418221473694, &quot;geometry&quot;: [[0.041015625, 0.517578125], [0.2041015625, 0.5517578125]]}, {&quot;value&quot;: &quot;-&quot;, &quot;confidence&quot;: 0.9209287166595459, &quot;geometry&quot;: [[0.21484375, 0.5244140625], [0.236328125, 0.5498046875]]}, {&quot;value&quot;: &quot;CHUCHUNGJULI&quot;, &quot;confidence&quot;: 0.5298648476600647, &quot;geometry&quot;: [[0.2841796875, 0.5244140625], [0.4267578125, 0.552734375]]}, {&quot;value&quot;: &quot;NO&quot;, &quot;confidence&quot;: 0.9970822334289551, &quot;geometry&quot;: [[0.2392578125, 0.51953125], [0.2724609375, 0.5546875]]}, {&quot;value&quot;: &quot;Phone:2:284238&quot;, &quot;confidence&quot;: 0.8328949809074402, &quot;geometry&quot;: [[0.7275390625, 0.5283203125], [0.8818359375, 0.5634765625]]}, {&quot;value&quot;: &quot;SIDDHINATHPUR&quot;, &quot;confidence&quot;: 0.5255517959594727, &quot;geometry&quot;: [[0.208984375, 0.5703125], [0.3681640625, 0.5986328125]]}, {&quot;value&quot;: &quot;P.0-&quot;, &quot;confidence&quot;: 0.7063982486724854, &quot;geometry&quot;: [[0.138671875, 0.5654296875], [0.19921875, 0.6044921875]]}, {&quot;value&quot;: &quot;TAMULPUR&quot;, &quot;confidence&quot;: 0.992978572845459, &quot;geometry&quot;: [[0.44140625, 0.5703125], [0.54296875, 0.6025390625]]}, {&quot;value&quot;: &quot;P.S-&quot;, &quot;confidence&quot;: 0.9322847127914429, &quot;geometry&quot;: [[0.3779296875, 0.568359375], [0.4345703125, 0.6044921875]]}, {&quot;value&quot;: &quot;Email:sbi.091470sb&quot;, &quot;confidence&quot;: 0.41425037384033203, &quot;geometry&quot;: [[0.7275390625, 0.5732421875], [0.9580078125, 0.611328125]]}, {&quot;value&quot;: &quot;DIST-&quot;, &quot;confidence&quot;: 0.9592916369438171, &quot;geometry&quot;: [[0.138671875, 0.61328125], [0.2109375, 0.650390625]]}, {&quot;value&quot;: &quot;BAKSA&quot;, &quot;confidence&quot;: 0.9974198341369629, &quot;geometry&quot;: [[0.2158203125, 0.61328125], [0.28515625, 0.650390625]]}, {&quot;value&quot;: &quot;ASSAM&quot;, &quot;confidence&quot;: 0.9992387890815735, &quot;geometry&quot;: [[0.2900390625, 0.61328125], [0.3603515625, 0.650390625]]}, {&quot;value&quot;: &quot;781360&quot;, &quot;confidence&quot;: 0.9988314509391785, &quot;geometry&quot;: [[0.3671875, 0.6123046875], [0.4453125, 0.6494140625]]}, {&quot;value&quot;: &quot;Branch&quot;, &quot;confidence&quot;: 0.9992311596870422, &quot;geometry&quot;: [[0.7255859375, 0.6201171875], [0.806640625, 0.6572265625]]}, {&quot;value&quot;: &quot;Code:91471&quot;, &quot;confidence&quot;: 0.6900002956390381, &quot;geometry&quot;: [[0.814453125, 0.6220703125], [0.939453125, 0.6611328125]]}, {&quot;value&quot;: &quot;Phone:&quot;, &quot;confidence&quot;: 0.9992220997810364, &quot;geometry&quot;: [[0.0390625, 0.65625], [0.1171875, 0.6943359375]]}, {&quot;value&quot;: &quot;Date&quot;, &quot;confidence&quot;: 0.9955922961235046, &quot;geometry&quot;: [[0.7236328125, 0.6630859375], [0.7822265625, 0.7021484375]]}, {&quot;value&quot;: &quot;of&quot;, &quot;confidence&quot;: 0.9997377991676331, &quot;geometry&quot;: [[0.787109375, 0.6630859375], [0.8212890625, 0.703125]]}, {&quot;value&quot;: &quot;Issue:30/06&quot;, &quot;confidence&quot;: 0.8237747550010681, &quot;geometry&quot;: [[0.8310546875, 0.66796875], [0.9716796875, 0.70703125]]}, {&quot;value&quot;: &quot;Email:&quot;, &quot;confidence&quot;: 0.9961839914321899, &quot;geometry&quot;: [[0.0380859375, 0.701171875], [0.115234375, 0.7392578125]]}, {&quot;value&quot;: &quot;40/06/2020&quot;, &quot;confidence&quot;: 0.2974379360675812, &quot;geometry&quot;: [[0.70703125, 0.6982421875], [0.8583984375, 0.7548828125]]}, {&quot;value&quot;: &quot;5529182&quot;, &quot;confidence&quot;: 0.9492482542991638, &quot;geometry&quot;: [[0.8798828125, 0.712890625], [0.9775390625, 0.75390625]]}, {&quot;value&quot;: &quot;D.0.B.&quot;, &quot;confidence&quot;: 0.8802379369735718, &quot;geometry&quot;: [[0.0380859375, 0.75], [0.1171875, 0.787109375]]}, {&quot;value&quot;: &quot;Minor):&quot;, &quot;confidence&quot;: 0.9770660996437073, &quot;geometry&quot;: [[0.177734375, 0.7451171875], [0.2705078125, 0.78515625]]}, {&quot;value&quot;: &quot;(If&quot;, &quot;confidence&quot;: 0.4771254062652588, &quot;geometry&quot;: [[0.1279296875, 0.7431640625], [0.173828125, 0.7880859375]]}, {&quot;value&quot;: &quot;IFSC:SBINOOO009147&quot;, &quot;confidence&quot;: 0.5092097520828247, &quot;geometry&quot;: [[0.7314453125, 0.7568359375], [0.93359375, 0.7919921875]]}, {&quot;value&quot;: &quot;MOP.:&quot;, &quot;confidence&quot;: 0.9868963360786438, &quot;geometry&quot;: [[0.0341796875, 0.7919921875], [0.103515625, 0.830078125]]}, {&quot;value&quot;: &quot;RIMLON1781002512&quot;, &quot;confidence&quot;: 0.2585943341255188, &quot;geometry&quot;: [[0.705078125, 0.798828125], [0.9072265625, 0.83984375]]}, {&quot;value&quot;: &quot;No.:0000000203836166&quot;, &quot;confidence&quot;: 0.8759520649909973, &quot;geometry&quot;: [[0.1669921875, 0.8408203125], [0.4189453125, 0.87890625]]}, {&quot;value&quot;: &quot;Nom.&quot;, &quot;confidence&quot;: 0.9955904483795166, &quot;geometry&quot;: [[0.0361328125, 0.84765625], [0.091796875, 0.8837890625]]}, {&quot;value&quot;: &quot;Reg.&quot;, &quot;confidence&quot;: 0.9835382699966431, &quot;geometry&quot;: [[0.0986328125, 0.8447265625], [0.1572265625, 0.8896484375]]}, {&quot;value&quot;: &quot;BranchoMana&quot;, &quot;confidence&quot;: 0.3897829055786133, &quot;geometry&quot;: [[0.6943359375, 0.8486328125], [0.7919921875, 0.8857421875]]}, {&quot;value&quot;: &quot;DATION&quot;, &quot;confidence&quot;: 0.5874566435813904, &quot;geometry&quot;: [[0.796875, 0.8515625], [0.8818359375, 0.888671875]]}]}], &quot;artefacts&quot;: []}]}]}\n</code></pre>\n<p>I want to draw a bounding box on each line and save the crop line image in the folder using OpenCV. How can I do that?\nas shown below.</p>\n<p><a href=\"https://i.stack.imgur.com/gO5Rf.jpg\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/gO5Rf.jpg\" alt=\"Image I want\" /></a></p>\n",
                    "OwnerUserId": "16990847",
                    "LastActivityDate": "2021-11-02T10:35:59.407",
                    "Title": "How to draw a single bounding box on each line ,crop the bounding box and save image in folder opencv python",
                    "Tags": "<python><json><opencv><image-processing><ocr>",
                    "AnswerCount": "1",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "69829252",
                "ParentRepo": "https://github.com/Intility/fastapi-azure-auth",
                "StackOverflow_Post": {
                    "Id": "69829252",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "69840207",
                    "CreationDate": "2021-11-03T17:29:11.583",
                    "Score": "1",
                    "ViewCount": "1586",
                    "Body": "<p>I'm creating an API gateway using <code>fastAPI</code> for some microservices, which in I authenticate user via Azure AD via <a href=\"https://github.com/Intility/fastapi-azure-auth\" rel=\"nofollow noreferrer\">fastapi-azure-auth</a>.\nSo I'm trying to take out the user info from the <code>request</code> object (<code>request.state.user</code>) and inject my own token in it to later pass to other microservices.</p>\n<p>I tried using <a href=\"https://fastapi.tiangolo.com/tutorial/middleware/\" rel=\"nofollow noreferrer\">app.middleware</a>,</p>\n<pre><code>@app.middleware(&quot;http&quot;)\nasync def add_process_time_header(request: Request, call_next):\n    new_token = generate_token(request.state.user)\n    request[&quot;new_token&quot;] = new_token\n    response = await call_next(request)\n    return response\n</code></pre>\n<p>but I'm getting following error at the initialization of the project:</p>\n<blockquote>\n<p>AttributeError: 'State' object has no attribute 'user'</p>\n</blockquote>\n<p>Also I tried creating a decorator:</p>\n<pre><code>from functools import wraps\n\ndef token_injector(function):\n    @wraps(function)\n    def wrap_function(*args, **kwargs):\n        user: User = kwargs['request'].state.user\n        new_token = generate_token(user)\n        kwargs[&quot;new_token&quot;] = new_token # or kwargs['request'][&quot;new_token&quot;] = new_token\n        return function(*args, **kwargs)\n    return wrap_function\n</code></pre>\n<p>and for this approach, I'm getting these errors:</p>\n<blockquote>\n<p>ValueError: [TypeError(&quot;'coroutine' object is not iterable&quot;),\nTypeError('vars() argument must have <strong>dict</strong> attribute')]</p>\n</blockquote>\n<p>and</p>\n<blockquote>\n<p>TypeError: 'Request' object does not support item assignment</p>\n</blockquote>\n<p>So does anyone have a solution for this?</p>\n<p><strong>UPDATE</strong></p>\n<p>Seems like it can't be done in middleware, cause the user info is added after it</p>\n",
                    "OwnerUserId": "2263683",
                    "LastEditorUserId": "2263683",
                    "LastEditDate": "2021-11-04T09:27:01.147",
                    "LastActivityDate": "2021-11-04T14:57:21.960",
                    "Title": "Inject additional parameter in request using FastAPI",
                    "Tags": "<python><request><fastapi><starlette>",
                    "AnswerCount": "2",
                    "CommentCount": "8",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "69906383",
                "ParentRepo": "https://github.com/ramnes/notion-sdk-py",
                "StackOverflow_Post": {
                    "Id": "69906383",
                    "PostTypeId": "2",
                    "ParentId": "66941759",
                    "CreationDate": "2021-11-09T23:42:21.583",
                    "Score": "0",
                    "Body": "<p>For fetching the data you can use <code>notion-client</code>. The great thing about it is that it supports both sync and async interfaces. What it lacks, though, is an easy way to navigate the data's structure (which is quite complicated in Notion)</p>\n<p>For that you can use <code>basic-notion</code>. It allows you to use model classes to easily access all the properties and attributes of your Notion objects - kind of like you would with an ORM.</p>\n<p>In your case the code might look something like this:</p>\n<pre><code>from notion_client import Client\n\nfrom basic_notion.query import Query\nfrom basic_notion.page import NotionPage, NotionPageList\nfrom basic_notion.field import SelectField, TitleField, NumberField\n\n# First define models\n\nclass MyRow(NotionPage):\n    name = TitleField(property_name='Name')\n    subscription = SelectField(property_name='Subscription')\n    some_number = NumberField(property_name='Some Number')\n    # ... your other fields go here\n    # See your database's schema and the available field classes\n    # in basic_notion.field to define this correctly.\n\nclass MyData(NotionPageList[MyRow]):\n    ITEM_CLS = MyRow\n\n# You need to create an integration and get an API token from Notion:\nNOTION_TOKEN = '&lt;your-notion-api-token&gt;'\nDATABASE_ID = '&lt;your-database-ID&gt;'\n\n# Now you can fetch the data\n\ndef get_data(database_id: str) -&gt; MyData:\n    client = Client(auth=NOTION_TOKEN)\n    data = client.databases.query(\n        **Query(database_id=database_id).filter(\n            # Some filter here\n            MyRow.name.filter.starts_with('John')\n        ).sorts(\n            # You can sort it here\n            MyRow.name.sort.ascending\n        ).serialize()\n    )\n    return MyData(data=data)\n\n\nmy_data = get_data()\nfor row in my_data.items():\n    print(f'{row.name.get_text()} - {row.some_number.number}')\n# Do whatever else you may need to do\n</code></pre>\n<p>For more info, examples and docs see:</p>\n<ul>\n<li>notion-client: <a href=\"https://github.com/ramnes/notion-sdk-py\" rel=\"nofollow noreferrer\">https://github.com/ramnes/notion-sdk-py</a></li>\n<li>basic-notion: <a href=\"https://github.com/altvod/basic-notion\" rel=\"nofollow noreferrer\">https://github.com/altvod/basic-notion</a></li>\n<li>Notion API Reference: <a href=\"https://developers.notion.com/reference/intro\" rel=\"nofollow noreferrer\">https://developers.notion.com/reference/intro</a></li>\n</ul>\n",
                    "OwnerUserId": "1411132",
                    "LastActivityDate": "2021-11-09T23:42:21.583",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "70019606",
                "ParentRepo": "https://github.com/8sagh8/DjangoRestApi-part1-youtube-project/blob/main/README.md",
                "StackOverflow_Post": {
                    "Id": "70019606",
                    "PostTypeId": "2",
                    "ParentId": "41254846",
                    "CreationDate": "2021-11-18T12:11:24.573",
                    "Score": "0",
                    "Body": "<p>I've been facing the exact same problem but it's not the staticfiles its <code>DEBUG = False</code> that's causing the issue. When I realised it I remembered I visited a github repo yesterday that had the solution to my problem.</p>\n<p><a href=\"https://github.com/8sagh8/DjangoRestApi-part1-youtube-project/blob/main/README.md\" rel=\"nofollow noreferrer\">https://github.com/8sagh8/DjangoRestApi-part1-youtube-project/blob/main/README.md</a></p>\n<p>You could keep changing <code>DEBUG</code> to <code>False</code> or <code>True</code> between production and development or you could use the code below</p>\n<pre><code>import sys\n\nif (len(sys.argv) &gt;= 2 and sys.argv[1] == 'runserver'):\n   DEBUG = True\nelse:\n   DEBUG = False\n\n</code></pre>\n<p>If you've worked with C programs this would look quite familiar, the code above   checks if you typed in <code>runserver</code> at the end of <code>python manage.py runserver</code> and sets <code>DEBUG</code> to <code>True</code> but else it will set <code>DEBUG</code> to <code>True</code></p>\n",
                    "OwnerUserId": "16766850",
                    "LastActivityDate": "2021-11-18T12:11:24.573",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "70204140",
                "ParentRepo": "https://github.com/evidentlyai/evidently/blob/main/evidently/tutorials/historical_drift_visualization.ipynb",
                "StackOverflow_Post": {
                    "Id": "70204140",
                    "PostTypeId": "1",
                    "CreationDate": "2021-12-02T17:42:16.243",
                    "Score": "0",
                    "ViewCount": "596",
                    "Body": "<p>I am getting the following error when trying to execute publicly available code (lines 200-205 &quot;Features Drift&quot; section) from <a href=\"https://github.com/evidentlyai/evidently/blob/main/evidently/tutorials/historical_drift_visualization.ipynb\" rel=\"nofollow noreferrer\">https://github.com/evidentlyai/evidently/blob/main/evidently/tutorials/historical_drift_visualization.ipynb</a>:</p>\n<pre class=\"lang-none prettyprint-override\"><code>TypeError                                 Traceback (most recent call last)\n&lt;ipython-input-17-0cdbc9afe012&gt; in &lt;module&gt;\n      3 \n      4 for date in experiment_batches:\n----&gt; 5     drifts = detect_features_drift(raw_data.loc[reference_dates[0]:reference_dates[1]], \n      6                            raw_data.loc[date[0]:date[1]],\n      7                            column_mapping=data_columns,\n\n&lt;ipython-input-16-044c700989fb&gt; in detect_features_drift(reference, production, column_mapping, confidence, threshold, get_pvalues)\n      8     &quot;&quot;&quot;\n      9 \n---&gt; 10     data_drift_profile = Profile(sections=[DataDriftProfileSection])\n     11     data_drift_profile.calculate(reference, production, column_mapping=column_mapping)\n     12     report = data_drift_profile.json()\n\n~\\AppData\\Roaming\\Python\\Python38\\site-packages\\evidently\\model_profile\\model_profile.py in __init__(self, sections, options)\n     16 \n     17     def __init__(self, sections: Sequence[ProfileSection], options: Optional[list] = None):\n---&gt; 18         super().__init__(sections, options if options is not None else [])\n     19         self.result = {}\n     20 \n\n~\\AppData\\Roaming\\Python\\Python38\\site-packages\\evidently\\pipeline\\pipeline.py in __init__(self, stages, options)\n     20         self.analyzers_results = {}\n     21         self.options_provider = OptionsProvider()\n---&gt; 22         self._analyzers = list(itertools.chain.from_iterable([stage.analyzers() for stage in stages]))\n     23         for option in options:\n     24             self.options_provider.add(option)\n\n~\\AppData\\Roaming\\Python\\Python38\\site-packages\\evidently\\pipeline\\pipeline.py in &lt;listcomp&gt;(.0)\n     20         self.analyzers_results = {}\n     21         self.options_provider = OptionsProvider()\n---&gt; 22         self._analyzers = list(itertools.chain.from_iterable([stage.analyzers() for stage in stages]))\n     23         for option in options:\n     24             self.options_provider.add(option)\n\nTypeError: analyzers() missing 1 required positional argument: 'self'\n</code></pre>\n<p>I obtained a similar error after trying to execute lines 195-196 (section: Dataset drift).</p>\n<p>I use Python 3.8.8.</p>\n<p>I installed Evidently with some problems. After successful installation (<code>pip install --user Evidently</code>) I got the following error:</p>\n<blockquote>\n<p>mitosheet 0.1.361 requires plotly==5.3.0, but you have plotly 4.12.0 which is incompatible</p>\n</blockquote>\n<p>and after <code>(pip install plotly==5.3.0)</code> pip informed me that</p>\n<blockquote>\n<p>0.1.34.dev0 requires plotly~=4.12.0, but you have plotly 5.3.0 which is incompatible.</p>\n</blockquote>\n",
                    "OwnerUserId": "17573228",
                    "LastEditorUserId": "6273251",
                    "LastEditDate": "2021-12-02T17:50:21.107",
                    "LastActivityDate": "2022-02-21T10:48:01.013",
                    "Title": "TypeError: analyzers() missing 1 required positional argument: 'self'",
                    "Tags": "<python><python-3.x>",
                    "AnswerCount": "1",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "70259130",
                "ParentRepo": "https://github.com/Azure/Azure-Sentinel-Notebooks/blob/7cb6e0f1566e9142e0a7e1b26a05a7418e180e85/Entity%20Explorer%20-%20IP%20Address.ipynb",
                "StackOverflow_Post": {
                    "Id": "70259130",
                    "PostTypeId": "2",
                    "ParentId": "70254502",
                    "CreationDate": "2021-12-07T11:12:36.127",
                    "Score": "1",
                    "Body": "<ol>\n<li><strong>Ingest the Data</strong> - As you've mentioned, ingest the data and join the tables. You would need to regularly ingest this though to ensure you can lookup the data within the desired time range (e.g. If you have an Analytics Rule, then this only looks up data for a 14 day period).</li>\n<li><strong>Use a Playbook</strong> - If you want the Geo-IP lookup post incident, you can perform this with a Logic App</li>\n<li><strong>Use Jupyter Notebooks</strong> - This have the flexibility to perform API calls against external locations and join the data to that hosted in Sentinel. An example notebook is the <a href=\"https://github.com/Azure/Azure-Sentinel-Notebooks/blob/7cb6e0f1566e9142e0a7e1b26a05a7418e180e85/Entity%20Explorer%20-%20IP%20Address.ipynb\" rel=\"nofollow noreferrer\">IP Explorer Notebook</a>. <a href=\"https://learn.microsoft.com/en-us/azure/sentinel/notebooks?tabs=public-endpoint\" rel=\"nofollow noreferrer\">Use Jupyter notebooks to hunt for security threats</a></li>\n<li><strong>Threat Intelligence</strong> - Microsoft enriches all imported threat intelligence indicators with <a href=\"https://learn.microsoft.com/en-us/azure/sentinel/understand-threat-intelligence#view-your-geolocation-and-whois-data-enrichments-public-preview\" rel=\"nofollow noreferrer\">GeoLocation and WhoIs data</a>, which is displayed together with other indicator details.</li>\n</ol>\n",
                    "OwnerUserId": "17369330",
                    "LastActivityDate": "2021-12-07T11:12:36.127",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "70333478",
                "ParentRepo": "https://github.com/Kludex/fastapi-health",
                "StackOverflow_Post": {
                    "Id": "70333478",
                    "PostTypeId": "2",
                    "ParentId": "70333286",
                    "CreationDate": "2021-12-13T10:52:24.363",
                    "Score": "2",
                    "Body": "<p>It depend totaly of your needs, there is no health endpoint implemented natively in fastapi.</p>\n<blockquote>\n<p>But I\u2019ve been told that before I start integrating the code, I need to set up a health endpoint.</p>\n</blockquote>\n<p>not necessarly a bad practice, you could start by listing all your futur health checks and build your route from there.</p>\n<p>update from comment:</p>\n<blockquote>\n<p>But I don\u2019t know how to implement this. I need a config file? I\u2019m very new to this.</p>\n</blockquote>\n<p>From what i understand you are very new to python api so you should start by following the <a href=\"https://fastapi.tiangolo.com/tutorial/\" rel=\"nofollow noreferrer\">official fastapi user guide</a>. You can also follow <a href=\"https://realpython.com/fastapi-python-web-apis/\" rel=\"nofollow noreferrer\">fastapi first steps</a> from <a href=\"https://realpython.com/\" rel=\"nofollow noreferrer\">this</a>.</p>\n<p>Very basic one file project that run as is:</p>\n<pre class=\"lang-py prettyprint-override\"><code># main.py\n\nfrom fastapi import FastAPI\n\napp = FastAPI()\n\n@app.get(&quot;/health&quot;)\nasync def root():\n    return {&quot;message&quot;: &quot;Alive!&quot;}\n\n</code></pre>\n<p>Remember that the above is not suitable for production, only for testing/learning purposes, to make a production api you should follow the official <a href=\"https://fastapi.tiangolo.com/advanced/\" rel=\"nofollow noreferrer\">advanced user guide</a> and implement something like the following.</p>\n<p>more advanced router:</p>\n<p>You have <a href=\"https://github.com/Kludex/fastapi-health\" rel=\"nofollow noreferrer\">this health lib</a> for fastapi that is nice.</p>\n<p>You can make basic checks like this:</p>\n<pre class=\"lang-py prettyprint-override\"><code># app.routers.health.py\nfrom fastapi import APIRouter, status, Depends\nfrom fastapi_health import health\n\nfrom app.internal.health import healthy_condition, sick_condition\n\nrouter = APIRouter(\n    tags=[&quot;healthcheck&quot;],\n    responses={404: {&quot;description&quot;: &quot;not found&quot;}},\n)\n\n\n@router.get('/health', status_code=status.HTTP_200_OK)\ndef perform_api_healthcheck(health_endpoint=Depends(health([healthy_condition, sick_condition]))):\n    return health_endpoint\n</code></pre>\n<pre class=\"lang-py prettyprint-override\"><code># app.internal.health.py\ndef healthy_condition():  # just for testing puposes\n    return {&quot;database&quot;: &quot;online&quot;}\n\n\ndef sick_condition():  # just for testing puposes\n    return True\n</code></pre>\n",
                    "OwnerUserId": "11869866",
                    "LastEditorUserId": "11869866",
                    "LastEditDate": "2021-12-13T14:12:03.213",
                    "LastActivityDate": "2021-12-13T14:12:03.213",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "70345113",
                "ParentRepo": "https://github.com/frictionlessdata/frictionless-py",
                "StackOverflow_Post": {
                    "Id": "70345113",
                    "PostTypeId": "2",
                    "ParentId": "70337230",
                    "CreationDate": "2021-12-14T07:23:23.293",
                    "Score": "0",
                    "Body": "<p>Starting from:</p>\n<pre><code>seq,name/first,age,dollar,date\n1,Samuel,18,2016.35,06/26/1918\n2,Jerome,18,6022.22,01/25/1959\n3,Jeremiah,31,4842.38,08/17/2065\n4,Mitchell,52,5579.49,01/20/1919\n5,Philip,48,8708.53,09/27/2043\n6,Mayme,63,3381.63,04/02/1968\n7,Theresa,45,3427.57,03/29/1954\n8,Dorothy,51,662.90,07/08/2070\n9,Olga,45,4456.29,02/16/2051\n10,Lee,65,884.33,05/09/1913\n</code></pre>\n<p>Two tools:</p>\n<ul>\n<li><a href=\"https://github.com/frictionlessdata/frictionless-py\" rel=\"nofollow noreferrer\">frictionless</a></li>\n</ul>\n<pre><code>frictionless validate input.csv --json\n</code></pre>\n<p>gives you</p>\n<pre class=\"lang-json prettyprint-override\"><code>        &quot;schema&quot;: {\n          &quot;fields&quot;: [\n            {\n              &quot;type&quot;: &quot;integer&quot;,\n              &quot;name&quot;: &quot;seq&quot;\n            },\n            {\n              &quot;type&quot;: &quot;string&quot;,\n              &quot;name&quot;: &quot;name/first&quot;\n            },\n            {\n              &quot;type&quot;: &quot;integer&quot;,\n              &quot;name&quot;: &quot;age&quot;\n            },\n            {\n              &quot;type&quot;: &quot;number&quot;,\n              &quot;name&quot;: &quot;dollar&quot;\n            },\n            {\n              &quot;type&quot;: &quot;string&quot;,\n              &quot;name&quot;: &quot;date&quot;\n            }\n          ]\n        }\n</code></pre>\n<ul>\n<li><a href=\"https://github.com/BurntSushi/xsv\" rel=\"nofollow noreferrer\">xsv</a></li>\n</ul>\n<pre><code>xsv stats  --everything input.csv\n</code></pre>\n<p>gives you</p>\n<pre><code>+------------+---------+-------------------+------------+------------+------------+------------+--------------------+--------------------+--------------------+------+-------------+\n| field      | type    | sum               | min        | max        | min_length | max_length | mean               | stddev             | median             | mode | cardinality |\n+------------+---------+-------------------+------------+------------+------------+------------+--------------------+--------------------+--------------------+------+-------------+\n| seq        | Integer | 55                | 1          | 10         | 1          | 2          | 5.5                | 2.8722813232690143 | 5.5                | N/A  | 10          |\n| name/first | Unicode |                   | Dorothy    | Theresa    | 3          | 8          |                    |                    |                    | N/A  | 10          |\n| age        | Integer | 436               | 18         | 65         | 2          | 2          | 43.6               | 15.660140484682762 | 46.5               | N/A  | 8           |\n| dollar     | Float   | 39981.69000000001 | 662.9      | 8708.53    | 6          | 7          | 3998.1690000000003 | 2348.632561630065  | 3941.9300000000003 | N/A  | 10          |\n| date       | Unicode |                   | 01/20/1919 | 09/27/2043 | 10         | 10         |                    |                    |                    | N/A  | 10          |\n+------------+---------+-------------------+------------+------------+------------+------------+--------------------+--------------------+--------------------+------+-------------+\n</code></pre>\n",
                    "OwnerUserId": "757714",
                    "LastActivityDate": "2021-12-14T07:23:23.293",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "70407924",
                "ParentRepo": "https://github.com/custom-components/alexa_media_player/wiki#triggering-a-skill",
                "StackOverflow_Post": {
                    "Id": "70407924",
                    "PostTypeId": "1",
                    "CreationDate": "2021-12-18T23:28:47.840",
                    "Score": "0",
                    "ViewCount": "101",
                    "Body": "<p>I would like to trigger this Alexa Skill (which I did not build) <a href=\"https://www.amazon.co.uk/Kailash-Panwar-Personal-Affirmations/dp/B07SVY2RMT\" rel=\"nofollow noreferrer\">https://www.amazon.co.uk/Kailash-Panwar-Personal-Affirmations/dp/B07SVY2RMT</a> using the Alexa Media Player Home Assistant Integration (<a href=\"https://github.com/custom-components/alexa_media_player/wiki#triggering-a-skill\" rel=\"nofollow noreferrer\">https://github.com/custom-components/alexa_media_player/wiki#triggering-a-skill</a>). This requires the Skill ID. Could you please tell me how to obtain this Skill ID if I did not build this Skill?</p>\n",
                    "OwnerUserId": "17712074",
                    "LastActivityDate": "2022-11-29T10:57:22.163",
                    "Title": "How to obtain Alexa Skill ID of any public Alexa Skill?",
                    "Tags": "<alexa-skill><home-assistant>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "70488395",
                "ParentRepo": "https://github.com/metaplex-foundation/python-api/blob/441c2ba9be76962d234d7700405358c72ee1b35b/metaplex/metadata.py#L180",
                "StackOverflow_Post": {
                    "Id": "70488395",
                    "PostTypeId": "2",
                    "ParentId": "70477694",
                    "CreationDate": "2021-12-26T17:15:00.480",
                    "Score": "0",
                    "Body": "<p>From the Information shared by @Kartic Soneji,</p>\n<p>I was able to dig into the metaplex python API to see exactly how they decoded the base 64,</p>\n<p><a href=\"https://github.com/metaplex-foundation/python-api/blob/441c2ba9be76962d234d7700405358c72ee1b35b/metaplex/metadata.py#L180\" rel=\"nofollow noreferrer\">https://github.com/metaplex-foundation/python-api/blob/441c2ba9be76962d234d7700405358c72ee1b35b/metaplex/metadata.py#L180</a>.</p>\n<pre><code>\ndef get_metadata(client, mint_key):\n    metadata_account = get_metadata_account(mint_key)\n    data = base64.b64decode(client.get_account_info(metadata_account)['result']['value']['data'][0])\n    metadata = unpack_metadata_account(data)\n    return metadata\n\n</code></pre>\n<p>So anyone could just import base64 and do this decode. Don't forget to run the unpack_metadata_account()</p>\n<p>Thanks to all who helped, and hope this helps out anyone out there.</p>\n",
                    "OwnerUserId": "11096911",
                    "LastActivityDate": "2021-12-26T17:15:00.480",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "70488760",
                "ParentRepo": "https://github.com/auredentan/starlette-session",
                "StackOverflow_Post": {
                    "Id": "70488760",
                    "PostTypeId": "2",
                    "ParentId": "70455897",
                    "CreationDate": "2021-12-26T18:05:11.743",
                    "Score": "1",
                    "Body": "<p>This is because FastAPI session variables are stored client-side as a cookie, which has a limit of 4096 bytes of data. The data being stored from the redirect url is pushes the cookie size over this limit and results in the data not being stored. <a href=\"https://github.com/auredentan/starlette-session\" rel=\"nofollow noreferrer\">Starlette-session</a> is an alternative SessionMiddleware that stores variables server-side, eliminating cookie limit. Below is a basic (but messy) implementation:</p>\n<pre><code>from fastapi import FastAPI\nfrom fastapi.templating import Jinja2Templates\n\nfrom starlette.requests import Request\nfrom starlette.responses import RedirectResponse\n\nfrom starlette_session import SessionMiddleware\nfrom starlette_session.backends import BackendType\n\nfrom redis import Redis\n\nimport uvicorn\nimport functools\nimport msal\n\n\napp_client_id = &quot;sample_msal_client_id&quot;\napp_client_secret = &quot;sample_msal_client_secret&quot;\ntenant_id = &quot;sample_msal_tenant_id&quot;\n\napp = FastAPI()\n\n\nredis_client = Redis(host=&quot;localhost&quot;, port=6379)\napp.add_middleware(\n    SessionMiddleware,\n    secret_key=&quot;SECURE_SECRET_KEY&quot;,\n    cookie_name=&quot;auth_cookie&quot;,\n    backend_type=BackendType.redis,\n    backend_client=redis_client,\n)\n\ntemplates = Jinja2Templates(directory=&quot;templates&quot;)\n\ndefault_scope = [&quot;https://graph.microsoft.com/.default&quot;]\ntoken_cache_key = &quot;token_cache&quot;\n\n# Private Functions - Start\ndef _load_cache(session):\n    cache = msal.SerializableTokenCache()\n    if session.get(token_cache_key):\n        cache.deserialize(session[token_cache_key])\n    return cache\n\ndef _save_cache(cache,session):\n    if cache.has_state_changed:\n        session[token_cache_key] = cache.serialize()\n\ndef _build_msal_app(cache=None):\n    return msal.ConfidentialClientApplication(\n        app_client_id, \n        client_credential=app_client_secret,\n        authority=f&quot;https://login.microsoftonline.com/{tenant_id}&quot;,\n        token_cache=cache\n    )\n\ndef _build_auth_code_flow(request):\n    return _build_msal_app().initiate_auth_code_flow(\n        default_scope, #Scopes\n        redirect_uri=request.url_for(&quot;callback&quot;) #Redirect URI\n    )\n\ndef _get_token_from_cache(session):\n    cache = _load_cache(session)  # This web app maintains one cache per session\n    cca = _build_msal_app(cache=cache)\n    accounts = cca.get_accounts()\n    if accounts:  # So all account(s) belong to the current signed-in user\n        result = cca.acquire_token_silent(default_scope, account=accounts[0])\n        _save_cache(cache,session)\n        return result\n# Private Functions - End\n\n\n# Custom Decorators - Start\ndef authenticated_endpoint(func):\n    @functools.wraps(func)\n    def is_authenticated(*args,**kwargs):\n        try:\n            request = kwargs[&quot;request&quot;]\n            token = _get_token_from_cache(request.session)\n            if not token:\n                return RedirectResponse(request.url_for(&quot;login&quot;))\n            return func(*args,**kwargs)\n        except:\n            return RedirectResponse(request.url_for(&quot;login&quot;))\n\n    return is_authenticated\n# Custom Decorators - End\n\n\n# Endpoints - Start\n@app.get(&quot;/&quot;)\n@authenticated_endpoint\ndef index(request:Request):\n    return {\n        &quot;result&quot;: &quot;good&quot;\n    }\n\n@app.get(&quot;/login&quot;)\ndef login(request:Request):\n    return templates.TemplateResponse(&quot;login.html&quot;,{\n        &quot;version&quot;: msal.__version__,\n        'request': request,\n        &quot;config&quot;: {\n            &quot;B2C_RESET_PASSWORD_AUTHORITY&quot;: False\n        }\n    })\n\n@app.get(&quot;/oauth/redirect&quot;)\ndef get_redirect_url(request:Request):\n    request.session[&quot;flow&quot;] = _build_auth_code_flow(request)\n    return RedirectResponse(request.session[&quot;flow&quot;][&quot;auth_uri&quot;])\n\n@app.get(&quot;/callback&quot;)\nasync def callback(request:Request):\n    cache = _load_cache(request.session)\n    result = _build_msal_app(cache=cache).acquire_token_by_auth_code_flow(request.session.get(&quot;flow&quot;, {}), dict(request.query_params))\n    if &quot;error&quot; in result:\n        return templates.TemplateResponse(&quot;auth_error.html&quot;,{\n            &quot;result&quot;: result,\n            'request': request\n        })\n    request.session[&quot;user&quot;] = result.get(&quot;id_token_claims&quot;)\n    request.session[token_cache_key] = cache.serialize()\n    return RedirectResponse(request.url_for(&quot;index&quot;))\n# Endpoints - End\n\nif __name__ == &quot;__main__&quot;:\n    uvicorn.run(&quot;main:app&quot;,host='0.0.0.0', port=4557,reload=True)`\n</code></pre>\n",
                    "OwnerUserId": "13217247",
                    "LastActivityDate": "2021-12-26T18:05:11.743",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "70506194",
                "ParentRepo": "https://github.com/robusta-dev/robusta",
                "StackOverflow_Post": {
                    "Id": "70506194",
                    "PostTypeId": "2",
                    "ParentId": "54806336",
                    "CreationDate": "2021-12-28T11:09:52.120",
                    "Score": "0",
                    "Body": "<p>You can silence it by sending your alerts through <a href=\"https://github.com/robusta-dev/robusta\" rel=\"nofollow noreferrer\">Robusta</a>. (Disclaimer: I wrote Robusta.)</p>\n<p>Here is an example:</p>\n<pre class=\"lang-yaml prettyprint-override\"><code>- triggers:\n  - on_prometheus_alert: {}\n  actions:\n  - name_silencer:\n      names: [&quot;Watchdog&quot;, &quot;CPUThrottlingHigh&quot;]\n</code></pre>\n<p>However, this is probably <strong>not</strong> what you want to do!</p>\n<p>Some <code>CPUThrottlingHigh</code> alerts are spammy and can't be fixed like <a href=\"https://github.com/robusta-dev/alert-explanations/wiki/CPUThrottlingHigh-on-metrics-server-(Prometheus-alert)\" rel=\"nofollow noreferrer\">the one for metrics-server on GKE.</a>.</p>\n<p>However, in general the alert is meaningful and can indicate a real problem. <a href=\"https://github.com/robusta-dev/alert-explanations/wiki/CPUThrottlingHigh-(Prometheus-Alert)\" rel=\"nofollow noreferrer\">Typically the best-practice is to change or remove the pod's CPU limit.</a>.</p>\n<p>I've spent more hours of my life than I care to admit looking at <code>CPUThrottlingHigh</code> as I wrote an automated playbook for Robusta which analyzes each <code>CPUThrottlingHigh</code> and recommends the best practice.</p>\n",
                    "OwnerUserId": "495995",
                    "LastActivityDate": "2021-12-28T11:09:52.120",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "70540765",
                "ParentRepo": "https://github.com/abersheeran/asgi-ratelimit",
                "StackOverflow_Post": {
                    "Id": "70540765",
                    "PostTypeId": "2",
                    "ParentId": "65491184",
                    "CreationDate": "2021-12-31T09:19:02.213",
                    "Score": "5",
                    "Body": "<p>You can use <a href=\"https://github.com/abersheeran/asgi-ratelimit\" rel=\"noreferrer\">https://github.com/abersheeran/asgi-ratelimit</a></p>\n<p>Compared to <a href=\"https://pypi.org/project/fastapi-limiter/\" rel=\"noreferrer\">https://pypi.org/project/fastapi-limiter/</a> and <a href=\"https://pypi.org/project/slowapi/\" rel=\"noreferrer\">https://pypi.org/project/slowapi/</a>, it can better meet your needs.</p>\n<p>This is a example: after exceeding the five times per second access limit, block a specific user for 60 seconds.</p>\n<pre><code>app.add_middleware(\n    RateLimitMiddleware,\n    authenticate=AUTH_FUNCTION,\n    backend=RedisBackend(),\n    config={\n        r&quot;^/user&quot;: [Rule(second=5, block_time=60)],\n    },\n)\n</code></pre>\n",
                    "OwnerUserId": "9301113",
                    "LastActivityDate": "2021-12-31T09:19:02.213",
                    "CommentCount": "3",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "70580126",
                "ParentRepo": "https://github.com/sunhailin-Leo/fastapi_profiler",
                "StackOverflow_Post": {
                    "Id": "70580126",
                    "PostTypeId": "2",
                    "ParentId": "70573083",
                    "CreationDate": "2022-01-04T14:14:27.953",
                    "Score": "1",
                    "Body": "<p>As some people pointed out in the comments, the slow response time could be because of badly optimized query. For example in your <code>get_all</code> method when applying filters for query you always fetch all columns which might not be the best practice when fetching such big amount of data so try fetching only those columns that are needed for your frontend/client in specific view. Also I think that you need to write your own custom pagination done at the query level (which will be faster because it's done by database itself) because I have suspicion that <a href=\"https://uriyyo-fastapi-pagination.netlify.app/\" rel=\"nofollow noreferrer\">fastapi-pagination</a> only paginates already pre-fetched data. Example of pagination using SQLAlchemy:</p>\n<pre class=\"lang-py prettyprint-override\"><code>offset = (page_number * items_count) - items_count\nfilters = [\n    getattr(cls, column_name) == value\n    for column_name, value in kwargs.items()\n]\nquery = query.where(*filters)\nresult = query.offset(offset).limit(items_count).all()\n</code></pre>\n<p>Try using <a href=\"https://github.com/sunhailin-Leo/fastapi_profiler\" rel=\"nofollow noreferrer\">fastapi-profiler</a> when looking for performance bottlenecks in your code. Here is simple configuration I used in one of my projects:</p>\n<pre><code>app.add_middleware(\n   CProfileMiddleware,\n   enable=True,\n   print_each_request=True,\n   strip_dirs=False,\n   sort_by=&quot;cumtime&quot;\n)\n</code></pre>\n",
                    "OwnerUserId": "7380417",
                    "LastActivityDate": "2022-01-04T14:14:27.953",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "70653551",
                "ParentRepo": "https://github.com/UKPLab/EasyNMT",
                "StackOverflow_Post": {
                    "Id": "70653551",
                    "PostTypeId": "2",
                    "ParentId": "65541788",
                    "CreationDate": "2022-01-10T13:56:54.710",
                    "Score": "0",
                    "Body": "<p><strong>One way to speedup the translations is to indicate (when possible) the\nsource language:</strong></p>\n<p>After importing the library and creating the model as such:</p>\n<pre class=\"lang-python prettyprint-override\"><code>from easynmt import EasyNMT\nmodel = EasyNMT('opus-mt')\n</code></pre>\n\n<p>then (if possible), provide the source language as such :</p>\n<pre class=\"lang-python prettyprint-override\"><code>translated_word = model.translate(&quot;Coucou!&quot;, source_lang=&quot;fr&quot;, target_lang=&quot;en&quot; )\nprint(translated_word)  # Hello!\n</code></pre>\n\n<p>This gets better translation results (for short sentences) and is faster than if you do not provide the source language :</p>\n<pre class=\"lang-python prettyprint-override\"><code>translated_word = model.translate(&quot;Coucou!&quot;, target_lang=&quot;en&quot;)\nprint(translated_word)  # He's gone!\n</code></pre>\n\n<p>More details on the official page : <a href=\"https://github.com/UKPLab/EasyNMT\" rel=\"nofollow noreferrer\">https://github.com/UKPLab/EasyNMT</a></p>\n<p>Enjoy</p>\n",
                    "OwnerUserId": "14175071",
                    "LastActivityDate": "2022-01-10T13:56:54.710",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "70722108",
                "ParentRepo": "https://github.com/Music-and-Culture-Technology-Lab/omnizart/issues/29#issuecomment-877557801",
                "StackOverflow_Post": {
                    "Id": "70722108",
                    "PostTypeId": "2",
                    "ParentId": "70670994",
                    "CreationDate": "2022-01-15T14:00:40.293",
                    "Score": "1",
                    "Body": "<p>The last <code>PyAudio</code> release was in 2017, it doesn't have <a href=\"https://pypi.org/project/PyAudio/#files\" rel=\"nofollow noreferrer\">wheels for Python 3.9</a> which means no easy installation process for you - one has to compile C code on the local machine. Unfortunately, the compiling process fails as you have missing dependencies namely <code>portaudio</code>. You need to install it, see the relevant question <a href=\"https://stackoverflow.com/q/33513522/2787185\">when installing pyaudio, pip cannot find portaudio.h in /usr/local/include</a>.</p>\n<p>Speaking of <code>omnizart</code> - not sure which error do you get, I pretty much doubt it is about <code>portaudio</code>. To start with - make sure to install all the dependencies as suggested in <code>omnizart</code> repo: <a href=\"https://github.com/Music-and-Culture-Technology-Lab/omnizart/issues/29#issuecomment-877557801\" rel=\"nofollow noreferrer\">https://github.com/Music-and-Culture-Technology-Lab/omnizart/issues/29#issuecomment-877557801</a>.</p>\n",
                    "OwnerUserId": "2787185",
                    "LastActivityDate": "2022-01-15T14:00:40.293",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "70788141",
                "ParentRepo": "https://github.com/psadi/bbcli",
                "StackOverflow_Post": {
                    "Id": "70788141",
                    "PostTypeId": "2",
                    "ParentId": "8721730",
                    "CreationDate": "2022-01-20T14:39:45.143",
                    "Score": "3",
                    "Body": "<p>I have created a pull request cli utility to ease my tasks.</p>\n<p>Currently,</p>\n<ul>\n<li>it can create/delete pr's right from the terminal</li>\n<li>show basic diff for a raised PR</li>\n</ul>\n<p>I have tested it with bitbucket enterprise 6.10.10</p>\n<p>Source code: <a href=\"https://github.com/psadi/bbcli\" rel=\"nofollow noreferrer\">https://github.com/psadi/bbcli</a></p>\n",
                    "OwnerUserId": "13554176",
                    "LastEditorUserId": "13554176",
                    "LastEditDate": "2022-02-19T12:08:44.083",
                    "LastActivityDate": "2022-02-19T12:08:44.083",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "70846619",
                "ParentRepo": "https://github.com/Kludex/fastapi-microservices",
                "StackOverflow_Post": {
                    "Id": "70846619",
                    "PostTypeId": "2",
                    "ParentId": "70833869",
                    "CreationDate": "2022-01-25T09:56:53.553",
                    "Score": "0",
                    "Body": "<p>You can follow the offcial <a href=\"https://fastapi.tiangolo.com/tutorial/sql-databases/\" rel=\"nofollow noreferrer\">fastapi guide regarding orm bests practices</a>. Fastapi is not tiedup with any orm or db client so you can implement sqlalchemy same way than flask (with fastapi you can do async db or orm calls wich is nice)</p>\n<p>Taken from the doc:</p>\n<pre class=\"lang-py prettyprint-override\"><code>from sqlalchemy import create_engine\nfrom sqlalchemy.ext.declarative import declarative_base\nfrom sqlalchemy.orm import sessionmaker\n\nSQLALCHEMY_DATABASE_URL = &quot;sqlite:///./sql_app.db&quot;\n# SQLALCHEMY_DATABASE_URL = &quot;postgresql://user:password@postgresserver/db&quot;\n\nengine = create_engine(\n    SQLALCHEMY_DATABASE_URL, connect_args={&quot;check_same_thread&quot;: False}\n)\nSessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)\n\nBase = declarative_base()\n</code></pre>\n<p>A <a href=\"https://github.com/Kludex/fastapi-microservices\" rel=\"nofollow noreferrer\">more complexe project</a> that implement async sqlalchemy calls and crud interface</p>\n",
                    "OwnerUserId": "11869866",
                    "LastActivityDate": "2022-01-25T09:56:53.553",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "70907144",
                "ParentRepo": "https://github.com/XRPLF/xrpl-py",
                "StackOverflow_Post": {
                    "Id": "70907144",
                    "PostTypeId": "1",
                    "CreationDate": "2022-01-29T15:52:11.683",
                    "Score": "0",
                    "ViewCount": "113",
                    "Body": "<p>I've been testing out interacting with the XRP Ledger, coding in Python. I started coding some basic queries regarding the status of the XRP Ledger from scratch based on the XRPL documentation (available <a href=\"https://xrpl.org/get-started-using-python.html\" rel=\"nofollow noreferrer\">here</a>) but then discovered XRPL-PY (I've reviewed the GitHub repo <a href=\"https://github.com/XRPLF/xrpl-py\" rel=\"nofollow noreferrer\">here</a> and the documentation <a href=\"https://xrpl-py.readthedocs.io/en/stable/index.html\" rel=\"nofollow noreferrer\">here</a>) and have since been predominately using XRPL-PY to interact with the XRP Ledger given its general ease of use. I've been able to accomplish most of the basic types of interactions with the XRP Ledger one might want to do, including creating a wallet and submitting an offer to exchange one currency for another on the XRP Ledger (what I'll call an &quot;Offer&quot;). However, one point that I have been unable to figure out, whether by using XRPL-PY or interacting with the XRP Ledger directly, is how to determine when/whether a previously submitted Offer has been fully consumed (i.e., another transaction, or transactions, were submitted to the XRP Ledger that accepted my Offer such that it is no longer outstanding and the offered currencies were exchanged at the offered rate). This seems like a basic query that most people interacting with the XRP Ledger would want to be able to establish, but I haven't seen anything in the XRPL or XRPL-PY documentation explaining how to do it. My preference would be to be able to subscribe to updates from the XRPL Ledger such that it lets me know once my Offer has been partially or fully consumed, but if that's not possible I would like to at least be able to repeatedly query the status of my Offer from the XRP Ledger and know what will change in the response once my Offer has been partially or fully consumed. Any suggestions would be greatly appreciated.</p>\n",
                    "OwnerUserId": "7550865",
                    "LastActivityDate": "2022-02-10T17:04:39.537",
                    "Title": "How to check when/whether an offer on the XRP Ledger's DEX has been accepted/fully consumed? [XRP] [XRPL]",
                    "Tags": "<ripple><xrp>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "71121384",
                "ParentRepo": "https://github.com/jondavid-black/AaC/tree/56588e41e1420eafd8042730e2e4ee9b34e7d262",
                "StackOverflow_Post": {
                    "Id": "71121384",
                    "PostTypeId": "1",
                    "CreationDate": "2022-02-15T05:12:41.680",
                    "Score": "0",
                    "ViewCount": "565",
                    "Body": "<h2>TL;DR</h2>\n<p>I have a VSCode extension acting as a client for an LSP server written in Python (using the <a href=\"https://github.com/openlawlibrary/pygls\" rel=\"nofollow noreferrer\">pygls</a> library) and I can't seem to get basic requests sent to my LSP server from the extension.</p>\n<h2>The Longer Version</h2>\n<p>I'm working on an LSP server for a custom YAML-based language and have run into some issues I can't seem to resolve. Specifically, our tool is written in Python, so I'm using <a href=\"https://github.com/openlawlibrary/pygls\" rel=\"nofollow noreferrer\">pygls</a> to ease the creation of the language server and am creating a VSCode extension to handle the client side of things.</p>\n<p>At this stage, my goal is to get a very basic hover functionality to work where I've hard-coded the hover text to be displayed to the user. Unfortunately, I have yet to be able to get this to work as it doesn't seem like my client is correctly sending the request to the server, or my server is not correctly handling it.</p>\n<p>To try and resolve this, I have:</p>\n<ul>\n<li>Looked through several examples of extensions to see how my VSCode extension differs (to name a few):\n<ul>\n<li><a href=\"https://github.com/microsoft/vscode-extension-samples/blob/e52c48f22a81355b568f3cde8c60538726caad22/lsp-sample/client/src/extension.ts\" rel=\"nofollow noreferrer\">Microsoft/vscode-extension-samples: lsp-sample</a></li>\n<li><a href=\"https://github.com/openlawlibrary/pygls/blob/bbf671f509b0d499a006daeeae8cdb78e3419fe5/examples/json-extension/client/src/extension.ts\" rel=\"nofollow noreferrer\">openlawlibrary/pygls: json-extension</a></li>\n<li><a href=\"https://github.com/Eugleo/magic-racket/blob/54f66ab58a1a4409e0ad149520cea4504c7f2f21/src/extension.ts\" rel=\"nofollow noreferrer\">Eugleo/magic-racket</a></li>\n</ul>\n</li>\n<li>Gone through the <a href=\"https://microsoft.github.io/language-server-protocol/specifications/specification-3-17/#textDocument_hover\" rel=\"nofollow noreferrer\">LSP Specification</a> to know which parameters need to be passed for the <code>Hover</code> request.</li>\n<li>Gone through the <a href=\"https://code.visualstudio.com/api/language-extensions/language-server-extension-guide\" rel=\"nofollow noreferrer\">VSCode Langage Server Extension Guide</a></li>\n<li>Looked through the <a href=\"https://github.com/Microsoft/vscode-languageserver-node\" rel=\"nofollow noreferrer\">vscode-Languageserver-node</a> code base for hints as to why my hover handler (in the server) is never getting called, etc.</li>\n</ul>\n<p>Some things I noticed that were different with what I'm doing versus what others have:</p>\n<ul>\n<li>Many extensions are using TypeScript to write the server; I'm using Python.</li>\n<li>Some extensions do not add the call to <code>client.start()</code> to the <code>context.subscriptions</code>; I do.</li>\n</ul>\n<p>Bonus: I get the sense that I should be sending the <a href=\"https://microsoft.github.io/language-server-protocol/specifications/specification-3-17/#initialize\" rel=\"nofollow noreferrer\"><code>initialize</code> request</a> and the <a href=\"https://microsoft.github.io/language-server-protocol/specifications/specification-3-17/#initialized\" rel=\"nofollow noreferrer\"><code>initialized</code> notification</a> before expecting any of the hovering to work but, from what I've seen, no other extension I've come across explicitly sends either of those. (Additionally, just because I was curious, I tried and it still didn't provide any different results.)</p>\n<p>At this point, I'm really not sure where I'm going wrong - any insights/pointers are greatly appreciated. Thanks!</p>\n<p>The relevant parts of my server implementation are as follows:</p>\n<p><code>server.py</code></p>\n<pre><code># imports elided\n\n# we start the server a bit differently, but the essence is this:\nserver = LanguageServer()\nserver.start_ws(&quot;127.0.0.1&quot;, 8080)\n\n@server.feature(methods.HOVER)\nasync def handle_hover(ls: LanguageServer, params: HoverParams):\n    &quot;&quot;&quot;Handle a hover event.&quot;&quot;&quot;\n    logger.info(f&quot;received hover request\\nparams are: {params.text_document.uri}&quot;)\n\n    ls.show_message(&quot;received hover request&quot;)\n    ls.show_message(f&quot;file: {params.text_document.uri}; line: {params.position.line}; character: {params.position.character}&quot;)\n\n    return Hover(contents=&quot;Hello from your friendly AaC LSP server!&quot;)\n</code></pre>\n<p>The relevant parts of the client (I think, I don't use VSCode so I may be missing something) are as follows:</p>\n<p><code>AacLanguageServer.ts</code></p>\n<pre><code>// imports elided\n// extension.ts (not this file) contains a call to the startLspClient(...) function\n\nexport class AacLanguageServerClient {\n    private static instance: AacLanguageServerClient;\n\n    private aacLspClient!: LanguageClient;\n\n    // certain checks are elided for brevity\n\n    private startLspClient(context: ExtensionContext, aacPath: string, host: string, port: number): void {\n        if (this.aacLspClient) { return; }\n        this.aacLspClient = new LanguageClient(\n            &quot;aac&quot;,\n            &quot;AaC Language Client&quot;,\n            this.getServerOptions(aacPath, &quot;start-lsp&quot;, &quot;--host&quot;, host, &quot;--port&quot;, `${port}`),\n            this.getClientOptions(),\n        );\n        this.aacLspClient.trace = Trace.Verbose;\n        context.subscriptions.push(this.aacLspClient.start());\n        this.registerHoverProvider(context);\n    }\n\n    private async registerHoverProvider(context: ExtensionContext): Promise&lt;void&gt; {\n        const client = this.aacLspClient;\n        context.subscriptions.push(languages.registerHoverProvider({ scheme: &quot;file&quot;, language: &quot;aac&quot;, pattern: &quot;**/*.yaml&quot; }, {\n            provideHover(document, position, token): ProviderResult&lt;Hover&gt; {\n                window.showInformationMessage(\n                    `File: ${document.uri.path}; Line: ${position.line}; Character: ${position.character}`\n                );\n                return client.sendRequest(&quot;textDocument/hover&quot;, {\n                    textDocument: document,\n                    position: position,\n                }, token);\n            }\n        }));\n    }\n\n    private getServerOptions(command: string, ...args: any[]): ServerOptions {\n        return {\n            args,\n            command,\n        };\n    }\n\n    private getClientOptions(): LanguageClientOptions {\n        return {\n            documentSelector: [\n                { scheme: &quot;file&quot;, language: &quot;aac&quot;, pattern: &quot;**/*.aac&quot; },\n                { scheme: &quot;file&quot;, language: &quot;aac&quot;, pattern: &quot;**/*.yaml&quot; },\n            ],\n            diagnosticCollectionName: &quot;aac&quot;,\n            outputChannelName: &quot;Architecture-as-Code&quot;,\n            synchronize: {\n                fileEvents: workspace.createFileSystemWatcher(&quot;**/.clientrc&quot;),\n            }\n        };\n    }\n\n}\n</code></pre>\n<p>When I debug this in VSCode, I can see that the server is started in the session but if I hover over any symbol in the shown file, nothing happens. Can someone</p>\n<p><a href=\"https://i.stack.imgur.com/InNaT.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/InNaT.png\" alt=\"Debug Session\" /></a></p>\n<p>Finally, all the code (in it's current state as of the time of posting this question) can be found in <a href=\"https://github.com/jondavid-black/AaC/tree/56588e41e1420eafd8042730e2e4ee9b34e7d262\" rel=\"nofollow noreferrer\">this</a> repository, if a more complete code reference is desired. The LSP server-related code is located in the <a href=\"https://github.com/jondavid-black/AaC/tree/56588e41e1420eafd8042730e2e4ee9b34e7d262/python/src/aac/lang/server.py\" rel=\"nofollow noreferrer\"><code>python/src/aac/lang/server.py</code></a> file; and the client-related code is located in the <a href=\"https://github.com/jondavid-black/AaC/tree/56588e41e1420eafd8042730e2e4ee9b34e7d262/vscode_extension/src/AacLanguageServer.ts\" rel=\"nofollow noreferrer\"><code>vscode_extension/src/AacLanguageServer.ts</code></a> file.</p>\n",
                    "OwnerUserId": "2247345",
                    "LastActivityDate": "2022-02-24T21:41:49.353",
                    "Title": "VSCode extension does not seem to be sending requests to my LSP server",
                    "Tags": "<python><visual-studio-code><vscode-extensions><language-server-protocol>",
                    "AnswerCount": "2",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "71233942",
                "ParentRepo": "https://github.com/abhijeetgupto/Face-Detection/",
                "StackOverflow_Post": {
                    "Id": "71233942",
                    "PostTypeId": "1",
                    "CreationDate": "2022-02-23T08:57:44.907",
                    "Score": "-1",
                    "ViewCount": "714",
                    "Body": "<p>I'm working on a <a href=\"https://github.com/abhijeetgupto/Face-Detection/\" rel=\"nofollow noreferrer\">project</a> to detect and track faces by taking video from webcam. It worked fine on my PC but when i <a href=\"https://face1-detection.herokuapp.com/\" rel=\"nofollow noreferrer\">deployed</a> it on Heroku, I found out that the open cv command i was using to get the video feed of the user (i.e. <code>video = cv2.VideoCapture(0)</code>) does not work when deployed.</p>\n<p>After some googling I found out <a href=\"https://github.com/euguroglu/Flask_WebCam_OpenCV\" rel=\"nofollow noreferrer\">this</a> repo where he did exactly the same and got video frames using javascript but I'm not able to figure out how he is sending those frames back to the flask app to process the images and send it back to HTML. I cloned this repo and found out that this code also doesn't work . It is not able to show the processed images back, Although the webcam using JS does work .</p>\n<p>Can someone please help me resolve this issue.\napp.py:</p>\n<pre><code>from flask import Flask, render_template, Response, url_for, redirect\nimport cv2 as cv\nfrom face_detector import face_detector\nfrom flask_wtf import FlaskForm\nfrom wtforms import SubmitField\n\napp = Flask(__name__)\napp.config['SECRET_KEY'] = 'password'\n\n\nclass InfoForm(FlaskForm):\n    submit = SubmitField(label=&quot;Submit&quot;)\n\n@app.route('/', methods=['GET', 'POST'])\ndef index():\n    form = InfoForm()\n\n    if form.validate_on_submit():\n        return redirect(url_for('home'))\n\n    return render_template('home.html', form=form)\n\n\n@app.route('/home',methods=['GET', 'POST'])\ndef home():\n    return render_template('index.html')\n\n@app.route('/video',methods=['GET', 'POST'])\ndef video():\n    vid = cv.VideoCapture(0)\n    success, dfs = vid.read()\n    if success:\n        return Response(face_detector(), mimetype='multipart/x-mixed-replace; boundary=frame')\n\n\nif __name__ == &quot;__main__&quot;:\n    app.run(debug=True)\n</code></pre>\n<p>index.html</p>\n<pre><code>{% extends &quot;base.html&quot; %}\n\n{% block content %}\n\n\n\n&lt;div class=&quot;jumbotron&quot; style = &quot;display : block&quot;&gt;\n  &lt;h1 style=&quot;display: block; justify-content: center; text-align: center&quot;&gt;---Live Face Detection ---&lt;/h1&gt;\n  &lt;br&gt;\n  &lt;br&gt;\n  &lt;div style=&quot;margin: auto 0px&quot;&gt;\n    &lt;center&gt;&lt;img src=&quot;{{ url_for('video') }}&quot; alt=&quot;Please turn on your camera !&quot;/&gt; &lt;/center&gt;\n  &lt;/div&gt;\n&lt;/div&gt;\n\n{% endblock %}\n</code></pre>\n",
                    "OwnerUserId": "17096367",
                    "LastActivityDate": "2022-09-18T06:27:38.047",
                    "Title": "Accessing webcam using Flask and Javascript",
                    "Tags": "<python><opencv><flask><heroku><flask-socketio>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "71316040",
                "ParentRepo": "https://github.com/PrefectHQ/Server",
                "StackOverflow_Post": {
                    "Id": "71316040",
                    "PostTypeId": "1",
                    "CreationDate": "2022-03-02T00:12:59.803",
                    "Score": "0",
                    "ViewCount": "211",
                    "Body": "<p>I have a question on LNK errors.  I've read several posts, but I'm still stuck.  I have setup a virtual environment using Anaconda and downloaded the prefect server files from git here: <a href=\"https://github.com/PrefectHQ/Server\" rel=\"nofollow noreferrer\">https://github.com/PrefectHQ/Server</a></p>\n<p>After activating my environment and installing prefect, I run pip install &quot;prefect[dev]&quot;.  Initially an error said I needed Microsoft Visual Studio and it provided a website to download visual studio build tools and the requirement was 14.0 or greater.  I know little on C++, but the error was unresolved external symbol _PyUnicodeEscape.  Can anyone help me out with this?</p>\n<p>Creating library build\\temp.win-amd64-3.10\\Release\\ast3/Custom_ast3.cp310-win_amd64.lib and object build\\temp.win-amd64-3.10\\Release\\ast3/Custom_ast3.cp310-win_amd64.exp\nast.obj : error LNK2001: unresolved external symbol _PyUnicode_DecodeUnicodeEscape\nbuild\\lib.win-amd64-3.10\\typed_ast_ast3.cp310-win_amd64.pyd : fatal error LNK1120: 1 unresolved externals\nerror: command 'C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\BuildTools\\VC\\Tools\\MSVC\\14.29.30133\\bin\\HostX86\\x64\\link.exe' failed with exit code 1120</p>\n",
                    "OwnerUserId": "18290538",
                    "LastActivityDate": "2022-03-02T13:22:46.993",
                    "Title": "How to solve a LNK 2001 and LNK 1120 error",
                    "Tags": "<python><visual-studio><prefect>",
                    "AnswerCount": "0",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "71352433",
                "ParentRepo": "https://github.com/Bilal815/LWD/tree/Project",
                "StackOverflow_Post": {
                    "Id": "71352433",
                    "PostTypeId": "1",
                    "CreationDate": "2022-03-04T13:52:03.817",
                    "Score": "-1",
                    "ViewCount": "19",
                    "Body": "<p><a href=\"https://i.stack.imgur.com/2kdv0.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/2kdv0.png\" alt=\"enter image description here\" /></a></p>\n<p>I'm getting these issues but not sure why I changed the models from in the master branch to as in Project Branch.</p>\n<p>This is my DB</p>\n<p><a href=\"https://i.stack.imgur.com/QZMWI.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/QZMWI.png\" alt=\"enter image description here\" /></a></p>\n<p>These are my tables\n<a href=\"https://i.stack.imgur.com/XGNcG.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/XGNcG.png\" alt=\"enter image description here\" /></a>\n<a href=\"https://i.stack.imgur.com/Unplr.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/Unplr.png\" alt=\"enter image description here\" /></a>\n<a href=\"https://i.stack.imgur.com/3idGG.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/3idGG.png\" alt=\"enter image description here\" /></a>\n<a href=\"https://i.stack.imgur.com/hJmSb.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/hJmSb.png\" alt=\"enter image description here\" /></a></p>\n<p><strong>My project URL:</strong> <a href=\"https://github.com/Bilal815/LWD/tree/Project\" rel=\"nofollow noreferrer\">https://github.com/Bilal815/LWD/tree/Project</a></p>\n<p>Now, what should I do to get going? <strong>I have very little time left!!!</strong></p>\n<p>Appreciate any help!</p>\n",
                    "OwnerUserId": "14789432",
                    "LastActivityDate": "2022-03-04T14:01:46.137",
                    "Title": "Is it Models or the Database?",
                    "Tags": "<python-3.x><django><django-models><django-rest-framework><mysql-python>",
                    "AnswerCount": "1",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "71374924",
                "ParentRepo": "https://github.com/Evernow/AutoDDU_CLI/blob/main/AutoDDU_CLI.py",
                "StackOverflow_Post": {
                    "Id": "71374924",
                    "PostTypeId": "1",
                    "CreationDate": "2022-03-06T23:11:07.777",
                    "Score": "0",
                    "ViewCount": "33",
                    "Body": "<p>I am making a Python pyinstaller executable with a console on Windows that prints new output and once in a while asks for input from user, however sometimes when the user does not have the console in focus the console does not print the new output until the user resizes it or presses some input. I have a video showcasing it here: <a href=\"https://cdn.discordapp.com/attachments/486190714863222784/950152317108387860/2022-03-06_17-05-27.mp4\" rel=\"nofollow noreferrer\">https://cdn.discordapp.com/attachments/486190714863222784/950152317108387860/2022-03-06_17-05-27.mp4</a></p>\n<p>Points of note:</p>\n<p>Using os.system('mode con: cols=80 lines=40') to resize the window, not sure if related.</p>\n<p>It doesn't always happen, in fact the above video it took me some 20 tries to get it to be reproduced.</p>\n<p>Source code can be found here: <a href=\"https://github.com/Evernow/AutoDDU_CLI/blob/main/AutoDDU_CLI.py\" rel=\"nofollow noreferrer\">https://github.com/Evernow/AutoDDU_CLI/blob/main/AutoDDU_CLI.py</a></p>\n<p>Any help is greatly appreciated!</p>\n",
                    "OwnerUserId": "17484902",
                    "LastActivityDate": "2022-03-06T23:11:07.777",
                    "Title": "Python console may not show new print until resized",
                    "Tags": "<python><python-3.x><windows>",
                    "AnswerCount": "0",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "71424999",
                "ParentRepo": "https://github.com/Azure-Samples/media-services-video-indexer/tree/master/ApiUsage/ArmBased",
                "StackOverflow_Post": {
                    "Id": "71424999",
                    "PostTypeId": "2",
                    "ParentId": "71402826",
                    "CreationDate": "2022-03-10T13:34:06.997",
                    "Score": "2",
                    "Body": "<p>Please see sample in there how to generate access token for AVAM ARM account:\n<a href=\"https://github.com/Azure-Samples/media-services-video-indexer/tree/master/ApiUsage/ArmBased\" rel=\"nofollow noreferrer\">https://github.com/Azure-Samples/media-services-video-indexer/tree/master/ApiUsage/ArmBased</a></p>\n<p>(look at Program.cs)</p>\n",
                    "OwnerUserId": "3540646",
                    "LastActivityDate": "2022-03-10T13:34:06.997",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "71433131",
                "ParentRepo": "https://github.com/Textualize/textual",
                "StackOverflow_Post": {
                    "Id": "71433131",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "71503651",
                    "CreationDate": "2022-03-11T02:55:22.490",
                    "Score": "2",
                    "ViewCount": "774",
                    "Body": "<p>I'm trying to get it so I can add links in text rendered by <a href=\"https://github.com/Textualize/textual\" rel=\"nofollow noreferrer\">Textual</a>.</p>\n<p>My text may have multiple links, for example:</p>\n<pre><code>Hello [@click=hello]World[/] there, how are you?\nThis is a test of [@click=more] more info[/] being clickable as well.\n</code></pre>\n<p>In this simple sample I made, clicking on the word &quot;World&quot; should hopefully change the background color to red, but it doesn't work.</p>\n<p>NOTE: I also bound the &quot;b&quot; key to do pretty much the same thing, so I could see it work\nIt should change the background color, and the subtitle of the app.</p>\n<pre class=\"lang-py prettyprint-override\"><code>import os\nimport sys\nfrom rich.console import RenderableType\nfrom rich.panel import Panel\nfrom rich.text import Text\nfrom textual.app import App\nfrom textual.widgets import Header, Footer, ScrollView\nfrom textual.widgets import Placeholder\n\nclass MyApp(App):\n\n    async def on_load(self) -&gt; None:\n        await self.bind(&quot;b&quot;, &quot;color('blue')&quot;)\n\n    async def on_mount(self) -&gt; None:\n        await self.view.dock(Header(), size=5, edge=&quot;top&quot;)\n        await self.view.dock(Footer(), edge=&quot;bottom&quot;)\n        await self.view.dock(ScrollView(Panel(&quot;Hello [@click=hello]World[/] more info here&quot;)), edge=&quot;top&quot;)\n\n    async def action_color(self, color:str) -&gt; None:\n        self.app.sub_title = &quot;KEYBOARD&quot;\n        self.background = f&quot;on {color}&quot;\n\n    async def action_hello(self) -&gt; None:\n        self.app.sub_title = &quot;CLICKED&quot;\n        self.background = &quot;on red&quot;\n\nMyApp.run(title=&quot;Test click&quot;, log=&quot;textual.log&quot;)\n</code></pre>\n<p>I asked this same question in the <a href=\"https://github.com/Textualize/textual/discussions/323\" rel=\"nofollow noreferrer\">textual discussions</a> and originally <a href=\"https://github.com/Textualize/rich/discussions/2021#discussioncomment-2288880\" rel=\"nofollow noreferrer\">rich discussions</a>, but haven't been able to see how to make this work from the feedback I received there, which was helpful for sure, but I'm missing something here, so thanks for any input.</p>\n",
                    "OwnerUserId": "26510",
                    "LastEditorUserId": "26510",
                    "LastEditDate": "2022-03-16T11:27:15.290",
                    "LastActivityDate": "2022-04-26T05:50:46.963",
                    "Title": "Textual (python) - how to add click event in simple Text object?",
                    "Tags": "<python><tui><rich>",
                    "AnswerCount": "2",
                    "CommentCount": "0",
                    "FavoriteCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "71514282",
                "ParentRepo": "https://github.com/Bilal815/ecommerce_storee",
                "StackOverflow_Post": {
                    "Id": "71514282",
                    "PostTypeId": "1",
                    "CreationDate": "2022-03-17T14:43:47.187",
                    "Score": "0",
                    "ViewCount": "33",
                    "Body": "<p><strong>ISSUE:</strong> I ran my project and tried adding a product through Django's Jet Dashboard, but it's giving me errors.</p>\n<p>Project Repository: <a href=\"https://github.com/Bilal815/ecommerce_storee\" rel=\"nofollow noreferrer\">https://github.com/Bilal815/ecommerce_storee</a></p>\n<p>ecommerce_storee/products/models.py/\n<a href=\"https://github.com/Bilal815/ecommerce_storee/blob/master/products/models.py\" rel=\"nofollow noreferrer\">https://github.com/Bilal815/ecommerce_storee/blob/master/products/models.py</a></p>\n<p>ecommerce_storee/products/documents.py/</p>\n<p>ecommerce_storee/products/urls.py/</p>\n<p>ecommerce_storee/products/views.py/</p>\n<p>ecommerce_storee/products/viewsets.py/</p>\n<p>My Redis giving warning:\n<a href=\"https://i.stack.imgur.com/9E76O.png\" rel=\"nofollow noreferrer\">Redis Warning</a></p>\n<p>My Logging Messages:\n<a href=\"https://i.stack.imgur.com/jtOjP.png\" rel=\"nofollow noreferrer\">Log Messages</a></p>\n<p>POST request's response:\n<a href=\"https://i.stack.imgur.com/3R0YK.png\" rel=\"nofollow noreferrer\">POST request's response</a></p>\n<p>Question: What do I do here? Is it an SSL issue or an elasticsearch issue?</p>\n<p>I've tried disabling elasticsearch but to no avail and also tried adding product via MySQL and it worked!</p>\n<p><strong>P.S.</strong> StackOverflow would not allow me to paste the images but is itself making links out of them.</p>\n<p><strong>Thank you for any help!</strong></p>\n",
                    "OwnerUserId": "15595083",
                    "LastEditorUserId": "15595083",
                    "LastEditDate": "2022-03-21T21:01:44.410",
                    "LastActivityDate": "2022-03-21T21:01:44.410",
                    "Title": "\"Connection Error\" When Adding A Product Through Admin Panel",
                    "Tags": "<django><elasticsearch><django-rest-framework><redis><mysql-python>",
                    "AnswerCount": "0",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "71532394",
                "ParentRepo": "https://github.com/AngellusMortis/sxm-player",
                "StackOverflow_Post": {
                    "Id": "71532394",
                    "PostTypeId": "1",
                    "CreationDate": "2022-03-18T19:41:44.483",
                    "Score": "1",
                    "ViewCount": "474",
                    "Body": "<p>May I ask for some help? I am attempting to clone an existing GitHub project and am struggling to identify what I could be doing wrong.  The project is a pluggable SXM music player written in Python ( <a href=\"https://github.com/AngellusMortis/sxm-player\" rel=\"nofollow noreferrer\">https://github.com/AngellusMortis/sxm-player</a>), that I've cloned and attempted to run through Visual Studio Code (v1.65.2).  Upon executing the project, <strong>the code returns an error - &quot;Exception has occurred: AttributeError module 'select' has no attribute 'poll'&quot;</strong>. Little doubt that I must be doing something incorrectly - but to this point, I haven't been able to identify what I need to do differently to get it to run properly.  My sincerest apologies for needing to ask this probably simple question on this forum, but I know that this would be the place to find the experience to get this package up and running and <strong>any assistance would be greatly appreciated</strong>.</p>\n<p>Here is the traceback for the error message:</p>\n<pre><code>File &quot;C:\\GitHub\\sxm-player\\sxm_player\\utils.py&quot;, line 173, in FFmpeg\n    _stderr_poll: Optional[select.poll] = None\nFile &quot;C:\\GitHub\\sxm-player\\sxm_player\\utils.py&quot;, line 169, in &lt;module&gt;\n    class FFmpeg:\nFile &quot;C:\\GitHub\\sxm-player\\sxm_player\\runner.py&quot;, line 9, in &lt;module&gt;\n    from sxm_player.utils import configure_root_logger\nFile &quot;C:\\GitHub\\sxm-player\\sxm_player\\handlers.py&quot;, line 6, in &lt;module&gt;\n    from sxm_player.runner import Runner, Worker\nFile &quot;C:\\GitHub\\sxm-player\\sxm_player\\cli.py&quot;, line 23, in &lt;module&gt;\n    from sxm_player import handlers\nFile &quot;C:\\GitHub\\sxm-player\\sxm_player\\__main__.py&quot;, line 3, in &lt;module&gt;\n    from sxm_player.cli import main\n</code></pre>\n",
                    "OwnerUserId": "303160",
                    "LastEditorUserId": "303160",
                    "LastEditDate": "2022-03-18T19:51:51.793",
                    "LastActivityDate": "2022-03-18T19:51:51.793",
                    "Title": "AttributeError module 'select' has no attribute 'poll'",
                    "Tags": "<python><github><attributeerror>",
                    "AnswerCount": "0",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "71543529",
                "ParentRepo": "https://github.com/jonra1993/fastapi-alembic-sqlmodel-async/blob/main/fastapi-alembic-sqlmodel-async/app/schemas/response_schema.py",
                "StackOverflow_Post": {
                    "Id": "71543529",
                    "PostTypeId": "2",
                    "ParentId": "69507122",
                    "CreationDate": "2022-03-20T02:09:27.770",
                    "Score": "5",
                    "Body": "<p>Also, You can create a custom responses using generic types as follow if you plan to reuse a response template</p>\n<pre><code>from typing import Any, Generic, List, Optional, TypeVar\nfrom pydantic import BaseModel\nfrom pydantic.generics import GenericModel\n\nDataType = TypeVar(&quot;DataType&quot;)\n\nclass IResponseBase(GenericModel, Generic[DataType]):\n    message: str = &quot;&quot;\n    meta: dict = {}\n    items: Optional[DataType] = None\n</code></pre>\n<pre><code>\n@router.get('/articles/', response_model=IResponseBase[List[Articles]])\nasync def main_endpoint():\n    query = articles_model.articles.select().where(articles_model.articles.c.status == 2)\n    items=await db.database.fetch_all(query)\n    return IResponseBase[List[Articles]](items=items)\n\n</code></pre>\n<p>You can find a FastAPI template here\n<a href=\"https://github.com/jonra1993/fastapi-alembic-sqlmodel-async/blob/main/fastapi-alembic-sqlmodel-async/app/schemas/response_schema.py\" rel=\"nofollow noreferrer\">https://github.com/jonra1993/fastapi-alembic-sqlmodel-async/blob/main/fastapi-alembic-sqlmodel-async/app/schemas/response_schema.py</a></p>\n",
                    "OwnerUserId": "12538106",
                    "LastEditorUserId": "12538106",
                    "LastEditDate": "2022-11-02T03:24:18.097",
                    "LastActivityDate": "2022-11-02T03:24:18.097",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "71562082",
                "ParentRepo": "https://github.com/roman-right/beanie/blob/main/tests/odm/documents/test_bulk_write.py",
                "StackOverflow_Post": {
                    "Id": "71562082",
                    "PostTypeId": "1",
                    "CreationDate": "2022-03-21T18:00:46.843",
                    "Score": "0",
                    "ViewCount": "1077",
                    "Body": "<p>I am using <code>beanie==1.10.1</code></p>\n<p>I want to perform bulk operation with updating multiple documents with <code>upsert=True</code>. I expect following code to insert full document if find query didn't give results.\nI was using this as a reference: <a href=\"https://github.com/roman-right/beanie/blob/main/tests/odm/documents/test_bulk_write.py\" rel=\"nofollow noreferrer\">https://github.com/roman-right/beanie/blob/main/tests/odm/documents/test_bulk_write.py</a></p>\n<p>Here is full code:</p>\n<pre><code>import beanie\nimport asyncio\nimport random\nfrom beanie import BulkWriter\nfrom beanie.odm.operators.update.general import Set\nfrom motor.motor_asyncio import AsyncIOMotorClient\n\n\nclass TestDoc(beanie.Document):\n    a: str\n    b: int\n\n\nasync def init_mongo():\n    mongo_client = AsyncIOMotorClient(&quot;mongodb://127.0.0.1:27017&quot;)\n    await beanie.init_beanie(\n        database=mongo_client.db_name, document_models=[TestDoc]\n    )\n\n\nasync def run_test():\n    await init_mongo()\n\n    docs = [TestDoc(a=f&quot;id_{i}&quot;, b=random.randint(1, 100)) for i in range(10)]\n    async with BulkWriter() as bulk_writer:\n        for doc in docs:\n            await TestDoc \\\n                .find_one({TestDoc.a: doc.a}, bulk_writer=bulk_writer) \\\n                .upsert(Set({TestDoc.b: doc.b}), on_insert=doc, bulk_writer=bulk_writer)\n                # .update_one(Set(doc), bulk_writer=bulk_writer, upsert=True)\n\n    read_docs = await TestDoc.find().to_list()\n    print(f&quot;read_docs: {read_docs}&quot;)\n\n\nif __name__ == '__main__':\n    pool = asyncio.get_event_loop()\n    pool.run_until_complete(run_test())\n\n</code></pre>\n<p>After executing no documents are inserted into db. Not with <code>.upsert()</code> nor with <code>.update_one()</code> method. What is correct way to achieve that logic?</p>\n<p>With <code>pymongo</code> such operation would be written like so (and it works):</p>\n<pre><code>def write_reviews(self, docs: List[TestDoc]):\n    operations = []\n    for doc in docs:\n        doc_dict = to_dict(doc)\n        update_operation = pymongo.UpdateOne(\n            {&quot;a&quot;: doc.a}, {&quot;$set&quot;: doc_dict}, upsert=True\n        )\n        operations.append(update_operation)\n\n    result = self.test_collection.bulk_write(operations)\n \n</code></pre>\n<p>PS: Cannot create <code>beanie</code> tag here. Can someone create it for me?</p>\n",
                    "OwnerUserId": "7968764",
                    "LastEditorUserId": "7968764",
                    "LastEditDate": "2022-03-21T18:08:04.387",
                    "LastActivityDate": "2022-09-04T01:56:19.863",
                    "Title": "Python `beanie` mongo ODM: Bulk update with upsert=True",
                    "Tags": "<python><mongodb><python-asyncio><tornado-motor>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "71567283",
                "ParentRepo": "https://github.com/awtkns/fastapi-crudrouter",
                "StackOverflow_Post": {
                    "Id": "71567283",
                    "PostTypeId": "2",
                    "ParentId": "69426613",
                    "CreationDate": "2022-03-22T05:26:37.750",
                    "Score": "1",
                    "Body": "<p>It appears you are using fastapi.  If so, what about <a href=\"https://github.com/awtkns/fastapi-crudrouter\" rel=\"nofollow noreferrer\">fastapi-crudrouter</a>? It did the bulk of the work for me.  While googling for the fastapi-crudrouter link, I found another project <a href=\"https://github.com/LuisLuii/FastAPIQuickCRUD\" rel=\"nofollow noreferrer\">FastAPIQuickCrud</a>. Just skimming, but it seems to solve the same problem.</p>\n",
                    "OwnerUserId": "759485",
                    "LastActivityDate": "2022-03-22T05:26:37.750",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "71675496",
                "ParentRepo": "https://github.com/sethmlarson/truststore",
                "StackOverflow_Post": {
                    "Id": "71675496",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "71812035",
                    "CreationDate": "2022-03-30T10:25:09.243",
                    "Score": "-1",
                    "ViewCount": "953",
                    "Body": "<p>I am able to connect to a certain URL with cURL, <strong>after I installed the corresponding SSL certificates</strong>:</p>\n<pre><code>$ export MY_URL=https://www.infosubvenciones.es/bdnstrans/GE/es/convocatoria/616783\n$ curl -vvvv $MY_URL  # Fails\n$ sudo openssl x509 -inform pem -outform pem -in /tmp/custom-cert.pem -out /usr/local/share/ca-certificates/custom-cert.crt\n$ sudo update-ca-certificates\n$ curl -vvvv $MY_URL  # OK\n</code></pre>\n<p>However, requests (or httpx, or any other library I use) refuses to do so:</p>\n<pre class=\"lang-py prettyprint-override\"><code>In [1]: import os\n   ...: import requests\n   ...: requests.get(os.environ[&quot;MY_URL&quot;])\n---------------------------------------------------------------------------\nSSLCertVerificationError                  Traceback (most recent call last)\n...\n\nSSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:997)\n</code></pre>\n<p>My understanding is that requests uses <code>certifi</code> and as such these custom certificates are not available here:</p>\n<pre><code>In [1]: import certifi\n\nIn [2]: certifi.where()\nOut[2]: '/tmp/test_ca/.venv/lib/python3.10/site-packages/certifi/cacert.pem'\n</code></pre>\n<p>I have already tried a number of things, like trying to use the system CA bundle:</p>\n<ul>\n<li><code>export REQUESTS_CA_BUNDLE=/etc/ssl/certs/ca-certificates.crt</code> same error</li>\n<li><code>requests.get(..., verify=&quot;/etc/ssl/certs/ca-certificates.crt&quot;)</code> same error</li>\n<li>switched to httpx + a custom SSL context as explained in <a href=\"https://www.python-httpx.org/advanced/#ssl-certificates\" rel=\"nofollow noreferrer\">the docs</a>, same error</li>\n<li>attempted <a href=\"https://github.com/sethmlarson/truststore\" rel=\"nofollow noreferrer\"><code>truststore</code></a> as discussed in <a href=\"https://github.com/encode/httpx/issues/302\" rel=\"nofollow noreferrer\">this httpx issue</a>, same error</li>\n</ul>\n<p>How can I make Python (requests, httpx, raw <code>ssl</code>, anything) use the same certificates that cURL is successfully using?</p>\n<p>The only thing that worked so far, inspired by <a href=\"https://stackoverflow.com/a/54385130/554319\">this hackish SO answer</a>, is to do <code>verify=False</code>. But I don't want to do that.</p>\n<pre><code>In [9]: requests.get(\n   ...:     my_url,\n   ...:     verify=False,\n   ...: )\n/tmp/test_ca/.venv/lib/python3.10/site-packages/urllib3/connectionpool.py:1043: InsecureRequestWarning: Unverified HTTPS request is being made to host 'xxx'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n\n</code></pre>\n",
                    "OwnerUserId": "554319",
                    "LastEditorUserId": "554319",
                    "LastEditDate": "2022-04-05T13:53:29.840",
                    "LastActivityDate": "2022-04-09T21:30:14.177",
                    "Title": "can connect to URL with curl but not with requests (i.e. requests ignoring my CA bundle?)",
                    "Tags": "<python><ssl><curl><python-requests><httpx>",
                    "AnswerCount": "1",
                    "CommentCount": "2",
                    "FavoriteCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "71681759",
                "ParentRepo": "https://github.com/supabase-community/postgrest-py/commit/1737e698d1ab5c8b740acef8d506dfc56cac9ca9",
                "StackOverflow_Post": {
                    "Id": "71681759",
                    "PostTypeId": "2",
                    "ParentId": "71639002",
                    "CreationDate": "2022-03-30T17:39:45.603",
                    "Score": "1",
                    "Body": "<p>You are using outdated versions of <a href=\"https://pypi.org/project/postgrest-py/\" rel=\"nofollow noreferrer\">postgrest-py</a> (&lt; 0.5.0) and <a href=\"https://pypi.org/project/supabase/\" rel=\"nofollow noreferrer\">supabase</a> (&lt; 0.1.1).</p>\n<p>The error is likely caused by accidentally downgrading <code>postgrest-py</code>.</p>\n<p>You should be able to fix this by running <code>pip install -U supabase</code>, which upgrades <code>supabase</code> (currently 0.5.3) and installs the compatible version of <code>postgrest-py</code> (currently 0.9.2).<br />\n<sub><em>Omit the <code>-U</code> flag if you only want to install the compatible version of <code>postgrest-py</code> without upgrading <code>supabase</code>.</em></sub></p>\n<h1>References</h1>\n<ul>\n<li><a href=\"https://github.com/supabase-community/postgrest-py/commit/1737e698d1ab5c8b740acef8d506dfc56cac9ca9\" rel=\"nofollow noreferrer\">supabase-community/postgrest-py@1737e69</a> (postgrest-py 0.5.0) started to accept <code>headers</code> in <code>PostgrestClient</code> <code>__init__</code>.</li>\n<li><a href=\"https://github.com/supabase-community/supabase-py/commit/04bf6ef1c854683b6ae1eb9b56b6273e147b2ed3\" rel=\"nofollow noreferrer\">supabase-community/supabase-py@04bf6ef</a> (supabase 0.3.0, depends on postgrest-py&lt;0.9.0 and &gt;=0.8.0) started to pass <code>headers</code> when instantiating <code>PostgrestClient</code>.</li>\n<li><a href=\"https://github.com/supabase-community/supabase-py/commit/66db7d3d45e898242551543dca85431aa2101060\" rel=\"nofollow noreferrer\">supabase-community/supabase-py@66db7d3</a> (supabase 0.1.1) switched to use <code>SyncPostgrestClient</code>; <code>PostgrestClient</code> was deprecated in <code>postgrest-py</code> 0.6.0.</li>\n</ul>\n",
                    "OwnerUserId": "8601760",
                    "LastActivityDate": "2022-03-30T17:39:45.603",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "71741367",
                "ParentRepo": "https://github.com/smagafurov/fastapi-jsonrpc",
                "StackOverflow_Post": {
                    "Id": "71741367",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "71741504",
                    "CreationDate": "2022-04-04T17:28:31.980",
                    "Score": "-1",
                    "ViewCount": "169",
                    "Body": "<p>I had a requirement of migrating twisted to FastApi.</p>\n<p>The old code was completely written in Python 2.7 and used JsonPrc along with twisted client.</p>\n<p>Like - [https://stackoverflow.com/a/4738563][1]</p>\n<p>Even the static content like html,css,js files used jsonprc to access the API calls. Like there is a complete <strong>index.html</strong> file which has dependency on html,css, js with jsonprc calls.</p>\n<p>I have gone through some documents but couldn't come to conclusion.</p>\n<p>Below were few links-</p>\n<p><a href=\"https://github.com/smagafurov/fastapi-jsonrpc\" rel=\"nofollow noreferrer\">https://github.com/smagafurov/fastapi-jsonrpc</a></p>\n<p><a href=\"https://github.com/authorizon/fastapi_websocket_rpc\" rel=\"nofollow noreferrer\">https://github.com/authorizon/fastapi_websocket_rpc</a></p>\n<p>In these I cant see how to integrate html,css,js with jsonrpc. for eg., <strong>index.html</strong></p>\n<p>So I just want to know the approach to achieve my requirement.</p>\n<p>Like websocket, jsonrpc or jinja Template ? Thanks</p>\n",
                    "OwnerUserId": "16582846",
                    "LastActivityDate": "2022-04-04T17:38:35.763",
                    "Title": "Approach to Migrate from twisted to fastapi Framework",
                    "Tags": "<python><python-3.x><twisted><fastapi><json-rpc>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ClosedDate": "2022-04-05T12:00:57.417",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "71879852",
                "ParentRepo": "https://github.com/nazmulnnb/fastapi-paginate/blob/main/examples/pagination_motor.py",
                "StackOverflow_Post": {
                    "Id": "71879852",
                    "PostTypeId": "2",
                    "ParentId": "67571946",
                    "CreationDate": "2022-04-15T03:44:58.297",
                    "Score": "1",
                    "Body": "<p>You can use this package to paginate:\n<a href=\"https://pypi.org/project/fastapi-paginate\" rel=\"nofollow noreferrer\">https://pypi.org/project/fastapi-paginate</a></p>\n<p>How to use it:\n<a href=\"https://github.com/nazmulnnb/fastapi-paginate/blob/main/examples/pagination_motor.py\" rel=\"nofollow noreferrer\">https://github.com/nazmulnnb/fastapi-paginate/blob/main/examples/pagination_motor.py</a></p>\n",
                    "OwnerUserId": "3077037",
                    "LastActivityDate": "2022-04-15T03:44:58.297",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "71888066",
                "ParentRepo": "https://github.com/WhiteApfel/pyQiwiP2P/blob/4760b788edb36ac01fb354cd2b82780c43e4e4e1/pyqiwip2p/Qiwip2p.py#L118",
                "StackOverflow_Post": {
                    "Id": "71888066",
                    "PostTypeId": "2",
                    "ParentId": "71887305",
                    "CreationDate": "2022-04-15T19:18:48.427",
                    "Score": "1",
                    "Body": "<p>This looks to be a bug in pyQiwiP2P.</p>\n<p>As per your traceback, <a href=\"https://github.com/WhiteApfel/pyQiwiP2P/blob/4760b788edb36ac01fb354cd2b82780c43e4e4e1/pyqiwip2p/Qiwip2p.py#L118\" rel=\"nofollow noreferrer\">line 118 of pyqiwip2p.Qiwip2p.py</a> is as follows:</p>\n<pre class=\"lang-py prettyprint-override\"><code>        pay_sources: list[str] = None,\n</code></pre>\n<p>This contains a broken type hint, <code>list[str]</code>. It seems the author wanted to add a type hint saying that the method parameter <code>pay_sources</code> should contain a list of strings. In this case, they should write</p>\n<pre class=\"lang-py prettyprint-override\"><code>        pay_sources: typing.List[str] = None,\n</code></pre>\n<p>or perhaps</p>\n<pre class=\"lang-py prettyprint-override\"><code>        pay_sources: typing.Union[typing.List[str], None] = None,\n</code></pre>\n<p>instead, given that <code>pay_sources</code> can also be <code>None</code>.</p>\n<p>To confirm this is the case, we can easily reproduce your exception in a Python interactive session:</p>\n<pre class=\"lang-none prettyprint-override\"><code>&gt;&gt;&gt; def test(a: list[str]):\n...     pass\n...\nTraceback (most recent call last):\n  File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;\nTypeError: 'type' object is not subscriptable\n</code></pre>\n<p>I would suggest you get in contact with the package author, perhaps by raising an issue on the <a href=\"https://github.com/WhiteApfel/pyQiwiP2P\" rel=\"nofollow noreferrer\">project's GitHub repository</a>.</p>\n",
                    "OwnerUserId": "48503",
                    "LastActivityDate": "2022-04-15T19:18:48.427",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "71960264",
                "ParentRepo": "https://github.com/suddenAppearance/fastapi_urlshortener/tree/master",
                "StackOverflow_Post": {
                    "Id": "71960264",
                    "PostTypeId": "2",
                    "ParentId": "71960083",
                    "CreationDate": "2022-04-21T19:58:35.607",
                    "Score": "0",
                    "Body": "<p>Ok, I recently was digging in Python type hinting abilities and came up with something like that</p>\n<pre><code>DBModel = TypeVar('DBModel')\n\nclass BaseRepository(Generic[DBModel]):\n\n    def __init__(self):\n        self.model: Type[DBModel] = get_args(self.__orig_bases__[0])[0]\n\n    def get_where(self, *args) -&gt; DBModel\n        ...  # any logic with self.model\n</code></pre>\n<p>as a base class and</p>\n<pre><code>class UsersRepository(BaseRepository[User]):\n    pass\n</code></pre>\n<p><code>UsersRepository</code> will now have already implemented <code>get_where()</code> with <code>User</code> model and will also have reference for <code>User</code> inside <code>self.model</code></p>\n<p>I guess that's what you want. <a href=\"https://github.com/suddenAppearance/fastapi_urlshortener/tree/master\" rel=\"nofollow noreferrer\">Github</a> with source code (small project actually.)</p>\n",
                    "OwnerUserId": "14882395",
                    "LastActivityDate": "2022-04-21T19:58:35.607",
                    "CommentCount": "8",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "72188495",
                "ParentRepo": "https://github.com/microsoft/msticpy/issues/393",
                "StackOverflow_Post": {
                    "Id": "72188495",
                    "PostTypeId": "2",
                    "ParentId": "72184418",
                    "CreationDate": "2022-05-10T14:47:03.483",
                    "Score": "0",
                    "Body": "<p>The author of msticpy has posted the issue on github &amp; we have to wait for the latest release. Please follow the thread for more details:</p>\n<p><a href=\"https://github.com/microsoft/msticpy/issues/393\" rel=\"nofollow noreferrer\">https://github.com/microsoft/msticpy/issues/393</a></p>\n",
                    "OwnerUserId": "10927566",
                    "LastActivityDate": "2022-05-10T14:47:03.483",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "72261789",
                "ParentRepo": "https://github.com/returntocorp/semgrep-rules",
                "StackOverflow_Post": {
                    "Id": "72261789",
                    "PostTypeId": "2",
                    "ParentId": "72261717",
                    "CreationDate": "2022-05-16T15:33:41.383",
                    "Score": "3",
                    "Body": "<p>The best way to find all rule yaml files from Semgrep is through the <a href=\"https://github.com/returntocorp/semgrep-rules\" rel=\"nofollow noreferrer\">Semgrep Rules Github Repository</a>. You can use the rule-id to search for it using the <strong>&quot;Go to file&quot;</strong> button within the repo:</p>\n<p><a href=\"https://i.stack.imgur.com/OBRbt.png\" rel=\"nofollow noreferrer\">&quot;Go to file button within repo&quot;</a></p>\n<p><a href=\"https://i.stack.imgur.com/h55bo.png\" rel=\"nofollow noreferrer\">&quot;Searching for rules via rule-id&quot;</a>.</p>\n<p>Once you have located the rule you wish to download, right-click on the <strong>&quot;Raw&quot;</strong> button and then click <strong>&quot;Save link as...&quot;</strong> to download the yaml file directly.</p>\n<p><a href=\"https://i.stack.imgur.com/TdC9J.png\" rel=\"nofollow noreferrer\">&quot;Rule yaml file within repo&quot;</a></p>\n",
                    "OwnerUserId": "19103295",
                    "LastActivityDate": "2022-05-16T15:33:41.383",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "72275164",
                "ParentRepo": "https://github.com/isaackogan/TikTokLive",
                "StackOverflow_Post": {
                    "Id": "72275164",
                    "PostTypeId": "1",
                    "CreationDate": "2022-05-17T13:45:16.370",
                    "Score": "0",
                    "ViewCount": "143",
                    "Body": "<p>I wrote this code to determine whether a TikTok live video is (live now) or (ended) one.</p>\n<p>After getting the result (live now or not), it keeps running and giving the result... I want to stop the API connection after having the result for one time.</p>\n<p>For example: <code>client.stop()</code> but I can't where to type that...</p>\n<p>Documentation <a href=\"https://github.com/isaackogan/TikTokLive\" rel=\"nofollow noreferrer\">https://github.com/isaackogan/TikTokLive</a></p>\n<p>Using the following code:</p>\n<pre><code>from TikTokLive import TikTokLiveClient\nfrom TikTokLive.types.events import ViewerCountUpdateEvent\nfrom TikTokLive.types.errors import FailedConnection\n\n\nclass TikTok:\n    &quot;&quot;&quot;\n    This class is to determine whether a TikTok live video is (live now) or (ended) one.\n    &quot;&quot;&quot;\n\n    @staticmethod\n    def is_live(url):\n        &quot;&quot;&quot;\n        This method will count the viewers and decide whether it is a current live or not.\n        &quot;&quot;&quot;\n        client: TikTokLiveClient = TikTokLiveClient(\n            unique_id=url, **(\n                {&quot;fetch_room_info_on_connect&quot;: True}\n            )\n        )\n\n        @client.on(&quot;viewer_count_update&quot;)\n        async def on_connect(event: ViewerCountUpdateEvent):\n            # since we have views, so it is live!\n            print(&quot;The live is running now.&quot;)\n\n        try:\n            client.run()\n\n        except FailedConnection:\n            # if there is no views, it will gives error, so I handled that here.\n            print(&quot;The video is no longer live.&quot;)\n\n# pass the live video username.\nis_livestream = TikTok.is_live(url=&quot;radwanghaddar&quot;)\n</code></pre>\n",
                    "OwnerDisplayName": "user18532875",
                    "LastEditorDisplayName": "user18532875",
                    "LastEditDate": "2022-05-17T14:10:55.423",
                    "LastActivityDate": "2022-05-17T14:10:55.423",
                    "Title": "How to stop an API connection using Python",
                    "Tags": "<python><tiktok>",
                    "AnswerCount": "0",
                    "CommentCount": "6",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "72473661",
                "ParentRepo": "https://github.com/GennadyShelukhin/python_fastapi_sqlmodel_example/blob/main/app/models/shop.py",
                "StackOverflow_Post": {
                    "Id": "72473661",
                    "PostTypeId": "1",
                    "CreationDate": "2022-06-02T09:11:54.080",
                    "Score": "0",
                    "ViewCount": "414",
                    "Body": "<p>I am doing a small project on Fastapi (my first project on it), python 3.10, using sqlalchemy, sqlmodel.\nI have 2 test models: shop and product.\nI want the endpoint <code>shop</code> to return the following structure:</p>\n<pre><code>{\n  &quot;name&quot;: &quot;Adidas&quot;,\n  &quot;id&quot;: 1,\n  &quot;is_main&quot;: true,\n  &quot;products&quot;: [\n    {\n      &quot;id&quot;: 1,\n      &quot;name&quot;: &quot;sneakers&quot;,\n      &quot;shop_id&quot;: 1\n    },\n    {\n      &quot;id&quot;: 2,\n      &quot;name&quot;: &quot;T-shirt&quot;,\n      &quot;shop_id&quot;: 1\n    }\n  ]\n}\n</code></pre>\n<p><a href=\"https://github.com/GennadyShelukhin/python_fastapi_sqlmodel_example/blob/main/app/models/shop.py\" rel=\"nofollow noreferrer\">Full test project on Github</a></p>\n<p>I use <a href=\"https://sqlmodel.tiangolo.com/tutorial/fastapi/relationships/\" rel=\"nofollow noreferrer\">Relationship() from SQLModel</a>:</p>\n<p><code>models</code></p>\n<p><code>product.py</code></p>\n<pre><code>from sqlmodel import SQLModel, Field, Relationship\nfrom typing import TYPE_CHECKING, Optional\n\nif TYPE_CHECKING:\n    from app.models.shop import Shop\n\n\nclass ProductBase(SQLModel):\n    name: Optional[str] = None\n    shop_id: int = Field(default=None, foreign_key=&quot;shop.id&quot;)\n\n\nclass Product(ProductBase, table=True):\n\n    __tablename__ = &quot;product&quot;\n\n    id: Optional[int] = Field(default=None, primary_key=True, nullable=False)\n    shop: Optional[&quot;Shop&quot;] = Relationship(back_populates=&quot;products&quot;)\n\n\nclass ProductRead(ProductBase):\n    id: int\n\n\nclass ProductCreate(ProductBase):\n    pass\n</code></pre>\n<p><code>shop.py</code></p>\n<pre><code>from sqlmodel import SQLModel, Field, Relationship\nfrom typing import TYPE_CHECKING, List, Optional\n\nif TYPE_CHECKING:\n    from app.models.product import Product, ProductRead\n\n\nclass ShopBase(SQLModel):\n    name: Optional[str] = None\n\n\nclass Shop(ShopBase, table=True):\n\n    __tablename__ = &quot;shop&quot;\n\n    id: Optional[int] = Field(default=None, primary_key=True, nullable=False)\n    products: List[&quot;Product&quot;] = Relationship(back_populates=&quot;shop&quot;)\n\n\nclass ShopRead(ShopBase):\n    id: int\n\n\nclass ShopGet(ShopRead):\n    products: List[&quot;ProductRead&quot;] = []\n    is_main: bool = True\n\n\nclass ShopCreate(ShopBase):\n    pass\n</code></pre>\n<p><code>repositories</code></p>\n<p><code>product.py</code></p>\n<pre><code>from typing import Optional\n\nfrom sqlalchemy.future import select\nfrom app.models.product import Product, ProductCreate\nfrom app.repositories.base import BaseRepository\n\n\nclass ProductRepository(BaseRepository):\n\n    async def create(self, product: ProductCreate) -&gt; Product:\n        db_product = Product.from_orm(product)\n        self.session.add(db_product)\n        await self.session.commit()\n        await self.session.refresh(db_product)\n        return db_product\n\n    async def get_by_id(self, product_id: int) -&gt; Optional[Product]:\n        result = await self.session.get(Product, int(product_id))\n        return result\n</code></pre>\n<p><code>shop.py</code></p>\n<pre><code>from typing import Optional\n\nfrom sqlalchemy.future import select\nfrom app.models.shop import Shop, ShopCreate, ShopGet\nfrom app.repositories.base import BaseRepository\n\n\nclass ShopRepository(BaseRepository):\n\n    async def create(self, shop: ShopCreate) -&gt; Shop:\n        db_shop = Shop.from_orm(shop)\n        self.session.add(db_shop)\n        await self.session.commit()\n        await self.session.refresh(db_shop)\n        return db_shop\n\n    async def get_by_id(self, shop_id: int) -&gt; Optional[ShopGet]:\n        result = await self.session.get(Shop, int(shop_id))\n        return result\n</code></pre>\n<p><code>endpoints</code></p>\n<p><code>shop.py</code></p>\n<pre><code>from fastapi import APIRouter, Depends, Query\nfrom app.repositories.shop import ShopRepository\nfrom app.models.shop import Shop, ShopCreate, ShopGet\nfrom app.endpoints.depends import get_shop_repository\n\n\nrouter = APIRouter()\n\n\n@router.get(&quot;/get_by_id&quot;, response_model=ShopGet)\nasync def get_by_id(\n        shop_id: int = Query(description=&quot;Shop ID&quot;),\n        shop: ShopRepository = Depends(get_shop_repository)):\n    return await shop.get_by_id(shop_id=shop_id)\n\n\n@router.post(&quot;/create&quot;, response_model=Shop)\nasync def create(\n        name: str = Query(description=&quot;Shop name&quot;),\n        shop: ShopRepository = Depends(get_shop_repository)):\n    return await shop.create(shop=ShopCreate(name=name))\n</code></pre>\n<p><code>db connect</code></p>\n<pre><code>from sqlalchemy.ext.asyncio import create_async_engine\nfrom sqlalchemy.orm import sessionmaker\nfrom sqlmodel.ext.asyncio.session import AsyncSession\n\nfrom app import settings\n\n\nasync_engine = create_async_engine(settings.db_async_connection_str, echo=True, future=True)\n\n\nasync def get_async_session() -&gt; AsyncSession:\n    async_session = sessionmaker(\n        bind=async_engine, class_=AsyncSession, expire_on_commit=False\n    )\n    async with async_session() as session:\n        yield session\n\n</code></pre>\n<p>I have 2 problems:</p>\n<ol>\n<li>Exception <code>TypeError: issubclass() arg 1 must be a class</code> when open swagger.\nReason:</li>\n</ol>\n<pre><code>if TYPE_CHECKING:\n    from app.models.product import Product, ProductRead\n\nclass ShopGet(ShopRead):\n    products: List[&quot;ProductRead&quot;] = []\n</code></pre>\n<p>But this is necessary due to <a href=\"https://sqlmodel.tiangolo.com/tutorial/code-structure/?h=import#make-circular-imports-work\" rel=\"nofollow noreferrer\">circular imports</a></p>\n<ol start=\"2\">\n<li>Main problem:</li>\n</ol>\n<p>Endpoint <code>shop</code> (shop_id=1) return empty products list. <a href=\"https://github.com/GennadyShelukhin/python_fastapi_sqlmodel_example/blob/main/app/models/shop.py\" rel=\"nofollow noreferrer\">Details</a>. There are 2 products in the database with shop_id=1.</p>\n<p><a href=\"https://ru.stackoverflow.com/questions/1415495/%D0%9A%D0%B0%D0%BA-%D0%BF%D1%80%D0%B0%D0%B2%D0%B8%D0%BB%D1%8C%D0%BD%D0%BE-%D0%B2%D0%BE%D0%B7%D0%B2%D1%80%D0%B0%D1%89%D0%B0%D1%82%D1%8C-%D0%B2-%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D0%B8-%D1%81%D0%BF%D0%B8%D1%81%D0%BE%D0%BA-%D0%B8%D0%B7-%D1%81%D1%83%D1%89%D0%BD%D0%BE%D1%81%D1%82%D0%B5%D0%B9-%D0%BF%D1%80%D0%B8%D0%BD%D0%B0%D0%B4%D0%BB%D0%B5%D0%B6%D0%B0%D1%89%D0%B8%D1%85-%D1%81%D0%B2%D1%8F%D0%B7%D0%B0%D0%BD%D0%BD%D0%BE%D0%B9-%D0%BC\">This question in Russian</a></p>\n",
                    "OwnerUserId": "15739127",
                    "LastEditorUserId": "15739127",
                    "LastEditDate": "2022-06-02T09:57:02.047",
                    "LastActivityDate": "2022-06-03T08:10:45.680",
                    "Title": "What is the correct way to return models to the list of entities owned by the related one?",
                    "Tags": "<python><sqlalchemy><fastapi><sqlmodel>",
                    "AnswerCount": "1",
                    "CommentCount": "2",
                    "FavoriteCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "72556076",
                "ParentRepo": "https://github.com/spec-first/connexion/pull/1475/files#diff-bdf30be2de6c3619889ec27e4b83268b50fa86d49bb01075cffac7f984ecf98bR284",
                "StackOverflow_Post": {
                    "Id": "72556076",
                    "PostTypeId": "1",
                    "CreationDate": "2022-06-09T07:11:21.133",
                    "Score": "0",
                    "ViewCount": "104",
                    "Body": "<p>We've just upgraded connexion (to version 2.13.1) and now we're getting the following deprecation warnings when running unit tests:</p>\n<blockquote>\n<p>DeprecationWarning: x-body-name within the requestBody schema will be deprecated in the next major version. It should be provided directly under the requestBody instead.</p>\n</blockquote>\n<p>This warning shows up even though we don't use <code>x-body-name</code> in the schema.</p>\n<p>Is this a false positive message?</p>\n<p>I see that this warning comes from <a href=\"https://github.com/spec-first/connexion/pull/1475/files#diff-bdf30be2de6c3619889ec27e4b83268b50fa86d49bb01075cffac7f984ecf98bR284\" rel=\"nofollow noreferrer\">the following code</a>:</p>\n<pre><code>    x_body_name = sanitize(self.request_body.get('x-body-name', None))\n\n    if not x_body_name:\n        # x-body-name also accepted in the schema field for legacy connexion compat\n        warnings.warn('x-body-name within the requestBody schema will be deprecated in the '\n                      'next major version. It should be provided directly under '\n                      'the requestBody instead.', DeprecationWarning)\n        x_body_name = sanitize(self.body_schema.get('x-body-name', 'body'))\n</code></pre>\n<p>This seems to output the warning in ALL case where it's not defined in the body whether or not it's defined in the schema (even though it's optional). I verified this by changing the code in connexion to only warn if the name is defined in the schema.</p>\n<p>Am I missing something? Are we using a deprecated feature without being aware of it?</p>\n",
                    "OwnerUserId": "3848",
                    "LastEditorUserId": "3848",
                    "LastEditDate": "2022-06-15T13:25:24.583",
                    "LastActivityDate": "2022-06-15T13:26:15.193",
                    "Title": "Deprecation warning in connexion regarding x-body-name",
                    "Tags": "<python><warnings><connexion>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "72603417",
                "ParentRepo": "https://github.com/roboflow-ai/roboflow-api-snippets/blob/main/Python/webcam/infer-simple.py",
                "StackOverflow_Post": {
                    "Id": "72603417",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "72607930",
                    "CreationDate": "2022-06-13T13:07:40.120",
                    "Score": "0",
                    "ViewCount": "855",
                    "Body": "<p>I tried to run the example <a href=\"https://github.com/roboflow-ai/roboflow-api-snippets/blob/main/Python/webcam/infer-simple.py\" rel=\"nofollow noreferrer\">infer-simple.py</a>, but I can't succeed, because the code is returning a None value when the command line (image = cv2.imdecode(image, cv2.IMREAD_COLOR)) is executed.</p>\n<ol>\n<li>code:</li>\n</ol>\n<pre><code>def infer():\n    # Get the current image from the webcam\n    ret, img = video.read()\n\n    # Resize (while maintaining the aspect ratio) to improve speed and save bandwidth\n    height, width, channels = img.shape\n    scale = ROBOFLOW_SIZE / max(height, width)\n    img = cv2.resize(img, (round(scale * width), round(scale * height)))\n\n    # Encode image to base64 string\n    retval, buffer = cv2.imencode('.jpg', img)\n    img_str = base64.b64encode(buffer)\n\n    # Get prediction from Roboflow Infer API\n    resp = requests.post(upload_url, data=img_str, headers={\n        &quot;Content-Type&quot;: &quot;application/x-www-form-urlencoded&quot;\n    }, stream=True).raw\n\n    # Parse result image\n    image = np.asarray(bytearray(resp.read()), dtype=&quot;uint8&quot;)\n    image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n    \n    return image\n\n</code></pre>\n<p>Always before the imdecode image is array not None, bellow is displayed one debug example.</p>\n<ol start=\"2\">\n<li>Debug</li>\n</ol>\n<pre><code>resp: &lt;urllib3.response.HTTPResponse object at 0x0000015055DE7070&gt;\n\nimage: array([ 11, 214,  13, ..., 170,   1,   3], dtype=uint8)\n</code></pre>\n<p>However, when I run cv2.imdecode(image, cv2.IMREAD_COLOR)) I get a none value for image.</p>\n<p>3.Error</p>\n<pre><code>Exception has occurred: error OpenCV(4.6.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgcodecs\\src\\loadsave.cpp:816: \nerror: (-215:Assertion failed) !buf.empty() in function 'cv::imdecode_'\n\n  File &quot;C:\\Users\\diego\\codes\\Webcam\\infer-simple.py&quot;, line 48, in infer\n    image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n  File &quot;C:\\Users\\diego\\codes\\Webcam\\infer-simple.py&quot;, line 63, in &lt;module&gt;\n    image = infer()\n</code></pre>\n<p>I did it all step by step according to <a href=\"https://blog.roboflow.com/python-webcam\" rel=\"nofollow noreferrer\">https://blog.roboflow.com/python-webcam</a>.</p>\n<p>I applied solutions found on the Internet and also reinstalled all necessary packages but nothing worked.</p>\n",
                    "OwnerUserId": "16993450",
                    "LastEditorUserId": "16993450",
                    "LastEditDate": "2022-06-14T12:12:09.403",
                    "LastActivityDate": "2022-06-14T12:12:09.403",
                    "Title": "Using Webcam with Yolov5 Models",
                    "Tags": "<python><opencv><webcam><yolov5><roboflow>",
                    "AnswerCount": "1",
                    "CommentCount": "9",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "72673644",
                "ParentRepo": "https://github.com/Lightning-AI/lightning/issues/3346#issuecomment-756476073",
                "StackOverflow_Post": {
                    "Id": "72673644",
                    "PostTypeId": "2",
                    "ParentId": "71888793",
                    "CreationDate": "2022-06-19T00:51:26.743",
                    "Score": "1",
                    "Body": "<p>You should remove <code>loss.backward()</code> and return only the computed loss.</p>\n<p>If you want to make special operation before or after, you can use <code>on_before_backward()</code> and <code>on_after_backward()</code>.</p>\n<p>Some changes to make when using Lightning:\n<a href=\"https://pl-bolts-doc-images.s3.us-east-2.amazonaws.com/pl_docs/pt_trainer_mov.m4v\" rel=\"nofollow noreferrer\">changes when using Lightning</a></p>\n<p>Using many optimizers for the same architecture: <a href=\"https://github.com/Lightning-AI/lightning/issues/3346#issuecomment-756476073\" rel=\"nofollow noreferrer\">example</a></p>\n<p>I hope this can help you build your own model.</p>\n",
                    "OwnerUserId": "12230833",
                    "LastActivityDate": "2022-06-19T00:51:26.743",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "72700190",
                "ParentRepo": "https://github.com/insolor/async-tkinter-loop",
                "StackOverflow_Post": {
                    "Id": "72700190",
                    "PostTypeId": "2",
                    "ParentId": "71648197",
                    "CreationDate": "2022-06-21T11:46:04.193",
                    "Score": "1",
                    "Body": "<p>An example with <a href=\"https://github.com/insolor/async-tkinter-loop\" rel=\"nofollow noreferrer\">async-tkinter-loop</a> library (written by me):</p>\n<pre><code>import asyncio\nimport tkinter as tk \nimport sys\n\nfrom async_tkinter_loop import async_handler, async_mainloop\n\n\nclass pseudo_example():\n    def app(self):\n        self.root = tk.Tk()\n        self.root.minsize(100,100)\n\n        start_button = tk.Button(self.root, text=&quot;start&quot;, command=async_handler(self.await_fun))\n        start_button.pack()\n\n        self.testfield = tk.Label(self.root, text=&quot;test&quot;)\n        self.testfield.pack()\n\n        async_mainloop(self.root)\n\n    async def await_fun(self):\n        self.testfield[&quot;text&quot;] = &quot;start waiting&quot;\n        await asyncio.sleep(2)\n        self.testfield[&quot;text&quot;] = &quot;end waiting&quot;\n\n\nif __name__ == '__main__':\n    gui = pseudo_example()\n    gui.app()\n</code></pre>\n",
                    "OwnerUserId": "4752653",
                    "LastEditorUserId": "4752653",
                    "LastEditDate": "2022-06-23T09:21:01.727",
                    "LastActivityDate": "2022-06-23T09:21:01.727",
                    "CommentCount": "3",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "72702513",
                "ParentRepo": "https://github.com/replicate/cog",
                "StackOverflow_Post": {
                    "Id": "72702513",
                    "PostTypeId": "1",
                    "CreationDate": "2022-06-21T14:24:26.153",
                    "Score": "1",
                    "ViewCount": "32",
                    "Body": "<p>I'm considering <a href=\"https://github.com/replicate/cog\" rel=\"nofollow noreferrer\">Cog</a> and <a href=\"https://github.com/triton-inference-server/server\" rel=\"nofollow noreferrer\">Triton Inference Server</a> for inference in production.\nDoes someone know what is the difference in capabilities as well as in run times between the two, especially on AWS?</p>\n",
                    "OwnerUserId": "8580622",
                    "LastActivityDate": "2022-06-21T14:24:26.153",
                    "Title": "Cog vs Triton Inference Server",
                    "Tags": "<production><replicate><triton><tritonserver>",
                    "AnswerCount": "0",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "72812866",
                "ParentRepo": "https://github.com/abhinavkulkarni/Stackoverflow-Issues/tree/2022-06-28",
                "StackOverflow_Post": {
                    "Id": "72812866",
                    "PostTypeId": "1",
                    "CreationDate": "2022-06-30T08:49:29.413",
                    "Score": "0",
                    "ViewCount": "77",
                    "Body": "<p>I have two very simple FastAPI APIs running in their respective docker containers with corresponding ports opened (ports <code>8000</code> and <code>8001</code>). The code can be found <a href=\"https://github.com/abhinavkulkarni/Stackoverflow-Issues/tree/2022-06-28\" rel=\"nofollow noreferrer\">here</a>.</p>\n<p>Both have an <code>/index</code> endpoint, the 2nd APIs <code>/index</code> endpoint redirects to the 1st.</p>\n<p>The first API's <code>/index</code> endpoint looks as follows:</p>\n<pre class=\"lang-py prettyprint-override\"><code>@app.get(&quot;/index&quot;)\nasync def index():\n    return JSONResponse(content={&quot;message&quot;: &quot;Welcome to my API 1!&quot;}, status_code=200)\n</code></pre>\n<p>The 2nd API's <code>/index</code> endpoint looks like the following:</p>\n<pre class=\"lang-py prettyprint-override\"><code>@app.get(&quot;/index&quot;)\nasync def index2():\n    api1_url = os.getenv('MYAPI1_URL')\n    return RedirectResponse(url=f&quot;{api1_url}/index&quot;)\n</code></pre>\n<p>where <code>MYAPI1_URL=http://{HOST_IP}:8000</code></p>\n<p>However, when I cURL <code>/index</code> endpoint of 2nd API, I am not automatically redirected to <code>/index</code> endpoint of 1st API.</p>\n<pre class=\"lang-bash prettyprint-override\"><code># No response without -L flag\n$ curl -X GET -i http://${HOST_IP}:8001/index\n\nHTTP/1.1 307 Temporary Redirect\ndate: Thu, 30 Jun 2022 09:47:19 GMT\nserver: uvicorn\ncontent-length: 0\nlocation: http://192.168.0.202:8000/index\n\n# Using -L flag does get the intended response\n$ curl -X GET -i http://${HOST_IP}:8001/index -L\n\nHTTP/1.1 307 Temporary Redirect\ndate: Thu, 30 Jun 2022 09:47:38 GMT\nserver: uvicorn\ncontent-length: 0\nlocation: http://192.168.0.202:8000/index\n\nHTTP/1.1 200 OK\ndate: Thu, 30 Jun 2022 09:47:38 GMT\nserver: uvicorn\ncontent-length: 34\ncontent-type: application/json\n\n{&quot;message&quot;:&quot;Welcome to my API 1!&quot;}\n\n</code></pre>\n<p>However, if I put some other URL in the <code>RedirectResponse</code> (for e.g. <code>https://reqres.in/api/users?page=1</code>), I do get a JSON response without needing to specify <code>-L</code> flag. What gives?</p>\n",
                    "OwnerUserId": "1522429",
                    "LastEditorUserId": "1522429",
                    "LastEditDate": "2022-06-30T09:48:47.553",
                    "LastActivityDate": "2022-06-30T09:48:47.553",
                    "Title": "cURL doesn't follow redirect automatically for an API running in Docker",
                    "Tags": "<python><docker><fastapi><http-redirect>",
                    "AnswerCount": "0",
                    "CommentCount": "5",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "72925293",
                "ParentRepo": "https://github.com/internetarchive/openlibrary/blob/master/conf/solr/conf/managed-schema#L136-L216",
                "StackOverflow_Post": {
                    "Id": "72925293",
                    "PostTypeId": "1",
                    "CreationDate": "2022-07-09T23:40:23.713",
                    "Score": "1",
                    "ViewCount": "37",
                    "Body": "<p>I am learning JS, and I am struggeling with this API request. The search API from Openlibrary returns an array of ISBNs, about 400 per book and its slowing down the response time. How can I structure the request so I only get the first result?</p>\n<p>This is what I tried:</p>\n<pre><code>axios.get(`http://openlibrary.org/search.json?title=${query}\n    &amp;limit=100\n    &amp;fields=isbn[0]`)\n</code></pre>\n<p>Searching for 0 index isn't working and their schema at <a href=\"https://github.com/internetarchive/openlibrary/blob/master/conf/solr/conf/managed-schema#L136-L216\" rel=\"nofollow noreferrer\">https://github.com/internetarchive/openlibrary/blob/master/conf/solr/conf/managed-schema#L136-L216</a> didnt help too much either.</p>\n",
                    "OwnerUserId": "17057045",
                    "LastEditorUserId": "9431571",
                    "LastEditDate": "2022-07-10T22:31:41.023",
                    "LastActivityDate": "2022-07-10T22:31:41.023",
                    "Title": "limiting query to search API from openlibrary.com",
                    "Tags": "<javascript><json><api><get><isbn>",
                    "AnswerCount": "0",
                    "CommentCount": "0",
                    "FavoriteCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "72972658",
                "ParentRepo": "https://github.com/SohamRatnaparkhi/Transliterate",
                "StackOverflow_Post": {
                    "Id": "72972658",
                    "PostTypeId": "1",
                    "CreationDate": "2022-07-13T21:07:08.607",
                    "Score": "0",
                    "ViewCount": "161",
                    "Body": "<p>I have made a flask app that translates speech from one language to another and for that, I must store the translated audio file in a folder; then the audio is played(in frontend) using the audio player in HTML. Locally everything works fine but the docker image or heroku app doesn't play any audio as it doesnt store any audio file in a folder. Dont know why it doesnt save the audio file for that request. How to solve this issue. <a href=\"https://github.com/SohamRatnaparkhi/Transliterate\" rel=\"nofollow noreferrer\">More info on my project</a> ;\n<a href=\"https://transliterate-ht.herokuapp.com/\" rel=\"nofollow noreferrer\">Heroku app</a></p>\n<p>Following is code-block wherein I have written the saving part of my backend</p>\n<pre><code>   translated_text = translator(transcript, target)\n   target = languages[target].lower()\n   try:\n       speak = gTTS(text=translated_text, lang=target, slow=False)\n   except:\n       return render_template(&quot;error.html&quot;, message = &quot;Sorry, I didn't understand that. Please try again.&quot;)\n\n   #? Using save() method to save the translated\n   global i\n   i += 1\n   \n   #? speech in capture_voice.mp3\n   speak.save(fr&quot;static\\translated_speech\\captured_voice{i}.mp3&quot;)\n\n   return render_template('translator2.html', translated_text=translated_text, path = fr&quot;static\\translated_speech\\captured_voice{i}.mp3&quot;)\n</code></pre>\n<p>Code block is of playing the audio in <code>translator2.html</code> which is being rendered by this function</p>\n<pre><code>&lt;div class=&quot;play-sound&quot;&gt;\n        &lt;audio controls=&quot;controls&quot;&gt;\n            &lt;source src=&quot;{{path}}&quot; type=&quot;audio/mpeg&quot;&gt;\n        &lt;/audio&gt;\n&lt;/div&gt;\n</code></pre>\n<p>File structure locally</p>\n<pre><code> - static\n    - css, favicon etc\n    - translated_speech\n - templates\n - app.py\n</code></pre>\n<p>DockerFile</p>\n<pre><code>FROM python:3.9.12\nWORKDIR /app/\nCOPY requirements.txt requirements.txt\nRUN pip install -r requirements.txt\nCOPY . .\nCMD [ &quot;python3&quot;, &quot;-m&quot; , &quot;flask&quot;, &quot;run&quot;, &quot;--host=0.0.0.0&quot;]\n</code></pre>\n<p>Docker image making commands</p>\n<pre><code>docker build -t app:v1 .\ndocker run -p 5000:5000 app:v1\n</code></pre>\n<p>How to solve this issue?\nThank you.</p>\n",
                    "OwnerUserId": "18037343",
                    "LastEditorUserId": "18037343",
                    "LastEditDate": "2022-07-13T21:09:25.337",
                    "LastActivityDate": "2022-07-13T21:49:47.043",
                    "Title": "Why is my Docker image of flask app not saving a file in folders",
                    "Tags": "<python-3.x><docker><flask><audio><html5-audio>",
                    "AnswerCount": "1",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "73031212",
                "ParentRepo": "https://github.com/SeldonIO/MLServer/blob/master/docs/examples/sklearn/README.md",
                "StackOverflow_Post": {
                    "Id": "73031212",
                    "PostTypeId": "1",
                    "CreationDate": "2022-07-19T04:42:24.623",
                    "Score": "1",
                    "ViewCount": "69",
                    "Body": "<p>I am following the example to serve sklearn model <a href=\"https://github.com/SeldonIO/MLServer/blob/master/docs/examples/sklearn/README.md\" rel=\"nofollow noreferrer\">https://github.com/SeldonIO/MLServer/blob/master/docs/examples/sklearn/README.md</a></p>\n<p>I am able to train and genreate the model, and then do a REST call for the inference successfully. However, I am trying to craft a gRPC call now, and the only example I could find is this <a href=\"https://mlserver.readthedocs.io/en/latest/examples/custom-json/README.html?highlight=grpc#send-test-inference-request-grpc\" rel=\"nofollow noreferrer\">https://mlserver.readthedocs.io/en/latest/examples/custom-json/README.html?highlight=grpc#send-test-inference-request-grpc</a></p>\n<p>However, this is using another model. SO I try to follow this example but replace it with inference request data from my current infer.py, please see <code>infer-grpc.py</code> below.</p>\n<p>train.py</p>\n<pre><code>from sklearn import datasets, svm, metrics\nfrom sklearn.model_selection import train_test_split\n\n# The digits dataset\ndigits = datasets.load_digits()\n\n# To apply a classifier on this data, we need to flatten the image, to\n# turn the data in a (samples, feature) matrix:\nn_samples = len(digits.images)\ndata = digits.images.reshape((n_samples, -1))\n\n# Create a classifier: a support vector classifier\nclassifier = svm.SVC(gamma=0.001)\n\n# Split data into train and test subsets\nX_train, X_test, y_train, y_test = train_test_split(\n    data, digits.target, test_size=0.5, shuffle=False)\n\n# We learn the digits on the first half of the digits\nclassifier.fit(X_train, y_train)\nimport joblib\n\nmodel_file_name = &quot;mnist-svm.joblib&quot;\njoblib.dump(classifier, model_file_name)\n\n\n</code></pre>\n<p>infer.py (http)</p>\n<pre><code>import requests\n# Import datasets, classifiers and performance metrics\nfrom sklearn import datasets, svm, metrics\nfrom sklearn.model_selection import train_test_split\n\n# The digits dataset\ndigits = datasets.load_digits()\n\n# To apply a classifier on this data, we need to flatten the image, to\n# turn the data in a (samples, feature) matrix:\nn_samples = len(digits.images)\ndata = digits.images.reshape((n_samples, -1))\n\n# Create a classifier: a support vector classifier\nclassifier = svm.SVC(gamma=0.001)\n\n# Split data into train and test subsets\nX_train, X_test, y_train, y_test = train_test_split(\n    data, digits.target, test_size=0.5, shuffle=False)\n\n# We learn the digits on the first half of the digits\nclassifier.fit(X_train, y_train)\n\n\nx_0 = X_test[0:1]\ninference_request = {\n    &quot;inputs&quot;: [\n        {\n          &quot;name&quot;: &quot;predict&quot;,\n          &quot;shape&quot;: x_0.shape,\n          &quot;datatype&quot;: &quot;FP32&quot;,\n          &quot;data&quot;: x_0.tolist()\n        }\n    ]\n}\n\nendpoint = &quot;http://localhost:8089/v2/models/mnist-svm/versions/v0.1.0/infer&quot;\nresponse = requests.post(endpoint, json=inference_request)\n\nprint(response.json())\n</code></pre>\n<p>infer-grpc.py</p>\n<pre><code>\nimport mlserver.types\nimport requests\nimport json\nimport grpc\nimport mlserver.grpc.converters as converters\nimport mlserver.grpc.dataplane_pb2_grpc as dataplane\nimport mlserver.types as types\nimport requests\n# Import datasets, classifiers and performance metrics\nfrom sklearn import datasets, svm, metrics\nfrom sklearn.model_selection import train_test_split\n\n# The digits dataset\ndigits = datasets.load_digits()\n\n# To apply a classifier on this data, we need to flatten the image, to\n# turn the data in a (samples, feature) matrix:\nn_samples = len(digits.images)\ndata = digits.images.reshape((n_samples, -1))\n\n# Create a classifier: a support vector classifier\nclassifier = svm.SVC(gamma=0.001)\n\n# Split data into train and test subsets\nX_train, X_test, y_train, y_test = train_test_split(\n    data, digits.target, test_size=0.5, shuffle=False)\n\n# We learn the digits on the first half of the digits\nclassifier.fit(X_train, y_train)\n\n\nx_0 = X_test[0:1]\n\n\n\nmodel_name = &quot;mnist-svm&quot;\n\nip = {&quot;input&quot;: x_0.tolist()}\n\n\ninputs_bytes = json.dumps(x_0.tolist()).encode(&quot;UTF-8&quot;)\n\nprint([len(inputs_bytes)])\nprint(inputs_bytes)\n\ninference_request = types.InferenceRequest(\n    inputs=[\n        types.RequestInput(\n            name=&quot;predict&quot;,\n            shape=[len(inputs_bytes)],\n            datatype=&quot;BYTES&quot;,\n            data=[inputs_bytes],\n\n\n        )\n    ]\n)\n\n\n\n\ninference_request_g = converters.ModelInferRequestConverter.from_types(\n    inference_request,\n    model_name=model_name,\n    model_version=None\n)\n\ngrpc_channel = grpc.insecure_channel(&quot;localhost:8081&quot;)\ngrpc_stub = dataplane.GRPCInferenceServiceStub(grpc_channel)\n\nresponse = grpc_stub.ModelInfer(inference_request_g)\nresponse\n\n</code></pre>\n<p>throws an error:</p>\n<pre><code>\ngrpc._channel._InactiveRpcError: &lt;_InactiveRpcError of RPC that terminated with:\n    status = StatusCode.UNKNOWN\n    details = &quot;Unexpected &lt;class 'ValueError'&gt;: cannot reshape array of size 347 into shape (1,)&quot;\n\n</code></pre>\n",
                    "OwnerUserId": "16228929",
                    "LastActivityDate": "2022-07-19T08:17:13.520",
                    "Title": "MLServer GRPC cannot reshape array of size 347 into shape (1,)",
                    "Tags": "<python><scikit-learn><grpc><grpc-python><seldon-core>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "73085558",
                "ParentRepo": "https://github.com/grillazz/fastapi-sqlalchemy-asyncpg/blob/main/alembic/env.py",
                "StackOverflow_Post": {
                    "Id": "73085558",
                    "PostTypeId": "2",
                    "ParentId": "71371795",
                    "CreationDate": "2022-07-22T20:03:05.910",
                    "Score": "0",
                    "Body": "<p>You have probably initlized alembic in your /app folder, which is not a problem, but cumbersome to handle.\nThe error originates from the fact that alembic does not generate a package.</p>\n<p>To fix your error, you can either delete your alembic folder and reinitlize alembic on the same level your /app folder is located.\nBy doing so you can checkout the general project structure of the official demo project of fastapi\n<a href=\"https://github.com/tiangolo/full-stack-fastapi-postgresql/tree/master/%7B%7Bcookiecutter.project_slug%7D%7D/backend/app\" rel=\"nofollow noreferrer\">https://github.com/tiangolo/full-stack-fastapi-postgresql/tree/master/%7B%7Bcookiecutter.project_slug%7D%7D/backend/app</a></p>\n<p>or you execute alembic with a set PYTHONPATH pointing to root of you app folder.</p>\n<pre><code>PYTHONPATH=/absolute/path/toyourproject/ alembic revision --autogenerate -m &quot;name&quot;\n</code></pre>\n<p>See: <a href=\"https://stackoverflow.com/questions/33821470/importing-app-when-using-alembic-raises-importerror\">Importing app when using Alembic raises ImportError</a></p>\n<p>You could also fix the error by using os and adding your path to sys</p>\n<p>See: <a href=\"https://github.com/grillazz/fastapi-sqlalchemy-asyncpg/blob/main/alembic/env.py\" rel=\"nofollow noreferrer\">https://github.com/grillazz/fastapi-sqlalchemy-asyncpg/blob/main/alembic/env.py</a></p>\n",
                    "OwnerUserId": "5825850",
                    "LastActivityDate": "2022-07-22T20:03:05.910",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "73100224",
                "ParentRepo": "https://github.com/microsoft/AzureTRE/blob/main/templates/shared_services/airlock_notifier/terraform/airlock_notifier.tf#L58",
                "StackOverflow_Post": {
                    "Id": "73100224",
                    "PostTypeId": "2",
                    "ParentId": "73021699",
                    "CreationDate": "2022-07-24T16:38:41.233",
                    "Score": "0",
                    "Body": "<p>As far as I know, this is currently not possible. <a href=\"https://github.com/hashicorp/terraform-provider-azurerm/issues/16195\" rel=\"nofollow noreferrer\">See the github issue</a></p>\n<p>I had a similar problem, and to workaround it I've used an ARM template and the 'azurerm_resource_group_template_deployment' terraform module.</p>\n<p>Here is a reference:\n<a href=\"https://github.com/microsoft/AzureTRE/blob/main/templates/shared_services/airlock_notifier/terraform/airlock_notifier.tf#L58\" rel=\"nofollow noreferrer\">https://github.com/microsoft/AzureTRE/blob/main/templates/shared_services/airlock_notifier/terraform/airlock_notifier.tf#L58</a></p>\n",
                    "OwnerUserId": "15393799",
                    "LastActivityDate": "2022-07-24T16:38:41.233",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "73236013",
                "ParentRepo": "https://github.com/RobertCraigie/prisma-client-py/discussions",
                "StackOverflow_Post": {
                    "Id": "73236013",
                    "PostTypeId": "2",
                    "ParentId": "73203340",
                    "CreationDate": "2022-08-04T12:33:27.617",
                    "Score": "1",
                    "Body": "<p>It is recommended that you create one instance of <code>PrismaClient</code> and reuse it across your application and you should only set it to a global variable in the development environment only and you do not need to explicitly <code>$disconnect</code>. You can learn more about Prisma connection management in the <a href=\"https://www.prisma.io/docs/guides/performance-and-optimization/connection-management\" rel=\"nofollow noreferrer\">docs</a>. Also, I\u2019ll encourage you to ask your Prisma Python client questions in prisma-client-py repositories <a href=\"https://github.com/RobertCraigie/prisma-client-py/discussions\" rel=\"nofollow noreferrer\">GitHub Discussion</a></p>\n",
                    "OwnerUserId": "1645620",
                    "LastActivityDate": "2022-08-04T12:33:27.617",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "73241648",
                "ParentRepo": "https://github.com/laurents/slowapi",
                "StackOverflow_Post": {
                    "Id": "73241648",
                    "PostTypeId": "2",
                    "ParentId": "73220174",
                    "CreationDate": "2022-08-04T20:00:03.147",
                    "Score": "2",
                    "Body": "<h2>Returning a File Response</h2>\n<p>First, to return a <code>file</code> that is saved on disk from a FastAPI backend, you could use <a href=\"https://fastapi.tiangolo.com/advanced/custom-response/#fileresponse\" rel=\"nofollow noreferrer\"><code>FileResponse</code></a> (in case the file was already fully loaded into memory, see <a href=\"https://stackoverflow.com/a/71639658/17865804\">here</a>). For example:</p>\n<pre class=\"lang-py prettyprint-override\"><code>from fastapi import FastAPI\nfrom fastapi.responses import FileResponse\n\nsome_file_path = &quot;large-video-file.mp4&quot;\napp = FastAPI()\n\n@app.get(&quot;/&quot;)\ndef main():\n    return FileResponse(some_file_path)\n</code></pre>\n<p>In case the <code>file</code> is too large to fit into memory\u2014as you may not have enough memory to handle the file data, e.g., if you have 16GB of RAM, you can\u2019t load a 100GB file\u2014you could use <a href=\"https://fastapi.tiangolo.com/advanced/custom-response/#using-streamingresponse-with-file-like-objects\" rel=\"nofollow noreferrer\"><code>StreamingResponse</code></a>. That way, you don't have to read it all first in memory, but, instead, load it into memory in chunks, thus processing the data one chunk at a time. Example is given below. If you find <code>yield from f</code> being rather slow when using <code>StreamingResponse</code>, you could instead create a custom generator, as described in <a href=\"https://stackoverflow.com/a/73843234/17865804\">this answer</a>.</p>\n<pre class=\"lang-py prettyprint-override\"><code>from fastapi import FastAPI\nfrom fastapi.responses import StreamingResponse\n\nsome_file_path = &quot;large-video-file.mp4&quot;\napp = FastAPI()\n\n@app.get(&quot;/&quot;)\ndef main():\n    def iterfile():\n        with open(some_file_path, mode=&quot;rb&quot;) as f:\n            yield from f\n\n    return StreamingResponse(iterfile(), media_type=&quot;video/mp4&quot;)\n</code></pre>\n<h2>Exposing the API to the public</h2>\n<p>As for exposing your API to the public\u2014i.e., external APIs, users, developers, etc.\u2014you can use <a href=\"https://ngrok.com/\" rel=\"nofollow noreferrer\">ngrok</a> (or <a href=\"https://expose.dev/\" rel=\"nofollow noreferrer\">expose</a>, as suggested in <a href=\"https://stackoverflow.com/a/70802911/17865804\">this answer</a>).</p>\n<p>Ngrok is a cross-platform application that enables developers to expose a local <em>development server</em> to the Internet with minimal effort. To embed the <code>ngrok</code> agent into your FastAPI application, you could use <a href=\"https://github.com/alexdlaird/pyngrok\" rel=\"nofollow noreferrer\"><code>pyngrok</code></a>\u2014as suggested <a href=\"https://ngrok.com/docs/using-ngrok-with#fastapi\" rel=\"nofollow noreferrer\">here</a> (see <a href=\"https://pyngrok.readthedocs.io/en/latest/integrations.html#fastapi\" rel=\"nofollow noreferrer\">here</a> for a FastAPI integration example). If you would like to run and expose your FastAPI app through <a href=\"https://colab.research.google.com/\" rel=\"nofollow noreferrer\">Google Colab</a> (using <code>ngrok</code>), instead of your local machine, please have a look at <a href=\"https://stackoverflow.com/a/63833779/17865804\">this answer</a> (plenty of tutorials/examples can also be found on the web).</p>\n<p>If you are looking for a more permanent solution, you may want to have a look at cloud platforms\u2014more specifically, a Platform as a Service (PaaS)\u2014such as <a href=\"https://www.heroku.com/\" rel=\"nofollow noreferrer\">Heroku</a>. I would strongly recommend you thoroughly read <a href=\"https://fastapi.tiangolo.com/deployment/\" rel=\"nofollow noreferrer\">FastAPI's Deployment documentation</a>. Have a closer look at <a href=\"https://fastapi.tiangolo.com/deployment/https/\" rel=\"nofollow noreferrer\">About HTTPS</a> and <a href=\"https://fastapi.tiangolo.com/deployment/concepts/\" rel=\"nofollow noreferrer\">Deployments Concepts</a>.</p>\n<h4>Important to note</h4>\n<p>By exposing your API to the outside world, you are also exposing it to various forms of attack. Before exposing your API to the public\u2014even if it\u2019s for free\u2014you need to make sure you are offering secure access (use <code>HTTPS</code>), as well as <code>authentication</code> (verify the identity of a user) and <code>authorisation</code> (verify their access rights; in other words, verify what specific routes, files and data a user has access to)\u2014take a look at 1. <a href=\"https://fastapi.tiangolo.com/tutorial/security/oauth2-jwt/\" rel=\"nofollow noreferrer\">OAuth2 and JWT tokens</a>, 2. <a href=\"https://fastapi.tiangolo.com/advanced/security/oauth2-scopes/\" rel=\"nofollow noreferrer\">OAuth2 scopes</a>, 3. <a href=\"https://en.wikipedia.org/wiki/Role-based_access_control\" rel=\"nofollow noreferrer\">Role-Based Access Control (RBAC)</a>, 4. <a href=\"https://fastapi.tiangolo.com/tutorial/security/get-current-user/\" rel=\"nofollow noreferrer\">Get Current User</a> and <a href=\"https://learnings.desipenguin.com/post/rolechecker-with-fastapi/\" rel=\"nofollow noreferrer\">How to Implement Role based Access Control With FastAPI</a>.</p>\n<p>Addtionally,  if you are exposing your API to be used publicly, you may want to limit the usage of the API because of expensive computation, limited resources, <a href=\"https://en.wikipedia.org/wiki/Denial-of-service_attack\" rel=\"nofollow noreferrer\">DDoS attacks</a>, <a href=\"https://en.wikipedia.org/wiki/Brute-force_attack\" rel=\"nofollow noreferrer\">Brute-force attacks</a>, <a href=\"https://en.wikipedia.org/wiki/Web_scraping\" rel=\"nofollow noreferrer\">Web scraping</a>, or simply due to monthly cost for a fixed amount of requests. You can do that at the application level using, for instance, <a href=\"https://github.com/laurents/slowapi\" rel=\"nofollow noreferrer\">slowapi</a> (related post <a href=\"https://stackoverflow.com/a/71183527/17865804\">here</a>), or at the platform level by setting the rate limit through your hosting service (if permitted). Furthermore, you would need to make sure that the files uploaded by users have the permitted file extension, e.g., <code>.mp4</code>, and are not files with, for instance, a <code>.exe</code> extension that are potentially harmful to your system. Finally, you would also need to ensure that the uploaded files do not exceed a predefined <code>MAX_FILE_SIZE</code> limit (based on your needs and system's resources), so that authenticated users, or an attacker, would be prevented from uploading extremely large files that would result in consuming server resources in a way that the application may end up crashing. You shouldn't rely, though, on the <code>Content-Length</code> header being present in the <code>request</code> to do that, as this might be easily altered, or even removed, by the client. You should rather use an approach similar to <a href=\"https://stackoverflow.com/a/70667530/17865804\"><strong>this answer</strong></a> (have a look at the &quot;Update&quot; section) that uses <code>request.stream()</code> to process the incoming data in chunks as they arrive, instead of loading the entire file into memory first. By using a simple counter, e.g., <code>total_len += len(chunk)</code>, you can check if the file size has exceeded the <code>MAX_FILE_SIZE</code>, and if so, raise an <a href=\"https://fastapi.tiangolo.com/tutorial/handling-errors/#use-httpexception\" rel=\"nofollow noreferrer\"><code>HTTPException</code></a> with <code>HTTP_413_REQUEST_ENTITY_TOO_LARGE</code> status code (see <a href=\"https://stackoverflow.com/a/73443824/17865804\"><strong>this answer</strong></a> as well, for more details and code examples).</p>\n<p>Read more on FastAPI's <a href=\"https://fastapi.tiangolo.com/tutorial/security/\" rel=\"nofollow noreferrer\">Security documentation</a> and <a href=\"https://www.cloudflare.com/learning/security/api/what-is-api-security/\" rel=\"nofollow noreferrer\">API Security</a> on Cloudflare.</p>\n",
                    "OwnerUserId": "17865804",
                    "LastEditorUserId": "17865804",
                    "LastEditDate": "2022-10-23T05:34:04.983",
                    "LastActivityDate": "2022-10-23T05:34:04.983",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "73344574",
                "ParentRepo": "https://github.com/orbitdb/py-orbit-db-http-client",
                "StackOverflow_Post": {
                    "Id": "73344574",
                    "PostTypeId": "1",
                    "CreationDate": "2022-08-13T13:10:31.390",
                    "Score": "1",
                    "ViewCount": "45",
                    "Body": "<p>I have created a dApp with Flask that uses an sqlite3 local database. I am trying to remove the local database and create a decentralized one. I guess <a href=\"https://orbitdb.org\" rel=\"nofollow noreferrer\">orbitdb</a> is one of the possibilities. Although a page about the <a href=\"https://github.com/orbitdb/py-orbit-db-http-client\" rel=\"nofollow noreferrer\">python3 implementation</a> exists I could not find any similar project or any guide on how to implement the database.</p>\n<p>Any help on how to create the database would be appreciated.</p>\n",
                    "OwnerUserId": "18028725",
                    "LastActivityDate": "2022-08-13T13:10:31.390",
                    "Title": "Orbitdb and python",
                    "Tags": "<python><orbitdb>",
                    "AnswerCount": "0",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "73356097",
                "ParentRepo": "https://github.com/mIcHyAmRaNe/okadminfinder3/blob/master/LinkFile/adminpanellinks.txt",
                "StackOverflow_Post": {
                    "Id": "73356097",
                    "PostTypeId": "2",
                    "ParentId": "71745492",
                    "CreationDate": "2022-08-15T00:57:44.367",
                    "Score": "0",
                    "Body": "<ol>\n<li><p>Try some google dorks on your target. Just search google hacking database in your browser and open first link (exploid-db.com). You can search &quot;admin&quot; in searchbox to filter out admin page related Google dorks. Like this <a href=\"https://i.stack.imgur.com/aKelg.jpg\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/aKelg.jpg\" alt=\"Like this\" /></a></p>\n</li>\n<li><p>Identify what technology is being used by host. For example if they are using WordPress then wp-login, login, admin, etc are common URI. So google common admin panel path for the technology you found on host.</p>\n</li>\n<li><p>Perform dictionary attack(burpsuite, dirbuster, etc) using file that contains lots of admin-panel pages. You will find plenty of list in GitHub.\n<a href=\"https://github.com/mIcHyAmRaNe/okadminfinder3/blob/master/LinkFile/adminpanellinks.txt\" rel=\"nofollow noreferrer\">For example this link</a></p>\n</li>\n</ol>\n",
                    "OwnerUserId": "14466362",
                    "LastActivityDate": "2022-08-15T00:57:44.367",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "73397723",
                "ParentRepo": "https://github.com/up9inc/mockintosh",
                "StackOverflow_Post": {
                    "Id": "73397723",
                    "PostTypeId": "2",
                    "ParentId": "21877387",
                    "CreationDate": "2022-08-18T05:09:40.413",
                    "Score": "0",
                    "Body": "<p><a href=\"https://github.com/up9inc/mockintosh\" rel=\"nofollow noreferrer\">Mockintosh</a> seems like another option.</p>\n",
                    "OwnerUserId": "13503720",
                    "LastActivityDate": "2022-08-18T05:09:40.413",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "73462780",
                "ParentRepo": "https://github.com/rveachkc/pymsteams/issues/11",
                "StackOverflow_Post": {
                    "Id": "73462780",
                    "PostTypeId": "2",
                    "ParentId": "72144055",
                    "CreationDate": "2022-08-23T17:19:38.050",
                    "Score": "0",
                    "Body": "<p>I believe you can use an <a href=\"https://github.com/rveachkc/pymsteams/issues/11\" rel=\"nofollow noreferrer\">AC card</a>. Here is a detailed <a href=\"https://learn.microsoft.com/en-us/microsoftteams/platform/task-modules-and-cards/what-are-cards\" rel=\"nofollow noreferrer\">explanation</a> where I learned it.</p>\n",
                    "OwnerUserId": "16739678",
                    "LastEditorUserId": "16739678",
                    "LastEditDate": "2022-08-29T22:38:51.517",
                    "LastActivityDate": "2022-08-29T22:38:51.517",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "73513786",
                "ParentRepo": "https://github.com/justpy-org/justpy/issues/314",
                "StackOverflow_Post": {
                    "Id": "73513786",
                    "PostTypeId": "2",
                    "ParentId": "73497028",
                    "CreationDate": "2022-08-27T19:19:59.517",
                    "Score": "0",
                    "Body": "<p>@Kanda - thank you for your excellent question.\nAs a committer of justpy I have added your code to the justpy codebase and tried it out using</p>\n<pre class=\"lang-bash prettyprint-override\"><code>python examples/stackoverflow/q73497028.py\n</code></pre>\n<p>The result is:</p>\n<p><a href=\"https://i.stack.imgur.com/qXZcP.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/qXZcP.png\" alt=\"screenshot\" /></a></p>\n<p>and i assume you are expecting the behavior described in</p>\n<p><a href=\"https://ag-grid.com/javascript-data-grid/floating-filters/\" rel=\"nofollow noreferrer\">https://ag-grid.com/javascript-data-grid/floating-filters/</a></p>\n<p>Given that <a href=\"https://github.com/justpy-org/justpy/issues/314\" rel=\"nofollow noreferrer\">https://github.com/justpy-org/justpy/issues/314</a>) is not fixed you might want to make sure whether the feature you are expecting is actually available in the justpy version you are using (which you might state in your question for clarity). I am assuming you are using the most current version 0.2.8. Since the revival of justpy as discussed in <a href=\"https://github.com/justpy-org/justpy/discussions/409\" rel=\"nofollow noreferrer\">https://github.com/justpy-org/justpy/discussions/409</a> you might note that the justpy community tries to stay on top of user expectations. Unfortunately there are limits to fullfilling the expectations so you might want to watch out for questions and issues labeled &quot;ag-grid&quot; in <a href=\"https://github.com/justpy-org/justpy/issues?q=is%3Aopen+is%3Aissue+label%3A%22AG+Grid%22\" rel=\"nofollow noreferrer\">https://github.com/justpy-org/justpy/issues?q=is%3Aopen+is%3Aissue+label%3A%22AG+Grid%22</a></p>\n",
                    "OwnerUserId": "1497139",
                    "LastActivityDate": "2022-08-27T19:19:59.517",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "73644462",
                "ParentRepo": "https://github.com/425show/fastapi_microsoft_identity/blob/main/fastapi_microsoft_identity/auth_service.py",
                "StackOverflow_Post": {
                    "Id": "73644462",
                    "PostTypeId": "2",
                    "ParentId": "73547978",
                    "CreationDate": "2022-09-08T06:16:46.027",
                    "Score": "0",
                    "Body": "<ul>\n<li><p>You can't really bypass a decorator but can circumnavigate it if in its implementation it uses <code>@wrap()</code> in the code.</p>\n</li>\n<li><p>Now <code>@ require_auth</code> does use a <code>@wrap</code> in its implementation so we can circumnavigate the decorator by calling the original function in this case \u2018weather\u2019 function as:-\n<code>weather.__wrapped__()</code>\ninstead of the usual way of calling the function.</p>\n</li>\n<li><p>The <code>__wrapped__ </code> method basically has reference to the original function instead of the decorator.</p>\n</li>\n<li><p>Here I created a small API which basically returns two strings now here I have called the weather function without the <code>.__wrapped__</code></p>\n</li>\n</ul>\n<pre><code># main.py\n\nfrom fastapi_microsoft_identity import requires_auth, validate_scope, AuthError\nimport fastapi\n\n\nfrom fastapi import FastAPI\n\napp = FastAPI()\n\n\n@requires_auth\nasync def weather()   :\n    return False\n    \n\n@app.get(&quot;/&quot;)\nasync def root():\n    if await weather.() :\n        return {&quot;Decorator is working and not allowing the function f() to work &quot;}\n    else :\n        return {&quot;Decorator is disabled&quot;}\n\n\n</code></pre>\n<p><a href=\"https://i.stack.imgur.com/RQkpP.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/RQkpP.png\" alt=\"enter image description here\" /></a></p>\n<p>Here the<code> weather ()</code> doesn\u2019t get executed that is why the string \u201cDecorator is working and not allowing the function f() to work\u201d is returned but in your  case it is giving unauthorize error\nBut now when I call it using wrapped</p>\n<pre><code>\n# main.py\n\nfrom fastapi_microsoft_identity import requires_auth, validate_scope, AuthError\nimport fastapi\n\n\nfrom fastapi import FastAPI\n\napp = FastAPI()\n\n\n@requires_auth\nasync def weather()   :\n    return False\n    \n\n@app.get(&quot;/&quot;)\nasync def root():\n    if await weather.__wrapped__() :\n        return {&quot;Decorator is working and not allowing the function f() to work &quot;}\n    else :\n        return {&quot;Decorator is disabled&quot;}\n\n\n</code></pre>\n<p><a href=\"https://i.stack.imgur.com/JV6Kg.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/JV6Kg.png\" alt=\"enter image description here\" /></a></p>\n<p>Now that I have used the<code>,__wrapped__</code> while calling the weather function it is being executed directly circumnavigating the decorator</p>\n<p>So if you don\u2019t want the <code>require@auth</code>to work call the weather function like this <code>weather.__wrapped__(&lt;arguments&gt;)</code></p>\n<p>Refer this python <a href=\"https://docs.python.org/3/library/functools.html#:%7E:text=The%20original%20underlying%20function%20is%20accessible%20through%20the,the%20cache%20or%20until%20the%20cache%20is%20cleared.\" rel=\"nofollow noreferrer\">docs </a> on wrapper method and this gihub <a href=\"https://github.com/425show/fastapi_microsoft_identity/blob/main/fastapi_microsoft_identity/auth_service.py\" rel=\"nofollow noreferrer\">repo</a> on require_auth.</p>\n",
                    "OwnerUserId": "18170152",
                    "LastActivityDate": "2022-09-08T06:16:46.027",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "73650173",
                "ParentRepo": "https://github.com/ioangrozea/Docker-dummy",
                "StackOverflow_Post": {
                    "Id": "73650173",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "73660118",
                    "CreationDate": "2022-09-08T13:50:10.710",
                    "Score": "3",
                    "ViewCount": "385",
                    "Body": "<p>I have 2 examples of docker file and one is working and another is not. The main difference between the 2 is the base image.</p>\n<p>Simple python base image docker file:</p>\n<pre><code># syntax = docker/dockerfile:experimental\nFROM python:3.9-slim-bullseye\n\nRUN apt-get update -qy &amp;&amp; apt-get install -qy \\\n    build-essential tini libsasl2-dev libssl-dev default-libmysqlclient-dev gnutls-bin\n\nRUN pip install poetry==1.1.15\nCOPY pyproject.toml .\nCOPY poetry.lock .\nRUN poetry config virtualenvs.create false\nRUN --mount=type=cache,mode=0777,target=/root/.cache/pypoetry poetry install\n</code></pre>\n<p>Airflow base image docker file:</p>\n<pre><code># syntax = docker/dockerfile:experimental\nFROM apache/airflow:2.3.3-python3.9\nUSER root\nRUN apt-get update -qy &amp;&amp; apt-get install -qy \\\n    build-essential tini libsasl2-dev libssl-dev default-libmysqlclient-dev gnutls-bin\n\nUSER airflow\nRUN pip install poetry==1.1.15\nCOPY pyproject.toml .\nCOPY poetry.lock .\nRUN poetry config virtualenvs.create false\nRUN poetry config cache-dir /opt/airflow/.cache/pypoetry\nRUN --mount=type=cache,uid=50000,mode=0777,target=/opt/airflow/.cache/pypoetry poetry install\n</code></pre>\n<p>Before building the docker file run <code>poetry lock</code> in the same folder as the <code>pyproject.toml</code> file!</p>\n<p><code>pyproject.toml</code> file:</p>\n<pre><code>[tool.poetry]\nname = &quot;Airflow-test&quot;\nversion = &quot;0.1.0&quot;\ndescription = &quot;&quot;\nauthors = [&quot;Lorem ipsum&quot;]\n\n[tool.poetry.dependencies]\npython = &quot;~3.9&quot;\napache-airflow = { version = &quot;2.3.3&quot;, extras = [&quot;amazon&quot;, &quot;crypto&quot;, &quot;celery&quot;, &quot;postgres&quot;, &quot;hive&quot;, &quot;jdbc&quot;, &quot;mysql&quot;, &quot;ssh&quot;, &quot;slack&quot;, &quot;statsd&quot;] }\nprometheus_client = &quot;^0.8.0&quot;\nisodate = &quot;0.6.1&quot;\ndacite = &quot;1.6.0&quot;\nsqlparse = &quot;^0.3.1&quot;\npython3-openid = &quot;^3.1.0&quot;\nflask-appbuilder = &quot;&gt;=3.4.3&quot;\nalembic = &quot;&gt;=1.7.7&quot;\napache-airflow-providers-google = &quot;^8.1.0&quot;\napache-airflow-providers-databricks = &quot;^3.0.0&quot;\napache-airflow-providers-amazon = &quot;^4.0.0&quot;\npendulum = &quot;^2.1.2&quot;\n\n[tool.poetry.dev-dependencies]\n\n[build-system]\nrequires = [&quot;poetry-core&gt;=1.0.0&quot;]\nbuild-backend = &quot;poetry.core.masonry.api&quot;\n\n</code></pre>\n<p>In order to build the images this is the command that I use:</p>\n<pre><code>DOCKER_BUILDKIT=1 docker build --progress=plain -t airflow-test -f Dockerfile . \n</code></pre>\n<p>For both images the first time they build <code>poetry install</code> will need to download all dependencies. The interesting part is, the second time I build the image, the python-based image is a lot faster as the dependencies are already cached, but the airflow-based image will try and download all 200 dependencies once again.\nFrom what O know by specifying <code>--mount=type=cache</code> that directory will be stored in the image repository so it can be reused next time the image is build. By this you trim the final image size.</p>\n<p>When running the image how do the dependencies appear? If I run <code>docker run -it --user 50000 --entrypoint /bin/bash image</code> a simple python import is working on the airflow image but not on the python image. When and how will the dependencies be reattached to the image?</p>\n<p>If you want to try it out, here is a dummy project that can be cloned locally and played around with:\n<a href=\"https://github.com/ioangrozea/Docker-dummy\" rel=\"nofollow noreferrer\">https://github.com/ioangrozea/Docker-dummy</a></p>\n",
                    "OwnerUserId": "8133640",
                    "LastEditorUserId": "8133640",
                    "LastEditDate": "2022-09-12T06:27:44.453",
                    "LastActivityDate": "2022-09-12T07:51:10.370",
                    "Title": "Poetry and buildkit mount=type=cache not working when building over airflow image",
                    "Tags": "<python><docker><airflow><python-poetry><docker-buildkit>",
                    "AnswerCount": "1",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "73719107",
                "ParentRepo": "https://github.com/aimhubio/aim/issues/2064",
                "StackOverflow_Post": {
                    "Id": "73719107",
                    "PostTypeId": "2",
                    "ParentId": "73703421",
                    "CreationDate": "2022-09-14T15:01:07.063",
                    "Score": "0",
                    "Body": "<p>This bug was reported on github a month ago, and no meaningful reply was given.</p>\n<p><a href=\"https://github.com/aimhubio/aim/issues/2064\" rel=\"nofollow noreferrer\">https://github.com/aimhubio/aim/issues/2064</a></p>\n",
                    "OwnerUserId": "1812732",
                    "LastActivityDate": "2022-09-14T15:01:07.063",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "73784643",
                "ParentRepo": "https://github.com/microsoft/AzureTre/",
                "StackOverflow_Post": {
                    "Id": "73784643",
                    "PostTypeId": "1",
                    "CreationDate": "2022-09-20T09:41:44.907",
                    "Score": "0",
                    "ViewCount": "20",
                    "Body": "<p>Working on Azure and want's to create Azure resource using Azure TRE(Trusted resource environment). We have downloaded the TRE code from GitHub (<a href=\"https://github.com/microsoft/AzureTre/\" rel=\"nofollow noreferrer\">https://github.com/microsoft/AzureTre/</a>), but not able to run the code.</p>\n<p>Any help would be appreciated. Thanks!</p>\n",
                    "OwnerUserId": "19975471",
                    "LastActivityDate": "2022-09-20T09:41:44.907",
                    "Title": "How to created resource using Azure TRE",
                    "Tags": "<azure>",
                    "AnswerCount": "0",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "73880331",
                "ParentRepo": "https://github.com/cerbos/cerbos-sdk-python",
                "StackOverflow_Post": {
                    "Id": "73880331",
                    "PostTypeId": "2",
                    "ParentId": "63549476",
                    "CreationDate": "2022-09-28T11:01:28.437",
                    "Score": "0",
                    "Body": "<p>For those stumbling across this post in 2022, I thought I'd mention an alternative solution in case it was helpful to anyone!</p>\n<p>Rather than rolling your own authorization, you could consider decoupling it from your application completely, thus avoiding much of the inevitable complexity that building your own could uncover.</p>\n<p><a href=\"https://github.com/cerbos/cerbos\" rel=\"nofollow noreferrer\">Cerbos</a> is an open source project which lets you define and deploy your access policies to a separate service, and exposes a simple API for checking permissions against the Policy Decision Point (PDP). The PDP is deployed separately (via kube svc/sidecar, systemd service, or AWS lambdas, currently).</p>\n<p>It's easily integrated with Python via the <a href=\"https://github.com/cerbos/cerbos-sdk-python\" rel=\"nofollow noreferrer\">SDK</a>.</p>\n<p>Creating a policy looks something like this: e.g. role <code>admin</code> can do anything to a <code>Contact</code>, role <code>user</code> can only read a <code>Contact</code>:</p>\n<pre><code>---\napiVersion: api.cerbos.dev/v1\nresourcePolicy:\n  version: default\n  resource: contact\n  rules:\n    - actions: [&quot;*&quot;]\n      effect: EFFECT_ALLOW\n      roles:\n        - admin\n\n    - actions: [&quot;read&quot;]\n      effect: EFFECT_ALLOW\n      derivedRoles:\n        - user\n</code></pre>\n<p>And then checking access in code:</p>\n<pre><code>user = Principal(\n    &quot;some_user_id&quot;,\n    roles={&quot;user&quot;},  # retrieved from IdP/data store\n)\n\ncontact = Resource(\n    id=&quot;some_contact_id&quot;,\n    kind=&quot;contact&quot;,\n)\n\nwith CerbosClient(host=&quot;http://localhost:3592&quot;) as c:\n    is_allowed = c.is_allowed(&quot;read&quot;, user, contact)\n</code></pre>\n<p>A more in depth example (using FastAPI, rather than Flask, and SQLAlchemy) is here, if interested: <a href=\"https://cerbos.dev/blog/implementing-role-and-attribute-based-access-control-in-sqlalchemy-with-cerbos\" rel=\"nofollow noreferrer\">Implementing role and attribute based access control in SQLAlchemy with Cerbos</a></p>\n<p>(Full disclosure: I work at Cerbos!)</p>\n",
                    "OwnerUserId": "20109412",
                    "LastEditorUserId": "20109412",
                    "LastEditDate": "2022-09-28T11:02:36.480",
                    "LastActivityDate": "2022-09-28T11:02:36.480",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "73920247",
                "ParentRepo": "https://github.com/supabase-community/storage-py",
                "StackOverflow_Post": {
                    "Id": "73920247",
                    "PostTypeId": "2",
                    "ParentId": "69872686",
                    "CreationDate": "2022-10-01T17:04:48.313",
                    "Score": "0",
                    "Body": "<pre class=\"lang-py prettyprint-override\"><code>from storage3 import create_client\n\nurl = &quot;https://&lt;your_supabase_id&gt;.supabase.co/storage/v1&quot;\nkey = &quot;&lt;your api key&gt;&quot;\nheaders = {&quot;apiKey&quot;: key, &quot;Authorization&quot;: f&quot;Bearer {key}&quot;}\nstorage_client = create_client(url, headers, is_async=False)\n\ndef upload_file(self):\n    if 'file' not in request.files:\n        flash('No file part')\n        return redirect('/')\n    file = request.files['file']\n    if file.filename == '':\n        flash('No selected file')\n        return redirect('/')\n    filename = secure_filename(file.filename)\n\n    buckets = storage_client.list_buckets()\n    bucket = buckets[0]\n    return bucket.upload(filename, file)\n</code></pre>\n<p>I didn't find official docs for python upload.<br />\nDidn't test the code above so appreciate any feedback.<br />\nI've based this on the github repo <a href=\"https://github.com/supabase-community/storage-py\" rel=\"nofollow noreferrer\">https://github.com/supabase-community/storage-py</a> and the docs here <a href=\"https://supabase-community.github.io/storage-py/api/bucket.html\" rel=\"nofollow noreferrer\">https://supabase-community.github.io/storage-py/api/bucket.html</a></p>\n",
                    "OwnerUserId": "19014722",
                    "LastActivityDate": "2022-10-01T17:04:48.313",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "73971260",
                "ParentRepo": "https://github.com/mage-ai/mage-ai",
                "StackOverflow_Post": {
                    "Id": "73971260",
                    "PostTypeId": "2",
                    "ParentId": "73945900",
                    "CreationDate": "2022-10-06T09:09:05.820",
                    "Score": "0",
                    "Body": "<h1>Simpler Alternatives to Airflow</h1>\n<p>I would rather not recommend airflow if you are not too invested in to this there are easy to use alternatives:</p>\n<ol>\n<li>Mage ai - <a href=\"https://github.com/mage-ai/mage-ai\" rel=\"nofollow noreferrer\">https://github.com/mage-ai/mage-ai</a></li>\n<li>jupyter scheduler - <a href=\"https://www.google.com/search?client=firefox-b-d&amp;q=jupyter+schduler\" rel=\"nofollow noreferrer\">https://www.google.com/search?client=firefox-b-d&amp;q=jupyter+schduler</a></li>\n<li>!!PAYED - <a href=\"https://docs.qubole.com/en/latest/user-guide/notebooks-and-dashboards/notebooks/jupyter-notebooks/scheduling-jupy-notebooks.html\" rel=\"nofollow noreferrer\">https://docs.qubole.com/en/latest/user-guide/notebooks-and-dashboards/notebooks/jupyter-notebooks/scheduling-jupy-notebooks.html</a></li>\n<li>jupyterlab-scheduler 0.1.5 - <a href=\"https://pypi.org/project/jupyterlab-scheduler/\" rel=\"nofollow noreferrer\">https://pypi.org/project/jupyterlab-scheduler/</a></li>\n<li><a href=\"https://pypi.org/project/notebooker/\" rel=\"nofollow noreferrer\">https://pypi.org/project/notebooker/</a></li>\n<li>notebooker 0.4.4  - <a href=\"https://pypi.org/project/notebooker/\" rel=\"nofollow noreferrer\">https://pypi.org/project/notebooker/</a></li>\n<li>papermill - <a href=\"https://pypi.org/project/papermill/\" rel=\"nofollow noreferrer\">https://pypi.org/project/papermill/</a></li>\n</ol>\n<h1>How to do it with Airflow</h1>\n<h2>1.) Original Dockerfile</h2>\n<p>[JUST TEXT, CHANGABLE] that becomes the original image that you can pull- <a href=\"https://hub.docker.com/r/apache/airflow/dockerfile\" rel=\"nofollow noreferrer\">https://hub.docker.com/r/apache/airflow/dockerfile</a></p>\n<h2>2.) Original image</h2>\n<p>[COMPILED, CHANGABLE] that is created from the original Dockerfile - <a href=\"https://hub.docker.com/layers/apache/airflow/latest/images/sha256-5015db92023bebb1e8518767bfa2e465b2f52270aca6a9cdef85d5d3e216d015?context=explore\" rel=\"nofollow noreferrer\">https://hub.docker.com/layers/apache/airflow/latest/images/sha256-5015db92023bebb1e8518767bfa2e465b2f52270aca6a9cdef85d5d3e216d015?context=explore</a></p>\n<h2>3.) MY requirements.txt</h2>\n<p>requirements.txt - Do not have to have airflow installed in it.</p>\n<pre><code>pandas==1.3.0\nnumpy==1.20.3\n</code></pre>\n<h2>3.) My Dockerfile</h2>\n<p>This pulls the original image and extends it</p>\n<pre><code>FROM apache/airflow:2.4.1-python3.8\n\n# Compulsory to switch parameter\nENV PIP_USER=false\n\n#python venv setup\nRUN python3 -m venv /opt/airflow/venv1\n\n# Install dependencies:\nCOPY requirements.txt .\n\n# --user   &lt;--- WRONG, this is what ENV PIP_USER=false turns off\n#RUN /opt/airflow/venv1/bin/pip install --user -r requirements.txt  &lt;---this is all wrong\nRUN /opt/airflow/venv1/bin/pip install -r requirements.txt\nRUN /opt/airflow/venv1/bin/pip install 'apache-airflow==2.4.1' --constraint &quot;https://raw.githubusercontent.com/apache/airflow/constraints-2.4.1/constraints-3.8.txt&quot;\n\nENV PIP_USER=true\n</code></pre>\n<h2>4.) Terminal Command</h2>\n<p>(be in the same library as your file must be called &quot;Dockerfile&quot;)</p>\n<p><code>docker build -t my-image-apache/airflow:2.4.1 .</code></p>\n<h2>5.) DAG File</h2>\n<ul>\n<li>If you have created dags folder the same way as the official guides says</li>\n<li><a href=\"https://airflow.apache.org/docs/apache-airflow/stable/howto/docker-compose/index.html#setting-the-right-airflow-user\" rel=\"nofollow noreferrer\">https://airflow.apache.org/docs/apache-airflow/stable/howto/docker-compose/index.html#setting-the-right-airflow-user</a></li>\n<li>if you have followed this above guide you should have your dag folder here and it should automaticly take over your new dag files !!!don't forget that your airflow task IDs have to be uinque.</li>\n</ul>\n<pre><code>mkdir -p ./dags ./logs ./plugins\necho -e &quot;AIRFLOW_UID=$(id -u)&quot; &gt; .env\n</code></pre>\n<ul>\n<li>if you have generated an &quot;.env&quot; file you can set up new username and password there fore the main user.</li>\n</ul>\n<h2>6.) ex test DAG</h2>\n<ul>\n<li>!!! dag_id , task_id - have to be unique!!</li>\n<li>!! Dag files automaticly added the running webserver if you drag them in to the local dags folder it just takes 5-10 min, if you modify an existing one them that gets refreshed in the webserver almost immediately</li>\n<li>! # python=os.fspath(sys.executable)  --&gt; '/opt/airflow/venv1/bin/python3'   &lt;-- have to point to an executable python file in thy python virtual environemnt</li>\n</ul>\n<pre><code>&quot;&quot;&quot;\nExample DAG demonstrating the usage of the TaskFlow API to execute Python functions natively and within a\nvirtual environment.\n&quot;&quot;&quot;\nfrom __future__ import annotations\n\nimport logging\nimport os\nimport shutil\nimport sys\nimport tempfile\nimport time\nfrom pprint import pprint\n\nimport pendulum\n\nfrom airflow import DAG\nfrom airflow.decorators import task\n\nlog = logging.getLogger(__name__)\n\nPYTHON = sys.executable\n\nBASE_DIR = tempfile.gettempdir()\n\nwith DAG(\n    dag_id='test_external_python_venv_dag2',\n    schedule=None,\n    start_date=pendulum.datetime(2021, 1, 1, tz=&quot;UTC&quot;),\n    catchup=False,\n    tags=['my_test'],\n) as dag:\n    #@task.external_python(task_id=&quot;test_external_python_venv_task&quot;, python=os.fspath(sys.executable))\n    # /opt/airflow/venv1/bin/python3  &lt;-- have to point to an executable python file in thy python virtual environemnt\n    @task.external_python(task_id=&quot;test_external_python_venv_task&quot;, python='/opt/airflow/venv1/bin/python3')\n    def test_external_python_venv_def():\n        &quot;&quot;&quot;\n        Example function that will be performed in a virtual environment.\n        Importing at the module level ensures that it will not attempt to import the\n        library before it is installed.\n        &quot;&quot;&quot;\n        import sys\n        from time import sleep\n        ########## MY CODE ##########\n        import numpy as np\n        import pandas as pd\n        d = {'col1': [1, 2], 'col2': [3, 4]}\n        df = pd.DataFrame(data=d)\n        print(df)\n        a = np.array([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\n        print(a)\n        #a= 10\n        return a\n        ########## XXXXX MY CODE XXXXX ##########\n\n        print(f&quot;Running task via {sys.executable}&quot;)\n        print(&quot;Sleeping&quot;)\n        for _ in range(4):\n            print('Please wait...', flush=True)\n            sleep(1)\n        print('Finished')\n\n    external_python_task = test_external_python_venv_def()\n</code></pre>\n<h2>7.) docker-compose.yml</h2>\n<p>Official original docker-compose.yml file  <a href=\"https://airflow.apache.org/docs/apache-airflow/2.4.1/docker-compose.yaml\" rel=\"nofollow noreferrer\">https://airflow.apache.org/docs/apache-airflow/2.4.1/docker-compose.yaml</a>  modify this part:</p>\n<pre><code>## Feel free to modify this file to suit your needs.\n---\nversion: '3'\nx-airflow-common:\n  &amp;airflow-common\n  # In order to add custom dependencies or upgrade provider packages you can use your extended image.\n  # Comment the image line, place your Dockerfile in the directory where you placed the docker-compose.yaml\n  # and uncomment the &quot;build&quot; line below, Then run `docker-compose build` to build the images.\n  image: ${AIRFLOW_IMAGE_NAME:-my-image-apache/airflow:2.4.1} #&lt;- this is because of my terminal command above section\n#  image: ${AIRFLOW_IMAGE_NAME:-apache/airflow:2.4.1} &lt;--- THIS WAS THE ORIGINAL\n  environment:\n    #.... many staff here originaly in this environment section.....\n    AIRFLOW__CORE__ENABLE_XCOM_PICKLING: 'true' # &lt;--ADD THIS. This is internal communication for airflow\n  volumes:\n    - ./dags:/opt/airflow/dags\n    - ./logs:/opt/airflow/logs\n\n</code></pre>\n<h2>9.) Build image to Container</h2>\n<p>(be in the same library as your file must be called &quot;docker-compose.yml&quot;)</p>\n<p><code>docker-compose up</code></p>\n<p>or start detached from the terminal by</p>\n<p><code>docker-compose up -d</code></p>\n<h2>10.) Logs</h2>\n<p>If you ever want to see the logs of your container on mac and Windows the Docker APP GUI allows you to do that on Linux you can use the following command</p>\n<p><code>docker logs -f CONTATINER_ACTUAL_ID</code></p>\n<p>You can quit it withouth closing the container by pressing</p>\n<p><code>CTRL + c</code></p>\n<h2>11.) Shut down Container:</h2>\n<ul>\n<li>normal way <code>docker-compose down</code></li>\n<li>or if you are in the logs press <code>CTRL + C</code></li>\n</ul>\n<h2>!!! Stop and delete containers, delete volumes with database data and download images, run.</h2>\n<p><code>docker-compose down --volumes --rmi all</code></p>\n",
                    "OwnerUserId": "10270590",
                    "LastEditorUserId": "10270590",
                    "LastEditDate": "2022-10-08T17:22:58.207",
                    "LastActivityDate": "2022-10-08T17:22:58.207",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "74005422",
                "ParentRepo": "https://github.com/gradio-app/gradio",
                "StackOverflow_Post": {
                    "Id": "74005422",
                    "PostTypeId": "1",
                    "CreationDate": "2022-10-09T14:00:49.573",
                    "Score": "0",
                    "ViewCount": "23",
                    "Body": "<p>I use <a href=\"https://github.com/gradio-app/gradio\" rel=\"nofollow noreferrer\">Gradio</a> to demonstrate some speech recognition system in a video. How can I display subtitles along with a video with Gradio?</p>\n",
                    "OwnerUserId": "395857",
                    "LastActivityDate": "2022-10-09T14:00:49.573",
                    "Title": "How can I display subtitles along with a video with Gradio?",
                    "Tags": "<python><caption><closed-captions><video-subtitles><gradio>",
                    "AnswerCount": "0",
                    "CommentCount": "1",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "74064316",
                "ParentRepo": "https://github.com/sabuhish/fastapi-mail",
                "StackOverflow_Post": {
                    "Id": "74064316",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "74067930",
                    "CreationDate": "2022-10-14T04:28:08.380",
                    "Score": "0",
                    "ViewCount": "227",
                    "Body": "<p>I'm using <a href=\"https://github.com/sabuhish/fastapi-mail\" rel=\"nofollow noreferrer\"><code>fastapi-mail</code></a> package, and trying to send multiple files to multiple email addresses. When I send the email to only one email address, the application works as expected. However, when I change to <code>List[EmailStr]</code> for sending to multiple email addresses, I get this error:</p>\n<pre><code>not a valid email address\n</code></pre>\n<p>Here is my code:</p>\n<pre><code>@app.post(&quot;/file&quot;)async def send_file(\nbackground_tasks: BackgroundTasks,\nemail:List[EmailStr] = Form(...), #I Change here before EmailStr = Form(...)\nfile:Optional[List[UploadFile]] = File(...),) -&gt; JSONResponse:\nprint(email)\nprint(file)\nmessage = MessageSchema(\n    subject=&quot;Fastapi mail module&quot;,\n    recipients=email,\n    body=&quot;Simple background task&quot;,\n    subtype=&quot;html&quot;,\n    attachments=file)\n\nfm = FastMail(ConnectionConfig(\n    MAIL_USERNAME=res(&quot;MAIL_USERNAME&quot;),\n    MAIL_PASSWORD=res(&quot;MAIL_PASSWORD&quot;),\n    MAIL_FROM=&quot;admin@acsebs.com&quot;,\n    MAIL_PORT=res(&quot;MAIL_PORT&quot;),\n    MAIL_SERVER=res(&quot;MAIL_SERVER&quot;),\n    MAIL_FROM_NAME=&quot;send attachment email service&quot;,\n    MAIL_TLS=res(&quot;MAIL_TLS&quot;),\n    MAIL_SSL=res(&quot;MAIL_SSL&quot;),\n    USE_CREDENTIALS=res(&quot;USE_CREDENTIALS&quot;),\n    VALIDATE_CERTS=res(&quot;VALIDATE_CERTS&quot;)\n))\n\nbackground_tasks.add_task(fm.send_message, message)\n\nreturn JSONResponse(status_code=200, content={&quot;message&quot;: &quot;email has been sent&quot;})\n</code></pre>\n<h2>Posting data through Swagger UI:</h2>\n<p><a href=\"https://i.stack.imgur.com/Z8YFb.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/Z8YFb.png\" alt=\"enter image description here\" /></a></p>\n<h2>The error:</h2>\n<p><a href=\"https://i.stack.imgur.com/zbTO3.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/zbTO3.png\" alt=\"enter image description here\" /></a></p>\n",
                    "OwnerUserId": "20237088",
                    "LastEditorUserId": "17865804",
                    "LastEditDate": "2022-10-14T11:51:46.720",
                    "LastActivityDate": "2022-10-16T08:45:09.227",
                    "Title": "\"Value is not a valid email address\" when sending multiple email addresses using Pydantic, FastAPI and Swagger UI",
                    "Tags": "<python><swagger><swagger-ui><fastapi><pydantic>",
                    "AnswerCount": "2",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "74175401",
                "ParentRepo": "https://github.com/wandb/wandb/issues/4409",
                "StackOverflow_Post": {
                    "Id": "74175401",
                    "PostTypeId": "1",
                    "CreationDate": "2022-10-23T23:04:20.533",
                    "Score": "1",
                    "ViewCount": "219",
                    "Body": "<p>I am having a weird issue where I change the location of all my code &amp; data to a different location with more disk space, then I soft link my projects &amp; data to those locations with more space. I assume there must be some file handle issue because wandb's logger is throwing me issues. So my questions:</p>\n<ol>\n<li>how do I have wandb only log  online and not locally? (e.g. stop trying to log anything to <code>./wandb</code>[or any secret place it might be logging to]  since it's creating issues). Note my code was running fine after I  stopped logging to wandb so I assume that was the issue. note that the <code>dir=None</code> is the default to wandb's param.</li>\n<li>how do I resolve this issue entirely so that it works seemlessly with all my projects softlinked somewhere else?</li>\n</ol>\n<hr />\n<h1>More details on the error</h1>\n<pre><code>Traceback (most recent call last):\n  File &quot;/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/logging/__init__.py&quot;, line 1087, in emit\n    self.flush()\n  File &quot;/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/logging/__init__.py&quot;, line 1067, in flush\n    self.stream.flush()\nOSError: [Errno 116] Stale file handle\nCall stack:\n  File &quot;/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/threading.py&quot;, line 930, in _bootstrap\n    self._bootstrap_inner()\n  File &quot;/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/threading.py&quot;, line 973, in _bootstrap_inner\n    self.run()\n  File &quot;/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/site-packages/wandb/vendor/watchdog/observers/api.py&quot;, line 199, in run\n    self.dispatch_events(self.event_queue, self.timeout)\n  File &quot;/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/site-packages/wandb/vendor/watchdog/observers/api.py&quot;, line 368, in dispatch_events\n    handler.dispatch(event)\n  File &quot;/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/site-packages/wandb/vendor/watchdog/events.py&quot;, line 454, in dispatch\n    _method_map[event_type](event)\n  File &quot;/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/site-packages/wandb/filesync/dir_watcher.py&quot;, line 275, in _on_file_created\n    logger.info(&quot;file/dir created: %s&quot;, event.src_path)\nMessage: 'file/dir created: %s'\nArguments: ('/shared/rsaas/miranda9/diversity-for-predictive-success-of-meta-learning/wandb/run-20221023_170722-1tfzh49r/files/output.log',)\n--- Logging error ---\nTraceback (most recent call last):\n  File &quot;/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/logging/__init__.py&quot;, line 1087, in emit\n    self.flush()\n  File &quot;/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/logging/__init__.py&quot;, line 1067, in flush\n    self.stream.flush()\nOSError: [Errno 116] Stale file handle\nCall stack:\n  File &quot;/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/threading.py&quot;, line 930, in _bootstrap\n    self._bootstrap_inner()\n  File &quot;/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/threading.py&quot;, line 973, in _bootstrap_inner\n    self.run()\n  File &quot;/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/site-packages/wandb/sdk/internal/internal_util.py&quot;, line 50, in run\n    self._run()\n  File &quot;/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/site-packages/wandb/sdk/internal/internal_util.py&quot;, line 101, in _run\n    self._process(record)\n  File &quot;/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/site-packages/wandb/sdk/internal/internal.py&quot;, line 263, in _process\n    self._hm.handle(record)\n  File &quot;/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/site-packages/wandb/sdk/internal/handler.py&quot;, line 130, in handle\n    handler(record)\n  File &quot;/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/site-packages/wandb/sdk/internal/handler.py&quot;, line 138, in handle_request\n    logger.debug(f&quot;handle_request: {request_type}&quot;)\nMessage: 'handle_request: stop_status'\nArguments: ()\nN/A% (0 of 100000) |      | Elapsed Time: 0:00:00 | ETA:  --:--:-- |   0.0 s/it\n\nTraceback (most recent call last):\n  File &quot;/home/miranda9/diversity-for-predictive-success-of-meta-learning/div_src/diversity_src/experiment_mains/main_dist_maml_l2l.py&quot;, line 1814, in &lt;module&gt;\n    main()\n  File &quot;/home/miranda9/diversity-for-predictive-success-of-meta-learning/div_src/diversity_src/experiment_mains/main_dist_maml_l2l.py&quot;, line 1747, in main\n    train(args=args)\n  File &quot;/home/miranda9/diversity-for-predictive-success-of-meta-learning/div_src/diversity_src/experiment_mains/main_dist_maml_l2l.py&quot;, line 1794, in train\n    meta_train_iterations_ala_l2l(args, args.agent, args.opt, args.scheduler)\n  File &quot;/home/miranda9/ultimate-utils/ultimate-utils-proj-src/uutils/torch_uu/training/meta_training.py&quot;, line 167, in meta_train_iterations_ala_l2l\n    log_zeroth_step(args, meta_learner)\n  File &quot;/home/miranda9/ultimate-utils/ultimate-utils-proj-src/uutils/logging_uu/wandb_logging/meta_learning.py&quot;, line 92, in log_zeroth_step\n    log_train_val_stats(args, args.it, step_name, train_loss, train_acc, training=True)\n  File &quot;/home/miranda9/ultimate-utils/ultimate-utils-proj-src/uutils/logging_uu/wandb_logging/supervised_learning.py&quot;, line 55, in log_train_val_stats\n    _log_train_val_stats(args=args,\n  File &quot;/home/miranda9/ultimate-utils/ultimate-utils-proj-src/uutils/logging_uu/wandb_logging/supervised_learning.py&quot;, line 116, in _log_train_val_stats\n    args.logger.log('\\n')\n  File &quot;/home/miranda9/ultimate-utils/ultimate-utils-proj-src/uutils/logger.py&quot;, line 89, in log\n    print(msg, flush=flush)\n  File &quot;/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/site-packages/wandb/sdk/lib/redirect.py&quot;, line 640, in write\n    self._old_write(data)\nOSError: [Errno 116] Stale file handle\nwandb: Waiting for W&amp;B process to finish... (failed 1). Press Control-C to abort syncing.\nwandb: Synced vit_mi Adam_rfs_cifarfs Adam_cosine_scheduler_rfs_cifarfs 0.001: args.jobid=101161: https://wandb.ai/brando/entire-diversity-spectrum/runs/1tfzh49r\nwandb: Synced 6 W&amp;B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\nwandb: Find logs at: ./wandb/run-20221023_170722-1tfzh49r/logs\n--- Logging error ---\nTraceback (most recent call last):\n  File &quot;/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/site-packages/wandb/sdk/interface/router_sock.py&quot;, line 27, in _read_message\n    resp = self._sock_client.read_server_response(timeout=1)\n  File &quot;/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/site-packages/wandb/sdk/lib/sock_client.py&quot;, line 283, in read_server_response\n    data = self._read_packet_bytes(timeout=timeout)\n  File &quot;/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/site-packages/wandb/sdk/lib/sock_client.py&quot;, line 269, in _read_packet_bytes\n    raise SockClientClosedError()\nwandb.sdk.lib.sock_client.SockClientClosedError\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File &quot;/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/site-packages/wandb/sdk/interface/router.py&quot;, line 70, in message_loop\n    msg = self._read_message()\n  File &quot;/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/site-packages/wandb/sdk/interface/router_sock.py&quot;, line 29, in _read_message\n    raise MessageRouterClosedError\nwandb.sdk.interface.router.MessageRouterClosedError\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File &quot;/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/logging/__init__.py&quot;, line 1087, in emit\n    self.flush()\n  File &quot;/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/logging/__init__.py&quot;, line 1067, in flush\n    self.stream.flush()\nOSError: [Errno 116] Stale file handle\nCall stack:\n  File &quot;/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/threading.py&quot;, line 930, in _bootstrap\n    self._bootstrap_inner()\n  File &quot;/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/threading.py&quot;, line 973, in _bootstrap_inner\n    self.run()\n  File &quot;/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/threading.py&quot;, line 910, in run\n    self._target(*self._args, **self._kwargs)\n  File &quot;/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/site-packages/wandb/sdk/interface/router.py&quot;, line 77, in message_loop\n    logger.warning(&quot;message_loop has been closed&quot;)\nMessage: 'message_loop has been closed'\nArguments: ()\n/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/tempfile.py:817: ResourceWarning: Implicitly cleaning up &lt;TemporaryDirectory '/srv/condor/execute/dir_27749/tmpmvf78q6owandb'&gt;\n  _warnings.warn(warn_message, ResourceWarning)\n/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/tempfile.py:817: ResourceWarning: Implicitly cleaning up &lt;TemporaryDirectory '/srv/condor/execute/dir_27749/tmpt5etqpw_wandb-artifacts'&gt;\n  _warnings.warn(warn_message, ResourceWarning)\n/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/tempfile.py:817: ResourceWarning: Implicitly cleaning up &lt;TemporaryDirectory '/srv/condor/execute/dir_27749/tmp55lzwviywandb-media'&gt;\n  _warnings.warn(warn_message, ResourceWarning)\n/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/tempfile.py:817: ResourceWarning: Implicitly cleaning up &lt;TemporaryDirectory '/srv/condor/execute/dir_27749/tmprmk7lnx4wandb-media'&gt;\n  _warnings.warn(warn_message, ResourceWarning)\n</code></pre>\n<hr />\n<p>Error:</p>\n<pre><code>====&gt; about to start train loop\nStarting training!\nWARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1129)'))': /api/5288891/envelope/\n--- Logging error ---\nTraceback (most recent call last):\n  File &quot;/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/logging/__init__.py&quot;, line 1086, in emit\n    stream.write(msg + self.terminator)\n  File &quot;/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/site-packages/wandb/sdk/lib/redirect.py&quot;, line 640, in write\n    self._old_write(data)\nOSError: [Errno 116] Stale file handle\nCall stack:\n  File &quot;/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/threading.py&quot;, line 930, in _bootstrap\n    self._bootstrap_inner()\n  File &quot;/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/threading.py&quot;, line 973, in _bootstrap_inner\n    self.run()\n  File &quot;/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/threading.py&quot;, line 910, in run\n    self._target(*self._args, **self._kwargs)\n  File &quot;/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/site-packages/sentry_sdk/worker.py&quot;, line 128, in _target\n    callback()\n  File &quot;/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/site-packages/sentry_sdk/transport.py&quot;, line 467, in send_envelope_wrapper\n    self._send_envelope(envelope)\n  File &quot;/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/site-packages/sentry_sdk/transport.py&quot;, line 384, in _send_envelope\n    self._send_request(\n  File &quot;/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/site-packages/sentry_sdk/transport.py&quot;, line 230, in _send_request\n    response = self._pool.request(\n  File &quot;/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/site-packages/urllib3/request.py&quot;, line 78, in request\n    return self.request_encode_body(\n  File &quot;/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/site-packages/urllib3/request.py&quot;, line 170, in request_encode_body\n    return self.urlopen(method, url, **extra_kw)\n  File &quot;/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/site-packages/urllib3/poolmanager.py&quot;, line 375, in urlopen\n    response = conn.urlopen(method, u.request_uri, **kw)\n  File &quot;/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/site-packages/urllib3/connectionpool.py&quot;, line 780, in urlopen\n    log.warning(\nMessage: &quot;Retrying (%r) after connection broken by '%r': %s&quot;\nArguments: (Retry(total=2, connect=None, read=None, redirect=None, status=None), SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1129)')), '/api/5288891/envelope/')\n</code></pre>\n<hr />\n<h1>Bounty</h1>\n<p>My suggestions on what might solve this are:</p>\n<ol>\n<li>Figuring out a way to stop wandb logging locally or minimize the amount of logging wandb is logging locally.</li>\n<li>Figure out what is exactly being logged and minimize the space.</li>\n<li>have the logging work even if all the folders are being symlinked. (imho this should work out of the box)</li>\n<li>figuring out a systematic and simple way to find where the stale file handles are coming from.</li>\n</ol>\n<p>I am surprised moving <strong>everything</strong> to <code>/shared/rsaas/miranda9/</code> and running experiments from there did not solve the issue.</p>\n<hr />\n<p>cross:</p>\n<ul>\n<li><a href=\"https://community.wandb.ai/t/how-to-stop-logging-locally-but-only-save-to-wandbs-servers-and-have-wandb-work-using-soft-links/3305\" rel=\"nofollow noreferrer\">https://community.wandb.ai/t/how-to-stop-logging-locally-but-only-save-to-wandbs-servers-and-have-wandb-work-using-soft-links/3305</a></li>\n<li><a href=\"https://www.reddit.com/r/learnmachinelearning/comments/ybvo73/how_to_stop_logging_locally_but_only_save_to/\" rel=\"nofollow noreferrer\">https://www.reddit.com/r/learnmachinelearning/comments/ybvo73/how_to_stop_logging_locally_but_only_save_to/</a></li>\n<li>gitissue: <a href=\"https://github.com/wandb/wandb/issues/4409\" rel=\"nofollow noreferrer\">https://github.com/wandb/wandb/issues/4409</a></li>\n</ul>\n",
                    "OwnerUserId": "1601580",
                    "LastEditorUserId": "1601580",
                    "LastEditDate": "2022-10-26T17:39:34.157",
                    "LastActivityDate": "2022-11-02T03:33:58.257",
                    "Title": "How to stop logging locally but only save to wandb's servers and have wandb work using soft links?",
                    "Tags": "<python><machine-learning><deep-learning><pytorch><wandb>",
                    "AnswerCount": "2",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "74227930",
                "ParentRepo": "https://github.com/aptos-labs/aptos-core/blob/05d04ecc511f572380e1e8fe0bbc234f30645f0d/ecosystem/python/sdk/aptos_sdk/client.py#L63",
                "StackOverflow_Post": {
                    "Id": "74227930",
                    "PostTypeId": "2",
                    "ParentId": "74133381",
                    "CreationDate": "2022-10-27T20:25:12.953",
                    "Score": "4",
                    "Body": "<p>If you want to read a resource on an account, you would submit a read request to the API. For example, with curl:</p>\n<pre><code>curl https://fullnode.mainnet.aptoslabs.com/v1/accounts/&lt;addr&gt;/resource/&lt;resource&gt;\n</code></pre>\n<p>A concrete example of this:</p>\n<pre><code>curl https://fullnode.mainnet.aptoslabs.com/v1/accounts/0x00ffe770ccae2e373bc1f217585a1f97b5fa003cc169a27e1b4d6bfc8d3b243b/resource/0x3::token::TokenStore\n</code></pre>\n<p>This is equivalent to:</p>\n<blockquote>\n<p>Read the resource <code>0x3::token::TokenStore</code> at account <code>0x00ffe770ccae2e373bc1f217585a1f97b5fa003cc169a27e1b4d6bfc8d3b243b</code>.</p>\n</blockquote>\n<p>In the Python SDK, you would do something like this:</p>\n<pre class=\"lang-py prettyprint-override\"><code>client.account_resource(\n    &quot;0x00ffe770ccae2e373bc1f217585a1f97b5fa003cc169a27e1b4d6bfc8d3b243b&quot;,\n    &quot;0x3::token::TokenStore&quot;,\n)\n</code></pre>\n<p>This uses this client method: <a href=\"https://github.com/aptos-labs/aptos-core/blob/05d04ecc511f572380e1e8fe0bbc234f30645f0d/ecosystem/python/sdk/aptos_sdk/client.py#L63\" rel=\"nofollow noreferrer\">https://github.com/aptos-labs/aptos-core/blob/05d04ecc511f572380e1e8fe0bbc234f30645f0d/ecosystem/python/sdk/aptos_sdk/client.py#L63</a></p>\n<p>The <code>get_message</code> function in the hello_blockchain example is somewhat misleading (we can improve this). There is a hint though, note that only <code>entry</code> functions can be run from external calls (e.g. using the CLI command <code>aptos move run</code>). All other functions can only be called from within a Move module.</p>\n<p>To be even clearer: In order to read from the Aptos blockchain, you must make requests to the read API endpoints, not to &quot;read functions&quot; in Move modules.</p>\n<p>For more info, check out these docs: <a href=\"https://aptos.dev/tutorials/your-first-transaction\" rel=\"nofollow noreferrer\">https://aptos.dev/tutorials/your-first-transaction</a>.</p>\n",
                    "OwnerUserId": "3846032",
                    "LastEditorUserId": "3846032",
                    "LastEditDate": "2022-10-27T20:41:56.817",
                    "LastActivityDate": "2022-10-27T20:41:56.817",
                    "CommentCount": "6",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "74458486",
                "ParentRepo": "https://github.com/fancidev/qtinter",
                "StackOverflow_Post": {
                    "Id": "74458486",
                    "PostTypeId": "2",
                    "ParentId": "70402725",
                    "CreationDate": "2022-11-16T09:59:43.113",
                    "Score": "1",
                    "Body": "<p>FWIW, you may also use the <a href=\"https://github.com/fancidev/qtinter\" rel=\"nofollow noreferrer\">qtinter</a> package to replace quamash, which supports Python 3.7 to 3.11.  (<em>Disclaimer</em>: I'm the author of <code>qtinter</code>.)</p>\n<p>With <code>qtinter</code> the last few lines need to be changed to the following:</p>\n<pre><code>app = QApplication(sys.argv)\napp.setApplicationName(&quot;Sample ;)&quot;)\n\nwith qtinter.using_asyncio_from_qt():\n    window = App(asyncio.get_running_loop())\n    window.show()\n    app.exec()\n</code></pre>\n",
                    "OwnerUserId": "1465038",
                    "LastActivityDate": "2022-11-16T09:59:43.113",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "74526115",
                "ParentRepo": "https://github.com/searxng/searxng",
                "StackOverflow_Post": {
                    "Id": "74526115",
                    "PostTypeId": "1",
                    "CreationDate": "2022-11-22T00:06:12.773",
                    "Score": "0",
                    "ViewCount": "48",
                    "Body": "<p>I searched for, and would like to expand/continue on the OP's question on how to resolve a Python error</p>\n<p><a href=\"https://stackoverflow.com/questions/72694757/cryptographydeprecationwarning-python-3-6-is-no-longer-supported-by-the-python?\">Related</a></p>\n<ul>\n<li>New installation of Ubuntu 20.04 on local bare-metal.</li>\n<li>Installed Docker using official installation guide, with Docker Compose.</li>\n<li>Executed instructions to install <a href=\"https://github.com/searxng/searxng\" rel=\"nofollow noreferrer\">SearXNG</a> docker image and run <code>docker-compose up</code>.</li>\n</ul>\n<p>Program terminated with:</p>\n<pre><code>/snap/docker/2285/lib/python3.6/site-packages/paramiko/transport.py:33: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography and will be removed in a future release.\n  from cryptography.hazmat.backends import default_backend\nERROR:\n        Can't find a suitable configuration file in this directory or any\n        parent. Are you in the right directory?\n\n        Supported filenames: docker-compose.yml, docker-compose.yaml, compose.yml, compose.yaml\n</code></pre>\n<p>Currently installed Python version is 3.10.6. The directory listing clearly shows:</p>\n<pre><code>%%%%@%%%%server1:/usr/local/searxng-docker# ls\nCaddyfile  LICENSE  README.md  docker-compose.yaml  searxng  searxng-docker.service.template\n</code></pre>\n<p>A helpful answer to the original question by <a href=\"https://stackoverflow.com/users/16659957/luv-python\">Luv_Python</a> suggested that a downgrade of <code>Paramiko</code> may be warranted. And, looking at source code (and I am using an IP address for hostname in SearXNG), I am using SSH, or at least Docker Compose is, when scripted.</p>\n<p>I shouldn't expect a breakdown on how to fix this. Just some direction on <strong>what</strong> library, software, Github author etc. to report it to. I politely refuse to accept that a downgrade in software, and therefore security, is the only way to correct the issue.</p>\n<p>Perhaps, I should just spool a Linode instance, with Docker and a domain name. Maybe this is the expected installation by the development team?!</p>\n",
                    "OwnerUserId": "20567261",
                    "LastActivityDate": "2022-11-22T00:06:12.773",
                    "Title": "Docker / Compose and subsequent halt to installation of SearXNG",
                    "Tags": "<python><linux>",
                    "AnswerCount": "0",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "74559115",
                "ParentRepo": "https://github.com/JovianX/Service-Hub/tree/182-events/application/services/procrastinate",
                "StackOverflow_Post": {
                    "Id": "74559115",
                    "PostTypeId": "1",
                    "CreationDate": "2022-11-24T10:20:31.447",
                    "Score": "1",
                    "ViewCount": "56",
                    "Body": "<p>I'm trying to use SQLAlchemy in async way with <a href=\"https://procrastinate.readthedocs.io/en/stable/\" rel=\"nofollow noreferrer\">procrastinate</a> task executor.</p>\n<p>When I'm executing task:</p>\n<pre><code>@procrastinate.task(name='application__remove_components')\nasync def remove_applicatoin_components(application_id: int):\n    &quot;&quot;&quot;\n    Uninstalls application components. If all application components uninstalled\n    successfully runs post-terminate hooks.\n    &quot;&quot;&quot;\n    async with session_maker() as session:\n        application_manager = get_application_manager(session)\n        application = await application_manager.get_application(application_id)\n        manifest: TemplateSchema = load_template(application.manifest)\n        try:\n            await asyncio.gather(*[\n                application_manager.uninstall_component(application, component)\n                for component in manifest.components if component.enabled\n            ])\n        except ApplicationComponentUninstallException:\n            await application_manager.set_state_status(application, ApplicationStatuses.error)\n            raise\n\n    await execute_post_terminate_hooks.defer_async(application_id=application_id)\n</code></pre>\n<p>I getting next error:</p>\n<pre><code>task-executor_1  | /home/app/hub/crud/base.py:34: SAWarning: Usage of the 'Session.add()' operation is not currently supported within the execution stage of the flush process. Results may not be consistent.  Consider using alternative event listeners or connection-level operations instead.\ntask-executor_1  |   self.session.add(instance)\ntask-executor_1  | ERROR:procrastinate.worker.worker:Job application__remove_components[23373](application_id=78) ended with status: Error, lasted 2.818 s\ntask-executor_1  | Traceback (most recent call last):\ntask-executor_1  |   File &quot;/usr/local/lib/python3.10/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py&quot;, line 739, in commit\ntask-executor_1  |     self.await_(self._transaction.commit())\ntask-executor_1  |   File &quot;/usr/local/lib/python3.10/site-packages/sqlalchemy/util/_concurrency_py3k.py&quot;, line 68, in await_only\ntask-executor_1  |     return current.driver.switch(awaitable)\ntask-executor_1  |   File &quot;/usr/local/lib/python3.10/site-packages/sqlalchemy/util/_concurrency_py3k.py&quot;, line 121, in greenlet_spawn\ntask-executor_1  |     value = await result\ntask-executor_1  |   File &quot;/usr/local/lib/python3.10/site-packages/asyncpg/transaction.py&quot;, line 211, in commit\ntask-executor_1  |     await self.__commit()\ntask-executor_1  |   File &quot;/usr/local/lib/python3.10/site-packages/asyncpg/transaction.py&quot;, line 179, in __commit\ntask-executor_1  |     await self._connection.execute(query)\ntask-executor_1  |   File &quot;/usr/local/lib/python3.10/site-packages/asyncpg/connection.py&quot;, line 317, in execute\ntask-executor_1  |     return await self._protocol.query(query, timeout)\ntask-executor_1  |   File &quot;asyncpg/protocol/protocol.pyx&quot;, line 323, in query\ntask-executor_1  |   File &quot;asyncpg/protocol/protocol.pyx&quot;, line 707, in asyncpg.protocol.protocol.BaseProtocol._check_state\ntask-executor_1  | asyncpg.exceptions._base.InterfaceError: cannot perform operation: another operation is in progress\ntask-executor_1  | \ntask-executor_1  | The above exception was the direct cause of the following exception:\ntask-executor_1  | \ntask-executor_1  | Traceback (most recent call last):\ntask-executor_1  |   File &quot;/usr/local/lib/python3.10/site-packages/sqlalchemy/engine/base.py&quot;, line 1089, in _commit_impl\ntask-executor_1  |     self.engine.dialect.do_commit(self.connection)\ntask-executor_1  |   File &quot;/usr/local/lib/python3.10/site-packages/sqlalchemy/engine/default.py&quot;, line 686, in do_commit\ntask-executor_1  |     dbapi_connection.commit()\ntask-executor_1  |   File &quot;/usr/local/lib/python3.10/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py&quot;, line 741, in commit\ntask-executor_1  |     self._handle_exception(error)\ntask-executor_1  |   File &quot;/usr/local/lib/python3.10/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py&quot;, line 682, in _handle_exception\ntask-executor_1  |     raise translated_error from error\ntask-executor_1  | sqlalchemy.dialects.postgresql.asyncpg.AsyncAdapt_asyncpg_dbapi.InterfaceError: &lt;class 'asyncpg.exceptions._base.InterfaceError'&gt;: cannot perform operation: another operation is in progress\ntask-executor_1  | \ntask-executor_1  | The above exception was the direct cause of the following exception:\ntask-executor_1  | \ntask-executor_1  | Traceback (most recent call last):\ntask-executor_1  |   File &quot;/usr/local/lib/python3.10/site-packages/procrastinate/worker.py&quot;, line 231, in run_job\ntask-executor_1  |     task_result = await task_result\ntask-executor_1  |   File &quot;/home/app/hub/services/procrastinate/tasks/application/terminate_flow.py&quot;, line 63, in remove_applicatoin_components\ntask-executor_1  |     await asyncio.gather(*[\ntask-executor_1  |   File &quot;/home/app/hub/managers/applications.py&quot;, line 380, in uninstall_component\ntask-executor_1  |     await self.helm_manager.uninstall_release(\ntask-executor_1  |   File &quot;/home/app/hub/managers/helm/manager.py&quot;, line 482, in uninstall_release\ntask-executor_1  |     await self.event_manager.create(EventSchema(\ntask-executor_1  |   File &quot;/home/app/hub/managers/events.py&quot;, line 26, in create\ntask-executor_1  |     await self.db.create(event.dict())\ntask-executor_1  |   File &quot;/home/app/hub/crud/base.py&quot;, line 35, in create\ntask-executor_1  |     await self.session.commit()\ntask-executor_1  |   File &quot;/usr/local/lib/python3.10/site-packages/sqlalchemy/ext/asyncio/session.py&quot;, line 582, in commit\ntask-executor_1  |     return await greenlet_spawn(self.sync_session.commit)\ntask-executor_1  |   File &quot;/usr/local/lib/python3.10/site-packages/sqlalchemy/util/_concurrency_py3k.py&quot;, line 126, in greenlet_spawn\ntask-executor_1  |     result = context.throw(*sys.exc_info())\ntask-executor_1  |   File &quot;/usr/local/lib/python3.10/site-packages/sqlalchemy/orm/session.py&quot;, line 1451, in commit\ntask-executor_1  |     self._transaction.commit(_to_root=self.future)\ntask-executor_1  |   File &quot;/usr/local/lib/python3.10/site-packages/sqlalchemy/orm/session.py&quot;, line 846, in commit\ntask-executor_1  |     return self._parent.commit(_to_root=True)\ntask-executor_1  |   File &quot;/usr/local/lib/python3.10/site-packages/sqlalchemy/orm/session.py&quot;, line 836, in commit\ntask-executor_1  |     trans.commit()\ntask-executor_1  |   File &quot;/usr/local/lib/python3.10/site-packages/sqlalchemy/engine/base.py&quot;, line 2459, in commit\ntask-executor_1  |     self._do_commit()\ntask-executor_1  |   File &quot;/usr/local/lib/python3.10/site-packages/sqlalchemy/engine/base.py&quot;, line 2649, in _do_commit\ntask-executor_1  |     self._connection_commit_impl()\ntask-executor_1  |   File &quot;/usr/local/lib/python3.10/site-packages/sqlalchemy/engine/base.py&quot;, line 2620, in _connection_commit_impl\ntask-executor_1  |     self.connection._commit_impl()\ntask-executor_1  |   File &quot;/usr/local/lib/python3.10/site-packages/sqlalchemy/engine/base.py&quot;, line 1091, in _commit_impl\ntask-executor_1  |     self._handle_dbapi_exception(e, None, None, None, None)\ntask-executor_1  |   File &quot;/usr/local/lib/python3.10/site-packages/sqlalchemy/engine/base.py&quot;, line 2124, in _handle_dbapi_exception\ntask-executor_1  |     util.raise_(\ntask-executor_1  |   File &quot;/usr/local/lib/python3.10/site-packages/sqlalchemy/util/compat.py&quot;, line 210, in raise_\ntask-executor_1  |     raise exception\ntask-executor_1  |   File &quot;/usr/local/lib/python3.10/site-packages/sqlalchemy/engine/base.py&quot;, line 1089, in _commit_impl\ntask-executor_1  |     self.engine.dialect.do_commit(self.connection)\ntask-executor_1  |   File &quot;/usr/local/lib/python3.10/site-packages/sqlalchemy/engine/default.py&quot;, line 686, in do_commit\ntask-executor_1  |     dbapi_connection.commit()\ntask-executor_1  |   File &quot;/usr/local/lib/python3.10/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py&quot;, line 741, in commit\ntask-executor_1  |     self._handle_exception(error)\ntask-executor_1  |   File &quot;/usr/local/lib/python3.10/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py&quot;, line 682, in _handle_exception\ntask-executor_1  |     raise translated_error from error\ntask-executor_1  | sqlalchemy.exc.InterfaceError: (sqlalchemy.dialects.postgresql.asyncpg.InterfaceError) &lt;class 'asyncpg.exceptions._base.InterfaceError'&gt;: cannot perform operation: another operation is in progress\ntask-executor_1  | (Background on this error at: https://sqlalche.me/e/14/rvf5)\n</code></pre>\n<p>This code is opensource and you can <a href=\"https://github.com/JovianX/Service-Hub/tree/182-events/application/services/procrastinate\" rel=\"nofollow noreferrer\">investigate</a> if you need.\nWhat I have tried:</p>\n<ol>\n<li>Disabling connection pool by passing <code>NullPool</code> to engine.</li>\n<li>As experiment tried to extend connection pool size to pool_size=50, max_overflow=100 .</li>\n<li>Tried to create new instance of engine, session maker, session.</li>\n</ol>\n",
                    "OwnerUserId": "753973",
                    "LastActivityDate": "2022-11-24T10:20:31.447",
                    "Title": "SQLAlchemy with asyncpg cannot perform operation: another operation is in progress",
                    "Tags": "<python><postgresql><sqlalchemy><python-asyncio>",
                    "AnswerCount": "0",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "74613780",
                "ParentRepo": "https://github.com/hwchase17/langchain",
                "StackOverflow_Post": {
                    "Id": "74613780",
                    "PostTypeId": "1",
                    "CreationDate": "2022-11-29T12:01:18.117",
                    "Score": "-2",
                    "ViewCount": "38",
                    "Body": "<p>I'm trying to build my own features for a python module (in this case, building LLM tools using <a href=\"https://github.com/hwchase17/langchain\" rel=\"nofollow noreferrer\">langchain</a>). I've forked the repo into my project folder, navigated to the newly created fork, and did <code>pip install -e .</code>, which was successful.</p>\n<p>However, when I try to <code>from langchain import LLMChain</code>, I get an <code>ImportError: cannot import name 'LLMChain' from 'langchain' (unknown location)</code></p>\n<p>I realized that this is because the <code>langchain</code> git repo itself contains a folder called <code>langchain</code>, which is the actual python module. you get if you just <code>pip install langchain</code>, so I solved this by using <code>from langchain.langchain import LLMChain</code>.\nHowever, I then got another similar ImportError originating from the <code>__init__.py</code> file: <code>ImportError: cannot import name 'ConversationChain' from 'langchain.chains' (unknown location)</code></p>\n<p>So, my question is: is there a way to change the path such that referencing <code>langchain</code> actually references <code>langchain/langchain</code>? I also tried deleting and reinstalling everything, navigating to <code>langchain/langchain</code> doing <code>pip install -e .</code> in there specifically, but got <code>ERROR: /path/to/langchain/langchain does not appear to be a Python project: neither 'setup.py' nor 'pyproject.toml' found.</code></p>\n<p>I'm quite new to this so I may be missing something obvious, thanks!</p>\n<p>EDIT: it seems like this error only occurs when I'm trying to run python outside of the original langchain directory that I cloned in. I'm going to mark as resolved but I'm wondering why I wouldn't be able to work in my normal project directory</p>\n",
                    "OwnerUserId": "19127793",
                    "LastEditorUserId": "19127793",
                    "LastEditDate": "2022-11-29T12:49:34.200",
                    "LastActivityDate": "2022-11-29T12:54:44.677",
                    "Title": "Forking a python module and working on it using pip install -e, getting ImportError due to paths not being consistent?",
                    "Tags": "<python><import><module><pip>",
                    "AnswerCount": "0",
                    "CommentCount": "11",
                    "ClosedDate": "2022-12-01T22:10:58.327",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "74646502",
                "ParentRepo": "https://github.com/loft-sh/devspace-example-python",
                "StackOverflow_Post": {
                    "Id": "74646502",
                    "PostTypeId": "2",
                    "ParentId": "74600160",
                    "CreationDate": "2022-12-01T18:20:34.817",
                    "Score": "1",
                    "Body": "<p>Yes, you can absolutely use whatever image you want -- the example/pre-canned devspace containers that are published are just a starting point for you.</p>\n<p>There is a python specific example <a href=\"https://github.com/loft-sh/devspace-example-python\" rel=\"nofollow noreferrer\">here</a> that covers everything you should need.</p>\n<p>TL:DR -- build your image with whatever you want in it, and set that image as the image in your deployment and/or dev sections of the devspace.yaml file. You can have devspace build the image for you as well by setting the appropriate <code>image</code> block with your docker file/context/and image name.</p>\n<p>An example devspace.yaml:</p>\n<pre class=\"lang-yaml prettyprint-override\"><code>version: v2beta1\nname: myapp\n\nvars:\n  MYIMAGE: myimagename\n  MYDEVIMAGE: mydevimagename\n\nimages:\n  myapp:\n    image: ${MYIMAGE}\n    context: ./\n    dockerfile: ./Dockerfile\n    rebuildStrategy: ignoreContextChanges\n\n  myappdev:\n    image: ${MYDEVIMAGE}\n    context: ./\n    dockerfile: ./Dockerfile.dev\n    rebuildStrategy: ignoreContextChanges\n\ndeployments:\n  myapp:\n    # you can also use manifests instead of helm charts, see devspace docs, its all covered there\n    helm:\n      chart:\n        name: ./path/to/my/chart \n\ndev:\n  myapp:\n    labelSelector:\n      app: myapp\n    devImage: ${MYDEVIMAGE}\n    # other dev things like sync and terminal as needed\n\n</code></pre>\n",
                    "OwnerUserId": "20659173",
                    "LastActivityDate": "2022-12-01T18:20:34.817",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            }
        ],
        "Type": 2
    },
    "https://github.com/cisagov/log4j-affected-db": {
        "CVE Description": [
            "Apache Log4j2 2.0-beta9 through 2.15.0 (excluding security releases 2.12.2, 2.12.3, and 2.3.1) JNDI features used in configuration, log messages, and parameters do not protect against attacker controlled LDAP and other JNDI related endpoints. An attacker who can control log messages or log message parameters can execute arbitrary code loaded from LDAP servers when message lookup substitution is enabled. From log4j 2.15.0, this behavior has been disabled by default. From version 2.16.0 (along with 2.12.2, 2.12.3, and 2.3.1), this functionality has been completely removed. Note that this vulnerability is specific to log4j-core and does not affect log4net, log4cxx, or other Apache Logging Services projects."
        ],
        "Edges": [
            {
                "SID": "70382798",
                "StackOverflow_Post": {
                    "Id": "70382798",
                    "PostTypeId": "2",
                    "ParentId": "70362519",
                    "CreationDate": "2021-12-16T16:54:48.107",
                    "Score": "0",
                    "Body": "<p>Here you find a list of affected software. Cassandra is not in the list. <a href=\"https://github.com/cisagov/log4j-affected-db\" rel=\"nofollow noreferrer\">https://github.com/cisagov/log4j-affected-db</a></p>\n",
                    "OwnerUserId": "2761985",
                    "LastActivityDate": "2021-12-16T16:54:48.107",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            }
        ],
        "Type":0
    },
    "https://github.com/libming/libming": {
        "CVE Description": [
            "In libming 0.4.8, a memory exhaustion vulnerability exist in the function cws2fws in util/main.c. Remote attackers could launch denial of service attacks by submitting a crafted SWF file that exploits this vulnerability.",
            "In libming 0.4.8, the parseSWF_DEFINELOSSLESS2 function in util/parser.c lacks a boundary check that would lead to denial-of-service attacks via a crafted SWF file."
        ],
        "Edges": [
            {
                "SID": "5768669",
                "StackOverflow_Post": {
                    "Id": "5768669",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "5903700",
                    "CreationDate": "2011-04-24T04:38:23.307",
                    "Score": "5",
                    "ViewCount": "720",
                    "Body": "<p>I was wondering if there is any Python library out there which would allow me to generate  Flash files (a simple slide show of a bunch of images). </p>\n\n<p>I tried installing <a href=\"https://github.com/libming/libming\" rel=\"nofollow\">Ming</a> but was running into some problems, so was wondering if there is any other library out there with better documentation.</p>\n",
                    "OwnerUserId": "388025",
                    "LastEditorUserId": "468793",
                    "LastEditDate": "2011-05-06T10:56:38.040",
                    "LastActivityDate": "2011-05-06T10:56:38.040",
                    "Title": "Python library to generate flash files",
                    "Tags": "<python><flash>",
                    "AnswerCount": "1",
                    "CommentCount": "2",
                    "FavoriteCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            }
        ],
        "Type": 0
    },
    "https://github.com/spipu/html2pdf": {
        "CVE Description": [
            "An issue was discovered in Spipu HTML2PDF before 5.2.4. Attackers can trigger deserialization of arbitrary data via the injection of a malicious <link> tag in the converted HTML document."
        ],
        "Edges": [
            {
                "SID": "391005",
                "StackOverflow_Post": {
                    "Id": "391005",
                    "PostTypeId": "1",
                    "AcceptedAnswerId": "434827",
                    "CreationDate": "2008-12-24T08:14:20.757",
                    "Score": "1715",
                    "ViewCount": "948432",
                    "Body": "<p>I have an HTML (not XHTML) document that renders fine in Firefox 3 and IE 7.  It uses fairly basic CSS to style it and renders fine in HTML.</p>\n\n<p>I'm now after a way of converting it to PDF.  I have tried:</p>\n\n<ul>\n<li><a href=\"https://github.com/dompdf/dompdf\" rel=\"noreferrer\">DOMPDF</a>: it had huge problems with tables.  I factored out my large nested tables and it helped (before it was just consuming up to 128M of memory then dying--thats my limit on memory in php.ini) but it makes a complete mess of tables and doesn't seem to get images.  The tables were just basic stuff with some border styles to add some lines at various points;</li>\n<li><a href=\"https://github.com/spipu/html2pdf\" rel=\"noreferrer\">HTML2PDF and HTML2PS</a>: I actually had better luck with this.  It rendered some of the images (all the images are Google Chart URLs) and the table formatting was much better but it seemed to have some complexity problem I haven't figured out yet and kept dying with unknown node_type() errors.  Not sure where to go from here; and</li>\n<li><a href=\"http://www.msweet.org/projects.php?Z1\" rel=\"noreferrer\">Htmldoc</a>: this seems to work fine on basic HTML but has almost no support for CSS whatsoever so you have to do everything in HTML (I didn't realize it was still 2001 in Htmldoc-land...) so it's useless to me.</li>\n</ul>\n\n<p>I tried a Windows app called Html2Pdf Pilot that actually did a pretty decent job but I need something that at a minimum runs on Linux and ideally runs on-demand via PHP on the Webserver.</p>\n\n<p>What am I missing, or how can I resolve this issue?</p>\n",
                    "OwnerUserId": "18393",
                    "OwnerDisplayName": "cletus",
                    "LastEditorUserId": "14837094",
                    "LastEditDate": "2021-04-05T13:06:47.177",
                    "LastActivityDate": "2021-06-28T14:36:30.453",
                    "Title": "How Can I add HTML And CSS Into PDF",
                    "Tags": "<php><html><css><pdf><pdf-generation>",
                    "AnswerCount": "30",
                    "CommentCount": "21",
                    "FavoriteCount": "0",
                    "ClosedDate": "2016-10-19T18:25:12.227",
                    "CommunityOwnedDate": "2013-12-08T11:09:22.980",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "15920472",
                "ParentRepo": "https://github.com/pi-engine/pi",
                "StackOverflow_Post": {
                    "Id": "15920472",
                    "PostTypeId": "1",
                    "CreationDate": "2013-04-10T08:16:54.637",
                    "Score": "5",
                    "ViewCount": "7252",
                    "Body": "<p>I am building an application on <a href=\"https://github.com/pi-engine/pi\" rel=\"noreferrer\">Pi-engine</a> (a php application engine based on zend framework 2). </p>\n\n<p>In my application the javascript file path depends on the application name, while the application name is\npickded by installer.</p>\n\n<p>For example the url of require.js would be:</p>\n\n<p><code>http://my.site.name/asset/module-{module_name}/script/js/require.js</code></p>\n\n<p>module_name changes according to what name the application is given.</p>\n\n<p>I know I can put path in 'data-main' attribute in backend like:</p>\n\n<pre><code>&lt;script data-main=\"/asset/module-{module_name}/script/\" src=\"/asset/module-{module_name}/script/js/require.js\"&gt;&lt;/script&gt;\n</code></pre>\n\n<p>But I want to know is there any way to set baseurl dynamicly using javascript so that I don't need to touch the backend.</p>\n",
                    "OwnerUserId": "1522830",
                    "LastActivityDate": "2013-12-09T20:12:32.483",
                    "Title": "Is there any way to set baseurl dynamicly in require.js?",
                    "Tags": "<javascript><zend-framework2><requirejs>",
                    "AnswerCount": "4",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "26486476",
                "ParentRepo": "https://github.com/Borales/yii-pdf",
                "StackOverflow_Post": {
                    "Id": "26486476",
                    "PostTypeId": "1",
                    "CreationDate": "2014-10-21T12:14:33.060",
                    "Score": "0",
                    "ViewCount": "1305",
                    "Body": "<p>So As My Title Says , I'm Using the <a href=\"http://www.yiiframework.com/extension/pdf/\" rel=\"nofollow\">YII_PDF EXTENSION</a>  , For that I have follow the below steps :</p>\n\n<ol>\n<li>Download the Extension from Git. <a href=\"https://github.com/Borales/yii-pdf\" rel=\"nofollow\">See</a> </li>\n<li>Put the edpf extension array in cpnfig/Main.php.</li>\n<li>Put the extenstions file in Extenstions folder in a directory extensions.</li>\n<li>Download the mpdf &amp; HTML2PDF and Put the code in Vendors folder.</li>\n</ol>\n\n<p>And When i Run the below code :</p>\n\n<pre><code>$html2pdf = Yii::app()-&gt;ePdf-&gt;HTML2PDF();\n$html2pdf-&gt;WriteHTML($this-&gt;renderPartial('analysis_report_pdf', array(), true));\n$html2pdf-&gt;Output();\n</code></pre>\n\n<p>Than it given me error </p>\n\n<blockquote>\n  <p>Property \"CWebApplication.ePdf\" is not defined.</p>\n</blockquote>\n\n<p>Please Help me where I'm wrong.</p>\n\n<p>Updated :\nSee What I have added in Main.php:</p>\n\n<pre><code> 'ePdf' =&gt; array(\n            'class'         =&gt; 'ext.yii-pdf.EYiiPdf',\n            'params'        =&gt; array(\n            'mpdf'     =&gt; array(\n                'librarySourcePath' =&gt; 'application.vendors.mpdf.*',\n                'constants'         =&gt; array(\n                    '_MPDF_TEMP_PATH' =&gt; Yii::getPathOfAlias('application.runtime'),\n                ),\n                'class'=&gt;'mpdf', // the literal class filename to be loaded from the vendors folder\n                /*'defaultParams'     =&gt; array( // More info: http://mpdf1.com/manual/index.php?tid=184\n                    'mode'              =&gt; '', //  This parameter specifies the mode of the new document.\n                    'format'            =&gt; 'A4', // format A4, A5, ...\n                    'default_font_size' =&gt; 0, // Sets the default document font size in points (pt)\n                    'default_font'      =&gt; '', // Sets the default font-family for the new document.\n                    'mgl'               =&gt; 15, // margin_left. Sets the page margins for the new document.\n                    'mgr'               =&gt; 15, // margin_right\n                    'mgt'               =&gt; 16, // margin_top\n                    'mgb'               =&gt; 16, // margin_bottom\n                    'mgh'               =&gt; 9, // margin_header\n                    'mgf'               =&gt; 9, // margin_footer\n                    'orientation'       =&gt; 'P', // landscape or portrait orientation\n                )*/\n            ),\n            'HTML2PDF' =&gt; array(\n                'librarySourcePath' =&gt; 'application.vendors.html2pdf.*',\n                'classFile'         =&gt; 'html2pdf.class.php', // For adding to Yii::$classMap\n                /*'defaultParams'     =&gt; array( // More info: http://wiki.spipu.net/doku.php?id=html2pdf:en:v4:accueil\n                    'orientation' =&gt; 'P', // landscape or portrait orientation\n                    'format'      =&gt; 'A4', // format A4, A5, ...\n                    'language'    =&gt; 'en', // language: fr, en, it ...\n                    'unicode'     =&gt; true, // TRUE means clustering the input text IS unicode (default = true)\n                    'encoding'    =&gt; 'UTF-8', // charset encoding; Default is UTF-8\n                    'marges'      =&gt; array(5, 5, 5, 8), // margins by default, in order (left, top, right, bottom)\n                )*/\n            )\n        )\n    ),\n</code></pre>\n",
                    "OwnerUserId": "1410056",
                    "LastEditorUserId": "1410056",
                    "LastEditDate": "2014-10-21T12:51:10.090",
                    "LastActivityDate": "2014-10-21T12:57:52.433",
                    "Title": "Yii-PDF Extension Gives Error",
                    "Tags": "<php><yii><yii-extensions><mpdf><html2pdf>",
                    "AnswerCount": "1",
                    "CommentCount": "2",
                    "ContentLicense": "CC BY-SA 3.0"
                }
            },
            {
                "ParentSID": "58540183",
                "ParentRepo": "https://github.com/OpenSID/OpenSID/blob/master/donjo-app/libraries/Date_conv.php#L44",
                "StackOverflow_Post": {
                    "Id": "58540183",
                    "PostTypeId": "2",
                    "ParentId": "31157323",
                    "CreationDate": "2019-10-24T11:17:39.880",
                    "Score": "0",
                    "Body": "<p>More accurate  will be</p>\n\n<pre><code>return floor((11 * $year + 3) / 30) + floor(354 * $year) + floor(30 * $month)\n            - floor(($month - 1) / 2) + $day + 1948440 - 386;\n</code></pre>\n\n<p>You can use the floor instead of int </p>\n\n<p><a href=\"https://github.com/OpenSID/OpenSID/blob/master/donjo-app/libraries/Date_conv.php#L44\" rel=\"nofollow noreferrer\">https://github.com/OpenSID/OpenSID/blob/master/donjo-app/libraries/Date_conv.php#L44</a></p>\n",
                    "OwnerUserId": "1906136",
                    "LastActivityDate": "2019-10-24T11:17:39.880",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            },
            {
                "ParentSID": "70273669",
                "ParentRepo": "https://github.com/GoteoFoundation/goteo",
                "StackOverflow_Post": {
                    "Id": "70273669",
                    "PostTypeId": "1",
                    "CreationDate": "2021-12-08T10:45:10.773",
                    "Score": "0",
                    "ViewCount": "72",
                    "Body": "<p>I'm testing the project Goteo <a href=\"https://github.com/GoteoFoundation/goteo\" rel=\"nofollow noreferrer\">https://github.com/GoteoFoundation/goteo</a> with docker and when I navigate to the site, the request HTTP take 200ms for the first requests. But after, request take minute.</p>\n<p>I use ubuntu 20:04 with firefox.</p>\n<p>For reproduce:</p>\n<pre><code>git clone https://github.com/GoteoFoundation/goteo.git\ncd goteo/\ncp config/docker-settings.yml config/local-docker-settings.yml\ndocker/up\n</code></pre>\n<p>The services will start and we can navigate on <strong>localhost:8081</strong>.</p>\n<p>I don't know if it is a problem related to Docker.</p>\n",
                    "OwnerUserId": "17624727",
                    "LastActivityDate": "2021-12-08T10:45:10.773",
                    "Title": "HTTP request take 300 seconds in docker container",
                    "Tags": "<docker><http><request>",
                    "AnswerCount": "0",
                    "CommentCount": "0",
                    "ContentLicense": "CC BY-SA 4.0"
                }
            }
        ],
        "Type": 1
    }
}