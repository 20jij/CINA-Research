# -*- coding: utf-8 -*-
"""data_pruning.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1k-bBiu-K4io5p6qUFU_PMTeUoTf42aWn
"""



"""# New Section"""

import re
import requests
import json
import numpy as np
import networkx as nx
import pickle
import random
import ndlib.models.ModelConfig as mc
import ndlib.models.epidemics as ep
import torch
import time
from scipy.sparse import coo_matrix
import matplotlib.pyplot as plt
import pandas as pd
from tqdm import tqdm
import pickle

from prunning_methods import *

"""Filter and save the github nodes by year"""

def filter_git_node(years):
  file_path = 'static_features_not_none.json'
  sf_df = pd.read_json(file_path, orient='index')
  sf_df.index.names = ['git_id']
  sf_df['created_at'] = pd.to_datetime(sf_df['created_at'])

  gid_set = set()
  for year in years:
    sf_df_year = sf_df[sf_df['created_at'].dt.year == year]
    sf_df_year_copy = sf_df_year.copy()
    sf_df_year_copy['created_at'] = sf_df_year_copy['created_at'].astype(str)
    sf_df_year_copy.to_json('static_features_' + str(year) + '.json', orient='index', indent=4)

    for row in sf_df_year_copy.itertuples(index=True):
        gid = row.Index
        gid_set.add(gid)

  return gid_set

# years = range(2008,2024)
# gid_set = filter_git_node(years)
# print(len(gid_set))

"""Find all github edges for that year"""

# years = range(2008,2015)
# # Initialize an empty dictionary to store the combined data
# combined_data = {}

# # Loop through the file paths and read the JSON files
# for year in years:
#     file_path = 'static_features_' + str(year) + '.json'
#     with open(file_path) as json_file:
#         target_static_features = json.load(json_file)
#         combined_data.update(target_static_features)  # Merge the data into the combined_data dictionary
# # Write the combined data to a new JSON file
# combined_file_path = 'static_features_2008_2015.json'
# with open(combined_file_path, 'w') as combined_file:
#     json.dump(combined_data, combined_file, indent=4)

print("Start building git graph")

orig_features_file_git = 'static_features_2015.json'
target_features_file_git = 'static_features_2008_2015.json'
edges_file_git = 'gid_edges.txt'
G_git, adj_matrix_git, static_array_git = json2graph(orig_features_file_git, target_features_file_git, edges_file_git)

# years = range(2008,2024)
# row_list = []

# for year in years:
#     orig_features_file_git = 'static_features_' + str(year) + '.json'
#     target_features_file_git = 'static_features_' + str(year) + '.json'
#     edges_file_git = 'gid_edges.txt'
#     G_git, adj_matrix_git, static_array_git = json2graph(orig_features_file_git, target_features_file_git, edges_file_git)
#     data = {'year': year, 'nodes': len(G_git.nodes()), 'edges': len(G_git.edges())}
#     row_list.append(data)

# df = pd.DataFrame(row_list)
# df.to_csv('git_graph_Stats_yearly.csv', index=False)  # Set index=False to exclude the index column



# with open('G_git.pkl', 'wb') as fp:
#     pickle.dump(G_git, fp)
# with open('adj_matrix_git.pkl', 'wb') as fp:
#     pickle.dump(adj_matrix_git, fp)
# with open('static_array_git.pkl', 'wb') as fp:
#     pickle.dump(static_array_git, fp)

# print(len(G_git.nodes()))
# print(len(G_git.edges()))

print("Git graph saved")


"""Experiment results: \\
2022, 2021: 653 nodes, 21 edges \\
2022, 2022-2008: 766 nodes, 148 edges \\
2015, 2014: 2465 nodes, 473 edges \\
2015, 2014-2013: 2561 nodes, 723 edges \\
**2015, 2015-2008: 2699 nodes, 1038 edges** \\
2016, 2016-2008: 2594 nodes, 981 edges \\\\

CHOOSE **2015, 2015-2008: 2699 nodes, 1038 edges**
"""



"""Get the corresponding stackoverflow network"""

print("Start building stack graph")

# build the github nodes json file 
git_nodes = {}
for node in G_git.nodes():
   git_nodes[node] = 1
with open('git_nodes.json', 'w') as file:
    json.dump(git_nodes, file, indent=4)
    
stackGraph('git_nodes.json', 1)

"""Generate the entire graph"""

# # features_file_git = '../data_preprocess/static_features_not_none.json'
# # edges_file_git = '../data_preprocess/gid_edges.txt'
# # G_git, adj_matrix_git, static_array_git = json2graph(features_file_git, edges_file_git)
# # data_generation(G_git, adj_matrix_git, static_array_git, 100, percentage=10, diffusion='LT', dataset='../CINA_data/github/github')

# # node_file_stack = '../data_preprocess/sid_all.txt'
# # edge_file_stack = '../data_preprocess/all_sid_link_edges.txt'
# # G_stack, adj_matrix_stack = text2graph(node_file_stack, edge_file_stack)
# with open('../CINA_data/gitHub/G_stack_pruned.pkl', 'rb') as fp:
#     G_stack = pickle.load(fp)
# adj_matrix_stack = nx.to_numpy_array(G_stack, dtype='f')
# # features_file_git = '../data_preprocess/static_features_not_none.json'
# # edges_file_git = '../data_preprocess/gid_edges.txt'
# # G_git, adj_matrix_git, static_array_git = json2graph(features_file_git, edges_file_git)

# proj2recived_file = '../data_preprocess/gid_sid_pruned.txt'
# cross_data_generation(G_proj_org=G_git, adj_proj=adj_matrix_git, static_proj=static_array_git,
#                       G_received_org=G_stack, adj_received=adj_matrix_stack, proj2recived_file=proj2recived_file,
#                       nums=1, percentage=10, diffusion_proj='LT', diffusion_recived='IC',
#                       dataset='github2stack')