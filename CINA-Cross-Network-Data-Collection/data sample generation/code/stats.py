# -*- coding: utf-8 -*-
"""data_pruning.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1k-bBiu-K4io5p6qUFU_PMTeUoTf42aWn
"""



"""# New Section"""

import re
import requests
import json
import numpy as np
import networkx as nx
import pickle
import random
import ndlib.models.ModelConfig as mc
import ndlib.models.epidemics as ep
import torch
import time
from scipy.sparse import coo_matrix
import matplotlib.pyplot as plt
import pandas as pd
from tqdm import tqdm
import pickle

from prunning_methods import *

def same_year(year, hop):
    orig_features_file_git = 'static_features_' + str(year) + '.json'
    target_features_file_git = 'static_features_' + str(year) + '.json'
    edges_file_git = 'gid_edges.txt'
    G_git, adj_matrix_git, static_array_git = json2graph(orig_features_file_git, target_features_file_git, edges_file_git, hop)

    
    data = {'year': str(year), 
            'git_nodes': len(G_git.nodes()), 
            'git_edges': len(G_git.edges())}

    return data


def before_year(year, hop):
    orig_features_file_git = 'static_features_' + str(year) + '.json'
    target_features_file_git = 'static_features_2008_' + str(year) + '.json'
    edges_file_git = 'gid_edges.txt'
    G_git, adj_matrix_git, static_array_git = json2graph(orig_features_file_git, target_features_file_git, edges_file_git, hop)

    
    # data = {'year': '2008-' + str(year), 
    #         'git_nodes': len(G_git.nodes()), 
    #         'git_edges': len(G_git.edges())}

    return G_git

# print(before_year(2015, 3))

years = range(2009,2024)
row_list = []

for year in years:
    print(year)

    # # first generate json file that combine prior year git data
    # combined_data = {}
    # prior_years = range(2008, year)

    # for p_year in prior_years:
    #     file_path = 'static_features_' + str(p_year) + '.json'
    #     with open(file_path) as json_file:
    #         target_static_features = json.load(json_file)
    #         combined_data.update(target_static_features)  # Merge the data into the combined_data dictionary
    # combined_file_path = 'static_features_2008_' + str(year) + '.json'
    # with open(combined_file_path, 'w') as combined_file:
    #     json.dump(combined_data, combined_file, indent=4)

    # github graph
    orig_features_file_git = 'static_features_' + str(year) + '.json'
    target_features_file_git = 'static_features_2008_' + str(year) + '.json'
    edges_file_git = 'gid_edges.txt'

    data = {}
    data['year'] =  str(year)

    for hop in [1,2,3]:
        G_git = before_year(year, hop)
        # G_git, adj_matrix_git, static_array_git = json2graph(orig_features_file_git, target_features_file_git, edges_file_git)

        # file_path = 'G_git_2008_' + str(year) + '.pkl'
        # with open(file_path, 'wb') as fp:
        #     pickle.dump(G_git, fp)


        data['git_nodes_hop_' + str(hop)] = len(G_git.nodes())
        data['git_edges_hop_' + str(hop)] = len(G_git.edges())
        

    # # stackoverflow graph
    
    # # build the github nodes json file 
    # git_nodes = {}
    # for node in G_git.nodes():
    #     git_nodes[node] = 1
    # with open('git_nodes.json', 'w') as file:
    #     json.dump(git_nodes, file, indent=4)
    
    # for hop in range(1,4):
    #     stack_nodes, stack_edges, cross_edge = stackGraph(year, 'git_nodes.json', hop)
    #     data['stack_nodes_hop_' + str(hop)] = stack_nodes
    #     data['stack_edges_hop_' + str(hop)] = stack_edges
    #     data['stack_cross_edges_hop_' + str(hop)] = cross_edge

    row_list.append(data)

df = pd.DataFrame(row_list)
df.to_csv('git_hop_Stats.csv', index=False)  # Set index=False to exclude the index column


# row_list = []

# # github graph
# orig_features_file_git = 'static_features_not_none.json'
# target_features_file_git = 'static_features_not_none.json'
# edges_file_git = 'gid_edges.txt'
# G_git, adj_matrix_git, static_array_git = json2graph(orig_features_file_git, target_features_file_git, edges_file_git)


# data = {'year': 'all', 
#         'git_nodes': len(G_git.nodes()), 
#         'git_edges': len(G_git.edges())}


# # stackoverflow graph

# # build the github nodes json file 
# git_nodes = {}
# for node in G_git.nodes():
#     git_nodes[node] = 1
# with open('git_nodes.json', 'w') as file:
#     json.dump(git_nodes, file, indent=4)

# for hop in range(1,4):
#     stack_nodes, stack_edges, cross_edge = stackGraph('git_nodes.json', hop)
#     data['stack_nodes_hop_' + str(hop)] = stack_nodes
#     data['stack_edges_hop_' + str(hop)] = stack_edges
#     data['stack_cross_edges_hop_' + str(hop)] = cross_edge

# row_list.append(data)

# df = pd.DataFrame(row_list)
# df.to_csv('git_graph_Stats_all.csv', index=False)  # Set index=False to exclude the index column


